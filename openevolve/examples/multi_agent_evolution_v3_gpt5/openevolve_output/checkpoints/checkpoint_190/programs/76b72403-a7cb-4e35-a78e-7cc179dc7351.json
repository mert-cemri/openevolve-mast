{"id": "76b72403-a7cb-4e35-a78e-7cc179dc7351", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Iterable\n\n# Design targets:\n# - Clear single-responsibility roles\n# - Robust LLM wrapper with retries/backoff and deterministic fallback\n# - Explicit routing via send_to\n# - Idempotent delivery using per-role delivered sets\n# - Strong verification and stable termination (consecutive identical digests)\n# - Contained error handling and retry for transient failures\n\nLLM_RETRIES = 3\nLLM_BACKOFF = 0.4\nROLE_ATTEMPTS = 2\nROLE_TIMEOUT = 20  # seconds per role invocation\nSTABLE_VERIFICATION_REQUIRED = 2\nNO_PROGRESS_LIMIT = 2  # rounds before nudging/stopping\n\ndef _normalize_send_to(msg: Message) -> set:\n    s = getattr(msg, \"send_to\", None)\n    if s is None:\n        try:\n            s = set(getattr(msg, \"sent_to\", set()) or set())\n        except Exception:\n            s = set()\n    return set(s or set())\n\nclass Action(ABC):\n    \"\"\"Base action with LLM-safe ask helper and deterministic fallback semantics.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_RETRIES\n    backoff: float = LLM_BACKOFF\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def ask_llm(self, messages: List[Dict[str, str]]) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface missing; using deterministic fallback\")\n            return \"LLM_UNAVAILABLE\"\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty LLM response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Received response len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}:{str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < self.max_retries:\n                    await asyncio.sleep(self.backoff * (2 ** (attempt - 1)) + random.uniform(0, 0.1))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea -> deterministic fallback code\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Return only valid Python code implementing the task below. \"\n            \"Include docstrings and input validation where appropriate.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.ask_llm(messages)\n        # deterministic fallback if LLM failed\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> fallback code\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback due to LLM failure.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        # validate syntax\n        try:\n            ast.parse(resp)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, f\"Parse error: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback because generated code did not parse.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code len={len(resp)}\")\n        return resp\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"No code provided -> fallback tests\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        truncated = (code or \"\")[:3500]\n        prompt = (\n            \"You are a QA engineer. Produce pytest-style tests for the provided module. Return only test code.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.ask_llm(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> fallback tests\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        # heuristic validation\n        try:\n            parsed = ast.parse(resp)\n            has_test = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed)) or (\"assert\" in resp)\n            if not (has_test or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, \"Generated tests invalid -> fallback\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated tests len={len(resp)}\")\n        return resp\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # static pre-checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{e}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{e}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: manual inspection recommended\\nVERDICT: REQUEST_CHANGES\" if issues else \"HUMAN_REVIEW: ok\\nVERDICT: APPROVE\"\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review and end with a single-line VERDICT: APPROVE or VERDICT: REQUEST_CHANGES.\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\nCode (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.ask_llm(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> request changes\")\n            return \"VERDICT: REQUEST_CHANGES\\nAutomated reviewer failed\"\n        if \"VERDICT:\" not in resp:\n            verdict = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            resp = resp.strip() + f\"\\n\\nVERDICT: {verdict}\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review len={len(resp)}\")\n        return resp\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        refs_ok = False\n        code_names = set()\n\n        # code syntax\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            code_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            details.append(f\"code_defs:{len(code_names)}\")\n        except Exception as e:\n            details.append(f\"code_parse_error:{e}\")\n\n        # tests syntax + asserts\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            details.append(\"tests_presence:ok\" if tests_ok else \"tests_presence:none\")\n        except Exception as e:\n            details.append(f\"tests_parse_error:{e}\")\n\n        # cross-reference\n        if code_names and tests_ok:\n            txt = tests or \"\"\n            for nm in code_names:\n                if nm and nm in txt:\n                    refs_ok = True\n                    break\n            details.append(\"tests_reference_ok\" if refs_ok else \"tests_reference_none\")\n        else:\n            details.append(\"tests_reference_skipped\")\n\n        verified = code_ok and tests_ok and refs_ok\n        # digest for stability\n        try:\n            digest = hashlib.sha256(((code or \"\") + \"\\n--\\n\" + (tests or \"\")).encode(\"utf-8\")).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with single primary action, watch_list, and processed-tracking.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = None\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: Iterable[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", str(a)) for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        targets = _normalize_send_to(msg)\n        if targets:\n            if self.profile in targets or self.name in targets:\n                return True\n            return False\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        # default: user input triggers coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg={getattr(message,'id',None)}\")\n            # mark as processed to avoid re-evaluating\n            if getattr(message, \"id\", None):\n                self._processed.add(message.id)\n            return None\n\n        # prepare input for action based on type\n        try:\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                out = await self.action.run(idea or \"\")\n                send_to = {\"SimpleTester\"}\n            elif isinstance(self.action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and message.cause_by == SimpleWriteCode.name else \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest.content if latest else \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleWriteReview):\n                latest_code = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                latest_tests = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(latest_code.content if latest_code else \"\", latest_tests.content if latest_tests else \"\")\n                lowered = (out or \"\").lower()\n                if \"request\" in lowered or \"fail\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleVerify):\n                latest_code = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                latest_tests = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(latest_code.content if latest_code else \"\", latest_tests.content if latest_tests else \"\")\n                send_to = set()  # broadcast handled by orchestrator\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err[:200])\n            out = err\n            send_to = {\"SimpleCoder\"}\n\n        # mark processed to ensure idempotency\n        if message and getattr(message, \"id\", None):\n            self._processed.add(message.id)\n\n        resp = Message(content=out or \"\", role=self.profile, cause_by=self.action.name if self.action else \"None\", sent_from=self.name, send_to=set(send_to))\n        # mark produced id as processed locally\n        try:\n            self._processed.add(resp.id)\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={getattr(resp,'id',None)} send_to={list(getattr(resp,'send_to',set()))}\")\n        return resp\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self.watch([])\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Message bus with per-role delivered tracking and artifact indexing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._delivered: Dict[str, Set[str]] = {}\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        try:\n            message.send_to = _normalize_send_to(message)\n        except Exception:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        # ensure id exists\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_delivered(self, role: Role, message: Message):\n        if not getattr(message, \"id\", None):\n            return\n        self._delivered.setdefault(role.name, set()).add(message.id)\n        if self.tracer:\n            self.tracer.log(\"ENV_MARK_DELIVERED\", \"Environment\", f\"{role.name} delivered {message.id}\")\n\n    def get_pending_for(self, role: Role) -> List[Message]:\n        \"\"\"Return messages not yet delivered to role that target or watch the role.\"\"\"\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            # never deliver own messages\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            targeted = bool(msg.send_to and (role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to))\n            watched = getattr(msg, \"cause_by\", None) in getattr(role, \"watch_list\", set())\n            if targeted or watched:\n                out.append(msg)\n                seen.add(mid)\n        return out\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        msgs = self._by_cause.get(cause, [])\n        return msgs[-1] if msgs else None\n\nclass Team:\n    \"\"\"Orchestrator with deterministic sequencing, verifier stability, and controlled retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = STABLE_VERIFICATION_REQUIRED\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        # placeholder for compatibility\n        pass\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        attempts = 0\n        while attempts < ROLE_ATTEMPTS:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=ROLE_TIMEOUT)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempts} for msg {getattr(msg,'id',None)}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempts}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.05 * attempts)\n        # return an explicit error message artifact\n        err = Message(content=f\"ERROR: role {role.name} failed processing message {getattr(msg,'id',None)} after {attempts} attempts\",\n                      role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need stable_passes={self._required_streak}\")\n        # initial message targeted to coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial = Message(content=f\"Let's work on this project: {self.idea}\",\n                          instruct_content=self.idea,\n                          role=\"Human\",\n                          sent_from=\"User\",\n                          cause_by=\"UserInput\",\n                          send_to=coder_profiles)\n        self.env.publish_message(initial)\n\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            produced = 0\n            for RoleClass in order:\n                roles = [r for r in self.env.roles if isinstance(r, RoleClass)]\n                for role in roles:\n                    pending = self.env.get_pending_for(role)\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and rnd == 1:\n                        if initial.id not in self.env._delivered.get(role.name, set()):\n                            pending = [initial] + pending\n                    for msg in pending:\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            self.env.mark_delivered(role, msg)\n                            continue\n                        resp = await self._invoke_role(role, msg)\n                        self.env.mark_delivered(role, msg)\n                        if resp:\n                            # ensure routing hints exist\n                            if getattr(resp, \"send_to\", None) is None:\n                                try:\n                                    resp.send_to = set(getattr(resp, \"sent_to\", set()) or set())\n                                except Exception:\n                                    resp.send_to = set()\n                            self.env.publish_message(resp)\n                            produced += 1\n                            # verifier handling\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    # extract digest\n                                    digest = None\n                                    for part in resp.content.split(\"|\"):\n                                        p = part.strip()\n                                        if p.startswith(\"digest=\"):\n                                            digest = p.split(\"=\", 1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    else:\n                                        self._last_digest = None\n                                        self._streak = 1\n                                else:\n                                    if self._streak > 0:\n                                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                                    self._streak = 0\n                                    self._last_digest = None\n            # progress detection\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed produced={produced} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require consecutive identical verification digests\n            if self._streak >= self._required_streak:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping early\")\n                break\n\n            # handle no progress\n            if no_progress_rounds >= NO_PROGRESS_LIMIT:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds; terminating early\")\n                break\n            elif produced == 0:\n                # nudge coder(s)\n                self.tracer.log(\"TEAM_NUDGE\", \"Team\", \"No new artifacts this round; nudging coder(s)\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please refine implementation for: {self.idea}\",\n                                        instruct_content=self.idea,\n                                        role=\"System\",\n                                        sent_from=\"Orchestrator\",\n                                        cause_by=\"Nudge\",\n                                        send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # small pause to allow immediate processing\n                await asyncio.sleep(0.01)\n            else:\n                # cooperative pause\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' completed after {rnd} rounds with {len(self.env.history)} messages. verifier_streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "fd897422-97c2-472f-a318-19001aff38ba", "generation": 4, "timestamp": 1754659531.0592499, "iteration_found": 158, "metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.16216216216216214, "avg_failures_per_task": 5.166666666666667, "total_failures": 31.0, "successful_runs": 6.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "Missing run_multi_agent_task function"}, "island": 3}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.0000\n- combined_score: 0.0000\n- avg_failures_per_task: 14.0000\n- error: Missing run_multi_agent_task function\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: avg_failures_per_task. Consider continuing with similar changes.\n- Metrics showing regression: runs_successfully, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 4\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.1667, avg_failures_per_task: 5.0000, total_failures: 30.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.1667, avg_failures_per_task: 5.0000, total_failures: 30.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2400, avg_failures_per_task: 3.1667, total_failures: 19.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 4.9844)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2400), Performs well on avg_failures_per_task (3.1667), Performs well on total_failures (19.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 2 (Score: 4.9844)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry and robust error handling\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 0.5  # base seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Call LLM with retries and backoff. Treat known error patterns as failures to retry.\n        Returns a string with result or an explicit error message.\n        \"\"\"\n        import asyncio\n        attempt = 0\n        last_error = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if not self.llm:\n                    # Local fallback\n                    response = \"LLM_NOT_AVAILABLE: fallback response\"\n                else:\n                    response = await self.llm.ask(messages)\n                # Treat structured error responses as failures\n                if isinstance(response, str) and response.startswith(\"Error\"):\n                    last_error = response\n                    raise RuntimeError(response)\n                # Success\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_OK\", self.name, f\"LLM responded (len={len(response)}) on attempt {attempt}\")\n                return response\n            except Exception as e:\n                last_error = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_FAIL\", self.name,\n                                            f\"Attempt {attempt} failed: {last_error}\")\n                if attempt < self.max_retries:\n                    await asyncio.sleep(self.retry_backoff * attempt)\n                else:\n                    # final give up\n                    break\n        # Final failure\n        err_msg = f\"LLM_FAILURE after {self.max_retries} attempts: {last_error}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_GIVEUP\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea with robust prompting and error handling\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:120]}\")\n\n        prompt = f\"\"\"You are a professional programmer. Write production-ready Python code for the following task.\nTask:\n{idea}\n\nRequirements:\n- Write clean, functional Python code.\n- Include error handling and docstrings.\n- Keep functions small and testable.\n- Include a short usage example in comments.\nReturn only the Python code. Do not include explanatory text.\"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        code = await self._llm_call(messages)\n\n        # Basic post-processing: ensure we return a non-empty string\n        if not code or code.startswith(\"LLM_FAILURE\") or code.startswith(\"Error\"):\n            fallback = f\"# ERROR_GENERATING_CODE: {code[:200]}\\n# Please check LLM logs.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Falling back to placeholder code\")\n            code = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} chars\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code, with heuristics and retries\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n\n        truncated_code = (code or \"\")[:4000]\n        prompt = f\"\"\"You are a QA engineer. Write pytest-style tests for the following Python code.\n\nCode:\n{truncated_code}\n\nRequirements:\n- Provide pytest test functions covering typical cases and edge cases.\n- Use clear assertions and include docstrings for tests.\n- If code cannot be tested because it's placeholder or missing, indicate that clearly.\n\nReturn only the pytest code.\"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        tests = await self._llm_call(messages)\n\n        # Heuristic validation: ensure tests contain 'assert' or 'pytest'\n        if not tests or (isinstance(tests, str) and \"assert\" not in tests and \"pytest\" not in tests and \"unittest\" not in tests):\n            note = f\"# GENERATED_TESTS_INCOMPLETE: LLM output may be insufficient. Raw: {tests[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated tests may be insufficient\")\n            tests = (tests or \"\") + \"\\n\\n\" + note\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} chars of tests\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests, produce actionable checklist and summary\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: manual check recommended.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Provide a concise actionable review.\n\nCode (truncated):\n{(code or '')[:2000]}\n\nTests (truncated):\n{(tests or '')[:2000]}\n\nProvide:\n- Short summary of major issues (if any).\n- A checklist of fixes or improvements.\n- A single-line readiness verdict: READY or NOT_READY.\n\nReturn as plain text with the verdict on the last line prefixed by VERDICT:\"\"\"\n\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n\n            review = await self._llm_call(messages)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n    max_attempts: int = 3\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"\n        Perform static verification and heuristics for readiness.\n        Returns a structured verification result string.\n        \"\"\"\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        code_ok = False\n        tests_ok = False\n        issues = []\n\n        # Syntax check for code\n        if code and code.strip():\n            try:\n                ast.parse(code)\n                code_ok = True\n            except Exception as e:\n                issues.append(f\"code_syntax_error: {str(e)}\")\n                code_ok = False\n        else:\n            issues.append(\"code_missing_or_empty\")\n\n        # Syntax and heuristic checks for tests\n        if tests and tests.strip():\n            try:\n                ast.parse(tests)\n                # heuristics: look for 'assert' or 'pytest' or 'unittest'\n                lower = tests.lower()\n                if \"assert\" in tests or \"pytest\" in lower or \"unittest\" in lower:\n                    tests_ok = True\n                else:\n                    issues.append(\"tests_lack_asserts_or_framework_usage\")\n                    tests_ok = False\n            except Exception as e:\n                issues.append(f\"tests_syntax_error: {str(e)}\")\n                tests_ok = False\n        else:\n            issues.append(\"tests_missing_or_empty\")\n            tests_ok = False\n\n        verified = code_ok and tests_ok\n        status = {\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok,\n            \"issues\": issues,\n            \"verified\": verified\n        }\n\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | details: {status}\"\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibilities, watch/trigger logic\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    def should_respond_to(self, message: Message) -> bool:\n        \"\"\"\n        Determine if the role should respond to the message.\n        Default: respond if message.cause_by matches any watched action name OR message is addressed to role.\n        \"\"\"\n        try:\n            if not message:\n                return False\n            # addressed to this role explicitly\n            if getattr(message, \"sent_to\", None):\n                if isinstance(message.sent_to, (list, set)) and (self.name in message.sent_to or self.profile in message.sent_to):\n                    return True\n                if isinstance(message.sent_to, str) and (message.sent_to == self.name or message.sent_to == self.profile):\n                    return True\n            # matches watched action\n            for watched in self.watch_list:\n                if message.cause_by == watched.name:\n                    return True\n            return False\n        except Exception:\n            return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform appropriate action(s) based on message and role responsibilities.\"\"\"\n        if not self.actions:\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Act called with message cause_by={getattr(message,'cause_by',None)}\")\n\n        # Try each action (ordered) and produce a single response message per call\n        final_result = None\n        chosen_action = None\n\n        try:\n            for action in self.actions:\n                # Determine if this action should run given the message\n                run_action = False\n                # If no message, allow starter roles (like coder on first round) to run\n                if message is None:\n                    run_action = True\n                else:\n                    run_action = self.should_respond_to(message)\n\n                if not run_action:\n                    # skip this action because message not relevant\n                    continue\n\n                chosen_action = action\n\n                # Determine inputs based on action type\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) if message else None\n                    # If no instruct content, try to find latest user instruction in env\n                    if not instruct and getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == \"UserInput\" or m.role.lower() == \"human\":\n                                instruct = getattr(m, \"instruct_content\", None) or m.content\n                                break\n                    result = await action.run(instruct or \"\")\n                elif isinstance(action, SimpleWriteTest):\n                    # Find the most recent code message in environment\n                    code_msg = None\n                    if message and message.cause_by == SimpleWriteCode.name and getattr(message, \"content\", None):\n                        code_msg = message\n                    elif getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name:\n                                code_msg = m\n                                break\n                    code_text = code_msg.content if code_msg else \"\"\n                    result = await action.run(code_text)\n                elif isinstance(action, SimpleWriteReview):\n                    # Need both code and tests\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if not code_text and m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                            if not tests_text and m.cause_by == SimpleWriteTest.name:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                elif isinstance(action, SimpleVerify):\n                    # Collect latest code/tests and run verification\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if not code_text and m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                            if not tests_text and m.cause_by == SimpleWriteTest.name:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    # Try verification possibly multiple times until stable or attempts exhausted\n                    attempt = 0\n                    verification_result = None\n                    while attempt < action.max_attempts:\n                        attempt += 1\n                        verification_result = await action.run(code_text, tests_text)\n                        if isinstance(verification_result, str) and \"VERIFICATION_RESULT: PASS\" in verification_result:\n                            result = verification_result\n                            break\n                        # If fail, try once more if there is a reviewer or tester messages to re-trigger improvements\n                        # but here we just record the latest failure\n                        result = verification_result\n                else:\n                    # Generic action\n                    result = await action.run(message) if message else await action.run()\n\n                final_result = result\n                # After a successful action run, break (roles execute one logical step per call)\n                break\n\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION in {self.name}: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err)\n            final_result = err\n\n        # Package response as Message\n        response = Message(\n            content=final_result or \"\",\n            role=self.profile,\n            cause_by=chosen_action.name if chosen_action else \"NoAction\",\n            sent_from=self.name\n        )\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed: {response.cause_by}\")\n        return response\n\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with improved message routing\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        # Provide environment reference to role for history lookups\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        # Ensure message has id (pydantic version already has)\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                          f\"Message from {message.sent_from}: cause_by={message.cause_by} content_preview={(message.content or '')[:120]}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to using explicit watch/trigger rules.\"\"\"\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            # If message explicitly addressed to role/profile\n            if getattr(msg, \"sent_to\", None):\n                if isinstance(msg.sent_to, (list, set)) and (role.name in msg.sent_to or role.profile in msg.sent_to):\n                    relevant_messages.append(msg)\n                    continue\n                if isinstance(msg.sent_to, str) and (msg.sent_to == role.name or msg.sent_to == role.profile):\n                    relevant_messages.append(msg)\n                    continue\n            # If role watches the cause_by action\n            for watched in role.watch_list:\n                if msg.cause_by == watched.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\n\nclass Team:\n    \"\"\"Team of agents working together with improved orchestration, termination, and validation\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with robust sequencing and termination rules\"\"\"\n        import asyncio\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        round_num = 0\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n\n            # Step 1: Coder attempts to produce/iterate code (only on first round or if re-triggered)\n            for role in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                try:\n                    # Coder acts on initial message or explicit trigger addressed to coder\n                    msg_to_coder = initial_msg if round_num == 0 else None\n                    response = await role.act(msg_to_coder)\n                    if response:\n                        self.env.publish_message(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Coder exception: {e}\")\n\n            # Step 2: Tester responds when code available\n            for role in [r for r in self.env.roles if isinstance(r, SimpleTester)]:\n                try:\n                    relevant = self.env.get_messages_for_role(role)\n                    if relevant:\n                        response = await role.act(relevant[-1])\n                        if response:\n                            self.env.publish_message(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Tester exception: {e}\")\n\n            # Step 3: Reviewer provides review when tests are produced\n            for role in [r for r in self.env.roles if isinstance(r, SimpleReviewer)]:\n                try:\n                    relevant = self.env.get_messages_for_role(role)\n                    if relevant:\n                        response = await role.act(relevant[-1])\n                        if response:\n                            self.env.publish_message(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Reviewer exception: {e}\")\n\n            # Step 4: Verifier attempts to verify; if PASS then stop\n            verifier_messages = []\n            for role in [r for r in self.env.roles if isinstance(r, SimpleVerifier)]:\n                try:\n                    relevant = self.env.get_messages_for_role(role)\n                    if relevant:\n                        response = await role.act(relevant[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            verifier_messages.append(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Verifier exception: {e}\")\n\n            # Check for verification pass by scanning verifier messages\n            for msg in reversed(self.env.history):\n                if getattr(msg, \"cause_by\", \"\") == SimpleVerify.name and isinstance(msg.content, str):\n                    if \"VERIFICATION_RESULT: PASS\" in msg.content:\n                        verified = True\n                        break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed. Verified={verified}\")\n\n            # Termination: stop early only when verification PASS observed AND at least one full cycle has occurred\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n\n            # Small wait to simulate asynchronous progression and give LLM backoff time if needed\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2400), Performs well on avg_failures_per_task (3.1667), Performs well on total_failures (19.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 3 (Score: 7.1111)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n\n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n\n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Iterable\n\n# Tunable parameters to improve robustness\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nROLE_ACTION_TIMEOUT = 30  # seconds\nROLE_MAX_ATTEMPTS = 2\nVERIFY_STABLE_REQUIRED = 2\nNO_PROGRESS_GRACE = 2  # rounds without progress before nudging/stop\n\n# ---------------------------\n# Actions\n# ---------------------------\n\nclass Action(ABC):\n    \"\"\"Base Action with LLM-safe call and tracing.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, backoff, jitter, and deterministic fallback on failure.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface missing; using deterministic fallback\")\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n\n        for attempt in range(1, LLM_MAX_RETRIES + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{LLM_MAX_RETRIES}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                # success\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} success len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}:{str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < LLM_MAX_RETRIES:\n                    backoff = LLM_BACKOFF_BASE * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n        # exhausted\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, f\"Failed after {LLM_MAX_RETRIES} attempts: {last_err}\")\n        return f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No idea, returning deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Produce a concise, testable Python module implementing the task.\\n\"\n            \"Constraints: return only Python source, include docstrings and input validation where appropriate.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        # Deterministic fallback if LLM failed\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback implementation due to LLM error.\\\"\\\"\\\"\\n\"\n                \"    if value is None:\\n\"\n                \"        return None\\n\"\n                \"    return value\\n\"\n            )\n        # Validate python\n        try:\n            ast.parse(resp)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, f\"AST parse failed: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback because generated code did not parse.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code -> placeholder test\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        # extract top-level symbols to guide test generation\n        symbols = []\n        try:\n            parsed = ast.parse(code)\n            for node in parsed.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)) and not node.name.startswith(\"_\"):\n                    symbols.append(node.name)\n        except Exception:\n            symbols = []\n        prompt = (\n            \"You are an expert QA engineer. Given the implementation, produce pytest tests covering normal and edge cases.\\n\"\n            f\"Public symbols: {', '.join(symbols[:6]) or '(none)'}\\n\\nCode (truncated):\\n{(code or '')[:3000]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic test fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        # Validate tests include assert or test functions\n        try:\n            parsed_tests = ast.parse(resp)\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = \"assert\" in resp\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, \"Generated tests invalid -> fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # quick static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{str(e)[:160]}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: manual inspection recommended; \" + (\"; \".join(issues) if issues else \"no static issues\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review and end with a single-line VERDICT: APPROVE or VERDICT: REQUEST_CHANGES.\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\nCode (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> request changes\")\n            return \"VERDICT: REQUEST_CHANGES\\nAutomated reviewer: failed to produce review.\"\n        if \"VERDICT:\" not in resp:\n            verdict = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            resp = resp.strip() + f\"\\n\\nVERDICT: {verdict}\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(resp)}\")\n        return resp\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Running deterministic verification\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n        code_defs = set()\n\n        # code parse\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            code_defs = {n.name for n in parsed_code.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            details.append(f\"code_defs:{len(code_defs)}\")\n        except Exception as e:\n            details.append(f\"code_parse_error:{str(e)[:160]}\")\n\n        # tests parse & heuristics\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            details.append(\"tests_present\" if tests_ok else \"tests_missing_asserts_or_fns\")\n        except Exception as e:\n            details.append(f\"tests_parse_error:{str(e)[:160]}\")\n\n        # reference check\n        if code_defs and tests_ok:\n            txt = tests or \"\"\n            for nm in code_defs:\n                if nm and nm in txt:\n                    references_ok = True\n                    break\n            details.append(\"tests_reference_ok\" if references_ok else \"tests_do_not_reference_code\")\n        else:\n            details.append(\"tests_reference_check_skipped\")\n\n        verified = code_ok and tests_ok and references_ok\n        # produce digest for stability\n        try:\n            digest_src = (code or \"\").encode(\"utf-8\") + b\"||\" + (tests or \"\").encode(\"utf-8\")\n            digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# ---------------------------\n# Roles\n# ---------------------------\n\nclass Role(ABC):\n    \"\"\"Clear role definition with watch/trigger and idempotency.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: Iterable[Type[Action]]):\n        self.watch_list = [getattr(a, \"name\", str(a)) for a in actions]\n\n    def should_handle(self, msg: Message) -> bool:\n        \"\"\"Decide whether to handle a message.\"\"\"\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # do not handle own messages\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # explicit routing (send_to has priority)\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None)\n        if targets:\n            try:\n                if isinstance(targets, (set, list)):\n                    if self.name in targets or self.profile in targets or \"*\" in targets:\n                        return True\n                elif isinstance(targets, str):\n                    if targets in (self.name, self.profile, \"*\"):\n                        return True\n            except Exception:\n                pass\n            # if explicitly addressed elsewhere, and not this role, don't handle\n            return False\n        # watchlist trigger\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        # default: user input to coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action for this role; return produced Message or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg={getattr(message,'id',None)}\")\n            return None\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Running {action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                out = await action.run(idea)\n                send_to = {\"SimpleTester\"}\n            elif isinstance(action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and getattr(message, \"content\", None) else \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest.content if latest else \"\"\n                out = await action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(action, SimpleWriteReview):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                lowered = (out or \"\").lower()\n                if \"request\" in lowered or \"reject\" in lowered or \"request_changes\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(action, SimpleVerify):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = set()  # broadcast semantics handled by orchestrator\n            else:\n                out = await action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n            # mark processed to avoid duplicates\n            if message and getattr(message, \"id\", None):\n                self._processed_ids.add(message.id)\n            resp = Message(content=out, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n            if tracer:\n                tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg {getattr(resp,'id',None)} send_to={send_to}\")\n            return resp\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            resp = Message(content=err, role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to={\"Team\"})\n            return resp\n\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])\n\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\n# ---------------------------\n# Environment & Team\n# ---------------------------\n\nclass Environment:\n    \"\"\"Message bus with delivery tracking and artifact lookup.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._delivered: Dict[str, Set[str]] = {}\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} -> {list(getattr(message,'send_to',set()))} preview={snippet}\")\n\n    def mark_delivered(self, role: Role, message: Message):\n        if not getattr(message, \"id\", None):\n            return\n        self._delivered.setdefault(role.name, set()).add(message.id)\n        if self.tracer:\n            self.tracer.log(\"ENV_MARK_DELIVERED\", \"Environment\", f\"{role.name} delivered {message.id}\")\n\n    def get_pending_for_role(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            # explicit targeting\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            targeted = False\n            try:\n                if isinstance(targets, (set, list)):\n                    if role.name in targets or role.profile in targets or \"*\" in targets:\n                        targeted = True\n                elif isinstance(targets, str):\n                    if targets in (role.name, role.profile, \"*\"):\n                        targeted = True\n            except Exception:\n                targeted = False\n            if targeted:\n                out.append(msg)\n                seen.add(mid)\n                continue\n            # watch-list trigger\n            if getattr(msg, \"cause_by\", None) in getattr(role, \"watch_list\", []):\n                out.append(msg)\n                seen.add(mid)\n                continue\n        return out\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        msgs = self._by_cause.get(cause, [])\n        return msgs[-1] if msgs else None\n\n\nclass Team:\n    \"\"\"Orchestrator that enforces deterministic ordering, verification stability, and robust retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_stable_passes: int = VERIFY_STABLE_REQUIRED\n        self._max_role_attempts_per_message: int = ROLE_MAX_ATTEMPTS\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        attempts = 0\n        while attempts < self._max_role_attempts_per_message:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=ROLE_ACTION_TIMEOUT)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempts} for msg {getattr(msg,'id',None)}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempts} for msg {getattr(msg,'id',None)}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.05 * attempts)\n        # publish an error message to keep traceability\n        err = Message(content=f\"ERROR: role {role.name} failed processing message {getattr(msg,'id',None)} after {attempts} attempts\",\n                      role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._required_stable_passes} stable verification passes\")\n        # initial user message targeted to coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial_msg = Message(content=f\"Let's work on this project: {self.idea}\",\n                              instruct_content=self.idea,\n                              role=\"Human\",\n                              sent_from=\"User\",\n                              cause_by=\"UserInput\",\n                              send_to=coder_profiles)\n        self.env.publish_message(initial_msg)\n\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            new_messages = 0\n            for role_type in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles:\n                    pending = self.env.get_pending_for_role(role)\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and rnd == 1:\n                        if initial_msg not in pending and initial_msg.id not in self.env._delivered.get(role.name, set()):\n                            pending = [initial_msg] + pending\n                    for msg in pending:\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            self.env.mark_delivered(role, msg)\n                            continue\n                        resp = await self._invoke_role(role, msg)\n                        # mark delivered irrespective of resp to avoid livelock\n                        self.env.mark_delivered(role, msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            new_messages += 1\n                            # verifier handling: update streak based on digest\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                content = resp.content\n                                if \"VERIFICATION_RESULT: PASS\" in content:\n                                    digest = None\n                                    for token in content.split(\"|\"):\n                                        token = token.strip()\n                                        if token.startswith(\"digest=\"):\n                                            digest = token.split(\"=\", 1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    else:\n                                        # no digest: treat as single pass but not stable\n                                        self._last_digest = None\n                                        self._streak = 1\n                                else:\n                                    if self._streak > 0:\n                                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                                    self._streak = 0\n                                    self._last_digest = None\n            # progress check\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed; new_messages={new_messages} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require stable consecutive verification passes and at least one round\n            if self._streak >= self._required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping early\")\n                break\n\n            # no progress handling: nudge coder(s) if grace exceeded; stop if prolonged stagnation\n            if new_messages == 0:\n                if no_progress_rounds >= NO_PROGRESS_GRACE:\n                    self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds; terminating early\")\n                    break\n                # gentle nudge\n                self.tracer.log(\"TEAM_NUDGE\", \"Team\", \"Nudging coder(s) due to lack of progress\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please refine implementation for: {self.idea}\",\n                                        instruct_content=self.idea,\n                                        role=\"System\",\n                                        sent_from=\"Orchestrator\",\n                                        cause_by=\"Nudge\",\n                                        send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # allow immediate small processing window\n                await asyncio.sleep(0.01)\n            else:\n                # allow cooperative pause\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rnd} rounds; messages={len(self.env.history)} verified_streak={self._streak}\")\n        summary = f\"Project '{self.idea}' completed after {rnd} rounds with {len(self.env.history)} messages. verifier_streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1667), Performs well on avg_failures_per_task (5.0000), Performs well on total_failures (30.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 4 (Score: 7.1111)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1667), Performs well on avg_failures_per_task (5.0000), Performs well on total_failures (30.0000), Performs well on successful_runs (6.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 7.8861)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nimport time\nimport ast\nimport hashlib\nfrom typing import Tuple\n\n# Goals:\n# - Clear role responsibilities and single action per role\n# - Robust LLM wrapper with retries, jitter, deterministic fallback\n# - Explicit routing via send_to, watch_list triggers\n# - Deterministic orchestrator ordering\n# - Stable termination: require consecutive verifier PASSes\n# - Strong deterministic verification and validation\n\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nROLE_ATTEMPTS = 2\nVERIFY_STABLE_REQUIRED = 2\nNO_PROGRESS_LIMIT = 2\n\nclass Action(ABC):\n    \"\"\"Base action with LLM safety wrapper and tracer usage.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _llm_safe(self, messages: List[Dict[str, str]]) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface unavailable - deterministic fallback\")\n            return \"LLM_ERROR:LLM_UNAVAILABLE\"\n        for attempt in range(1, LLM_MAX_RETRIES + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{LLM_MAX_RETRIES}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty LLM response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} succeeded len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < LLM_MAX_RETRIES:\n                    backoff = LLM_BACKOFF_BASE * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, f\"Failed after retries: {last_err}\")\n        return f\"LLM_ERROR:{last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea - returning deterministic placeholder\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback placeholder.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module implementing the described task.\\n\"\n            \"- Return only Python source (no markdown)\\n\"\n            \"- Include docstrings and basic input validation where appropriate\\n\\n\"\n            f\"Task: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self._llm_safe(messages)\n        if isinstance(code, str) and code.startswith(\"LLM_ERROR\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed - deterministic fallback code\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback: returns input or raises on None to encourage explicit handling.\\\"\\\"\\\"\\n\"\n                \"    if value is None:\\n\"\n                \"        raise ValueError('value required')\\n\"\n                \"    return value\\n\"\n            )\n        # Validate parseable\n        try:\n            ast.parse(code)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Parse failed: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback: parse error in generated code.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code len={len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"No code provided - returning placeholder test\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        # Heuristic public names\n        symbols = []\n        try:\n            tree = ast.parse(code)\n            for n in tree.body:\n                if isinstance(n, (ast.FunctionDef, ast.ClassDef)) and not n.name.startswith(\"_\"):\n                    symbols.append(n.name)\n        except Exception:\n            symbols = []\n        prompt = (\n            \"You are an expert QA engineer. Given this module, write pytest tests covering nominal and edge cases.\\n\\n\"\n            f\"Public symbols: {', '.join(symbols[:6]) or '(none)'}\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:3000]}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self._llm_safe(messages)\n        if isinstance(tests, str) and tests.startswith(\"LLM_ERROR\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed - deterministic tests\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        # Validate tests contain assert or test_ functions\n        try:\n            parsed = ast.parse(tests)\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body)\n            has_assert = \"assert\" in tests\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, \"Generated tests invalid - returning fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated tests len={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static pre-checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{str(e)[:160]}\")\n        if self.is_human:\n            verdict = \"VERDICT: REQUEST_CHANGES\" if issues else \"VERDICT: PASS\"\n            return (\"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\") + f\"\\n{verdict}\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review and include a single-line VERDICT: PASS or VERDICT: FAIL.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        review = await self._llm_safe(messages)\n        if isinstance(review, str) and review.startswith(\"LLM_ERROR\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed - defaulting to request changes\")\n            return \"REQUEST_CHANGE: Automated review unavailable; please perform manual review.\\nVERDICT: FAIL\"\n        # Ensure VERDICT present\n        if \"VERDICT:\" not in review:\n            review = review.strip() + \"\\n\\nVERDICT: FAIL\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Deterministic verification begins\")\n        diagnostics: List[str] = []\n        code_ok = False\n        tests_ok = False\n        referenced = False\n\n        # Code parse and defs\n        code_defs = set()\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_defs = {n.name for n in ast.walk(parsed_code) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            code_ok = len(code_defs) > 0\n            diagnostics.append(f\"code_defs:{len(code_defs)}\")\n        except Exception as e:\n            diagnostics.append(f\"code_parse_error:{str(e)[:160]}\")\n\n        # Tests parse and asserts\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            diagnostics.append(\"tests_asserts:ok\" if has_assert else \"tests_asserts:none\")\n            diagnostics.append(\"tests_have_test_fn:yes\" if has_test_fn else \"tests_have_test_fn:no\")\n        except Exception as e:\n            diagnostics.append(f\"tests_parse_error:{str(e)[:160]}\")\n\n        # Cross-reference\n        try:\n            if code_defs and tests_ok:\n                test_text = tests or \"\"\n                for nm in code_defs:\n                    if nm and nm in test_text:\n                        referenced = True\n                        break\n                diagnostics.append(f\"tests_reference:{'ok' if referenced else 'none'}\")\n            else:\n                diagnostics.append(\"tests_reference:skipped\")\n        except Exception as e:\n            diagnostics.append(f\"reference_check_error:{str(e)[:160]}\")\n\n        verified = bool(code_ok and tests_ok and referenced)\n        status = \"PASS\" if verified else \"FAIL\"\n        # stable digest\n        try:\n            digest = hashlib.sha256(((code or \"\") + \"\\n--\\n\" + (tests or \"\")).encode(\"utf-8\")).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | {'; '.join(diagnostics)}\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"\n    Base role:\n    - Single primary action\n    - watch_list triggers by action.name\n    - maintains processed ids to ensure idempotence\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional['Environment'] = kwargs.get('env', None)\n        self._processed: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: List[Type[Action]]):\n        self.watch_list = [a.name for a in actions]\n\n    def should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed:\n            return False\n        # do not handle our own messages\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # explicit routing priority\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None)\n        if targets:\n            if isinstance(targets, (set, list)):\n                if self.name in targets or self.profile in targets or \"*\" in targets:\n                    return True\n            elif isinstance(targets, str):\n                if targets in (self.name, self.profile, \"*\"):\n                    return True\n            return False\n        # watch-list by cause_by\n        if getattr(msg, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # default: user input -> coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.actions:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No actions configured\")\n            return None\n        action = self.actions[0]\n        if message is not None and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={getattr(message,'id',None)}\")\n            return None\n\n        attempts = 0\n        last_err = None\n        while attempts < ROLE_ATTEMPTS:\n            attempts += 1\n            try:\n                if isinstance(action, SimpleWriteCode):\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    out = await action.run(idea)\n                    send_to = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                    if not code_text and self.env:\n                        latest = self.env.get_latest_artifact([SimpleWriteCode.name])\n                        code_text = latest.content if latest else \"\"\n                    out = await action.run(code_text)\n                    send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    latest_code = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                    latest_tests = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                    out = await action.run(latest_code.content if latest_code else \"\", latest_tests.content if latest_tests else \"\")\n                    low = (out or \"\").lower()\n                    if \"request\" in low or \"reject\" in low or \"fail\" in low:\n                        send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                    else:\n                        send_to = {\"SimpleVerifier\"}\n                elif isinstance(action, SimpleVerify):\n                    latest_code = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                    latest_tests = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                    out = await action.run(latest_code.content if latest_code else \"\", latest_tests.content if latest_tests else \"\")\n                    send_to = set()  # broadcast semantics handled by orchestrator\n                else:\n                    out = await action.run(getattr(message, \"content\", \"\") if message else \"\")\n                    send_to = set()\n\n                # mark processed for input message\n                if message and getattr(message, \"id\", None):\n                    self._processed.add(message.id)\n                # create response message\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n                if tracer:\n                    tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={getattr(response,'id',None)[:8]} cause_by={response.cause_by} send_to={send_to}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                await asyncio.sleep(0.05 * attempts)\n        # exhausted attempts\n        err = f\"ROLE_FAILED: {self.name} after {ROLE_ATTEMPTS} attempts - {last_err}\"\n        if tracer:\n            tracer.log(\"ROLE_FAIL\", self.name, err)\n        response = Message(\n            content=err,\n            role=self.profile,\n            cause_by=\"RoleFailure\",\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Message bus with history, artifact index and per-role delivered tracking.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # delivered mapping role.name -> set(message.id)\n        self._delivered: Dict[str, Set[str]] = {}\n        # index by cause_by for artifact lookup\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        # normalize send_to\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {getattr(message,'id',None)[:8]} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={snippet}\")\n\n    def mark_delivered(self, role: Role, message: Message):\n        mid = getattr(message, \"id\", None)\n        if not mid:\n            return\n        self._delivered.setdefault(role.name, set()).add(mid)\n        if self.tracer:\n            self.tracer.log(\"ENV_DELIVERED\", \"Environment\", f\"{role.name} delivered {mid[:8]}\")\n\n    def get_pending_for(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        delivered = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in delivered:\n                continue\n            # skip own messages\n            if getattr(msg, \"sent_from\", None) == role.name:\n                delivered.add(mid)\n                continue\n            # explicit routing\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            targeted = False\n            try:\n                if isinstance(targets, (set, list)):\n                    if role.name in targets or role.profile in targets:\n                        targeted = True\n                elif isinstance(targets, str):\n                    if targets in (role.name, role.profile):\n                        targeted = True\n            except Exception:\n                targeted = False\n            if targeted:\n                out.append(msg)\n                delivered.add(mid)\n                continue\n            # watch-list trigger\n            if getattr(msg, \"cause_by\", None) in getattr(role, \"watch_list\", []):\n                out.append(msg)\n                delivered.add(mid)\n        return out\n\n    def get_latest_artifact(self, cause_names: List[str]) -> Optional[Message]:\n        for name in cause_names:\n            msgs = self._by_cause.get(name, [])\n            if msgs:\n                return msgs[-1]\n        return None\n\n\nclass Team:\n    \"\"\"Orchestrator coordinating roles, termination, stability and retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self._verifier_streak = 0\n        self._required_stable = VERIFY_STABLE_REQUIRED\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        \"\"\"Invoke role.act with a timeout and bounded retries to avoid stalls.\"\"\"\n        attempts = 0\n        while attempts < ROLE_ATTEMPTS:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=30)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout attempt {attempts} for msg {getattr(msg,'id',None)[:8]}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception attempt {attempts}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.05 * attempts)\n        # publish an error artifact for traceability\n        err = Message(content=f\"ERROR: role {role.name} failed to process message {getattr(msg,'id',None)[:8]}\",\n                      role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {_required_stable if ( _required_stable := self._required_stable) else VERIFY_STABLE_REQUIRED} stable verifier passes\")\n        # initial message targeted to coders\n        initial = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial)\n\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_idx in range(n_round):\n            round_num = round_idx + 1\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            produced_this_round = 0\n\n            # deterministic processing order\n            for RoleClass in order:\n                roles = [r for r in self.env.roles if isinstance(r, RoleClass)]\n                for role in roles:\n                    pending = self.env.get_pending_for(role)\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and round_idx == 0:\n                        if initial not in pending:\n                            pending = [initial] + pending\n                    for msg in pending:\n                        resp = await self._invoke_role(role, msg)\n                        # mark delivered even if exception to avoid livelock\n                        self.env.mark_delivered(role, msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            produced_this_round += 1\n                            # handle verifier streak\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    # extract digest\n                                    digest = None\n                                    for token in resp.content.split(\"|\"):\n                                        token = token.strip()\n                                        if token.startswith(\"digest=\"):\n                                            digest = token.split(\"=\", 1)[1]\n                                            break\n                                    # treat any PASS as increment; require consecutive stable digest passes for early stop\n                                    if hasattr(self, \"_last_digest\") and digest and getattr(self, \"_last_digest\", None) == digest:\n                                        self._verifier_streak += 1\n                                    else:\n                                        self._last_digest = digest\n                                        self._verifier_streak = 1\n                                    self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"streak={self._verifier_streak} digest={digest}\")\n                                else:\n                                    # reset on fail\n                                    if self._verifier_streak > 0:\n                                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._verifier_streak}->0\")\n                                    self._verifier_streak = 0\n                                    self._last_digest = None\n\n            # check progress/no-progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} complete produced={produced_this_round} verifier_streak={self._verifier_streak}\")\n\n            # Termination: require consecutive stable verifier passes\n            if self._verifier_streak >= self._required_stable and round_num >= 1:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable ({self._verifier_streak}) - stopping early\")\n                break\n\n            # If no progress for multiple rounds, nudge coder and/or stop\n            if no_progress_rounds >= NO_PROGRESS_LIMIT:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds - terminating\")\n                break\n\n            # nudge coder once if little produced this round but not yet terminal\n            if produced_this_round == 0:\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: Please refine implementation for: {self.idea}\",\n                            instruct_content=self.idea,\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.profile}\n                        )\n                        self.env.publish_message(nudge)\n                # small pause to allow immediate processing\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' finished after {round_num} rounds with {len(self.env.history)} messages. verifier_streak={self._verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D2 (Score: 8.0799)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport time\nfrom typing import Tuple, Iterable\n\n# Evolution objectives applied:\n# - Explicit role responsibilities and simple single-action contract\n# - Reliable inter-agent routing: send_to normalized, watch_list triggers, delivered tracking\n# - Robust LLM calls with retries, backoff and deterministic fallback\n# - Strong verification with syntax, structural presence, and cross-reference heuristics\n# - Termination only after stable verification (consecutive identical digests)\n# - Error handling and limited retries for role execution\n\nDEFAULT_LLM_RETRIES = 3\nDEFAULT_LLM_BACKOFF = 0.4\nREQUIRED_STABLE_PASSES = 2  # require this many consecutive identical verification digests\n\ndef _normalize_send_to_field(msg: Message) -> Set[str]:\n    s = getattr(msg, \"send_to\", None)\n    if s is None:\n        s = set(getattr(msg, \"sent_to\", set()) or set())\n    # Ensure set type\n    return set(s or set())\n\nclass Action(ABC):\n    \"\"\"Base action with LLM-safe call and a single run(...) contract.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = DEFAULT_LLM_RETRIES\n    backoff: float = DEFAULT_LLM_BACKOFF\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def ask_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM robustly with retries and exponential backoff. Returns result or explicit error string.\"\"\"\n        last_err = None\n        tracer = getattr(self.context, \"tracer\", None)\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    fallback = \"LLM_UNAVAILABLE: deterministic fallback\"\n                    if tracer:\n                        tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                res = await self.llm.ask(messages)\n                if isinstance(res, str) and (res.strip() == \"\" or res.lower().startswith(\"error\")):\n                    last_err = res\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, f\"LLM responded with error-like text: {res[:200]}\")\n                    await asyncio.sleep(self.backoff * (2 ** (attempt - 1)))\n                    continue\n                return res\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {e}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_err[:200])\n                await asyncio.sleep(self.backoff * (2 ** (attempt - 1)))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            # deterministic minimal fallback\n            fallback = (\n                \"# fallback placeholder implementation (empty idea)\\n\"\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder that echoes input.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"empty idea -> fallback code\")\n            return fallback\n\n        prompt = (\n            \"You are a professional Python developer. Return only Python source code implementing the task.\\n\"\n            \"Include docstrings and basic input validation. Avoid external network calls.\\n\\n\"\n            f\"Task:\\n{idea}\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = await self.ask_with_retries(messages)\n\n        # Validate produced code; if invalid, replace with safe fallback\n        try:\n            if not isinstance(code, str) or not code.strip():\n                raise ValueError(\"Empty or non-string code\")\n            ast.parse(code)\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed successfully\")\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_INVALID\", self.name, f\"Generated code invalid: {e}\")\n            code = (\n                \"def placeholder(input_data=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback implementation.\\\"\\\"\\\"\\n\"\n                \"    return input_data\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"No code provided; returning fallback tests\")\n            return (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided module. \"\n            \"Return only test code.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = await self.ask_with_retries(messages)\n\n        # Validate tests: require 'assert' or def test_\n        try:\n            if not isinstance(tests, str) or tests.strip() == \"\":\n                raise ValueError(\"Empty tests\")\n            parsed = ast.parse(tests)\n            has_test = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed))\n            if not (has_test or has_assert):\n                raise ValueError(\"No test functions or assert statements detected\")\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE\", self.name, \"Tests validated\")\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Tests invalid or insufficient: {e}; using fallback\")\n            tests = (\n                \"def test_placeholder_positive():\\n\"\n                \"    \\\"\\\"\\\"Basic positive fallback test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: Please check edge cases. REVIEW_DECISION: APPROVE\"\n\n        prompt = (\n            \"You are a senior reviewer. Produce a concise review and end with:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REJECT\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\n\"\n            f\"Tests (truncated):\\n{(tests or '')[:1500]}\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        review = await self.ask_with_retries(messages)\n        if not isinstance(review, str) or \"REVIEW_DECISION:\" not in review:\n            # heuristic: if code has 'def' and tests mention 'test_' or 'assert' approve\n            heur_decision = \"REJECT\"\n            if (\"def \" in (code or \"\") or \"class \" in (code or \"\")) and (\"def test_\" in (tests or \"\") or \"assert\" in (tests or \"\")):\n                heur_decision = \"APPROVE\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {heur_decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"No explicit decision; inferred {heur_decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_defs_ok = False\n        tests_have_funcs = False\n        cross_ref_ok = False\n\n        # Syntax checks\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # heuristics for tests\n            tests_have_funcs = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            has_asserts = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n            tests_ok = tests_have_funcs or has_asserts\n            details.append(\"tests_presence_and_syntax: ok\" if tests_ok else \"tests_presence_and_syntax: fail\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # Structural presence in code\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_defs_ok = any(isinstance(n, (ast.FunctionDef, ast.ClassDef)) for n in parsed_code.body)\n            details.append(\"code_has_defs: ok\" if code_defs_ok else \"code_has_defs: fail\")\n        except Exception:\n            details.append(\"code_has_defs: fail\")\n\n        # Cross-reference: do tests mention code defs?\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_names = {n.name for n in parsed_code.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            parsed_tests = ast.parse(tests or \"\")\n            tests_names = {n.id for n in ast.walk(parsed_tests) if isinstance(n, ast.Name)}\n            text_overlap = any(name in (tests or \"\") for name in code_names)\n            cross_ref_ok = bool(code_names) and (not tests_names.isdisjoint(code_names) or text_overlap)\n            details.append(\"cross_reference: ok\" if cross_ref_ok else \"cross_reference: fail\")\n        except Exception:\n            details.append(\"cross_reference: fail (error)\")\n\n        verified = all([code_ok, tests_ok, code_defs_ok, cross_ref_ok])\n        digest = hashlib.sha256(((code or \"\") + \"\\n--\\n\" + (tests or \"\")).encode(\"utf-8\")).hexdigest()[:12]\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with single responsibility, watch/trigger logic and idempotent processing.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()  # names of actions this role watches\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = kwargs.get(\"env\", None)\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: Iterable[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", str(a)) for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        \"\"\"Decide whether to handle a message based on explicit addressing or watch_list triggers.\"\"\"\n        if msg is None:\n            return False\n        # avoid self-handling\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # if already processed\n        if getattr(msg, \"id\", None) in self._processed:\n            return False\n        # explicit target\n        send_to = _normalize_send_to_field(msg)\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the assigned action for this role and return a Message (always).\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        # if message present but not relevant, skip\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message {getattr(message,'id',None)}\")\n            return None\n\n        # Protect against repeated processing\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Running action {self.action.name} for msg={msg_id}\")\n\n        try:\n            # dispatch inputs explicitly based on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                out = await self.action.run(idea or \"\")\n                send_to = {\"SimpleTester\"}\n                response = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n\n            elif isinstance(self.action, SimpleWriteTest):\n                # prefer message content (code) else latest artifact\n                code_text = getattr(message, \"content\", \"\") if message else \"\"\n                if not code_text and self.env:\n                    code_msg = self.env.get_latest_artifact([SimpleWriteCode.name])\n                    code_text = code_msg.content if code_msg else \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                response = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n\n            elif isinstance(self.action, SimpleWriteReview):\n                code_msg = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                tests_msg = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                out = await self.action.run(code_text, tests_text)\n                # parse decision to route appropriately\n                decision = \"REVIEW_DECISION: APPROVE\" if \"REVIEW_DECISION: APPROVE\" in (out or \"\") else None\n                if decision:\n                    send_to = {\"SimpleVerifier\"}\n                else:\n                    # if review rejects, route back for changes\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                response = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n\n            elif isinstance(self.action, SimpleVerify):\n                code_msg = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                tests_msg = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                out = await self.action.run(code_text, tests_text)\n                # verification result is broadcast for traceability\n                response = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=set())\n\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                response = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=set())\n\n        except Exception as e:\n            # contain errors: report and route to coder for recovery\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, f\"{type(e).__name__}: {str(e)[:200]}\")\n            response = Message(content=f\"ROLE_ERROR: {type(e).__name__}: {str(e)[:200]}\", role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to={\"SimpleCoder\"})\n\n        # Mark processed for idempotency\n        if msg_id:\n            self._processed.add(msg_id)\n        # Also mark produced message id to avoid self-processing\n        try:\n            self._processed.add(getattr(response, \"id\", \"\"))\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={getattr(response,'id',None)} cause_by={response.cause_by} send_to={_normalize_send_to_field(response)}\")\n        return response\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Message bus with deterministic routing and delivered tracking.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # per-role delivered message ids\n        self._delivered: Dict[str, Set[str]] = {}\n        # index by cause_by for artifact lookup\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile}) watching {sorted(list(role.watch_list))}\")\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        try:\n            message.send_to = _normalize_send_to_field(message)\n        except Exception:\n            message.send_to = set()\n        # ensure id exists\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", \"\"):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} to={sorted(list(message.send_to))} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages not yet delivered to a role that the role should handle.\"\"\"\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            if not getattr(msg, \"id\", None):\n                continue\n            if msg.id in seen:\n                continue\n            # avoid sending a role its own messages\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(msg.id)\n                continue\n            targeted = bool(msg.send_to and (role.profile in msg.send_to or role.name in msg.send_to))\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        return out\n\n    def get_latest_artifact(self, cause_names: Iterable[str]) -> Optional[Message]:\n        \"\"\"Return the most recent message whose cause_by is in cause_names.\"\"\"\n        for cname in cause_names:\n            msgs = self._by_cause.get(cname, [])\n            if msgs:\n                return msgs[-1]\n        return None\n\nclass Team:\n    \"\"\"Orchestrator with deterministic sequencing, verification stability, nudges and robust error handling.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = REQUIRED_STABLE_PASSES\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds with stability_required={self._required_streak}\")\n\n        # Kickoff: explicit message targeted to coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial_msg = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        rounds_executed = 0\n\n        # stable deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_idx in range(1, n_round + 1):\n            rounds_executed = round_idx\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_idx}/{n_round}\")\n            new_messages = 0\n\n            for RoleType in order:\n                roles = [r for r in self.env.roles if isinstance(r, RoleType)]\n                for role in roles:\n                    try:\n                        # On first round ensure coders see initial message if not already delivered\n                        incoming = self.env.get_messages_for_role(role)\n                        if isinstance(role, SimpleCoder) and round_idx == 1 and not incoming:\n                            incoming = [initial_msg]\n                            self.env._delivered.setdefault(role.name, set()).add(initial_msg.id)\n                        for msg in incoming:\n                            # execute role; protect against role exceptions\n                            resp = None\n                            try:\n                                resp = await role.act(msg)\n                            except Exception as e:\n                                self.tracer.log(\"ROLE_ACT_EXCEPTION\", role.name, f\"Exception during act: {type(e).__name__}: {e}\")\n                                resp = Message(content=f\"ERROR: role {role.name} crashed: {e}\", role=role.profile, cause_by=\"RoleCrash\", sent_from=role.name)\n                            if resp:\n                                self.env.publish_message(resp)\n                                new_messages += 1\n                                # track verification passes if produced by verifier role\n                                if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    # extract digest\n                                    digest = None\n                                    for part in resp.content.split(\"|\"):\n                                        p = part.strip()\n                                        if p.startswith(\"digest=\"):\n                                            digest = p.split(\"=\", 1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    else:\n                                        # no digest -> treat as non-stable\n                                        self._streak = 1\n                                        self._last_digest = None\n                                elif isinstance(role, SimpleVerifier):\n                                    # any non-pass resets streak\n                                    self._streak = 0\n                                    self._last_digest = None\n                    except Exception as e:\n                        self.tracer.log(\"ROUND_ERROR\", \"Team\", f\"Error processing role {role.name}: {type(e).__name__}: {e}\")\n                        # continue with next role\n\n            # Termination checks\n            if self._streak >= self._required_streak:\n                verified = True\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Verification stable for {self._required_streak} passes; stopping\")\n                break\n\n            if new_messages == 0:\n                # no progress this round; nudge coders but avoid infinite nudging by only doing one nudge per round\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No new messages this round; nudging coder(s)\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: please refine or propose implementation for: {self.idea}\",\n                            instruct_content=self.idea,\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.profile}\n                        )\n                        self.env.publish_message(nudge)\n                        new_messages += 1\n                # allow a small pause for asynchronicity\n                await asyncio.sleep(0.01)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_idx} completed; new_messages={new_messages} history_len={len(self.env.history)}\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' executed rounds={rounds_executed} messages={len(self.env.history)} verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D3 (Score: 7.3048)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic response\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nfrom typing import Iterable, Tuple\n\n# Goals:\n# - Reduce failure modes (clear roles, robust comms, retrying LLM/API calls)\n# - Explicit watch/trigger logic and deterministic sequencing\n# - Strong verification (syntax + tests + cross-reference) with digest stability\n# - Error handling: contain exceptions, produce fallback artifacts, limited retries\n# - Termination: require consecutive identical verification digests\n\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF = 0.25\nREQUIRED_STABLE_DIGESTS = 2\n\ndef _ensure_set(obj) -> Set[str]:\n    if obj is None:\n        return set()\n    if isinstance(obj, (set, list, tuple)):\n        return set(obj)\n    return {str(obj)}\n\nclass Action(ABC):\n    \"\"\"Abstract action with safe LLM call helper and deterministic fallback behavior.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    backoff: float = LLM_BACKOFF\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n                    if tracer:\n                        tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str):\n                    low = resp.strip().lower()\n                    if low == \"\" or low.startswith(\"error\") or \"error communicating\" in low:\n                        last_err = resp\n                        raise RuntimeError(resp)\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Received {len(resp or '')} chars\")\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"{attempt} failed: {last_err[:200]}\")\n                # exponential backoff + jitter\n                await asyncio.sleep(self.backoff * (2 ** (attempt - 1)) + random.uniform(0, 0.1))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_preview={(idea or '')[:120]}\")\n        if not idea or not idea.strip():\n            fallback = (\n                \"# Fallback placeholder implementation (no idea provided)\\n\"\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea -> fallback code\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python engineer. Produce a single parseable Python module implementing the task.\\n\"\n            \"Return only Python code. Include docstrings and at least one function or class.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = await self.safe_ask(messages)\n        # Validate syntax\n        try:\n            if isinstance(code, str) and code.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                raise RuntimeError(code)\n            ast.parse(code or \"\")\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed OK\")\n            return code\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_INVALID\", self.name, f\"Parse failed: {str(e)[:160]}\")\n            fallback = (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback deterministic implementation.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            return fallback\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"No code -> fallback tests\")\n            return (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n\n        truncated = (code or \"\")[:3500]\n        prompt = (\n            \"You are a QA engineer. Produce pytest-style tests for the Python module below.\\n\"\n            \"Return only the pytest code. Include at least one regular case and one edge case.\\n\\n\"\n            f\"Module:\\n{truncated}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = await self.safe_ask(messages)\n        # Heuristic validation\n        try:\n            if isinstance(tests, str) and tests.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                raise RuntimeError(tests)\n            parsed = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed))\n            if has_test_fn or has_assert:\n                if tracer:\n                    tracer.log(\"ACTION_VALIDATE\", self.name, \"Tests validated\")\n                return tests\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_INVALID\", self.name, f\"Tests invalid: {str(e)[:160]}\")\n        # fallback\n        fallback = (\n            \"def test_placeholder_positive():\\n\"\n            \"    \\\"\\\"\\\"Deterministic fallback test.\\\"\\\"\\\"\\n\"\n            \"    assert True\\n\"\n        )\n        if tracer:\n            tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback tests\")\n        return fallback\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if self.is_human:\n            msg = \"HUMAN_REVIEW: manual check recommended\\nREVIEW_DECISION: REQUEST_CHANGE\"\n            if tracer:\n                tracer.log(\"ACTION_HUMAN\", self.name, \"Simulated human review\")\n            return msg\n\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Automatic review\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review and end with a line:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGE\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        review = await self.safe_ask(messages)\n        # Ensure decision present\n        if not isinstance(review, str) or \"REVIEW_DECISION:\" not in review:\n            # heuristic decision\n            decision = \"APPROVE\" if (\"def \" in (code or \"\") or \"class \" in (code or \"\")) and (\"assert\" in (tests or \"\")) else \"REQUEST_CHANGE\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Inferred decision {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verification started\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n        tests_has_assert = False\n        cross_ref_ok = False\n\n        # Code syntax & entities\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(\"code_syntax: ok\")\n            details.append(f\"code_entities:{len(code_entities)}\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:140]})\")\n            parsed_code = None\n\n        # Tests syntax & asserts\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n            tests_has_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            tests_ok = tests_has_assert or tests_has_testfn\n            details.append(\"tests_syntax: ok\" if tests_ok else \"tests_syntax: ok_but_no_asserts_or_testfn\")\n            details.append(f\"tests_asserts:{tests_has_assert}\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:140]})\")\n            parsed_tests = None\n\n        # Cross references\n        if parsed_code and parsed_tests and code_entities:\n            test_names = {n.id for n in ast.walk(parsed_tests) if isinstance(n, ast.Name)}\n            text_overlap = any(name in (tests or \"\") for name in code_entities)\n            inter = code_entities & test_names\n            cross_ref_ok = bool(inter) or text_overlap\n            details.append(f\"tests_refs_count:{len(inter)}\")\n        else:\n            details.append(\"tests_refs_count:0\")\n\n        verified = all([code_ok, tests_ok, bool(code_entities), cross_ref_ok])\n        digest_src = ((code or \"\") + \"\\n--\\n\" + (tests or \"\")).encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with one primary action, explicit watch triggers, and per-role delivery tracking.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = kwargs.get(\"env\", None)\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: Iterable[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", str(a)) for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed:\n            return False\n        send_to = _ensure_set(getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None))\n        if send_to:\n            if self.profile in send_to or self.name in send_to or \"*\" in send_to:\n                return True\n            return False\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg {getattr(message,'id',None)}\")\n            # mark as processed to avoid repeated unnecessary checks\n            if getattr(message, \"id\", None):\n                self._processed.add(message.id)\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already handled {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Running {self.action.name} for msg={msg_id}\")\n\n        try:\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                out = await self.action.run(idea)\n                send_to = {\"SimpleTester\"}\n            elif isinstance(self.action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and message.cause_by == SimpleWriteCode.name else \"\"\n                if not code_text and self.env:\n                    code_msg = self.env.get_latest_artifact([SimpleWriteCode.name])\n                    code_text = code_msg.content if code_msg else \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleWriteReview):\n                code_msg = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                tests_msg = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                # route based on decision\n                if \"REVIEW_DECISION: REQUEST_CHANGE\" in (out or \"\") or \"REQUEST_CHANGE\" in (out or \"\"):\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleVerify):\n                code_msg = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                tests_msg = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = set(r.profile for r in (self.env.roles if self.env else []))\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)}\"\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, err[:200])\n            # produce a message pointing to coder for recovery\n            out = err\n            send_to = {\"SimpleCoder\"}\n\n        # mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n\n        # create Message (pydantic or fallback compatible)\n        response = Message(\n            content=out or \"\",\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"\",\n            sent_from=self.name,\n            send_to=set(send_to)\n        )\n\n        # mark produced id locally to avoid self-processing\n        try:\n            self._processed.add(response.id)\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={sorted(list(response.send_to))}\")\n        return response\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Message bus: stores history, delivered tracking and artifact indexing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # per-role delivered ids\n        self.delivered: Dict[str, Set[str]] = {}\n        # by cause index\n        self.by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self.delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile}) watching {sorted(list(role.watch_list))}\")\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        try:\n            message.send_to = _ensure_set(getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None))\n        except Exception:\n            message.send_to = set()\n        # ensure id\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", \"\"):\n            self.by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} to={sorted(list(message.send_to))} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self.delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            # never send back a role's own messages\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            targeted = bool(msg.send_to and (role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to))\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                seen.add(mid)\n        return out\n\n    def get_latest_artifact(self, cause_names: Iterable[str]) -> Optional[Message]:\n        for cname in cause_names:\n            msgs = self.by_cause.get(cname, [])\n            if msgs:\n                return msgs[-1]\n        return None\n\nclass Team:\n    \"\"\"Orchestrates the multi-agent pipeline deterministically, with stable verification termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = REQUIRED_STABLE_DIGESTS\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        # placeholder for compatibility\n        pass\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {(idea or '')[:200]}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_required={self._required_streak})\")\n        # Kickoff: target coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        rounds_executed = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n            new_messages = 0\n\n            for RoleType in order:\n                roles = [r for r in self.env.roles if isinstance(r, RoleType)]\n                for role in roles:\n                    # Ensure coder sees kickoff in first round\n                    incoming = self.env.get_messages_for_role(role)\n                    if isinstance(role, SimpleCoder) and rnd == 1 and not incoming:\n                        incoming = [initial]\n                        self.env.delivered.setdefault(role.name, set()).add(initial.id)\n                    for msg in incoming:\n                        try:\n                            resp = await role.act(msg)\n                        except Exception as e:\n                            self.tracer.log(\"ROLE_ACT_EXCEPTION\", role.name, f\"{type(e).__name__}: {e}\")\n                            resp = Message(content=f\"ERROR: role {role.name} crashed: {e}\", role=role.profile, cause_by=\"RoleCrash\", sent_from=role.name, send_to={\"SimpleCoder\"})\n                        if resp:\n                            self.env.publish_message(resp)\n                            any_activity = True\n                            new_messages += 1\n                            # If verifier produced PASS, update streak logic\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                digest = None\n                                for part in resp.content.split(\"|\"):\n                                    p = part.strip()\n                                    if p.startswith(\"digest=\"):\n                                        digest = p.split(\"=\", 1)[1]\n                                        break\n                                if digest:\n                                    if digest == self._last_digest:\n                                        self._streak += 1\n                                    else:\n                                        self._last_digest = digest\n                                        self._streak = 1\n                                    self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                else:\n                                    # treat as non-stable\n                                    self._last_digest = None\n                                    self._streak = 0\n                            elif isinstance(role, SimpleVerifier):\n                                # reset streak on non-pass\n                                if self._streak > 0:\n                                    self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"Resetting streak from {self._streak} to 0\")\n                                self._streak = 0\n                                self._last_digest = None\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed new_messages={new_messages} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require stable digest streak and at least one round with no new artifacts after streak reached\n            if self._streak >= self._required_streak:\n                verified = True\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Stable verification: streak={self._streak}\")\n                break\n\n            # deadlock detection and nudge\n            if not any_activity:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No activity this round; nudging coder(s)\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: please propose or refine implementation for: {self.idea}\",\n                            instruct_content=self.idea,\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.profile}\n                        )\n                        self.env.publish_message(nudge)\n                        any_activity = True\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project completed rounds={rounds_executed} verified={verified}\")\n        summary = f\"Project '{self.idea}' finished rounds={rounds_executed} messages={len(self.env.history)} verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D4 (Score: 9.5833)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic response\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nfrom typing import Tuple\n\ndef _preview(text: Optional[str], n: int = 120) -> str:\n    if not text:\n        return \"\"\n    return text[:n] + (\"...\" if len(text) > n else \"\")\n\nclass Action(ABC):\n    \"\"\"Base Action with robust LLM calls and clear responsibilities.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    backoff_base: float = 0.25\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, exponential backoff, and logging. Return a stable fallback on failure.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or resp.startswith(\"Error communicating\")):\n                    last_err = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, f\"LLM error response: {resp[:200]}\")\n                    await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n                    continue\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_err[:200])\n                await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n        failure = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure)\n        return failure\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produces Python code implementing the given idea, with fallback and syntax validation.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea={_preview(idea,200)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module that implements the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no markdown or backticks).\\n\"\n            \"- Include docstrings, basic input validation, and error handling.\\n\"\n            \"- Ensure at least one function or class is defined.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = await self.safe_ask(messages)\n        # Validate and fallback if necessary\n        parsed_ok = False\n        try:\n            ast.parse(code or \"\")\n            parsed_ok = True\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Generated code failed to parse: {e}\")\n        if not parsed_ok:\n            # Deterministic fallback minimal module\n            code = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback placeholder code\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"produced_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generates pytest tests for the provided module, with basic heuristics and fallback.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided Python module.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Include docstrings and clear asserts.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = await self.safe_ask(messages)\n        # Heuristic validation\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests and \"unittest\" not in tests):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            tests = fallback\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback tests\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Reviews code and tests and provides an explicit decision line (APPROVE/REQUEST_CHANGE).\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: APPROVE\\nREVIEW_DECISION: APPROVE\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review and end with a decisive line:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGE\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\\n\\n\"\n            \"Focus on correctness, missing tests, and actionable improvements. Keep concise.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        review = await self.safe_ask(messages)\n        if not review or \"REVIEW_DECISION:\" not in review:\n            # Heuristic decision\n            decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and ((\"def \" in (code or \"\")) or (\"class \" in (code or \"\"))) else \"REQUEST_CHANGE\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"No explicit decision from LLM, inferred {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Performs deterministic verification of code/tests and returns standardized result with digest.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_code = None\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = True\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_tests = None\n\n        # Semantic checks\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(f\"code_entities: {len(code_entities)}\")\n\n        tests_has_assert = False\n        tests_references = set()\n        if parsed_tests:\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Assert):\n                    tests_has_assert = True\n                if isinstance(node, ast.Name):\n                    tests_references.add(node.id)\n            details.append(f\"tests_asserts: {tests_has_assert}\")\n            inter = code_entities & tests_references\n            details.append(f\"tests_refs_code: {len(inter)}\")\n\n        # Decide PASS/FAIL\n        passed = all([code_ok, tests_ok, bool(code_entities), tests_has_assert, len(code_entities & tests_references) > 0])\n        # Stable digest for verification uniqueness\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        result = f\"VERIFICATION_RESULT: {'PASS' if passed else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base Role: single responsibility, explicit watch list, idempotent processing.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: List[str] = []  # list of action names or triggers\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        # Normalize to action.name strings\n        names = []\n        for a in actions:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            else:\n                names.append(str(a))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute primary action if message matches watch rules. Ensures idempotency and safe error handling.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        # Evaluate if this role should act on this message\n        msg_id = getattr(message, \"id\", None)\n        # Skip if already processed this message\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {msg_id}\")\n            return None\n\n        # If message exists and not targeted to this role and not in watch_list, skip\n        if message:\n            send_to = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n            targeted = False\n            if send_to:\n                try:\n                    if isinstance(send_to, (set, list)):\n                        targeted = (self.name in send_to or self.profile in send_to)\n                    else:\n                        targeted = (send_to == self.name or send_to == self.profile)\n                except Exception:\n                    targeted = False\n            watches = getattr(message, \"cause_by\", None) in self.watch_list\n            # If neither targeted nor watched, skip (unless watch_list empty -> proactive)\n            if not targeted and not watches and self.watch_list:\n                if tracer:\n                    tracer.log(\"ROLE_SKIP\", self.name, f\"Not a target/watched message cause_by={getattr(message,'cause_by',None)}\")\n                return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing {self.action.name} for message {msg_id} preview={_preview(getattr(message,'content',None) or '',120)}\")\n\n        try:\n            # Determine inputs for action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                result = await self.action.run(idea)\n            elif isinstance(self.action, SimpleWriteTest):\n                # Prefer code from message, else fetch latest code in env\n                code = getattr(message, \"content\", \"\") if message and message.cause_by == SimpleWriteCode.name else \"\"\n                if not code and self.env:\n                    code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code)\n            elif isinstance(self.action, SimpleWriteReview):\n                # Collect latest code and tests\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            elif isinstance(self.action, SimpleVerify):\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            else:\n                result = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err[:200])\n            # Mark processed to avoid retry storms\n            if msg_id:\n                self._processed.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build outgoing message\n        out_msg = Message(\n            content=result,\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"\",\n            sent_from=self.name\n        )\n        # Mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={getattr(out_msg,'id',None)} cause_by={out_msg.cause_by}\")\n        return out_msg\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        # Coder is triggered by user input or explicit 'REQUEST_CHANGE'\n        self._watch([\"UserInput\", \"REQUEST_CHANGE\"])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest.name])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest.name, SimpleWriteReview.name])\n\nclass Environment:\n    \"\"\"Holds roles and messages; provides routing and artifact retrieval helpers.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # track which roles have seen which message ids to avoid duplicate delivery\n        self.delivered: Dict[str, Set[str]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Ensure send_to is a set for consistency\n        send_to = getattr(message, \"send_to\", None)\n        if send_to is None:\n            try:\n                message.send_to = set()\n            except Exception:\n                pass\n        self.history.append(message)\n        self.delivered.setdefault(message.id, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content,200)} send_to={sorted(list(getattr(message,'send_to',set()))[:10])}\")\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[str]:\n        \"\"\"Return content of the latest message with matching cause_by.\"\"\"\n        for msg in reversed(self.history):\n            if msg.cause_by == cause_by:\n                return msg.content\n        return None\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Determine messages a role should process:\n        - messages explicitly addressed to role.profile or role.name\n        - messages where cause_by matches role.watch_list\n        Excludes messages already delivered to that role.\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            if targets:\n                try:\n                    if role.name in targets or role.profile in targets:\n                        targeted = True\n                except Exception:\n                    targeted = False\n            watched = (getattr(msg, \"cause_by\", None) in role.watch_list)\n            # If message is proactive (no watch_list), coder should still be able to act (handled via initial targeting)\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\nclass Team:\n    \"\"\"Orchestrates the multi-agent workflow with deterministic pipeline and robust termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea = \"\"\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # termination stability: require same digest for consecutive confirms\n        self._last_digest: Optional[str] = None\n        self._streak = 0\n        self._required_streak = 2  # require two stable verifications\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        # kept for compatibility\n        pass\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {_preview(idea,200)}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Kickoff message targeted to coders (by profile)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            # Deterministic processing order\n            for role_type in self.order:\n                roles_of_type = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles_of_type:\n                    msgs = self.env.get_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # don't let role process its own message\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n                        try:\n                            response = await role.act(msg)\n                        except Exception as e:\n                            self.tracer.log(\"TEAM_ROLE_EXCEPTION\", \"Team\", f\"Role {role.name} crashed: {type(e).__name__}: {e}\")\n                            response = Message(content=f\"ERROR: {role.name} crashed: {e}\", role=role.profile, cause_by=\"exception\", sent_from=role.name)\n                        if response:\n                            # Provide routing hints if none present\n                            if not getattr(response, \"send_to\", None):\n                                # by default, route next stage based on pipeline\n                                if isinstance(role, SimpleCoder):\n                                    response.send_to = {SimpleTester.profile}\n                                elif isinstance(role, SimpleTester):\n                                    response.send_to = {SimpleReviewer.profile, SimpleVerifier.profile}\n                                elif isinstance(role, SimpleReviewer):\n                                    # If reviewer requests change, target coder\n                                    if isinstance(response.content, str) and response.content.strip().upper().startswith(\"REQUEST_CHANGE\"):\n                                        response.send_to = {SimpleCoder.profile}\n                                        response.cause_by = \"REQUEST_CHANGE\"\n                                    else:\n                                        response.send_to = {SimpleVerifier.profile}\n                                elif isinstance(role, SimpleVerifier):\n                                    response.send_to = {r.profile for r in self.env.roles}\n                            self.env.publish_message(response)\n                            any_activity = True\n                            # parse verification results for termination logic\n                            if isinstance(role, SimpleVerifier) and isinstance(response.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                    # try to extract digest\n                                    digest = None\n                                    for part in (response.content or \"\").split(\"|\"):\n                                        p = part.strip()\n                                        if p.startswith(\"digest=\"):\n                                            digest = p.split(\"=\",1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                        if self._streak >= self._required_streak:\n                                            verified = True\n                                    else:\n                                        # If no digest, require explicit reviewer approval to stop\n                                        self._streak = 0\n                                        self._last_digest = None\n                                        self.tracer.log(\"VERIFIER\", \"Team\", \"Pass without digest - not stable\")\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # Deadlock detection: nudge coder(s)\n                self.tracer.log(\"TEAM_DEADLOCK\", \"Team\", \"No activity this round; nudging coder(s)\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please propose initial code for '{_preview(self.idea,120)}'\", role=\"System\", sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # small sleep to allow async LLM to settle if applicable\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds} rounds; verified={verified} history_len={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 4.9844, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (3.167)\n\n\n### Inspiration 2 (Score: 9.5833, Type: High-Performer)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic response\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nfrom typing import Tuple\n\ndef _preview(text: Optional[str], n: int = 120) -> str:\n    if not text:\n        return \"\"\n    return text[:n] + (\"...\" if len(text) > n else \"\")\n\nclass Action(ABC):\n    \"\"\"Base Action with robust LLM calls and clear responsibilities.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    backoff_base: float = 0.25\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, exponential backoff, and logging. Return a stable fallback on failure.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or resp.startswith(\"Error communicating\")):\n                    last_err = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, f\"LLM error response: {resp[:200]}\")\n                    await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n                    continue\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_err[:200])\n                await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n        failure = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure)\n        return failure\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produces Python code implementing the given idea, with fallback and syntax validation.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea={_preview(idea,200)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module that implements the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no markdown or backticks).\\n\"\n            \"- Include docstrings, basic input validation, and error handling.\\n\"\n            \"- Ensure at least one function or class is defined.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = await self.safe_ask(messages)\n        # Validate and fallback if necessary\n        parsed_ok = False\n        try:\n            ast.parse(code or \"\")\n            parsed_ok = True\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Generated code failed to parse: {e}\")\n        if not parsed_ok:\n            # Deterministic fallback minimal module\n            code = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback placeholder code\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"produced_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generates pytest tests for the provided module, with basic heuristics and fallback.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided Python module.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Include docstrings and clear asserts.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = await self.safe_ask(messages)\n        # Heuristic validation\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests and \"unittest\" not in tests):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            tests = fallback\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback tests\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Reviews code and tests and provides an explicit decision line (APPROVE/REQUEST_CHANGE).\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: APPROVE\\nREVIEW_DECISION: APPROVE\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review and end with a decisive line:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGE\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\\n\\n\"\n            \"Focus on correctness, missing tests, and actionable improvements. Keep concise.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        review = await self.safe_ask(messages)\n        if not review or \"REVIEW_DECISION:\" not in review:\n            # Heuristic decision\n            decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and ((\"def \" in (code or \"\")) or (\"class \" in (code or \"\"))) else \"REQUEST_CHANGE\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"No explicit decision from LLM, inferred {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Performs deterministic verification of code/tests and returns standardized result with digest.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_code = None\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = True\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_tests = None\n\n        # Semantic checks\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(f\"code_entities: {len(code_entities)}\")\n\n        tests_has_assert = False\n        tests_references = set()\n        if parsed_tests:\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Assert):\n                    tests_has_assert = True\n                if isinstance(node, ast.Name):\n                    tests_references.add(node.id)\n            details.append(f\"tests_asserts: {tests_has_assert}\")\n            inter = code_entities & tests_references\n            details.append(f\"tests_refs_code: {len(inter)}\")\n\n        # Decide PASS/FAIL\n        passed = all([code_ok, tests_ok, bool(code_entities), tests_has_assert, len(code_entities & tests_references) > 0])\n        # Stable digest for verification uniqueness\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        result = f\"VERIFICATION_RESULT: {'PASS' if passed else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base Role: single responsibility, explicit watch list, idempotent processing.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: List[str] = []  # list of action names or triggers\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        # Normalize to action.name strings\n        names = []\n        for a in actions:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            else:\n                names.append(str(a))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute primary action if message matches watch rules. Ensures idempotency and safe error handling.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        # Evaluate if this role should act on this message\n        msg_id = getattr(message, \"id\", None)\n        # Skip if already processed this message\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {msg_id}\")\n            return None\n\n        # If message exists and not targeted to this role and not in watch_list, skip\n        if message:\n            send_to = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n            targeted = False\n            if send_to:\n                try:\n                    if isinstance(send_to, (set, list)):\n                        targeted = (self.name in send_to or self.profile in send_to)\n                    else:\n                        targeted = (send_to == self.name or send_to == self.profile)\n                except Exception:\n                    targeted = False\n            watches = getattr(message, \"cause_by\", None) in self.watch_list\n            # If neither targeted nor watched, skip (unless watch_list empty -> proactive)\n            if not targeted and not watches and self.watch_list:\n                if tracer:\n                    tracer.log(\"ROLE_SKIP\", self.name, f\"Not a target/watched message cause_by={getattr(message,'cause_by',None)}\")\n                return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing {self.action.name} for message {msg_id} preview={_preview(getattr(message,'content',None) or '',120)}\")\n\n        try:\n            # Determine inputs for action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                result = await self.action.run(idea)\n            elif isinstance(self.action, SimpleWriteTest):\n                # Prefer code from message, else fetch latest code in env\n                code = getattr(message, \"content\", \"\") if message and message.cause_by == SimpleWriteCode.name else \"\"\n                if not code and self.env:\n                    code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code)\n            elif isinstance(self.action, SimpleWriteReview):\n                # Collect latest code and tests\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            elif isinstance(self.action, SimpleVerify):\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            else:\n                result = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err[:200])\n            # Mark processed to avoid retry storms\n            if msg_id:\n                self._processed.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build outgoing message\n        out_msg = Message(\n            content=result,\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"\",\n            sent_from=self.name\n        )\n        # Mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={getattr(out_msg,'id',None)} cause_by={out_msg.cause_by}\")\n        return out_msg\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        # Coder is triggered by user input or explicit 'REQUEST_CHANGE'\n        self._watch([\"UserInput\", \"REQUEST_CHANGE\"])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest.name])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest.name, SimpleWriteReview.name])\n\nclass Environment:\n    \"\"\"Holds roles and messages; provides routing and artifact retrieval helpers.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # track which roles have seen which message ids to avoid duplicate delivery\n        self.delivered: Dict[str, Set[str]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Ensure send_to is a set for consistency\n        send_to = getattr(message, \"send_to\", None)\n        if send_to is None:\n            try:\n                message.send_to = set()\n            except Exception:\n                pass\n        self.history.append(message)\n        self.delivered.setdefault(message.id, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content,200)} send_to={sorted(list(getattr(message,'send_to',set()))[:10])}\")\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[str]:\n        \"\"\"Return content of the latest message with matching cause_by.\"\"\"\n        for msg in reversed(self.history):\n            if msg.cause_by == cause_by:\n                return msg.content\n        return None\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Determine messages a role should process:\n        - messages explicitly addressed to role.profile or role.name\n        - messages where cause_by matches role.watch_list\n        Excludes messages already delivered to that role.\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            if targets:\n                try:\n                    if role.name in targets or role.profile in targets:\n                        targeted = True\n                except Exception:\n                    targeted = False\n            watched = (getattr(msg, \"cause_by\", None) in role.watch_list)\n            # If message is proactive (no watch_list), coder should still be able to act (handled via initial targeting)\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\nclass Team:\n    \"\"\"Orchestrates the multi-agent workflow with deterministic pipeline and robust termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea = \"\"\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # termination stability: require same digest for consecutive confirms\n        self._last_digest: Optional[str] = None\n        self._streak = 0\n        self._required_streak = 2  # require two stable verifications\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        # kept for compatibility\n        pass\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {_preview(idea,200)}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Kickoff message targeted to coders (by profile)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            # Deterministic processing order\n            for role_type in self.order:\n                roles_of_type = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles_of_type:\n                    msgs = self.env.get_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # don't let role process its own message\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n                        try:\n                            response = await role.act(msg)\n                        except Exception as e:\n                            self.tracer.log(\"TEAM_ROLE_EXCEPTION\", \"Team\", f\"Role {role.name} crashed: {type(e).__name__}: {e}\")\n                            response = Message(content=f\"ERROR: {role.name} crashed: {e}\", role=role.profile, cause_by=\"exception\", sent_from=role.name)\n                        if response:\n                            # Provide routing hints if none present\n                            if not getattr(response, \"send_to\", None):\n                                # by default, route next stage based on pipeline\n                                if isinstance(role, SimpleCoder):\n                                    response.send_to = {SimpleTester.profile}\n                                elif isinstance(role, SimpleTester):\n                                    response.send_to = {SimpleReviewer.profile, SimpleVerifier.profile}\n                                elif isinstance(role, SimpleReviewer):\n                                    # If reviewer requests change, target coder\n                                    if isinstance(response.content, str) and response.content.strip().upper().startswith(\"REQUEST_CHANGE\"):\n                                        response.send_to = {SimpleCoder.profile}\n                                        response.cause_by = \"REQUEST_CHANGE\"\n                                    else:\n                                        response.send_to = {SimpleVerifier.profile}\n                                elif isinstance(role, SimpleVerifier):\n                                    response.send_to = {r.profile for r in self.env.roles}\n                            self.env.publish_message(response)\n                            any_activity = True\n                            # parse verification results for termination logic\n                            if isinstance(role, SimpleVerifier) and isinstance(response.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                    # try to extract digest\n                                    digest = None\n                                    for part in (response.content or \"\").split(\"|\"):\n                                        p = part.strip()\n                                        if p.startswith(\"digest=\"):\n                                            digest = p.split(\"=\",1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                        if self._streak >= self._required_streak:\n                                            verified = True\n                                    else:\n                                        # If no digest, require explicit reviewer approval to stop\n                                        self._streak = 0\n                                        self._last_digest = None\n                                        self.tracer.log(\"VERIFIER\", \"Team\", \"Pass without digest - not stable\")\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # Deadlock detection: nudge coder(s)\n                self.tracer.log(\"TEAM_DEADLOCK\", \"Team\", \"No activity this round; nudging coder(s)\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please propose initial code for '{_preview(self.idea,120)}'\", role=\"System\", sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # small sleep to allow async LLM to settle if applicable\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds} rounds; verified={verified} history_len={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n### Inspiration 3 (Score: 4.6667, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport re\nfrom typing import Tuple\n\n# -------- Utility helpers --------\n\ndef _preview(text: Optional[str], n: int = 140) -> str:\n    if not text:\n        return \"\"\n    return text if len(text) <= n else text[:n] + \"...\"\n\ndef _strip_code_fences(text: str) -> str:\n    \"\"\"Remove common Markdown code fences; keep Python content only.\"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    s = text.strip()\n    #\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n### Inspiration 4 (Score: 4.6667, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\n# Shared safe fallbacks to reduce failure modes and ensure determinism\n_DEFAULT_CODE = (\n    \"def solve(input_data):\\n\"\n    \"    \\\"\\\"\\\"Echo solver: returns the input data. Safe fallback implementation.\\\"\\\"\\\"\\n\"\n    \"    return input_data\\n\"\n)\n_DEFAULT_TESTS = (\n    \"import pytest\\n\\n\"\n    \"def test_solve_identity_behavior():\\n\"\n    \"    try:\\n\"\n    \"        from __main__ import solve\\n\"\n    \"    except Exception:\\n\"\n    \"        # If the function is not importable in this context, just assert True to keep syntax valid\\n\"\n    \"        assert True\\n\"\n    \"        return\\n\"\n    \"    assert solve(123) == 123\\n\"\n    \"    assert solve('abc') == 'abc'\\n\"\n)\n\ndef _strip_code_fences(text: str) -> str:\n    if not text:\n        return text\n    t = text.strip()\n    # Remove common Markdown fences\n    if t.startswith(\"\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n### Inspiration 5 (Score: 7.3048, Type: High-Performer)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic response\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nfrom typing import Iterable, Tuple\n\n# Goals:\n# - Reduce failure modes (clear roles, robust comms, retrying LLM/API calls)\n# - Explicit watch/trigger logic and deterministic sequencing\n# - Strong verification (syntax + tests + cross-reference) with digest stability\n# - Error handling: contain exceptions, produce fallback artifacts, limited retries\n# - Termination: require consecutive identical verification digests\n\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF = 0.25\nREQUIRED_STABLE_DIGESTS = 2\n\ndef _ensure_set(obj) -> Set[str]:\n    if obj is None:\n        return set()\n    if isinstance(obj, (set, list, tuple)):\n        return set(obj)\n    return {str(obj)}\n\nclass Action(ABC):\n    \"\"\"Abstract action with safe LLM call helper and deterministic fallback behavior.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    backoff: float = LLM_BACKOFF\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n                    if tracer:\n                        tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str):\n                    low = resp.strip().lower()\n                    if low == \"\" or low.startswith(\"error\") or \"error communicating\" in low:\n                        last_err = resp\n                        raise RuntimeError(resp)\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Received {len(resp or '')} chars\")\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"{attempt} failed: {last_err[:200]}\")\n                # exponential backoff + jitter\n                await asyncio.sleep(self.backoff * (2 ** (attempt - 1)) + random.uniform(0, 0.1))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_preview={(idea or '')[:120]}\")\n        if not idea or not idea.strip():\n            fallback = (\n                \"# Fallback placeholder implementation (no idea provided)\\n\"\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea -> fallback code\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python engineer. Produce a single parseable Python module implementing the task.\\n\"\n            \"Return only Python code. Include docstrings and at least one function or class.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = await self.safe_ask(messages)\n        # Validate syntax\n        try:\n            if isinstance(code, str) and code.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                raise RuntimeError(code)\n            ast.parse(code or \"\")\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed OK\")\n            return code\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_INVALID\", self.name, f\"Parse failed: {str(e)[:160]}\")\n            fallback = (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback deterministic implementation.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            return fallback\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"No code -> fallback tests\")\n            return (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n\n        truncated = (code or \"\")[:3500]\n        prompt = (\n            \"You are a QA engineer. Produce pytest-style tests for the Python module below.\\n\"\n            \"Return only the pytest code. Include at least one regular case and one edge case.\\n\\n\"\n            f\"Module:\\n{truncated}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = await self.safe_ask(messages)\n        # Heuristic validation\n        try:\n            if isinstance(tests, str) and tests.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                raise RuntimeError(tests)\n            parsed = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed))\n            if has_test_fn or has_assert:\n                if tracer:\n                    tracer.log(\"ACTION_VALIDATE\", self.name, \"Tests validated\")\n                return tests\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_INVALID\", self.name, f\"Tests invalid: {str(e)[:160]}\")\n        # fallback\n        fallback = (\n            \"def test_placeholder_positive():\\n\"\n            \"    \\\"\\\"\\\"Deterministic fallback test.\\\"\\\"\\\"\\n\"\n            \"    assert True\\n\"\n        )\n        if tracer:\n            tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback tests\")\n        return fallback\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if self.is_human:\n            msg = \"HUMAN_REVIEW: manual check recommended\\nREVIEW_DECISION: REQUEST_CHANGE\"\n            if tracer:\n                tracer.log(\"ACTION_HUMAN\", self.name, \"Simulated human review\")\n            return msg\n\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Automatic review\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review and end with a line:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGE\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        review = await self.safe_ask(messages)\n        # Ensure decision present\n        if not isinstance(review, str) or \"REVIEW_DECISION:\" not in review:\n            # heuristic decision\n            decision = \"APPROVE\" if (\"def \" in (code or \"\") or \"class \" in (code or \"\")) and (\"assert\" in (tests or \"\")) else \"REQUEST_CHANGE\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Inferred decision {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verification started\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n        tests_has_assert = False\n        cross_ref_ok = False\n\n        # Code syntax & entities\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(\"code_syntax: ok\")\n            details.append(f\"code_entities:{len(code_entities)}\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:140]})\")\n            parsed_code = None\n\n        # Tests syntax & asserts\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n            tests_has_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            tests_ok = tests_has_assert or tests_has_testfn\n            details.append(\"tests_syntax: ok\" if tests_ok else \"tests_syntax: ok_but_no_asserts_or_testfn\")\n            details.append(f\"tests_asserts:{tests_has_assert}\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:140]})\")\n            parsed_tests = None\n\n        # Cross references\n        if parsed_code and parsed_tests and code_entities:\n            test_names = {n.id for n in ast.walk(parsed_tests) if isinstance(n, ast.Name)}\n            text_overlap = any(name in (tests or \"\") for name in code_entities)\n            inter = code_entities & test_names\n            cross_ref_ok = bool(inter) or text_overlap\n            details.append(f\"tests_refs_count:{len(inter)}\")\n        else:\n            details.append(\"tests_refs_count:0\")\n\n        verified = all([code_ok, tests_ok, bool(code_entities), cross_ref_ok])\n        digest_src = ((code or \"\") + \"\\n--\\n\" + (tests or \"\")).encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with one primary action, explicit watch triggers, and per-role delivery tracking.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = kwargs.get(\"env\", None)\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: Iterable[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", str(a)) for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed:\n            return False\n        send_to = _ensure_set(getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None))\n        if send_to:\n            if self.profile in send_to or self.name in send_to or \"*\" in send_to:\n                return True\n            return False\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg {getattr(message,'id',None)}\")\n            # mark as processed to avoid repeated unnecessary checks\n            if getattr(message, \"id\", None):\n                self._processed.add(message.id)\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already handled {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Running {self.action.name} for msg={msg_id}\")\n\n        try:\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                out = await self.action.run(idea)\n                send_to = {\"SimpleTester\"}\n            elif isinstance(self.action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and message.cause_by == SimpleWriteCode.name else \"\"\n                if not code_text and self.env:\n                    code_msg = self.env.get_latest_artifact([SimpleWriteCode.name])\n                    code_text = code_msg.content if code_msg else \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleWriteReview):\n                code_msg = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                tests_msg = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                # route based on decision\n                if \"REVIEW_DECISION: REQUEST_CHANGE\" in (out or \"\") or \"REQUEST_CHANGE\" in (out or \"\"):\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleVerify):\n                code_msg = self.env.get_latest_artifact([SimpleWriteCode.name]) if self.env else None\n                tests_msg = self.env.get_latest_artifact([SimpleWriteTest.name]) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = set(r.profile for r in (self.env.roles if self.env else []))\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)}\"\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, err[:200])\n            # produce a message pointing to coder for recovery\n            out = err\n            send_to = {\"SimpleCoder\"}\n\n        # mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n\n        # create Message (pydantic or fallback compatible)\n        response = Message(\n            content=out or \"\",\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"\",\n            sent_from=self.name,\n            send_to=set(send_to)\n        )\n\n        # mark produced id locally to avoid self-processing\n        try:\n            self._processed.add(response.id)\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={sorted(list(response.send_to))}\")\n        return response\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Message bus: stores history, delivered tracking and artifact indexing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # per-role delivered ids\n        self.delivered: Dict[str, Set[str]] = {}\n        # by cause index\n        self.by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self.delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile}) watching {sorted(list(role.watch_list))}\")\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        try:\n            message.send_to = _ensure_set(getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None))\n        except Exception:\n            message.send_to = set()\n        # ensure id\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", \"\"):\n            self.by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} to={sorted(list(message.send_to))} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self.delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            # never send back a role's own messages\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            targeted = bool(msg.send_to and (role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to))\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                seen.add(mid)\n        return out\n\n    def get_latest_artifact(self, cause_names: Iterable[str]) -> Optional[Message]:\n        for cname in cause_names:\n            msgs = self.by_cause.get(cname, [])\n            if msgs:\n                return msgs[-1]\n        return None\n\nclass Team:\n    \"\"\"Orchestrates the multi-agent pipeline deterministically, with stable verification termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = REQUIRED_STABLE_DIGESTS\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        # placeholder for compatibility\n        pass\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {(idea or '')[:200]}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_required={self._required_streak})\")\n        # Kickoff: target coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        rounds_executed = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n            new_messages = 0\n\n            for RoleType in order:\n                roles = [r for r in self.env.roles if isinstance(r, RoleType)]\n                for role in roles:\n                    # Ensure coder sees kickoff in first round\n                    incoming = self.env.get_messages_for_role(role)\n                    if isinstance(role, SimpleCoder) and rnd == 1 and not incoming:\n                        incoming = [initial]\n                        self.env.delivered.setdefault(role.name, set()).add(initial.id)\n                    for msg in incoming:\n                        try:\n                            resp = await role.act(msg)\n                        except Exception as e:\n                            self.tracer.log(\"ROLE_ACT_EXCEPTION\", role.name, f\"{type(e).__name__}: {e}\")\n                            resp = Message(content=f\"ERROR: role {role.name} crashed: {e}\", role=role.profile, cause_by=\"RoleCrash\", sent_from=role.name, send_to={\"SimpleCoder\"})\n                        if resp:\n                            self.env.publish_message(resp)\n                            any_activity = True\n                            new_messages += 1\n                            # If verifier produced PASS, update streak logic\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                digest = None\n                                for part in resp.content.split(\"|\"):\n                                    p = part.strip()\n                                    if p.startswith(\"digest=\"):\n                                        digest = p.split(\"=\", 1)[1]\n                                        break\n                                if digest:\n                                    if digest == self._last_digest:\n                                        self._streak += 1\n                                    else:\n                                        self._last_digest = digest\n                                        self._streak = 1\n                                    self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                else:\n                                    # treat as non-stable\n                                    self._last_digest = None\n                                    self._streak = 0\n                            elif isinstance(role, SimpleVerifier):\n                                # reset streak on non-pass\n                                if self._streak > 0:\n                                    self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"Resetting streak from {self._streak} to 0\")\n                                self._streak = 0\n                                self._last_digest = None\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed new_messages={new_messages} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require stable digest streak and at least one round with no new artifacts after streak reached\n            if self._streak >= self._required_streak:\n                verified = True\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Stable verification: streak={self._streak}\")\n                break\n\n            # deadlock detection and nudge\n            if not any_activity:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No activity this round; nudging coder(s)\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: please propose or refine implementation for: {self.idea}\",\n                            instruct_content=self.idea,\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.profile}\n                        )\n                        self.env.publish_message(nudge)\n                        any_activity = True\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project completed rounds={rounds_executed} verified={verified}\")\n        summary = f\"Project '{self.idea}' finished rounds={rounds_executed} messages={len(self.env.history)} verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (5.167)\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nfrom typing import Tuple\n\n# Simplification + reliability improvements:\n# - Single responsibility per role and explicit routing\n# - Normalize/send explicit recipients to avoid missed triggers\n# - Resilient LLM calls with retries, backoff and deterministic local fallbacks\n# - Strong verification: syntax, asserts in tests, and tests reference code names\n# - Stable termination: require 2 consecutive PASSes from verifier\n# - Clear error surfaces and no silent failures\n\n_DEFAULT_CODE = (\n    \"def solve(input_data=None):\\n\"\n    \"    \\\"\\\"\\\"Fallback implementation: returns the input unchanged.\\\"\\\"\\\"\\n\"\n    \"    return input_data\\n\"\n)\n\n_DEFAULT_TESTS = (\n    \"def test_solve_identity():\\n\"\n    \"    \\\"\\\"\\\"Fallback tests for solve() identity behavior.\\\"\\\"\\\"\\n\"\n    \"    assert solve(123) == 123\\n\"\n    \"    assert solve('a') == 'a'\\n\"\n)\n\ndef _strip_code_fences(text: str) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    s = text.strip()\n    # Remove\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Iterable\n\n# Design targets:\n# - Clear single-responsibility roles\n# - Robust LLM wrapper with retries/backoff and deterministic fallback\n# - Explicit routing via send_to\n# - Idempotent delivery using per-role delivered sets\n# - Strong verification and stable termination (consecutive identical digests)\n# - Contained error handling and retry for transient failures\n\nLLM_RETRIES = 3\nLLM_BACKOFF = 0.4\nROLE_ATTEMPTS = 2\nROLE_TIMEOUT = 20  # seconds per role invocation\nSTABLE_VERIFICATION_REQUIRED = 2\nNO_PROGRESS_LIMIT = 2  # rounds before nudging/stopping\n\ndef _normalize_send_to(msg: Message) -> set:\n    s = getattr(msg, \"send_to\", None)\n    if s is None:\n        try:\n            s = set(getattr(msg, \"sent_to\", set()) or set())\n        except Exception:\n            s = set()\n    return set(s or set())\n\nclass Action(ABC):\n    \"\"\"Base action with LLM-safe ask helper and deterministic fallback semantics.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_RETRIES\n    backoff: float = LLM_BACKOFF\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def ask_llm(self, messages: List[Dict[str, str]]) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface missing; using deterministic fallback\")\n            return \"LLM_UNAVAILABLE\"\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty LLM response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Received response len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}:{str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < self.max_retries:\n                    await asyncio.sleep(self.backoff * (2 ** (attempt - 1)) + random.uniform(0, 0.1))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea -> deterministic fallback code\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Return only valid Python code implementing the task below. \"\n            \"Include docstrings and input validation where appropriate.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.ask_llm(messages)\n        # deterministic fallback if LLM failed\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> fallback code\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback due to LLM failure.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        # validate syntax\n        try:\n            ast.parse(resp)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, f\"Parse error: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback because generated code did not parse.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code len={len(resp)}\")\n        return resp\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"No code provided -> fallback tests\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        truncated = (code or \"\")[:3500]\n        prompt = (\n            \"You are a QA engineer. Produce pytest-style tests for the provided module. Return only test code.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.ask_llm(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> fallback tests\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        # heuristic validation\n        try:\n            parsed = ast.parse(resp)\n            has_test = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed)) or (\"assert\" in resp)\n            if not (has_test or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, \"Generated tests invalid -> fallback\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated tests len={len(resp)}\")\n        return resp\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # static pre-checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{e}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{e}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: manual inspection recommended\\nVERDICT: REQUEST_CHANGES\" if issues else \"HUMAN_REVIEW: ok\\nVERDICT: APPROVE\"\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review and end with a single-line VERDICT: APPROVE or VERDICT: REQUEST_CHANGES.\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\nCode (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.ask_llm(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> request changes\")\n            return \"VERDICT: REQUEST_CHANGES\\nAutomated reviewer failed\"\n        if \"VERDICT:\" not in resp:\n            verdict = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            resp = resp.strip() + f\"\\n\\nVERDICT: {verdict}\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review len={len(resp)}\")\n        return resp\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        refs_ok = False\n        code_names = set()\n\n        # code syntax\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            code_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            details.append(f\"code_defs:{len(code_names)}\")\n        except Exception as e:\n            details.append(f\"code_parse_error:{e}\")\n\n        # tests syntax + asserts\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            details.append(\"tests_presence:ok\" if tests_ok else \"tests_presence:none\")\n        except Exception as e:\n            details.append(f\"tests_parse_error:{e}\")\n\n        # cross-reference\n        if code_names and tests_ok:\n            txt = tests or \"\"\n            for nm in code_names:\n                if nm and nm in txt:\n                    refs_ok = True\n                    break\n            details.append(\"tests_reference_ok\" if refs_ok else \"tests_reference_none\")\n        else:\n            details.append(\"tests_reference_skipped\")\n\n        verified = code_ok and tests_ok and refs_ok\n        # digest for stability\n        try:\n            digest = hashlib.sha256(((code or \"\") + \"\\n--\\n\" + (tests or \"\")).encode(\"utf-8\")).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with single primary action, watch_list, and processed-tracking.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = None\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: Iterable[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", str(a)) for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        targets = _normalize_send_to(msg)\n        if targets:\n            if self.profile in targets or self.name in targets:\n                return True\n            return False\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        # default: user input triggers coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg={getattr(message,'id',None)}\")\n            # mark as processed to avoid re-evaluating\n            if getattr(message, \"id\", None):\n                self._processed.add(message.id)\n            return None\n\n        # prepare input for action based on type\n        try:\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                out = await self.action.run(idea or \"\")\n                send_to = {\"SimpleTester\"}\n            elif isinstance(self.action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and message.cause_by == SimpleWriteCode.name else \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest.content if latest else \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleWriteReview):\n                latest_code = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                latest_tests = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(latest_code.content if latest_code else \"\", latest_tests.content if latest_tests else \"\")\n                lowered = (out or \"\").lower()\n                if \"request\" in lowered or \"fail\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(self.action, SimpleVerify):\n                latest_code = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                latest_tests = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(latest_code.content if latest_code else \"\", latest_tests.content if latest_tests else \"\")\n                send_to = set()  # broadcast handled by orchestrator\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err[:200])\n            out = err\n            send_to = {\"SimpleCoder\"}\n\n        # mark processed to ensure idempotency\n        if message and getattr(message, \"id\", None):\n            self._processed.add(message.id)\n\n        resp = Message(content=out or \"\", role=self.profile, cause_by=self.action.name if self.action else \"None\", sent_from=self.name, send_to=set(send_to))\n        # mark produced id as processed locally\n        try:\n            self._processed.add(resp.id)\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={getattr(resp,'id',None)} send_to={list(getattr(resp,'send_to',set()))}\")\n        return resp\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self.watch([])\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Message bus with per-role delivered tracking and artifact indexing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._delivered: Dict[str, Set[str]] = {}\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        try:\n            message.send_to = _normalize_send_to(message)\n        except Exception:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        # ensure id exists\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_delivered(self, role: Role, message: Message):\n        if not getattr(message, \"id\", None):\n            return\n        self._delivered.setdefault(role.name, set()).add(message.id)\n        if self.tracer:\n            self.tracer.log(\"ENV_MARK_DELIVERED\", \"Environment\", f\"{role.name} delivered {message.id}\")\n\n    def get_pending_for(self, role: Role) -> List[Message]:\n        \"\"\"Return messages not yet delivered to role that target or watch the role.\"\"\"\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            # never deliver own messages\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            targeted = bool(msg.send_to and (role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to))\n            watched = getattr(msg, \"cause_by\", None) in getattr(role, \"watch_list\", set())\n            if targeted or watched:\n                out.append(msg)\n                seen.add(mid)\n        return out\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        msgs = self._by_cause.get(cause, [])\n        return msgs[-1] if msgs else None\n\nclass Team:\n    \"\"\"Orchestrator with deterministic sequencing, verifier stability, and controlled retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = STABLE_VERIFICATION_REQUIRED\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        # placeholder for compatibility\n        pass\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        attempts = 0\n        while attempts < ROLE_ATTEMPTS:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=ROLE_TIMEOUT)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempts} for msg {getattr(msg,'id',None)}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempts}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.05 * attempts)\n        # return an explicit error message artifact\n        err = Message(content=f\"ERROR: role {role.name} failed processing message {getattr(msg,'id',None)} after {attempts} attempts\",\n                      role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need stable_passes={self._required_streak}\")\n        # initial message targeted to coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial = Message(content=f\"Let's work on this project: {self.idea}\",\n                          instruct_content=self.idea,\n                          role=\"Human\",\n                          sent_from=\"User\",\n                          cause_by=\"UserInput\",\n                          send_to=coder_profiles)\n        self.env.publish_message(initial)\n\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            produced = 0\n            for RoleClass in order:\n                roles = [r for r in self.env.roles if isinstance(r, RoleClass)]\n                for role in roles:\n                    pending = self.env.get_pending_for(role)\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and rnd == 1:\n                        if initial.id not in self.env._delivered.get(role.name, set()):\n                            pending = [initial] + pending\n                    for msg in pending:\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            self.env.mark_delivered(role, msg)\n                            continue\n                        resp = await self._invoke_role(role, msg)\n                        self.env.mark_delivered(role, msg)\n                        if resp:\n                            # ensure routing hints exist\n                            if getattr(resp, \"send_to\", None) is None:\n                                try:\n                                    resp.send_to = set(getattr(resp, \"sent_to\", set()) or set())\n                                except Exception:\n                                    resp.send_to = set()\n                            self.env.publish_message(resp)\n                            produced += 1\n                            # verifier handling\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    # extract digest\n                                    digest = None\n                                    for part in resp.content.split(\"|\"):\n                                        p = part.strip()\n                                        if p.startswith(\"digest=\"):\n                                            digest = p.split(\"=\", 1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    else:\n                                        self._last_digest = None\n                                        self._streak = 1\n                                else:\n                                    if self._streak > 0:\n                                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                                    self._streak = 0\n                                    self._last_digest = None\n            # progress detection\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed produced={produced} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require consecutive identical verification digests\n            if self._streak >= self._required_streak:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping early\")\n                break\n\n            # handle no progress\n            if no_progress_rounds >= NO_PROGRESS_LIMIT:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds; terminating early\")\n                break\n            elif produced == 0:\n                # nudge coder(s)\n                self.tracer.log(\"TEAM_NUDGE\", \"Team\", \"No new artifacts this round; nudging coder(s)\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please refine implementation for: {self.idea}\",\n                                        instruct_content=self.idea,\n                                        role=\"System\",\n                                        sent_from=\"Orchestrator\",\n                                        cause_by=\"Nudge\",\n                                        send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # small pause to allow immediate processing\n                await asyncio.sleep(0.01)\n            else:\n                # cooperative pause\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' completed after {rnd} rounds with {len(self.env.history)} messages. verifier_streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}