{"id": "7c53c365-b77e-45a4-b6e3-468fd6a14690", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic response\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport time\nfrom typing import Tuple\n\n# Utility for short previews in logs\ndef _preview(text: Optional[str], length: int = 120) -> str:\n    if not text:\n        return \"\"\n    return (text[:length] + \"...\") if len(text) > length else text\n\n# Base Action with robust LLM calling, retry/backoff, and deterministic fallbacks\nclass Action(ABC):\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper around LLMInterface.ask with retries, backoff, and logging.\n        Returns deterministic fallback string on fatal failure.\n        \"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_FALLBACK: no LLM available\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        last_exc = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                res = await self.llm.ask(messages)\n                # treat explicit \"Error\" responses as failures to retry\n                if isinstance(res, str) and res.startswith(\"Error\"):\n                    last_exc = res\n                    if tracer:\n                        tracer.log(\"LLM_RESPONSE_ERROR\", self.name, _preview(res, 240))\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                return res\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:200]}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_exc)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted\n        failure = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_exc}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure)\n        return failure\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\n# Concrete actions\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea={_preview(idea,200)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single valid Python module implementing the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only Python source code (no surrounding markdown or explanation).\\n\"\n            \"- Include at least one function or class, a module docstring, and basic input validation or error handling.\\n\"\n            \"- Keep code self-contained and parseable by ast.parse().\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        res = await self._safe_ask(messages)\n        # Validate basic structure\n        code = res or \"\"\n        try:\n            ast.parse(code)\n        except Exception:\n            # fallback deterministic code\n            fallback = (\n                \"def solve(input_data):\\n\"\n                \"    \\\"\\\"\\\"Fallback deterministic implementation: echoes input_data.\\\"\\\"\\\"\\n\"\n                \"    return input_data\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Generated code invalid; using fallback\")\n            code = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_len={len(code)} preview={_preview(code,120)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-compatible tests for the provided Python module.\\n\\n\"\n            \"Module (truncated):\\n\"\n            f\"{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-style tests only (no explanation).\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Use assert statements and reference public functions/classes present in the module.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        res = await self._safe_ask(messages)\n        tests = res or \"\"\n        # Heuristic validation\n        if not tests or (\"assert \" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test to ensure syntactic validity.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM produced no valid tests; using fallback\")\n            tests = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)} preview={_preview(tests,120)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_DECISION: APPROVE\\nHuman review simulated: minor suggestions.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review that starts with either:\\n\"\n            \"- 'REVIEW_DECISION: APPROVE' or\\n\"\n            \"- 'REVIEW_DECISION: REQUEST_CHANGES'\\n\\n\"\n            \"Then provide 1-3 short actionable bullets.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing reviews.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        res = await self._safe_ask(messages)\n        review = res or \"\"\n        if \"REVIEW_DECISION:\" not in review:\n            # Conservative default\n            decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and ((\"def \" in (code or \"\")) or (\"class \" in (code or \"\"))) else \"REQUEST_CHANGES\"\n            review = f\"REVIEW_DECISION: {decision}\\nAutomated review: no explicit decision returned; falling back to {decision}.\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"Review lacked explicit decision; applied heuristic\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)} preview={_preview(review,120)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = True\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        # Semantic checks: at least one function/class\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    entities.add(node.name)\n            details.append(f\"code_entities_count: {len(entities)}\")\n\n        # Tests reference code entities and include asserts\n        tests_has_assert = False\n        referenced = False\n        if parsed_tests:\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Assert):\n                    tests_has_assert = True\n                if isinstance(node, ast.Name) and node.id in entities:\n                    referenced = True\n            details.append(f\"tests_has_assert: {tests_has_assert}\")\n            details.append(f\"tests_references_entities: {referenced}\")\n\n        # Determine pass/fail\n        passed = all([code_ok, tests_ok, len(entities) > 0, tests_has_assert, referenced])\n        # Create digest for artifact stability\n        digest_input = (code or \"\").encode(\"utf-8\") + b\"\\n==\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_input).hexdigest()[:12]\n        result = f\"VERIFICATION_RESULT: {'PASS' if passed else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# Roles with clear responsibilities and idempotency\nclass Role(ABC):\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: Set[str] = set()  # action names to watch (cause_by)\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = set()\n        self.env: Optional['Environment'] = None\n        # processed message ids for idempotency\n        self._processed: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store action names\n        self.watch_list = {getattr(a, \"name\", getattr(a, \"__name__\", \"\")) for a in actions}\n\n    def should_respond_to(self, msg: Message) -> bool:\n        # Respond if explicitly targeted\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n        if targets:\n            if isinstance(targets, (set, list)):\n                if self.name in targets or self.profile in targets:\n                    return True\n            else:\n                if targets == self.name or targets == self.profile:\n                    return True\n        # Or if message cause_by is in watch list\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.actions:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n        action = self.actions[0]\n        msg_id = getattr(message, \"id\", None) if message else None\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {msg_id}\")\n            return None\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Acting on message id={msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Prepare inputs based on action type\n            if isinstance(action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                out = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # Prefer code included in message, else fetch latest from env\n                code_src = getattr(message, \"content\", \"\") if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name else \"\"\n                if not code_src and self.env:\n                    code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                out = await action.run(code_src)\n            elif isinstance(action, SimpleWriteReview):\n                code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                tests_src = self.env.find_latest_content_by_cause(SimpleWriteTest.name) or \"\"\n                out = await action.run(code_src, tests_src)\n            elif isinstance(action, SimpleVerify):\n                code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                tests_src = self.env.find_latest_content_by_cause(SimpleWriteTest.name) or \"\"\n                out = await action.run(code_src, tests_src)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                out = await action.run(payload)\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark processed to avoid repeated failures\n            if msg_id:\n                self._processed.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build response message\n        response = Message(\n            content=out,\n            role=self.profile,\n            cause_by=action.name,\n            sent_from=self.name,\n            send_to=set()\n        )\n        # Mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={response.id} cause_by={response.cause_by} preview={_preview(response.content,120)}\")\n        return response\n\n# Concrete Roles\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Triggered by user input or explicit nudges\n        self._watch([])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n# Environment: message bus with deterministic routing and delivery tracking\nclass Environment:\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # message_id -> set(role.name) delivered\n        self.delivered: Dict[str, Set[str]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile})\")\n\n    def publish_message(self, message: Message):\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self.delivered.setdefault(message.id, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content,200)} send_to={sorted(list(getattr(message,'send_to',set()))[:10])}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages that the role should process, respecting explicit addressing and watch_list.\n        Excludes messages already delivered to that role.\n        \"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            already = role.name in self.delivered.get(msg.id, set())\n            if already:\n                continue\n            # explicit addressing\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            targeted = False\n            if targets:\n                if isinstance(targets, (set, list)):\n                    if role.name in targets or role.profile in targets:\n                        targeted = True\n                else:\n                    if targets == role.name or targets == role.profile:\n                        targeted = True\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                # mark tentatively delivered to avoid reselecting in same cycle\n                self.delivered.setdefault(msg.id, set()).add(role.name)\n        return out\n\n    def find_latest_content_by_cause(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return msg.content\n        return None\n\n# Team orchestrator with robust termination and confirmation\nclass Team:\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        # deterministic pipeline order\n        self.pipeline = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # verification stability: require same digest twice\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {_preview(idea,200)}\")\n\n    async def _safe_role_call(self, role: Role, message: Optional[Message], timeout: float = 60.0, max_retries: int = 1) -> Optional[Message]:\n        \"\"\"\n        Call role.act with retries and timeout. Returns a Message even on failure to allow robust flow.\n        \"\"\"\n        tracer = self.tracer\n        last_err = None\n        for attempt in range(1, max_retries + 2):\n            try:\n                if tracer:\n                    tracer.log(\"ROLE_CALL\", role.name, f\"Attempt {attempt} for message {getattr(message,'id',None)}\")\n                coro = role.act(message)\n                resp = await asyncio.wait_for(coro, timeout=timeout)\n                return resp\n            except asyncio.TimeoutError:\n                last_err = \"timeout\"\n                if tracer:\n                    tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempt}\")\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)[:200]}\"\n                if tracer:\n                    tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempt}: {last_err}\")\n            await asyncio.sleep(0.2 * attempt)\n        # return error message as response to keep pipeline deterministic\n        err_msg = Message(content=f\"ERROR: role {role.name} failed after retries: {last_err}\", role=role.profile, cause_by=\"System\", sent_from=role.name)\n        return err_msg\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # initial message targeted to coders\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds_executed = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            activity = False\n\n            # deterministic pipeline\n            for role_cls in self.pipeline:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    msgs = self.env.get_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # Avoid processing role's own messages\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n                        resp = await self._safe_role_call(role, msg)\n                        if resp:\n                            # ensure cause_by set\n                            if not getattr(resp, \"cause_by\", None):\n                                resp.cause_by = getattr(role.actions[0], \"name\", \"\")\n                            self.env.publish_message(resp)\n                            activity = True\n                            # If verifier produced a PASS, examine digest and enforce streak\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                # parse digest\n                                digest = None\n                                for part in (resp.content or \"\").split(\"|\"):\n                                    part = part.strip()\n                                    if part.startswith(\"digest=\"):\n                                        digest = part.split(\"=\", 1)[1]\n                                        break\n                                if digest:\n                                    if digest == self._last_digest:\n                                        self._streak += 1\n                                    else:\n                                        self._last_digest = digest\n                                        self._streak = 1\n                                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    if self._streak >= self._required_streak:\n                                        verified = True\n                                else:\n                                    # no digest, cannot confirm stability\n                                    self._streak = 0\n                                    self._last_digest = None\n                                    self.tracer.log(\"VERIFIER_NO_DIGEST\", \"Team\", \"Pass without digest - not stable\")\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed activity={activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verified stable; stopping at round {rnd}\")\n                break\n            if not activity:\n                # deadlock handling: nudge coders once\n                self.tracer.log(\"TEAM_DEADLOCK\", \"Team\", \"No activity; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: propose code for '{_preview(self.idea,120)}'\", role=\"System\", sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.name})\n                        self.env.publish_message(nudge)\n                # give a short pause\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds_executed} rounds verified={verified} messages={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds_executed} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "0f7744d7-c700-421a-bcfb-a3b48c61aaad", "generation": 2, "timestamp": 1754656090.6733103, "iteration_found": 51, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "unterminated string literal (detected at line 182) (tmp601s1kla.py, line 182)"}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.0000\n- combined_score: 0.0000\n- avg_failures_per_task: 14.0000\n- error: unterminated string literal (detected at line 182) (tmp601s1kla.py, line 182)\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 4\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.0000, combined_score: 0.0000, avg_failures_per_task: 14.0000, error: unterminated string literal (detected at line 182) (tmp601s1kla.py, line 182)\n- Outcome: Mixed results\n\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 7.1111)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1667), Performs well on avg_failures_per_task (5.0000), Performs well on total_failures (30.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 2 (Score: 3.2125)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport hashlib\nimport ast\nfrom collections import defaultdict\n\ndef artifact_preview(text: Optional[str], length: int = 80) -> str:\n    if not text:\n        return \"\"\n    return (text[:length] + \"...\") if len(text) > length else text\n\nclass Action(ABC):\n    \"\"\"\n    Base action class.\n    Responsibilities:\n    - Provide run(...) coroutine performing the action.\n    - Encapsulate robust LLM calls with retries, backoff and logging.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper for LLM calls:\n        - Retries on exceptions or error markers.\n        - Exponential backoff.\n        - Logs each attempt and final outcome.\n        - Returns explicit failure marker on exhaustion.\n        \"\"\"\n        if not self.llm:\n            # Deterministic fallback for testing without LLM\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                # LLMInterface uses \"Error:\" prefix for non-200 responses or exceptions returned as strings\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error: {resp[:200]}\")\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # Accept string responses (successful)\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)[:200]}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, last_err)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                continue\n\n        failure_msg = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_ABORT\", self.name, failure_msg)\n        return failure_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate Python module code from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea={artifact_preview(idea, 200)}\")\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module implementing the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no surrounding markdown).\\n\"\n            \"- Include docstrings, input validation and basic error handling.\\n            \"\n            \"- Ensure at least one function or class is defined.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self.safe_ask(messages)\n        if not code or not any(token in code for token in (\"def \", \"class \")):\n            # deterministic fallback if LLM failed or produced non-code\n            fallback = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"LLM produced no valid code; using fallback\")\n            code = fallback\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"generated_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following Python module.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Use assert statements and include docstrings for tests.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self.safe_ask(messages)\n        # Fallback if the LLM response doesn't look like tests\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"LLM produced no valid tests; using fallback\")\n            tests = fallback\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Produce a concise review; include explicit REVIEW_DECISION.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: APPROVE\\nREVIEW_DECISION: APPROVE\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Provide a concise review and an explicit decision line:\\n\"\n                \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REJECT\\n\\n\"\n                \"Code (truncated):\\n\"\n                f\"{(code or '')[:2000]}\\n\\nTests (truncated):\\n\"\n                f\"{(tests or '')[:2000]}\\n\\n\"\n                \"Focus on bugs, missing tests and actionable improvements.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self.safe_ask(messages)\n            if not review or \"REVIEW_DECISION:\" not in review:\n                # derive decision heuristically\n                decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REJECT\"\n                review = (review or \"Automated review\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"\n    Verify code and tests using deterministic checks:\n    - Syntax parsing\n    - At least one function/class in code\n    - Tests include asserts and reference code entities\n    - Produces VERIFICATION_RESULT: PASS/FAIL and digest\n    \"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_code = None\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = True\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_tests = None\n\n        # Semantic checks\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            if code_entities:\n                details.append(f\"code_entities: {sorted(list(code_entities))[:6]}\")\n            else:\n                details.append(\"code_entities: none\")\n\n        tests_has_assert = False\n        tests_references = set()\n        if parsed_tests:\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Assert):\n                    tests_has_assert = True\n                if isinstance(node, ast.Name):\n                    tests_references.add(node.id)\n            details.append(f\"tests_asserts: {tests_has_assert}\")\n            inter = code_entities & tests_references\n            details.append(f\"tests_references_code_entities: {sorted(list(inter))[:6]}\")\n\n        # Determine pass/fail\n        passed = all([code_ok, tests_ok, bool(code_entities), tests_has_assert, len(code_entities & tests_references) > 0])\n        # Compute digest of current artifacts for stability detection\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if passed else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"\n    Base Role:\n    - Single primary responsibility (one action).\n    - Maintains processed message ids to ensure idempotency.\n    - Uses environment subscriptions for explicit routing.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed messages\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Execute the role's primary action in response to a message.\n        Ensures idempotency by skipping already processed messages.\n        Returns a Message or None.\n        \"\"\"\n        if not self.action:\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping already processed message {msg_id}\")\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Acting on message {msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Extract inputs depending on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                result = await self.action.run(idea)\n            elif isinstance(self.action, SimpleWriteTest):\n                # Expect code in message.content, or fetch last code from env\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and self.env:\n                    code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code)\n            elif isinstance(self.action, SimpleWriteReview):\n                # Need both code and tests\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            elif isinstance(self.action, SimpleVerify):\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            else:\n                # Generic action fallback\n                result = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark message as processed to avoid repeated failing attempts\n            if msg_id:\n                self._processed.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"\",\n            sent_from=self.name,\n            send_to=set()  # environment will fill routing based on subscriptions if left empty\n        )\n\n        # Mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message {response.id} cause_by={response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # coder is typically triggered by UserInput (explicit send_to)\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"\n    Environment:\n    - Holds history of Messages.\n    - Maintains action_name -> roles subscriptions.\n    - Provides helpers to route messages deterministically and fetch latest artifacts.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # subscriptions mapping: action_name -> set(role.name)\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)\n        # track delivery: message_id -> set(role.name) delivered\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile})\")\n        for watched in role.watch_list:\n            self.subscriptions[watched.name].add(role.name)\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        if getattr(message, \"send_to\", None) is None:\n            message.send_to = set()\n        self.history.append(message)\n        # initialize delivered set\n        self.delivered[message.id] = set()\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={artifact_preview(message.content,200)} send_to={sorted(list(message.send_to)[:10])}\")\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[str]:\n        \"\"\"Return content of the latest message with cause_by.\"\"\"\n        for msg in reversed(self.history):\n            if msg.cause_by == cause_by:\n                return msg.content\n        return None\n\n    def get_routable_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Determine messages a role should process:\n        - Explicitly targeted via send_to (role.name or role.profile)\n        - OR messages caused by an action the role watches\n        - Excludes messages already delivered to that role\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            targets = getattr(msg, \"send_to\", None) or set()\n            if role.name in targets or role.profile in targets:\n                targeted = True\n            watched = False\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    watched = True\n                    break\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\nclass Team:\n    \"\"\"\n    Team orchestrator:\n    - Deterministic order of role processing.\n    - Explicit routing via Environment.subscriptions and message.send_to.\n    - Termination requires stable verification: same digest consecutively.\n    - Robust handling of role/LLM failures and retries at action level.\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment = 20.0\n        self.idea = \"\"\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # verification stability\n        self._last_digest: Optional[str] = None\n        self._streak = 0\n        self._required_streak = 2\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {artifact_preview(idea,200)}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # initial kickoff: targeted to coders explicitly\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            # deterministic role order\n            for role_type in self.order:\n                roles_of_type = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles_of_type:\n                    msgs = self.env.get_routable_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # guard redundant processing at role level\n                        try:\n                            response = await role.act(msg)\n                            # mark delivery/processing\n                            # Environment.delivery was updated in get_routable_messages_for_role\n                            any_activity = True\n                            if response:\n                                # route response: if send_to empty, fill subscribers watching this action\n                                if not getattr(response, \"send_to\", None):\n                                    # find roles who watch this action\n                                    subscribers = self.env.subscriptions.get(response.cause_by, set())\n                                    response.send_to = set(subscribers)\n                                self.env.publish_message(response)\n                                # If verifier directly produced PASS, parse it\n                                if response.cause_by == SimpleVerify.name and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                    # parse digest\n                                    digest = None\n                                    for part in (response.content or \"\").split(\"|\"):\n                                        part = part.strip()\n                                        if part.startswith(\"digest=\"):\n                                            digest = part.split(\"=\",1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                        if self._streak >= self._required_streak:\n                                            verified = True\n                                    else:\n                                        # no digest, treat as non-stable pass\n                                        self._streak = 0\n                                        self._last_digest = None\n                                        self.tracer.log(\"VERIFIER\", \"Team\", \"Pass without digest - not considered stable\")\n                            # record that role processed msg to ensure idempotency\n                            self.env.delivered[msg.id].add(role.name)\n                        except Exception as e:\n                            self.tracer.log(\"TEAM_ROLE_ERROR\", \"Team\", f\"Role {role.name} raised {type(e).__name__}: {str(e)[:200]}\")\n                            continue\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed; any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # deadlock: allow coders to re-attempt once by targeting them explicitly\n                self.tracer.log(\"TEAM_DEADLOCK\", \"Team\", \"No activity this round; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        # create a nudge message targeting that coder only if they haven't processed the initial\n                        if not self.env.has_been_processed_by if False else True:\n                            nudge = Message(content=f\"Nudge: please propose initial code for '{artifact_preview(self.idea,120)}'\", role=\"System\", sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.name})\n                            self.env.publish_message(nudge)\n                # short pause to allow asynchronous LLM processing in environments where real LLM calls might be queued\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds} rounds; verified={verified} history_len={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n### Program 3 (Score: 3.2125)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport re\nfrom typing import Tuple\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry + logging utilities\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _call_llm_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, exponential backoff, and structured tracing.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_exc = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # Deterministic fallback for environments without aiohttp/LLM\n                    return \"LLM_FALLBACK: no LLM available\"\n                resp = await self.llm.ask(messages)\n                if not resp:\n                    raise RuntimeError(\"Empty LLM response\")\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or \"Error communicating\" in resp):\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_exc = e\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(e)[:200]}\")\n                if attempt < self.max_retries:\n                    await asyncio.sleep(self.retry_backoff * attempt)\n        # After retries exhausted\n        if tracer:\n            tracer.log(\"LLM_FAIL\", self.name, f\"LLM failed after {self.max_retries} attempts: {last_exc}\")\n        return f\"ERROR: LLM failed after {self.max_retries} attempts: {last_exc}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce a code artifact from an idea. Responsibility: produce parseable, testable Python code.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Generating code for idea (len={len(idea or '')})\")\n        prompt = (\n            \"You are a professional Python programmer. Produce production-ready Python code for the task below.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no backticks nor explanation)\\n\"\n            \"- Include docstrings and comments\\n\"\n            \"- Use small testable functions or classes\\n\"\n            \"- Avoid placeholders like TODO or FIXME\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._call_llm_with_retry(messages)\n        # Quick syntax validation\n        try:\n            ast.parse(result)\n            status = \"ok\"\n        except Exception as e:\n            status = f\"syntax_error: {e}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Generated code has syntax issues: {e}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code status={status} length={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Produce pytest-style tests for a given code artifact. Responsibility: test coverage and edge-cases.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Generating tests for code length={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code provided; returning placeholder test\")\n            return \"import pytest\\n\\ndef test_placeholder():\\n    assert True\\n\"\n        snippet = code[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided Python code below.\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover positive and negative cases\\n\"\n            \"- Add docstrings for each test\\n\"\n            \"- Reference public functions/classes from the code\\n\\n\"\n            \"Return only Python test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._call_llm_with_retry(messages)\n        # heuristic check for assertions\n        tests_ok = bool(result and (\"assert \" in result or \"pytest\" in result))\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Tests generated ok={tests_ok} length={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce concise actionable feedback. Responsibility: accept or request changes.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        if self.is_human:\n            review = \"APPROVE: Human reviewer simulated approval. Consider adding more edge-case tests.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        snippet_code = code[:1500] if code else \"\"\n        snippet_tests = tests[:1500] if tests else \"\"\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise actionable review.\\n\\n\"\n            \"Output format:\\n\"\n            \"- If critical issues: start with 'REQUEST_CHANGE:' followed by changes.\\n\"\n            \"- If acceptable: start with 'APPROVE:' followed by brief rationale.\\n\\n\"\n            f\"Code:\\n{snippet_code}\\n\\nTests:\\n{snippet_tests}\\n\\n\"\n            \"Keep response short (3-6 lines).\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing code reviews.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._call_llm_with_retry(messages)\n        # Ensure we produce a verdict; if none, default to conservative REQUEST_CHANGE\n        if result and not (result.strip().upper().startswith(\"REQUEST_CHANGE\") or result.strip().upper().startswith(\"APPROVE\")):\n            result = \"REQUEST_CHANGE: Reviewer did not provide explicit verdict; ask for clearer tests or fixes.\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review completed length={len(result)}\")\n        return result\n\nclass SimpleVerify(Action):\n    \"\"\"Deterministic verification combining syntax checks and structural heuristics. Responsibility: decide PASS/FAIL.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Running verification checks\")\n        results = []\n        code_ok = False\n        tests_ok = False\n        # Code syntax\n        try:\n            ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n            results.append(\"code_syntax: ok\")\n        except Exception as e:\n            results.append(f\"code_syntax: fail ({str(e)[:140]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Code parse error: {e}\")\n        # Tests syntax and asserts\n        try:\n            ast.parse(tests or \"\")\n            if tests and (\"assert \" in tests or \"pytest\" in tests):\n                tests_ok = True\n                results.append(\"tests_syntax: ok\")\n            else:\n                results.append(\"tests_syntax: fail (no assertions found)\")\n        except Exception as e:\n            results.append(f\"tests_syntax: fail ({str(e)[:140]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Tests parse error: {e}\")\n        # Structural: tests reference code symbols\n        referenced = False\n        try:\n            if code_ok and tests_ok:\n                code_tree = ast.parse(code)\n                code_names = {n.name for n in ast.walk(code_tree) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n                for name in code_names:\n                    if name and re.search(r'\\b' + re.escape(name) + r'\\b', tests or \"\"):\n                        referenced = True\n                        break\n            results.append(f\"tests_reference: {'ok' if referenced else 'fail'}\")\n        except Exception as e:\n            results.append(f\"structural_check: fail ({str(e)[:140]})\")\n            if tracer:\n                tracer.log(\"VERIFY_EXCEPTION\", self.name, f\"Structural check error: {e}\")\n        verified = code_ok and tests_ok and referenced\n        result = \"VERIFICATION_RESULT: \" + (\"PASS\" if verified else \"FAIL\") + \" | \" + \"; \".join(results)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class with explicit responsibilities, watch/trigger logic, and safe execution.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # list of action names this role listens for\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # environment reference populated by Team.hire\n        self.env: Optional['Environment'] = kwargs.get('env')\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set watch list by Action.name to avoid class identity issues.\"\"\"\n        self.watch_list = [getattr(a, \"name\", a.__name__) for a in actions]\n\n    def should_respond_to(self, message: Optional[Message]) -> bool:\n        \"\"\"Decide whether to respond: direct addressing OR cause_by in watch_list.\"\"\"\n        if message is None:\n            return False\n        # direct addressing via send_to or sent_to\n        target = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n        if target:\n            if isinstance(target, (set, list)):\n                if self.name in target or self.profile in target:\n                    return True\n            elif target == self.name or target == self.profile:\n                return True\n        # watch list match\n        if getattr(message, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action safely. Returns a Message regardless of success to keep system robust.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.actions:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n        action = self.actions[0]\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Preparing to execute {action.name} on message id={getattr(message,'id',None)}\")\n\n        try:\n            # prepare inputs per action type\n            if isinstance(action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or (message.content if message else \"\")\n                payload = idea or \"\"\n                result = await action.run(payload)\n            elif isinstance(action, SimpleWriteTest):\n                # prefer code from message, else search environment\n                code_src = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_src = message.content\n                elif getattr(self, \"env\", None):\n                    for msg in reversed(self.env.history):\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name:\n                            code_src = msg.content\n                            break\n                result = await action.run(code_src)\n            elif isinstance(action, SimpleWriteReview):\n                # gather latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                env = getattr(self, \"env\", None)\n                if env:\n                    for msg in reversed(env.history):\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteTest.name and not tests_text:\n                            tests_text = msg.content\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name and not code_text:\n                            code_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                code_text = \"\"\n                tests_text = \"\"\n                env = getattr(self, \"env\", None)\n                if env:\n                    for msg in reversed(env.history):\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteTest.name and not tests_text:\n                            tests_text = msg.content\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name and not code_text:\n                            code_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            else:\n                # generic fallback\n                payload = message.content if message else \"\"\n                result = await action.run(payload) if hasattr(action, \"run\") else \"OK\"\n\n            # Build outgoing message\n            out = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name\n            )\n            if tracer:\n                tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={out.id} cause_by={out.cause_by} len={len(str(result))}\")\n            return out\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            err_msg = Message(\n                content=f\"ERROR: Role {self.name} failed to perform {action.name}: {e}\",\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name\n            )\n            return err_msg\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder responds to explicit user input or reviewer request change triggers\n        self._watch([type(\"UserInputDummy\", (), {\"name\": \"UserInput\"}), type(\"RequestChangeDummy\", (), {\"name\": \"REQUEST_CHANGE\"})])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"Message bus with processing tracking to avoid duplicate processing and support addressing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._processed: Dict[str, Set[str]] = {}  # message.id -> set(role.name)\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        # ensure role.env is set\n        setattr(role, \"env\", self)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # normalize message id if needed\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        if self.tracer:\n            preview = (message.content[:200] + \"...\") if len(message.content) > 200 else message.content\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message {getattr(message,'id','')} from {message.sent_from} cause_by={message.cause_by}: {preview}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        self._processed.setdefault(message.id, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"Message {message.id} processed by {role.name}\")\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages that match role.watch_list and not yet processed by this role.\"\"\"\n        results: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                processed = self._processed.get(msg.id, set())\n                if role.name not in processed:\n                    results.append(msg)\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str) -> Tuple[Optional[Message], Optional[Message]]:\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and getattr(msg, \"cause_by\", \"\") == code_cause:\n                code_msg = msg\n            if not tests_msg and getattr(msg, \"cause_by\", \"\") == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Orchestrates the pipeline, ensures robust termination and verification confirmation.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification handshake\n        self.verification_confirmations = 0\n        self.required_confirmations = 1  # Number of independent confirmations required\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            setattr(role, \"env\", self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _safe_act_call(self, role: Role, message: Optional[Message], timeout: float = 120.0, max_retries: int = 2) -> Optional[Message]:\n        \"\"\"Call role.act with retries and timeouts; returns a Message describing result (or error)\"\"\"\n        tracer = self.tracer\n        attempt = 0\n        last_exc = None\n        while attempt <= max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"ACT_ATTEMPT\", role.name, f\"Attempt {attempt} to act on message id={getattr(message,'id',None)}\")\n                coro = role.act(message)\n                resp = await asyncio.wait_for(coro, timeout=timeout)\n                if resp and getattr(resp, \"content\", None):\n                    # mark processed for the input message (if we responded to a specific message)\n                    if message:\n                        self.env.mark_processed(message, role)\n                    return resp\n                # empty response is treated as transient failure\n                last_exc = \"empty_response\"\n                if tracer:\n                    tracer.log(\"ACT_EMPTY\", role.name, f\"Empty response on attempt {attempt}\")\n            except asyncio.TimeoutError:\n                last_exc = \"timeout\"\n                if tracer:\n                    tracer.log(\"ACT_TIMEOUT\", role.name, f\"Timeout on attempt {attempt}\")\n            except Exception as e:\n                last_exc = str(e)\n                if tracer:\n                    tracer.log(\"ACT_EXCEPTION\", role.name, f\"Exception on attempt {attempt}: {last_exc}\")\n            # backoff\n            await asyncio.sleep(0.5 * attempt)\n        # failed after retries\n        if tracer:\n            tracer.log(\"ACT_FAIL\", role.name, f\"Failed after {max_retries+1} attempts: {last_exc}\")\n        error_msg = Message(\n            content=f\"ERROR: role {role.name} failed after retries: {last_exc}\",\n            role=role.profile,\n            cause_by=\"System\",\n            sent_from=role.name\n        )\n        return error_msg\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # initial user instruction\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        consecutive_verifications = 0\n        last_verification_round = -1\n\n        # deterministic pipeline order\n        pipeline = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            progress_made = False\n\n            # For each stage, call all roles of that type deterministically\n            for role_type in pipeline:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # determine trigger message(s)\n                    inbox: List[Message] = []\n                    if isinstance(role, SimpleCoder):\n                        # coder acts on initial user instruction in first round or explicit requests\n                        if round_num == 1:\n                            inbox = [initial_msg]\n                        else:\n                            inbox = self.env.get_unprocessed_messages_for_role(role)\n                    else:\n                        inbox = self.env.get_unprocessed_messages_for_role(role)\n\n                    # process the latest message only to keep deterministic flow\n                    if not inbox:\n                        continue\n                    msg_to_process = inbox[-1]\n\n                    # avoid role processing its own messages\n                    if getattr(msg_to_process, \"sent_from\", None) == role.name:\n                        continue\n\n                    response = await self._safe_act_call(role, msg_to_process)\n                    if response:\n                        # annotate cause_by if not set\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.actions[0], \"name\", \"\")\n                        # deliver to environment\n                        self.env.publish_message(response)\n                        progress_made = True\n\n                        # handle verifier-specific checks\n                        if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            # Confirm verification by running an immediate re-check (deterministic)\n                            # Re-run verifier action locally with latest code/tests\n                            verifier_action = role.actions[0]\n                            code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                            confirm = await verifier_action.run((code_msg.content if code_msg else \"\"), (tests_msg.content if tests_msg else \"\"))\n                            if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                consecutive_verifications += 1\n                                last_verification_round = round_num\n                                self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"Verifier {role.name} PASS confirmed (consecutive={consecutive_verifications})\")\n                            else:\n                                consecutive_verifications = 0\n                                self.tracer.log(\"VERIFIER_UNCONFIRMED\", \"Team\", \"Verifier reported PASS but confirmation failed\")\n\n            # Termination policy:\n            # - require at least one confirmed verification (required_confirmations) OR consecutive confirmations threshold\n            if consecutive_verifications >= self.required_confirmations:\n                verified = True\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed after round {round_num}\")\n                break\n\n            # detect lack of progress to avoid livelock\n            if not progress_made:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress in round {round_num}; stopping to avoid livelock\")\n                break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project completed Verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n### Program 4 (Score: 4.6667)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\n# Shared safe fallbacks to reduce failure modes and ensure determinism\n_DEFAULT_CODE = (\n    \"def solve(input_data):\\n\"\n    \"    \\\"\\\"\\\"Echo solver: returns the input data. Safe fallback implementation.\\\"\\\"\\\"\\n\"\n    \"    return input_data\\n\"\n)\n_DEFAULT_TESTS = (\n    \"import pytest\\n\\n\"\n    \"def test_solve_identity_behavior():\\n\"\n    \"    try:\\n\"\n    \"        from __main__ import solve\\n\"\n    \"    except Exception:\\n\"\n    \"        # If the function is not importable in this context, just assert True to keep syntax valid\\n\"\n    \"        assert True\\n\"\n    \"        return\\n\"\n    \"    assert solve(123) == 123\\n\"\n    \"    assert solve('abc') == 'abc'\\n\"\n)\n\ndef _strip_code_fences(text: str) -> str:\n    if not text:\n        return text\n    t = text.strip()\n    # Remove common Markdown fences\n    if t.startswith(\"\n```\nKey features: Performs well on runs_successfully (0.0000), Performs well on combined_score (0.0000), Performs well on avg_failures_per_task (14.0000), Performs well on error (unterminated string literal (detected at line 182) (tmp601s1kla.py, line 182))\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 4.6667)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\n# ========== Utility helpers for robust payload handling ==========\n\ndef _strip_code_fences(text: str) -> str:\n    \"\"\"Remove common Markdown code fences to reduce noise.\"\"\"\n    if not text:\n        return \"\"\n    t = text.strip()\n    # Remove triple backticks blocks\n    if \"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to combined_score\n\n\n### Program D2 (Score: 4.6667)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with error handling, output sanitation, and retry support.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        self.max_retries = kwargs.get('max_retries', 2)\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    @staticmethod\n    def _strip_code_fences(text: str) -> str:\n        \"\"\"Remove surrounding markdown code fences and extract Python block if present.\"\"\"\n        if not isinstance(text, str):\n            return \"\"\n        s = text.strip()\n        if s.startswith(\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 7.1111, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (5.000), Excellent total_failures (30.000)\n\n\n### Inspiration 2 (Score: 4.6667, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\n# ========== Utility helpers for robust payload handling ==========\n\ndef _strip_code_fences(text: str) -> str:\n    \"\"\"Remove common Markdown code fences to reduce noise.\"\"\"\n    if not text:\n        return \"\"\n    t = text.strip()\n    # Remove triple backticks blocks\n    if \"\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n### Inspiration 3 (Score: 3.2125, Type: High-Performer)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport re\nfrom typing import Tuple\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry + logging utilities\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _call_llm_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, exponential backoff, and structured tracing.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_exc = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # Deterministic fallback for environments without aiohttp/LLM\n                    return \"LLM_FALLBACK: no LLM available\"\n                resp = await self.llm.ask(messages)\n                if not resp:\n                    raise RuntimeError(\"Empty LLM response\")\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or \"Error communicating\" in resp):\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_exc = e\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(e)[:200]}\")\n                if attempt < self.max_retries:\n                    await asyncio.sleep(self.retry_backoff * attempt)\n        # After retries exhausted\n        if tracer:\n            tracer.log(\"LLM_FAIL\", self.name, f\"LLM failed after {self.max_retries} attempts: {last_exc}\")\n        return f\"ERROR: LLM failed after {self.max_retries} attempts: {last_exc}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce a code artifact from an idea. Responsibility: produce parseable, testable Python code.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Generating code for idea (len={len(idea or '')})\")\n        prompt = (\n            \"You are a professional Python programmer. Produce production-ready Python code for the task below.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no backticks nor explanation)\\n\"\n            \"- Include docstrings and comments\\n\"\n            \"- Use small testable functions or classes\\n\"\n            \"- Avoid placeholders like TODO or FIXME\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._call_llm_with_retry(messages)\n        # Quick syntax validation\n        try:\n            ast.parse(result)\n            status = \"ok\"\n        except Exception as e:\n            status = f\"syntax_error: {e}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Generated code has syntax issues: {e}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code status={status} length={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Produce pytest-style tests for a given code artifact. Responsibility: test coverage and edge-cases.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Generating tests for code length={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code provided; returning placeholder test\")\n            return \"import pytest\\n\\ndef test_placeholder():\\n    assert True\\n\"\n        snippet = code[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided Python code below.\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover positive and negative cases\\n\"\n            \"- Add docstrings for each test\\n\"\n            \"- Reference public functions/classes from the code\\n\\n\"\n            \"Return only Python test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._call_llm_with_retry(messages)\n        # heuristic check for assertions\n        tests_ok = bool(result and (\"assert \" in result or \"pytest\" in result))\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Tests generated ok={tests_ok} length={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce concise actionable feedback. Responsibility: accept or request changes.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        if self.is_human:\n            review = \"APPROVE: Human reviewer simulated approval. Consider adding more edge-case tests.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        snippet_code = code[:1500] if code else \"\"\n        snippet_tests = tests[:1500] if tests else \"\"\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise actionable review.\\n\\n\"\n            \"Output format:\\n\"\n            \"- If critical issues: start with 'REQUEST_CHANGE:' followed by changes.\\n\"\n            \"- If acceptable: start with 'APPROVE:' followed by brief rationale.\\n\\n\"\n            f\"Code:\\n{snippet_code}\\n\\nTests:\\n{snippet_tests}\\n\\n\"\n            \"Keep response short (3-6 lines).\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing code reviews.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._call_llm_with_retry(messages)\n        # Ensure we produce a verdict; if none, default to conservative REQUEST_CHANGE\n        if result and not (result.strip().upper().startswith(\"REQUEST_CHANGE\") or result.strip().upper().startswith(\"APPROVE\")):\n            result = \"REQUEST_CHANGE: Reviewer did not provide explicit verdict; ask for clearer tests or fixes.\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review completed length={len(result)}\")\n        return result\n\nclass SimpleVerify(Action):\n    \"\"\"Deterministic verification combining syntax checks and structural heuristics. Responsibility: decide PASS/FAIL.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Running verification checks\")\n        results = []\n        code_ok = False\n        tests_ok = False\n        # Code syntax\n        try:\n            ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n            results.append(\"code_syntax: ok\")\n        except Exception as e:\n            results.append(f\"code_syntax: fail ({str(e)[:140]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Code parse error: {e}\")\n        # Tests syntax and asserts\n        try:\n            ast.parse(tests or \"\")\n            if tests and (\"assert \" in tests or \"pytest\" in tests):\n                tests_ok = True\n                results.append(\"tests_syntax: ok\")\n            else:\n                results.append(\"tests_syntax: fail (no assertions found)\")\n        except Exception as e:\n            results.append(f\"tests_syntax: fail ({str(e)[:140]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Tests parse error: {e}\")\n        # Structural: tests reference code symbols\n        referenced = False\n        try:\n            if code_ok and tests_ok:\n                code_tree = ast.parse(code)\n                code_names = {n.name for n in ast.walk(code_tree) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n                for name in code_names:\n                    if name and re.search(r'\\b' + re.escape(name) + r'\\b', tests or \"\"):\n                        referenced = True\n                        break\n            results.append(f\"tests_reference: {'ok' if referenced else 'fail'}\")\n        except Exception as e:\n            results.append(f\"structural_check: fail ({str(e)[:140]})\")\n            if tracer:\n                tracer.log(\"VERIFY_EXCEPTION\", self.name, f\"Structural check error: {e}\")\n        verified = code_ok and tests_ok and referenced\n        result = \"VERIFICATION_RESULT: \" + (\"PASS\" if verified else \"FAIL\") + \" | \" + \"; \".join(results)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class with explicit responsibilities, watch/trigger logic, and safe execution.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # list of action names this role listens for\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # environment reference populated by Team.hire\n        self.env: Optional['Environment'] = kwargs.get('env')\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set watch list by Action.name to avoid class identity issues.\"\"\"\n        self.watch_list = [getattr(a, \"name\", a.__name__) for a in actions]\n\n    def should_respond_to(self, message: Optional[Message]) -> bool:\n        \"\"\"Decide whether to respond: direct addressing OR cause_by in watch_list.\"\"\"\n        if message is None:\n            return False\n        # direct addressing via send_to or sent_to\n        target = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n        if target:\n            if isinstance(target, (set, list)):\n                if self.name in target or self.profile in target:\n                    return True\n            elif target == self.name or target == self.profile:\n                return True\n        # watch list match\n        if getattr(message, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action safely. Returns a Message regardless of success to keep system robust.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.actions:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n        action = self.actions[0]\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Preparing to execute {action.name} on message id={getattr(message,'id',None)}\")\n\n        try:\n            # prepare inputs per action type\n            if isinstance(action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or (message.content if message else \"\")\n                payload = idea or \"\"\n                result = await action.run(payload)\n            elif isinstance(action, SimpleWriteTest):\n                # prefer code from message, else search environment\n                code_src = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_src = message.content\n                elif getattr(self, \"env\", None):\n                    for msg in reversed(self.env.history):\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name:\n                            code_src = msg.content\n                            break\n                result = await action.run(code_src)\n            elif isinstance(action, SimpleWriteReview):\n                # gather latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                env = getattr(self, \"env\", None)\n                if env:\n                    for msg in reversed(env.history):\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteTest.name and not tests_text:\n                            tests_text = msg.content\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name and not code_text:\n                            code_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                code_text = \"\"\n                tests_text = \"\"\n                env = getattr(self, \"env\", None)\n                if env:\n                    for msg in reversed(env.history):\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteTest.name and not tests_text:\n                            tests_text = msg.content\n                        if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name and not code_text:\n                            code_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            else:\n                # generic fallback\n                payload = message.content if message else \"\"\n                result = await action.run(payload) if hasattr(action, \"run\") else \"OK\"\n\n            # Build outgoing message\n            out = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name\n            )\n            if tracer:\n                tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={out.id} cause_by={out.cause_by} len={len(str(result))}\")\n            return out\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            err_msg = Message(\n                content=f\"ERROR: Role {self.name} failed to perform {action.name}: {e}\",\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name\n            )\n            return err_msg\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder responds to explicit user input or reviewer request change triggers\n        self._watch([type(\"UserInputDummy\", (), {\"name\": \"UserInput\"}), type(\"RequestChangeDummy\", (), {\"name\": \"REQUEST_CHANGE\"})])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"Message bus with processing tracking to avoid duplicate processing and support addressing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._processed: Dict[str, Set[str]] = {}  # message.id -> set(role.name)\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        # ensure role.env is set\n        setattr(role, \"env\", self)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # normalize message id if needed\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        if self.tracer:\n            preview = (message.content[:200] + \"...\") if len(message.content) > 200 else message.content\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message {getattr(message,'id','')} from {message.sent_from} cause_by={message.cause_by}: {preview}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        self._processed.setdefault(message.id, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"Message {message.id} processed by {role.name}\")\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages that match role.watch_list and not yet processed by this role.\"\"\"\n        results: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                processed = self._processed.get(msg.id, set())\n                if role.name not in processed:\n                    results.append(msg)\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str) -> Tuple[Optional[Message], Optional[Message]]:\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and getattr(msg, \"cause_by\", \"\") == code_cause:\n                code_msg = msg\n            if not tests_msg and getattr(msg, \"cause_by\", \"\") == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Orchestrates the pipeline, ensures robust termination and verification confirmation.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification handshake\n        self.verification_confirmations = 0\n        self.required_confirmations = 1  # Number of independent confirmations required\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            setattr(role, \"env\", self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _safe_act_call(self, role: Role, message: Optional[Message], timeout: float = 120.0, max_retries: int = 2) -> Optional[Message]:\n        \"\"\"Call role.act with retries and timeouts; returns a Message describing result (or error)\"\"\"\n        tracer = self.tracer\n        attempt = 0\n        last_exc = None\n        while attempt <= max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"ACT_ATTEMPT\", role.name, f\"Attempt {attempt} to act on message id={getattr(message,'id',None)}\")\n                coro = role.act(message)\n                resp = await asyncio.wait_for(coro, timeout=timeout)\n                if resp and getattr(resp, \"content\", None):\n                    # mark processed for the input message (if we responded to a specific message)\n                    if message:\n                        self.env.mark_processed(message, role)\n                    return resp\n                # empty response is treated as transient failure\n                last_exc = \"empty_response\"\n                if tracer:\n                    tracer.log(\"ACT_EMPTY\", role.name, f\"Empty response on attempt {attempt}\")\n            except asyncio.TimeoutError:\n                last_exc = \"timeout\"\n                if tracer:\n                    tracer.log(\"ACT_TIMEOUT\", role.name, f\"Timeout on attempt {attempt}\")\n            except Exception as e:\n                last_exc = str(e)\n                if tracer:\n                    tracer.log(\"ACT_EXCEPTION\", role.name, f\"Exception on attempt {attempt}: {last_exc}\")\n            # backoff\n            await asyncio.sleep(0.5 * attempt)\n        # failed after retries\n        if tracer:\n            tracer.log(\"ACT_FAIL\", role.name, f\"Failed after {max_retries+1} attempts: {last_exc}\")\n        error_msg = Message(\n            content=f\"ERROR: role {role.name} failed after retries: {last_exc}\",\n            role=role.profile,\n            cause_by=\"System\",\n            sent_from=role.name\n        )\n        return error_msg\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # initial user instruction\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        consecutive_verifications = 0\n        last_verification_round = -1\n\n        # deterministic pipeline order\n        pipeline = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            progress_made = False\n\n            # For each stage, call all roles of that type deterministically\n            for role_type in pipeline:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # determine trigger message(s)\n                    inbox: List[Message] = []\n                    if isinstance(role, SimpleCoder):\n                        # coder acts on initial user instruction in first round or explicit requests\n                        if round_num == 1:\n                            inbox = [initial_msg]\n                        else:\n                            inbox = self.env.get_unprocessed_messages_for_role(role)\n                    else:\n                        inbox = self.env.get_unprocessed_messages_for_role(role)\n\n                    # process the latest message only to keep deterministic flow\n                    if not inbox:\n                        continue\n                    msg_to_process = inbox[-1]\n\n                    # avoid role processing its own messages\n                    if getattr(msg_to_process, \"sent_from\", None) == role.name:\n                        continue\n\n                    response = await self._safe_act_call(role, msg_to_process)\n                    if response:\n                        # annotate cause_by if not set\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.actions[0], \"name\", \"\")\n                        # deliver to environment\n                        self.env.publish_message(response)\n                        progress_made = True\n\n                        # handle verifier-specific checks\n                        if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            # Confirm verification by running an immediate re-check (deterministic)\n                            # Re-run verifier action locally with latest code/tests\n                            verifier_action = role.actions[0]\n                            code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                            confirm = await verifier_action.run((code_msg.content if code_msg else \"\"), (tests_msg.content if tests_msg else \"\"))\n                            if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                consecutive_verifications += 1\n                                last_verification_round = round_num\n                                self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"Verifier {role.name} PASS confirmed (consecutive={consecutive_verifications})\")\n                            else:\n                                consecutive_verifications = 0\n                                self.tracer.log(\"VERIFIER_UNCONFIRMED\", \"Team\", \"Verifier reported PASS but confirmation failed\")\n\n            # Termination policy:\n            # - require at least one confirmed verification (required_confirmations) OR consecutive confirmations threshold\n            if consecutive_verifications >= self.required_confirmations:\n                verified = True\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed after round {round_num}\")\n                break\n\n            # detect lack of progress to avoid livelock\n            if not progress_made:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress in round {round_num}; stopping to avoid livelock\")\n                break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project completed Verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach, Alternative combined_score approach, Excellent avg_failures_per_task (12.000)\n\n\n### Inspiration 4 (Score: 3.2125, Type: Migrant)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport hashlib\nimport ast\nfrom collections import defaultdict\n\ndef artifact_preview(text: Optional[str], length: int = 80) -> str:\n    if not text:\n        return \"\"\n    return (text[:length] + \"...\") if len(text) > length else text\n\nclass Action(ABC):\n    \"\"\"\n    Base action class.\n    Responsibilities:\n    - Provide run(...) coroutine performing the action.\n    - Encapsulate robust LLM calls with retries, backoff and logging.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper for LLM calls:\n        - Retries on exceptions or error markers.\n        - Exponential backoff.\n        - Logs each attempt and final outcome.\n        - Returns explicit failure marker on exhaustion.\n        \"\"\"\n        if not self.llm:\n            # Deterministic fallback for testing without LLM\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                # LLMInterface uses \"Error:\" prefix for non-200 responses or exceptions returned as strings\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error: {resp[:200]}\")\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # Accept string responses (successful)\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)[:200]}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, last_err)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                continue\n\n        failure_msg = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_ABORT\", self.name, failure_msg)\n        return failure_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate Python module code from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea={artifact_preview(idea, 200)}\")\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module implementing the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no surrounding markdown).\\n\"\n            \"- Include docstrings, input validation and basic error handling.\\n            \"\n            \"- Ensure at least one function or class is defined.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self.safe_ask(messages)\n        if not code or not any(token in code for token in (\"def \", \"class \")):\n            # deterministic fallback if LLM failed or produced non-code\n            fallback = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"LLM produced no valid code; using fallback\")\n            code = fallback\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"generated_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following Python module.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Use assert statements and include docstrings for tests.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self.safe_ask(messages)\n        # Fallback if the LLM response doesn't look like tests\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"LLM produced no valid tests; using fallback\")\n            tests = fallback\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Produce a concise review; include explicit REVIEW_DECISION.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: APPROVE\\nREVIEW_DECISION: APPROVE\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Provide a concise review and an explicit decision line:\\n\"\n                \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REJECT\\n\\n\"\n                \"Code (truncated):\\n\"\n                f\"{(code or '')[:2000]}\\n\\nTests (truncated):\\n\"\n                f\"{(tests or '')[:2000]}\\n\\n\"\n                \"Focus on bugs, missing tests and actionable improvements.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self.safe_ask(messages)\n            if not review or \"REVIEW_DECISION:\" not in review:\n                # derive decision heuristically\n                decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REJECT\"\n                review = (review or \"Automated review\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"\n    Verify code and tests using deterministic checks:\n    - Syntax parsing\n    - At least one function/class in code\n    - Tests include asserts and reference code entities\n    - Produces VERIFICATION_RESULT: PASS/FAIL and digest\n    \"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_code = None\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = True\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_tests = None\n\n        # Semantic checks\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            if code_entities:\n                details.append(f\"code_entities: {sorted(list(code_entities))[:6]}\")\n            else:\n                details.append(\"code_entities: none\")\n\n        tests_has_assert = False\n        tests_references = set()\n        if parsed_tests:\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Assert):\n                    tests_has_assert = True\n                if isinstance(node, ast.Name):\n                    tests_references.add(node.id)\n            details.append(f\"tests_asserts: {tests_has_assert}\")\n            inter = code_entities & tests_references\n            details.append(f\"tests_references_code_entities: {sorted(list(inter))[:6]}\")\n\n        # Determine pass/fail\n        passed = all([code_ok, tests_ok, bool(code_entities), tests_has_assert, len(code_entities & tests_references) > 0])\n        # Compute digest of current artifacts for stability detection\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if passed else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"\n    Base Role:\n    - Single primary responsibility (one action).\n    - Maintains processed message ids to ensure idempotency.\n    - Uses environment subscriptions for explicit routing.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed messages\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Execute the role's primary action in response to a message.\n        Ensures idempotency by skipping already processed messages.\n        Returns a Message or None.\n        \"\"\"\n        if not self.action:\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping already processed message {msg_id}\")\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Acting on message {msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Extract inputs depending on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                result = await self.action.run(idea)\n            elif isinstance(self.action, SimpleWriteTest):\n                # Expect code in message.content, or fetch last code from env\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and self.env:\n                    code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code)\n            elif isinstance(self.action, SimpleWriteReview):\n                # Need both code and tests\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            elif isinstance(self.action, SimpleVerify):\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            else:\n                # Generic action fallback\n                result = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark message as processed to avoid repeated failing attempts\n            if msg_id:\n                self._processed.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"\",\n            sent_from=self.name,\n            send_to=set()  # environment will fill routing based on subscriptions if left empty\n        )\n\n        # Mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message {response.id} cause_by={response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # coder is typically triggered by UserInput (explicit send_to)\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"\n    Environment:\n    - Holds history of Messages.\n    - Maintains action_name -> roles subscriptions.\n    - Provides helpers to route messages deterministically and fetch latest artifacts.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # subscriptions mapping: action_name -> set(role.name)\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)\n        # track delivery: message_id -> set(role.name) delivered\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile})\")\n        for watched in role.watch_list:\n            self.subscriptions[watched.name].add(role.name)\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        if getattr(message, \"send_to\", None) is None:\n            message.send_to = set()\n        self.history.append(message)\n        # initialize delivered set\n        self.delivered[message.id] = set()\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={artifact_preview(message.content,200)} send_to={sorted(list(message.send_to)[:10])}\")\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[str]:\n        \"\"\"Return content of the latest message with cause_by.\"\"\"\n        for msg in reversed(self.history):\n            if msg.cause_by == cause_by:\n                return msg.content\n        return None\n\n    def get_routable_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Determine messages a role should process:\n        - Explicitly targeted via send_to (role.name or role.profile)\n        - OR messages caused by an action the role watches\n        - Excludes messages already delivered to that role\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            targets = getattr(msg, \"send_to\", None) or set()\n            if role.name in targets or role.profile in targets:\n                targeted = True\n            watched = False\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    watched = True\n                    break\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\nclass Team:\n    \"\"\"\n    Team orchestrator:\n    - Deterministic order of role processing.\n    - Explicit routing via Environment.subscriptions and message.send_to.\n    - Termination requires stable verification: same digest consecutively.\n    - Robust handling of role/LLM failures and retries at action level.\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment = 20.0\n        self.idea = \"\"\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # verification stability\n        self._last_digest: Optional[str] = None\n        self._streak = 0\n        self._required_streak = 2\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {artifact_preview(idea,200)}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # initial kickoff: targeted to coders explicitly\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            # deterministic role order\n            for role_type in self.order:\n                roles_of_type = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles_of_type:\n                    msgs = self.env.get_routable_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # guard redundant processing at role level\n                        try:\n                            response = await role.act(msg)\n                            # mark delivery/processing\n                            # Environment.delivery was updated in get_routable_messages_for_role\n                            any_activity = True\n                            if response:\n                                # route response: if send_to empty, fill subscribers watching this action\n                                if not getattr(response, \"send_to\", None):\n                                    # find roles who watch this action\n                                    subscribers = self.env.subscriptions.get(response.cause_by, set())\n                                    response.send_to = set(subscribers)\n                                self.env.publish_message(response)\n                                # If verifier directly produced PASS, parse it\n                                if response.cause_by == SimpleVerify.name and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                    # parse digest\n                                    digest = None\n                                    for part in (response.content or \"\").split(\"|\"):\n                                        part = part.strip()\n                                        if part.startswith(\"digest=\"):\n                                            digest = part.split(\"=\",1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                        if self._streak >= self._required_streak:\n                                            verified = True\n                                    else:\n                                        # no digest, treat as non-stable pass\n                                        self._streak = 0\n                                        self._last_digest = None\n                                        self.tracer.log(\"VERIFIER\", \"Team\", \"Pass without digest - not considered stable\")\n                            # record that role processed msg to ensure idempotency\n                            self.env.delivered[msg.id].add(role.name)\n                        except Exception as e:\n                            self.tracer.log(\"TEAM_ROLE_ERROR\", \"Team\", f\"Role {role.name} raised {type(e).__name__}: {str(e)[:200]}\")\n                            continue\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed; any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # deadlock: allow coders to re-attempt once by targeting them explicitly\n                self.tracer.log(\"TEAM_DEADLOCK\", \"Team\", \"No activity this round; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        # create a nudge message targeting that coder only if they haven't processed the initial\n                        if not self.env.has_been_processed_by if False else True:\n                            nudge = Message(content=f\"Nudge: please propose initial code for '{artifact_preview(self.idea,120)}'\", role=\"System\", sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.name})\n                            self.env.publish_message(nudge)\n                # short pause to allow asynchronous LLM processing in environments where real LLM calls might be queued\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds} rounds; verified={verified} history_len={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach, Alternative combined_score approach, Excellent avg_failures_per_task (12.000)\n\n\n### Inspiration 5 (Score: 4.6667, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with error handling, output sanitation, and retry support.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        self.max_retries = kwargs.get('max_retries', 2)\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    @staticmethod\n    def _strip_code_fences(text: str) -> str:\n        \"\"\"Remove surrounding markdown code fences and extract Python block if present.\"\"\"\n        if not isinstance(text, str):\n            return \"\"\n        s = text.strip()\n        if s.startswith(\"\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\n# Shared safe fallbacks to reduce failure modes and ensure determinism\n_DEFAULT_CODE = (\n    \"def solve(input_data):\\n\"\n    \"    \\\"\\\"\\\"Echo solver: returns the input data. Safe fallback implementation.\\\"\\\"\\\"\\n\"\n    \"    return input_data\\n\"\n)\n_DEFAULT_TESTS = (\n    \"import pytest\\n\\n\"\n    \"def test_solve_identity_behavior():\\n\"\n    \"    try:\\n\"\n    \"        from __main__ import solve\\n\"\n    \"    except Exception:\\n\"\n    \"        # If the function is not importable in this context, just assert True to keep syntax valid\\n\"\n    \"        assert True\\n\"\n    \"        return\\n\"\n    \"    assert solve(123) == 123\\n\"\n    \"    assert solve('abc') == 'abc'\\n\"\n)\n\ndef _strip_code_fences(text: str) -> str:\n    if not text:\n        return text\n    t = text.strip()\n    # Remove common Markdown fences\n    if t.startswith(\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic response\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport time\nfrom typing import Tuple\n\n# Utility for short previews in logs\ndef _preview(text: Optional[str], length: int = 120) -> str:\n    if not text:\n        return \"\"\n    return (text[:length] + \"...\") if len(text) > length else text\n\n# Base Action with robust LLM calling, retry/backoff, and deterministic fallbacks\nclass Action(ABC):\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper around LLMInterface.ask with retries, backoff, and logging.\n        Returns deterministic fallback string on fatal failure.\n        \"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_FALLBACK: no LLM available\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        last_exc = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                res = await self.llm.ask(messages)\n                # treat explicit \"Error\" responses as failures to retry\n                if isinstance(res, str) and res.startswith(\"Error\"):\n                    last_exc = res\n                    if tracer:\n                        tracer.log(\"LLM_RESPONSE_ERROR\", self.name, _preview(res, 240))\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                return res\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:200]}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_exc)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted\n        failure = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_exc}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure)\n        return failure\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\n# Concrete actions\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea={_preview(idea,200)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single valid Python module implementing the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only Python source code (no surrounding markdown or explanation).\\n\"\n            \"- Include at least one function or class, a module docstring, and basic input validation or error handling.\\n\"\n            \"- Keep code self-contained and parseable by ast.parse().\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        res = await self._safe_ask(messages)\n        # Validate basic structure\n        code = res or \"\"\n        try:\n            ast.parse(code)\n        except Exception:\n            # fallback deterministic code\n            fallback = (\n                \"def solve(input_data):\\n\"\n                \"    \\\"\\\"\\\"Fallback deterministic implementation: echoes input_data.\\\"\\\"\\\"\\n\"\n                \"    return input_data\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Generated code invalid; using fallback\")\n            code = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_len={len(code)} preview={_preview(code,120)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-compatible tests for the provided Python module.\\n\\n\"\n            \"Module (truncated):\\n\"\n            f\"{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-style tests only (no explanation).\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Use assert statements and reference public functions/classes present in the module.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        res = await self._safe_ask(messages)\n        tests = res or \"\"\n        # Heuristic validation\n        if not tests or (\"assert \" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test to ensure syntactic validity.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM produced no valid tests; using fallback\")\n            tests = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)} preview={_preview(tests,120)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_DECISION: APPROVE\\nHuman review simulated: minor suggestions.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review that starts with either:\\n\"\n            \"- 'REVIEW_DECISION: APPROVE' or\\n\"\n            \"- 'REVIEW_DECISION: REQUEST_CHANGES'\\n\\n\"\n            \"Then provide 1-3 short actionable bullets.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing reviews.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        res = await self._safe_ask(messages)\n        review = res or \"\"\n        if \"REVIEW_DECISION:\" not in review:\n            # Conservative default\n            decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and ((\"def \" in (code or \"\")) or (\"class \" in (code or \"\"))) else \"REQUEST_CHANGES\"\n            review = f\"REVIEW_DECISION: {decision}\\nAutomated review: no explicit decision returned; falling back to {decision}.\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"Review lacked explicit decision; applied heuristic\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)} preview={_preview(review,120)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = True\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        # Semantic checks: at least one function/class\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    entities.add(node.name)\n            details.append(f\"code_entities_count: {len(entities)}\")\n\n        # Tests reference code entities and include asserts\n        tests_has_assert = False\n        referenced = False\n        if parsed_tests:\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Assert):\n                    tests_has_assert = True\n                if isinstance(node, ast.Name) and node.id in entities:\n                    referenced = True\n            details.append(f\"tests_has_assert: {tests_has_assert}\")\n            details.append(f\"tests_references_entities: {referenced}\")\n\n        # Determine pass/fail\n        passed = all([code_ok, tests_ok, len(entities) > 0, tests_has_assert, referenced])\n        # Create digest for artifact stability\n        digest_input = (code or \"\").encode(\"utf-8\") + b\"\\n==\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_input).hexdigest()[:12]\n        result = f\"VERIFICATION_RESULT: {'PASS' if passed else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# Roles with clear responsibilities and idempotency\nclass Role(ABC):\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: Set[str] = set()  # action names to watch (cause_by)\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = set()\n        self.env: Optional['Environment'] = None\n        # processed message ids for idempotency\n        self._processed: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store action names\n        self.watch_list = {getattr(a, \"name\", getattr(a, \"__name__\", \"\")) for a in actions}\n\n    def should_respond_to(self, msg: Message) -> bool:\n        # Respond if explicitly targeted\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n        if targets:\n            if isinstance(targets, (set, list)):\n                if self.name in targets or self.profile in targets:\n                    return True\n            else:\n                if targets == self.name or targets == self.profile:\n                    return True\n        # Or if message cause_by is in watch list\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.actions:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n        action = self.actions[0]\n        msg_id = getattr(message, \"id\", None) if message else None\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {msg_id}\")\n            return None\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Acting on message id={msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Prepare inputs based on action type\n            if isinstance(action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                out = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # Prefer code included in message, else fetch latest from env\n                code_src = getattr(message, \"content\", \"\") if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name else \"\"\n                if not code_src and self.env:\n                    code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                out = await action.run(code_src)\n            elif isinstance(action, SimpleWriteReview):\n                code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                tests_src = self.env.find_latest_content_by_cause(SimpleWriteTest.name) or \"\"\n                out = await action.run(code_src, tests_src)\n            elif isinstance(action, SimpleVerify):\n                code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                tests_src = self.env.find_latest_content_by_cause(SimpleWriteTest.name) or \"\"\n                out = await action.run(code_src, tests_src)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                out = await action.run(payload)\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark processed to avoid repeated failures\n            if msg_id:\n                self._processed.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build response message\n        response = Message(\n            content=out,\n            role=self.profile,\n            cause_by=action.name,\n            sent_from=self.name,\n            send_to=set()\n        )\n        # Mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={response.id} cause_by={response.cause_by} preview={_preview(response.content,120)}\")\n        return response\n\n# Concrete Roles\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Triggered by user input or explicit nudges\n        self._watch([])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n# Environment: message bus with deterministic routing and delivery tracking\nclass Environment:\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # message_id -> set(role.name) delivered\n        self.delivered: Dict[str, Set[str]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile})\")\n\n    def publish_message(self, message: Message):\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self.delivered.setdefault(message.id, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content,200)} send_to={sorted(list(getattr(message,'send_to',set()))[:10])}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages that the role should process, respecting explicit addressing and watch_list.\n        Excludes messages already delivered to that role.\n        \"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            already = role.name in self.delivered.get(msg.id, set())\n            if already:\n                continue\n            # explicit addressing\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            targeted = False\n            if targets:\n                if isinstance(targets, (set, list)):\n                    if role.name in targets or role.profile in targets:\n                        targeted = True\n                else:\n                    if targets == role.name or targets == role.profile:\n                        targeted = True\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                # mark tentatively delivered to avoid reselecting in same cycle\n                self.delivered.setdefault(msg.id, set()).add(role.name)\n        return out\n\n    def find_latest_content_by_cause(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return msg.content\n        return None\n\n# Team orchestrator with robust termination and confirmation\nclass Team:\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        # deterministic pipeline order\n        self.pipeline = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # verification stability: require same digest twice\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {_preview(idea,200)}\")\n\n    async def _safe_role_call(self, role: Role, message: Optional[Message], timeout: float = 60.0, max_retries: int = 1) -> Optional[Message]:\n        \"\"\"\n        Call role.act with retries and timeout. Returns a Message even on failure to allow robust flow.\n        \"\"\"\n        tracer = self.tracer\n        last_err = None\n        for attempt in range(1, max_retries + 2):\n            try:\n                if tracer:\n                    tracer.log(\"ROLE_CALL\", role.name, f\"Attempt {attempt} for message {getattr(message,'id',None)}\")\n                coro = role.act(message)\n                resp = await asyncio.wait_for(coro, timeout=timeout)\n                return resp\n            except asyncio.TimeoutError:\n                last_err = \"timeout\"\n                if tracer:\n                    tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempt}\")\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)[:200]}\"\n                if tracer:\n                    tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempt}: {last_err}\")\n            await asyncio.sleep(0.2 * attempt)\n        # return error message as response to keep pipeline deterministic\n        err_msg = Message(content=f\"ERROR: role {role.name} failed after retries: {last_err}\", role=role.profile, cause_by=\"System\", sent_from=role.name)\n        return err_msg\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # initial message targeted to coders\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds_executed = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            activity = False\n\n            # deterministic pipeline\n            for role_cls in self.pipeline:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    msgs = self.env.get_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # Avoid processing role's own messages\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n                        resp = await self._safe_role_call(role, msg)\n                        if resp:\n                            # ensure cause_by set\n                            if not getattr(resp, \"cause_by\", None):\n                                resp.cause_by = getattr(role.actions[0], \"name\", \"\")\n                            self.env.publish_message(resp)\n                            activity = True\n                            # If verifier produced a PASS, examine digest and enforce streak\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                # parse digest\n                                digest = None\n                                for part in (resp.content or \"\").split(\"|\"):\n                                    part = part.strip()\n                                    if part.startswith(\"digest=\"):\n                                        digest = part.split(\"=\", 1)[1]\n                                        break\n                                if digest:\n                                    if digest == self._last_digest:\n                                        self._streak += 1\n                                    else:\n                                        self._last_digest = digest\n                                        self._streak = 1\n                                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    if self._streak >= self._required_streak:\n                                        verified = True\n                                else:\n                                    # no digest, cannot confirm stability\n                                    self._streak = 0\n                                    self._last_digest = None\n                                    self.tracer.log(\"VERIFIER_NO_DIGEST\", \"Team\", \"Pass without digest - not stable\")\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed activity={activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verified stable; stopping at round {rnd}\")\n                break\n            if not activity:\n                # deadlock handling: nudge coders once\n                self.tracer.log(\"TEAM_DEADLOCK\", \"Team\", \"No activity; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: propose code for '{_preview(self.idea,120)}'\", role=\"System\", sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.name})\n                        self.env.publish_message(nudge)\n                # give a short pause\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds_executed} rounds verified={verified} messages={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds_executed} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}