{"id": "59982d8a-2e7f-4fbe-9a08-c75ffdf584c5", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport hashlib\nimport ast\nfrom collections import defaultdict\n\nclass Action(ABC):\n    \"\"\"Base action class\n\n    Responsibilities:\n    - Provide a run(...) coroutine that performs the action.\n    - Provide safe_ask(...) wrapper to call LLM with retries and logging.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM.ask with retry and basic error detection.\"\"\"\n        if not self.llm:\n            # No LLM configured, return a helpful fallback\n            fallback = \"LLM not available: fallback response.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        while attempt < self.max_retries:\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt+1}\")\n                resp = await self.llm.ask(messages)\n                # If LLMInterface returns an error string, consider retrying\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Received error: {resp[:200]}\")\n                    attempt += 1\n                    await asyncio.sleep(self.retry_backoff * attempt)\n                    continue\n                return resp\n            except Exception as e:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, f\"{type(e).__name__}: {str(e)[:200]}\")\n                attempt += 1\n                await asyncio.sleep(self.retry_backoff * attempt)\n        # Exhausted retries\n        err = \"LLM request failed after retries.\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err)\n        return err\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\n\n    Inputs: idea text\n    Outputs: code text\n    \"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea: {idea[:120]}\")\n\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module that implements the \"\n            \"requested functionality. Focus on clarity, docstrings, error handling, and testability.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Provide only the Python code for the implementation (no surrounding backticks).\\n\"\n            \"- Keep the implementation self-contained and avoid external network calls.\\n\"\n            \"- Include docstrings and comments for functions.\\n\"\n            \"- Ensure the code defines at least one function or class.\\n\\n\"\n            \"Return the code only.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        code = await self.safe_ask(messages)\n\n        # Basic validation: non-empty and contains def or class\n        if not code or not any(token in code for token in (\"def \", \"class \")):\n            fallback = f\"# Fallback implementation for: {idea}\\n\\n\" \\\n                       \"def placeholder():\\n\" \\\n                       \"    '''Fallback placeholder implementation.'''\\n\" \\\n                       \"    return None\\n\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated code missing definitions; using fallback\")\n            code = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\n\n    Inputs: code text\n    Outputs: pytest-style test code\n    \"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code (len={len(code)})\")\n\n        # Extract top-level function/class names to suggest tests reference them\n        try:\n            parsed = ast.parse(code or \"\")\n            names = [n.name for n in parsed.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            names_snippet = \", \".join(names[:5]) if names else \"main\"\n        except Exception:\n            names_snippet = \"main\"\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style test cases for the following Python module. \"\n            \"Aim for clear, focused tests that exercise core behavior and edge cases. \"\n            \"Include docstrings for each test.\\n\\n\"\n            f\"Module summary: top-level names -> {names_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible test code only.\\n\"\n            \"- Include both positive and negative tests when applicable.\\n\"\n            \"- Use assert statements.\\n\\n\"\n            \"Return only the test code.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        tests = await self.safe_ask(messages)\n\n        # Basic validation: ensure there is at least one 'assert' or 'pytest'\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    '''Fallback test: ensures placeholder returns None.'''\\n\"\n                \"    from placeholder_module import placeholder if False else None\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated tests missing asserts; using fallback\")\n            tests = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\n\n    Inputs: code text, tests text\n    Outputs: review text (short) - includes REVIEW_DECISION token when possible\n    \"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: APPROVE. The code looks acceptable; consider edge-case tests.\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Provide a concise review with actionable items and an explicit \"\n                \"'REVIEW_DECISION: APPROVE' or 'REVIEW_DECISION: REJECT' line.\\n\\n\"\n                \"Code (first 2000 chars):\\n\"\n                f\"{(code or '')[:2000]}\\n\\n\"\n                \"Tests (first 2000 chars):\\n\"\n                f\"{(tests or '')[:2000]}\\n\\n\"\n                \"Focus on: code quality, test coverage, potential bugs, and a final decision line.\\n\"\n                \"Return the review text only.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self.safe_ask(messages)\n\n            # If the LLM reply lacks decision token, derive a simple heuristic\n            if \"REVIEW_DECISION:\" not in review:\n                decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REJECT\"\n                review = f\"{review}\\n\\nREVIEW_DECISION: {decision}\"\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed length={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\n\n    Inputs: code text, tests text\n    Outputs: structured verification result string starting with VERIFICATION_RESULT: PASS/FAIL\n    \"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        result_parts = []\n        code_ok = False\n        tests_ok = False\n        details = []\n\n        # Syntax checks\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = True if (tests and tests.strip()) else False\n            details.append(\"tests_syntax: ok\" if tests_ok else \"tests_syntax: fail (empty or invalid)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            tests_ok = False\n\n        # Semantic checks: ensure at least one function/class in code and at least one assert in tests\n        code_has_def = False\n        try:\n            parsed = ast.parse(code or \"\")\n            code_has_def = any(isinstance(n, (ast.FunctionDef, ast.ClassDef)) for n in parsed.body)\n            details.append(\"code_has_def: ok\" if code_has_def else \"code_has_def: fail\")\n        except Exception:\n            details.append(\"code_has_def: fail (parse error)\")\n\n        tests_has_assert = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # search for Assert nodes or pytest import\n            tests_has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"pytest\" in (tests or \"\"))\n            details.append(\"tests_has_assert: ok\" if tests_has_assert else \"tests_has_assert: fail\")\n        except Exception:\n            details.append(\"tests_has_assert: fail (parse error)\")\n\n        # Cross-reference: confirm tests reference at least one name defined in code\n        cross_ref_ok = False\n        try:\n            code_names = {n.name for n in ast.parse(code or \"\").body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            tests_text = tests or \"\"\n            if code_names:\n                for nm in code_names:\n                    if nm in tests_text:\n                        cross_ref_ok = True\n                        break\n            details.append(\"cross_reference: ok\" if cross_ref_ok else \"cross_reference: fail\")\n        except Exception:\n            details.append(\"cross_reference: fail (error)\")\n\n        verified = all([code_ok, tests_ok, code_has_def, tests_has_assert, cross_ref_ok])\n        status_line = \"VERIFICATION_RESULT: PASS\" if verified else \"VERIFICATION_RESULT: FAIL\"\n        # Compute a digest of code+tests to detect stability across rounds\n        digest = hashlib.sha256((code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")).hexdigest()[:12]\n        result = f\"{status_line} | digest={digest} | \" + \"; \".join(details)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\n\n    Responsibilities:\n    - Maintain clear responsibilities (single primary action).\n    - Track processed messages to avoid duplicate processing.\n    - Provide act(message) which handles errors and returns a Message.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # Track message ids we've processed\n        self._processed_ids: Set[str] = set()\n        # Environment reference may be set by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action in response to a message.\n\n        The role will not reprocess messages (idempotency), and will log failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        # pick primary action (roles are designed for single-action)\n        action = self.actions[0]\n\n        # If message is provided but already processed, skip\n        if message and message.id in self._processed_ids:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {message.id}\")\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message id={getattr(message, 'id', None)}\")\n\n        try:\n            # Dispatch based on action type; keep logic explicit\n            if isinstance(action, SimpleWriteCode):\n                inp = (message.instruct_content or message.content) if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteTest):\n                # Expect to receive the latest code message (message.content holds code or reference)\n                inp = message.content if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteReview):\n                # Expects a message that contains code and/or tests combined or references to both.\n                # Try to lookup latest code and test messages in environment if message is not explicit\n                code_text = \"\"\n                tests_text = \"\"\n                if message and message.cause_by == SimpleWriteTest.name:\n                    tests_text = message.content\n                    # find latest code\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteCode.name:\n                                code_text = msg.content\n                                break\n                elif message and message.cause_by == SimpleWriteCode.name:\n                    code_text = message.content\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name:\n                                tests_text = msg.content\n                                break\n                else:\n                    # fallback: try to find both in env\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = msg.content\n                            if msg.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = msg.content\n                            if code_text and tests_text:\n                                break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # Find latest code and tests from environment\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_text and msg.cause_by == SimpleWriteCode.name:\n                            code_text = msg.content\n                        if not tests_text and msg.cause_by == SimpleWriteTest.name:\n                            tests_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            else:\n                result = \"Action completed\"\n\n            # mark message processed\n            if message:\n                self._processed_ids.add(message.id)\n\n            # create response message\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name if action else \"\",\n                sent_from=self.name\n            )\n\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created id={response.id}\")\n            return response\n\n        except Exception as e:\n            # catch-all to avoid crashing the orchestrator\n            err_text = f\"Role {self.name} failed executing {action.name}: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err_text)\n            response = Message(\n                content=err_text,\n                role=self.profile,\n                cause_by=\"Error\",\n                sent_from=self.name\n            )\n            return response\n\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\n\n    Responsibilities:\n    - Store message history.\n    - Maintain subscriptions mapping from action names to roles that watch them.\n    - Provide role-specific unprocessed messages.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Map action_name -> list of roles that watch it\n        self.subscriptions: Dict[str, List[Role]] = defaultdict(list)\n        # Track which messages have been delivered to which role ids\n        self._delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n        # Register subscriptions based on watch_list\n        for watched in role.watch_list:\n            self.subscriptions[watched.name].append(role)\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment (append to history)\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {message.sent_from} ({message.cause_by}): {message.content[:200]} id={message.id}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get new messages that a role should respond to.\n\n        Criteria:\n        - Messages explicitly targeted to the role (send_to contains role.name)\n        - Messages caused by actions that this role watches\n        - Excludes messages already delivered to this role (idempotency)\n        \"\"\"\n        relevant_messages = []\n        seen = self._delivered.get(role.name, set())\n        for msg in self.history:\n            # Skip if already delivered to this role\n            if msg.id in seen:\n                continue\n            targeted = False\n            if hasattr(msg, \"send_to\") and msg.send_to:\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    targeted = True\n            # If it's targeted or it's from a watched action, include\n            if targeted or any(msg.cause_by == watched.name for watched in role.watch_list):\n                relevant_messages.append(msg)\n                seen.add(msg.id)\n        # record delivery\n        if relevant_messages:\n            self._delivered[role.name] = seen\n        return relevant_messages\n\n\nclass Team:\n    \"\"\"Team of agents working together\n\n    Improvements:\n    - Deterministic orchestration order\n    - No duplicate processing\n    - Explicit termination criteria: require stable verification (consecutive passes)\n    - Robust error handling and tracing\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Orchestration order\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # Track consecutive verification stability\n        self._last_verified_digest: Optional[str] = None\n        self._verified_streak: int = 0\n        self._required_consecutive_verifications: int = 2  # require stability across rounds\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\n\n        Termination:\n        - Stop early if verifier reports PASS for the same digest _required_consecutive_verifications_ times.\n        - Otherwise proceed up to n_round rounds.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n\n            # For each role type in orchestration order, find all roles of that type and let them act on new messages\n            for role_type in self.order:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # find messages for role\n                    messages = self.env.get_messages_for_role(role)\n                    # Choose the latest message (if multiple) to act upon, but allow acting on each new message once\n                    for msg in messages:\n                        if msg.id in getattr(role, \"_processed_ids\", set()):\n                            continue\n                        response = await role.act(msg)\n                        if response:\n                            # Tag responses to indicate they should be considered by watchers\n                            # Responses will have cause_by set by role.act\n                            response.sent_to = None\n                            self.env.publish_message(response)\n\n            # After roles acted, let verifier run (could have been triggered above)\n            # Check latest verifier messages to determine verification status\n            verifier_roles = [r for r in self.env.roles if isinstance(r, SimpleVerifier)]\n            for verifier in verifier_roles:\n                # get messages intended for verifier (env.get_messages_for_role will return new relevant ones)\n                v_msgs = self.env.get_messages_for_role(verifier)\n                for vmsg in v_msgs:\n                    if vmsg.id in getattr(verifier, \"_processed_ids\", set()):\n                        continue\n                    resp = await verifier.act(vmsg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        # parse verification result\n                        content = resp.content or \"\"\n                        if \"VERIFICATION_RESULT: PASS\" in content:\n                            # extract digest\n                            digest_part = None\n                            for tok in content.split(\"|\"):\n                                tok = tok.strip()\n                                if tok.startswith(\"digest=\"):\n                                    digest_part = tok.split(\"=\", 1)[1]\n                                    break\n                            if digest_part:\n                                if digest_part == self._last_verified_digest:\n                                    self._verified_streak += 1\n                                else:\n                                    self._last_verified_digest = digest_part\n                                    self._verified_streak = 1\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", f\"Digest={digest_part} streak={self._verified_streak}\")\n                                if self._verified_streak >= self._required_consecutive_verifications:\n                                    verified = True\n                            else:\n                                # If no digest, count as one pass but not stable\n                                self._verified_streak = 1\n                                verified = False\n                                self._last_verified_digest = None\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Pass without digest; continuing\")\n                        else:\n                            # Reset streak on fail\n                            self._verified_streak = 0\n                            self._last_verified_digest = None\n                            self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Verification failed\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed; verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_consecutive_verifications} rounds, stopping early\")\n                break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project ended after {round_num} rounds; verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "3d91acaf-bcc7-43c5-88af-7196dafaee82", "generation": 1, "timestamp": 1754655301.4671738, "iteration_found": 6, "metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.16216216216216214, "avg_failures_per_task": 5.166666666666667, "total_failures": 31.0, "successful_runs": 6.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.16666666666666666, "avg_failures_per_task": 5.0, "total_failures": 30.0, "successful_runs": 6.0}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 1.0000\n- overall_score: 0.5000\n- combined_score: 0.1667\n- avg_failures_per_task: 5.0000\n- total_failures: 30.0000\n- successful_runs: 6.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.1667, avg_failures_per_task: 5.0000, total_failures: 30.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 7.1111)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1667), Performs well on avg_failures_per_task (5.0000), Performs well on total_failures (30.0000), Performs well on successful_runs (6.0000)\n\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport hashlib\nimport ast\nfrom collections import defaultdict\n\nclass Action(ABC):\n    \"\"\"Base action class\n\n    Responsibilities:\n    - Provide a run(...) coroutine that performs the action.\n    - Provide safe_ask(...) wrapper to call LLM with retries and logging.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM.ask with retry and basic error detection.\"\"\"\n        if not self.llm:\n            # No LLM configured, return a helpful fallback\n            fallback = \"LLM not available: fallback response.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        while attempt < self.max_retries:\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt+1}\")\n                resp = await self.llm.ask(messages)\n                # If LLMInterface returns an error string, consider retrying\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Received error: {resp[:200]}\")\n                    attempt += 1\n                    await asyncio.sleep(self.retry_backoff * attempt)\n                    continue\n                return resp\n            except Exception as e:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, f\"{type(e).__name__}: {str(e)[:200]}\")\n                attempt += 1\n                await asyncio.sleep(self.retry_backoff * attempt)\n        # Exhausted retries\n        err = \"LLM request failed after retries.\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err)\n        return err\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\n\n    Inputs: idea text\n    Outputs: code text\n    \"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea: {idea[:120]}\")\n\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module that implements the \"\n            \"requested functionality. Focus on clarity, docstrings, error handling, and testability.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Provide only the Python code for the implementation (no surrounding backticks).\\n\"\n            \"- Keep the implementation self-contained and avoid external network calls.\\n\"\n            \"- Include docstrings and comments for functions.\\n\"\n            \"- Ensure the code defines at least one function or class.\\n\\n\"\n            \"Return the code only.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        code = await self.safe_ask(messages)\n\n        # Basic validation: non-empty and contains def or class\n        if not code or not any(token in code for token in (\"def \", \"class \")):\n            fallback = f\"# Fallback implementation for: {idea}\\n\\n\" \\\n                       \"def placeholder():\\n\" \\\n                       \"    '''Fallback placeholder implementation.'''\\n\" \\\n                       \"    return None\\n\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated code missing definitions; using fallback\")\n            code = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\n\n    Inputs: code text\n    Outputs: pytest-style test code\n    \"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code (len={len(code)})\")\n\n        # Extract top-level function/class names to suggest tests reference them\n        try:\n            parsed = ast.parse(code or \"\")\n            names = [n.name for n in parsed.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            names_snippet = \", \".join(names[:5]) if names else \"main\"\n        except Exception:\n            names_snippet = \"main\"\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style test cases for the following Python module. \"\n            \"Aim for clear, focused tests that exercise core behavior and edge cases. \"\n            \"Include docstrings for each test.\\n\\n\"\n            f\"Module summary: top-level names -> {names_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible test code only.\\n\"\n            \"- Include both positive and negative tests when applicable.\\n\"\n            \"- Use assert statements.\\n\\n\"\n            \"Return only the test code.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        tests = await self.safe_ask(messages)\n\n        # Basic validation: ensure there is at least one 'assert' or 'pytest'\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    '''Fallback test: ensures placeholder returns None.'''\\n\"\n                \"    from placeholder_module import placeholder if False else None\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated tests missing asserts; using fallback\")\n            tests = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\n\n    Inputs: code text, tests text\n    Outputs: review text (short) - includes REVIEW_DECISION token when possible\n    \"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: APPROVE. The code looks acceptable; consider edge-case tests.\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Provide a concise review with actionable items and an explicit \"\n                \"'REVIEW_DECISION: APPROVE' or 'REVIEW_DECISION: REJECT' line.\\n\\n\"\n                \"Code (first 2000 chars):\\n\"\n                f\"{(code or '')[:2000]}\\n\\n\"\n                \"Tests (first 2000 chars):\\n\"\n                f\"{(tests or '')[:2000]}\\n\\n\"\n                \"Focus on: code quality, test coverage, potential bugs, and a final decision line.\\n\"\n                \"Return the review text only.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self.safe_ask(messages)\n\n            # If the LLM reply lacks decision token, derive a simple heuristic\n            if \"REVIEW_DECISION:\" not in review:\n                decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REJECT\"\n                review = f\"{review}\\n\\nREVIEW_DECISION: {decision}\"\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed length={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\n\n    Inputs: code text, tests text\n    Outputs: structured verification result string starting with VERIFICATION_RESULT: PASS/FAIL\n    \"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        result_parts = []\n        code_ok = False\n        tests_ok = False\n        details = []\n\n        # Syntax checks\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = True if (tests and tests.strip()) else False\n            details.append(\"tests_syntax: ok\" if tests_ok else \"tests_syntax: fail (empty or invalid)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            tests_ok = False\n\n        # Semantic checks: ensure at least one function/class in code and at least one assert in tests\n        code_has_def = False\n        try:\n            parsed = ast.parse(code or \"\")\n            code_has_def = any(isinstance(n, (ast.FunctionDef, ast.ClassDef)) for n in parsed.body)\n            details.append(\"code_has_def: ok\" if code_has_def else \"code_has_def: fail\")\n        except Exception:\n            details.append(\"code_has_def: fail (parse error)\")\n\n        tests_has_assert = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # search for Assert nodes or pytest import\n            tests_has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"pytest\" in (tests or \"\"))\n            details.append(\"tests_has_assert: ok\" if tests_has_assert else \"tests_has_assert: fail\")\n        except Exception:\n            details.append(\"tests_has_assert: fail (parse error)\")\n\n        # Cross-reference: confirm tests reference at least one name defined in code\n        cross_ref_ok = False\n        try:\n            code_names = {n.name for n in ast.parse(code or \"\").body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            tests_text = tests or \"\"\n            if code_names:\n                for nm in code_names:\n                    if nm in tests_text:\n                        cross_ref_ok = True\n                        break\n            details.append(\"cross_reference: ok\" if cross_ref_ok else \"cross_reference: fail\")\n        except Exception:\n            details.append(\"cross_reference: fail (error)\")\n\n        verified = all([code_ok, tests_ok, code_has_def, tests_has_assert, cross_ref_ok])\n        status_line = \"VERIFICATION_RESULT: PASS\" if verified else \"VERIFICATION_RESULT: FAIL\"\n        # Compute a digest of code+tests to detect stability across rounds\n        digest = hashlib.sha256((code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")).hexdigest()[:12]\n        result = f\"{status_line} | digest={digest} | \" + \"; \".join(details)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\n\n    Responsibilities:\n    - Maintain clear responsibilities (single primary action).\n    - Track processed messages to avoid duplicate processing.\n    - Provide act(message) which handles errors and returns a Message.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # Track message ids we've processed\n        self._processed_ids: Set[str] = set()\n        # Environment reference may be set by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action in response to a message.\n\n        The role will not reprocess messages (idempotency), and will log failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        # pick primary action (roles are designed for single-action)\n        action = self.actions[0]\n\n        # If message is provided but already processed, skip\n        if message and message.id in self._processed_ids:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {message.id}\")\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message id={getattr(message, 'id', None)}\")\n\n        try:\n            # Dispatch based on action type; keep logic explicit\n            if isinstance(action, SimpleWriteCode):\n                inp = (message.instruct_content or message.content) if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteTest):\n                # Expect to receive the latest code message (message.content holds code or reference)\n                inp = message.content if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteReview):\n                # Expects a message that contains code and/or tests combined or references to both.\n                # Try to lookup latest code and test messages in environment if message is not explicit\n                code_text = \"\"\n                tests_text = \"\"\n                if message and message.cause_by == SimpleWriteTest.name:\n                    tests_text = message.content\n                    # find latest code\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteCode.name:\n                                code_text = msg.content\n                                break\n                elif message and message.cause_by == SimpleWriteCode.name:\n                    code_text = message.content\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name:\n                                tests_text = msg.content\n                                break\n                else:\n                    # fallback: try to find both in env\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = msg.content\n                            if msg.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = msg.content\n                            if code_text and tests_text:\n                                break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # Find latest code and tests from environment\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_text and msg.cause_by == SimpleWriteCode.name:\n                            code_text = msg.content\n                        if not tests_text and msg.cause_by == SimpleWriteTest.name:\n                            tests_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            else:\n                result = \"Action completed\"\n\n            # mark message processed\n            if message:\n                self._processed_ids.add(message.id)\n\n            # create response message\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name if action else \"\",\n                sent_from=self.name\n            )\n\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created id={response.id}\")\n            return response\n\n        except Exception as e:\n            # catch-all to avoid crashing the orchestrator\n            err_text = f\"Role {self.name} failed executing {action.name}: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err_text)\n            response = Message(\n                content=err_text,\n                role=self.profile,\n                cause_by=\"Error\",\n                sent_from=self.name\n            )\n            return response\n\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\n\n    Responsibilities:\n    - Store message history.\n    - Maintain subscriptions mapping from action names to roles that watch them.\n    - Provide role-specific unprocessed messages.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Map action_name -> list of roles that watch it\n        self.subscriptions: Dict[str, List[Role]] = defaultdict(list)\n        # Track which messages have been delivered to which role ids\n        self._delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n        # Register subscriptions based on watch_list\n        for watched in role.watch_list:\n            self.subscriptions[watched.name].append(role)\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment (append to history)\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {message.sent_from} ({message.cause_by}): {message.content[:200]} id={message.id}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get new messages that a role should respond to.\n\n        Criteria:\n        - Messages explicitly targeted to the role (send_to contains role.name)\n        - Messages caused by actions that this role watches\n        - Excludes messages already delivered to this role (idempotency)\n        \"\"\"\n        relevant_messages = []\n        seen = self._delivered.get(role.name, set())\n        for msg in self.history:\n            # Skip if already delivered to this role\n            if msg.id in seen:\n                continue\n            targeted = False\n            if hasattr(msg, \"send_to\") and msg.send_to:\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    targeted = True\n            # If it's targeted or it's from a watched action, include\n            if targeted or any(msg.cause_by == watched.name for watched in role.watch_list):\n                relevant_messages.append(msg)\n                seen.add(msg.id)\n        # record delivery\n        if relevant_messages:\n            self._delivered[role.name] = seen\n        return relevant_messages\n\n\nclass Team:\n    \"\"\"Team of agents working together\n\n    Improvements:\n    - Deterministic orchestration order\n    - No duplicate processing\n    - Explicit termination criteria: require stable verification (consecutive passes)\n    - Robust error handling and tracing\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Orchestration order\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # Track consecutive verification stability\n        self._last_verified_digest: Optional[str] = None\n        self._verified_streak: int = 0\n        self._required_consecutive_verifications: int = 2  # require stability across rounds\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\n\n        Termination:\n        - Stop early if verifier reports PASS for the same digest _required_consecutive_verifications_ times.\n        - Otherwise proceed up to n_round rounds.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n\n            # For each role type in orchestration order, find all roles of that type and let them act on new messages\n            for role_type in self.order:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # find messages for role\n                    messages = self.env.get_messages_for_role(role)\n                    # Choose the latest message (if multiple) to act upon, but allow acting on each new message once\n                    for msg in messages:\n                        if msg.id in getattr(role, \"_processed_ids\", set()):\n                            continue\n                        response = await role.act(msg)\n                        if response:\n                            # Tag responses to indicate they should be considered by watchers\n                            # Responses will have cause_by set by role.act\n                            response.sent_to = None\n                            self.env.publish_message(response)\n\n            # After roles acted, let verifier run (could have been triggered above)\n            # Check latest verifier messages to determine verification status\n            verifier_roles = [r for r in self.env.roles if isinstance(r, SimpleVerifier)]\n            for verifier in verifier_roles:\n                # get messages intended for verifier (env.get_messages_for_role will return new relevant ones)\n                v_msgs = self.env.get_messages_for_role(verifier)\n                for vmsg in v_msgs:\n                    if vmsg.id in getattr(verifier, \"_processed_ids\", set()):\n                        continue\n                    resp = await verifier.act(vmsg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        # parse verification result\n                        content = resp.content or \"\"\n                        if \"VERIFICATION_RESULT: PASS\" in content:\n                            # extract digest\n                            digest_part = None\n                            for tok in content.split(\"|\"):\n                                tok = tok.strip()\n                                if tok.startswith(\"digest=\"):\n                                    digest_part = tok.split(\"=\", 1)[1]\n                                    break\n                            if digest_part:\n                                if digest_part == self._last_verified_digest:\n                                    self._verified_streak += 1\n                                else:\n                                    self._last_verified_digest = digest_part\n                                    self._verified_streak = 1\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", f\"Digest={digest_part} streak={self._verified_streak}\")\n                                if self._verified_streak >= self._required_consecutive_verifications:\n                                    verified = True\n                            else:\n                                # If no digest, count as one pass but not stable\n                                self._verified_streak = 1\n                                verified = False\n                                self._last_verified_digest = None\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Pass without digest; continuing\")\n                        else:\n                            # Reset streak on fail\n                            self._verified_streak = 0\n                            self._last_verified_digest = None\n                            self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Verification failed\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed; verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_consecutive_verifications} rounds, stopping early\")\n                break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project ended after {round_num} rounds; verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}