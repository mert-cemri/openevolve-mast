{"id": "bd8b781f-0011-470b-be1d-ccd70eb9a7c4_migrant_1", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n\n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n\n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Iterable\n\n# Tunable parameters to improve robustness\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nROLE_ACTION_TIMEOUT = 30  # seconds\nROLE_MAX_ATTEMPTS = 2\nVERIFY_STABLE_REQUIRED = 2\nNO_PROGRESS_GRACE = 2  # rounds without progress before nudging/stop\n\n# ---------------------------\n# Actions\n# ---------------------------\n\nclass Action(ABC):\n    \"\"\"Base Action with LLM-safe call and tracing.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, backoff, jitter, and deterministic fallback on failure.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface missing; using deterministic fallback\")\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n\n        for attempt in range(1, LLM_MAX_RETRIES + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{LLM_MAX_RETRIES}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                # success\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} success len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}:{str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < LLM_MAX_RETRIES:\n                    backoff = LLM_BACKOFF_BASE * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n        # exhausted\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, f\"Failed after {LLM_MAX_RETRIES} attempts: {last_err}\")\n        return f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No idea, returning deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Produce a concise, testable Python module implementing the task.\\n\"\n            \"Constraints: return only Python source, include docstrings and input validation where appropriate.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        # Deterministic fallback if LLM failed\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback implementation due to LLM error.\\\"\\\"\\\"\\n\"\n                \"    if value is None:\\n\"\n                \"        return None\\n\"\n                \"    return value\\n\"\n            )\n        # Validate python\n        try:\n            ast.parse(resp)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, f\"AST parse failed: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback because generated code did not parse.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code -> placeholder test\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        # extract top-level symbols to guide test generation\n        symbols = []\n        try:\n            parsed = ast.parse(code)\n            for node in parsed.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)) and not node.name.startswith(\"_\"):\n                    symbols.append(node.name)\n        except Exception:\n            symbols = []\n        prompt = (\n            \"You are an expert QA engineer. Given the implementation, produce pytest tests covering normal and edge cases.\\n\"\n            f\"Public symbols: {', '.join(symbols[:6]) or '(none)'}\\n\\nCode (truncated):\\n{(code or '')[:3000]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic test fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        # Validate tests include assert or test functions\n        try:\n            parsed_tests = ast.parse(resp)\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = \"assert\" in resp\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, \"Generated tests invalid -> fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # quick static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{str(e)[:160]}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: manual inspection recommended; \" + (\"; \".join(issues) if issues else \"no static issues\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review and end with a single-line VERDICT: APPROVE or VERDICT: REQUEST_CHANGES.\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\nCode (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> request changes\")\n            return \"VERDICT: REQUEST_CHANGES\\nAutomated reviewer: failed to produce review.\"\n        if \"VERDICT:\" not in resp:\n            verdict = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            resp = resp.strip() + f\"\\n\\nVERDICT: {verdict}\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(resp)}\")\n        return resp\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Running deterministic verification\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n        code_defs = set()\n\n        # code parse\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            code_defs = {n.name for n in parsed_code.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            details.append(f\"code_defs:{len(code_defs)}\")\n        except Exception as e:\n            details.append(f\"code_parse_error:{str(e)[:160]}\")\n\n        # tests parse & heuristics\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            details.append(\"tests_present\" if tests_ok else \"tests_missing_asserts_or_fns\")\n        except Exception as e:\n            details.append(f\"tests_parse_error:{str(e)[:160]}\")\n\n        # reference check\n        if code_defs and tests_ok:\n            txt = tests or \"\"\n            for nm in code_defs:\n                if nm and nm in txt:\n                    references_ok = True\n                    break\n            details.append(\"tests_reference_ok\" if references_ok else \"tests_do_not_reference_code\")\n        else:\n            details.append(\"tests_reference_check_skipped\")\n\n        verified = code_ok and tests_ok and references_ok\n        # produce digest for stability\n        try:\n            digest_src = (code or \"\").encode(\"utf-8\") + b\"||\" + (tests or \"\").encode(\"utf-8\")\n            digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# ---------------------------\n# Roles\n# ---------------------------\n\nclass Role(ABC):\n    \"\"\"Clear role definition with watch/trigger and idempotency.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: Iterable[Type[Action]]):\n        self.watch_list = [getattr(a, \"name\", str(a)) for a in actions]\n\n    def should_handle(self, msg: Message) -> bool:\n        \"\"\"Decide whether to handle a message.\"\"\"\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # do not handle own messages\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # explicit routing (send_to has priority)\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None)\n        if targets:\n            try:\n                if isinstance(targets, (set, list)):\n                    if self.name in targets or self.profile in targets or \"*\" in targets:\n                        return True\n                elif isinstance(targets, str):\n                    if targets in (self.name, self.profile, \"*\"):\n                        return True\n            except Exception:\n                pass\n            # if explicitly addressed elsewhere, and not this role, don't handle\n            return False\n        # watchlist trigger\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        # default: user input to coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action for this role; return produced Message or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg={getattr(message,'id',None)}\")\n            return None\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Running {action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                out = await action.run(idea)\n                send_to = {\"SimpleTester\"}\n            elif isinstance(action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and getattr(message, \"content\", None) else \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest.content if latest else \"\"\n                out = await action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(action, SimpleWriteReview):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                lowered = (out or \"\").lower()\n                if \"request\" in lowered or \"reject\" in lowered or \"request_changes\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(action, SimpleVerify):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = set()  # broadcast semantics handled by orchestrator\n            else:\n                out = await action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n            # mark processed to avoid duplicates\n            if message and getattr(message, \"id\", None):\n                self._processed_ids.add(message.id)\n            resp = Message(content=out, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n            if tracer:\n                tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg {getattr(resp,'id',None)} send_to={send_to}\")\n            return resp\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            resp = Message(content=err, role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to={\"Team\"})\n            return resp\n\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])\n\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\n# ---------------------------\n# Environment & Team\n# ---------------------------\n\nclass Environment:\n    \"\"\"Message bus with delivery tracking and artifact lookup.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._delivered: Dict[str, Set[str]] = {}\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} -> {list(getattr(message,'send_to',set()))} preview={snippet}\")\n\n    def mark_delivered(self, role: Role, message: Message):\n        if not getattr(message, \"id\", None):\n            return\n        self._delivered.setdefault(role.name, set()).add(message.id)\n        if self.tracer:\n            self.tracer.log(\"ENV_MARK_DELIVERED\", \"Environment\", f\"{role.name} delivered {message.id}\")\n\n    def get_pending_for_role(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            # explicit targeting\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            targeted = False\n            try:\n                if isinstance(targets, (set, list)):\n                    if role.name in targets or role.profile in targets or \"*\" in targets:\n                        targeted = True\n                elif isinstance(targets, str):\n                    if targets in (role.name, role.profile, \"*\"):\n                        targeted = True\n            except Exception:\n                targeted = False\n            if targeted:\n                out.append(msg)\n                seen.add(mid)\n                continue\n            # watch-list trigger\n            if getattr(msg, \"cause_by\", None) in getattr(role, \"watch_list\", []):\n                out.append(msg)\n                seen.add(mid)\n                continue\n        return out\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        msgs = self._by_cause.get(cause, [])\n        return msgs[-1] if msgs else None\n\n\nclass Team:\n    \"\"\"Orchestrator that enforces deterministic ordering, verification stability, and robust retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_stable_passes: int = VERIFY_STABLE_REQUIRED\n        self._max_role_attempts_per_message: int = ROLE_MAX_ATTEMPTS\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        attempts = 0\n        while attempts < self._max_role_attempts_per_message:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=ROLE_ACTION_TIMEOUT)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempts} for msg {getattr(msg,'id',None)}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempts} for msg {getattr(msg,'id',None)}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.05 * attempts)\n        # publish an error message to keep traceability\n        err = Message(content=f\"ERROR: role {role.name} failed processing message {getattr(msg,'id',None)} after {attempts} attempts\",\n                      role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._required_stable_passes} stable verification passes\")\n        # initial user message targeted to coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial_msg = Message(content=f\"Let's work on this project: {self.idea}\",\n                              instruct_content=self.idea,\n                              role=\"Human\",\n                              sent_from=\"User\",\n                              cause_by=\"UserInput\",\n                              send_to=coder_profiles)\n        self.env.publish_message(initial_msg)\n\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            new_messages = 0\n            for role_type in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles:\n                    pending = self.env.get_pending_for_role(role)\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and rnd == 1:\n                        if initial_msg not in pending and initial_msg.id not in self.env._delivered.get(role.name, set()):\n                            pending = [initial_msg] + pending\n                    for msg in pending:\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            self.env.mark_delivered(role, msg)\n                            continue\n                        resp = await self._invoke_role(role, msg)\n                        # mark delivered irrespective of resp to avoid livelock\n                        self.env.mark_delivered(role, msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            new_messages += 1\n                            # verifier handling: update streak based on digest\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                content = resp.content\n                                if \"VERIFICATION_RESULT: PASS\" in content:\n                                    digest = None\n                                    for token in content.split(\"|\"):\n                                        token = token.strip()\n                                        if token.startswith(\"digest=\"):\n                                            digest = token.split(\"=\", 1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    else:\n                                        # no digest: treat as single pass but not stable\n                                        self._last_digest = None\n                                        self._streak = 1\n                                else:\n                                    if self._streak > 0:\n                                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                                    self._streak = 0\n                                    self._last_digest = None\n            # progress check\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed; new_messages={new_messages} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require stable consecutive verification passes and at least one round\n            if self._streak >= self._required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping early\")\n                break\n\n            # no progress handling: nudge coder(s) if grace exceeded; stop if prolonged stagnation\n            if new_messages == 0:\n                if no_progress_rounds >= NO_PROGRESS_GRACE:\n                    self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds; terminating early\")\n                    break\n                # gentle nudge\n                self.tracer.log(\"TEAM_NUDGE\", \"Team\", \"Nudging coder(s) due to lack of progress\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please refine implementation for: {self.idea}\",\n                                        instruct_content=self.idea,\n                                        role=\"System\",\n                                        sent_from=\"Orchestrator\",\n                                        cause_by=\"Nudge\",\n                                        send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # allow immediate small processing window\n                await asyncio.sleep(0.01)\n            else:\n                # allow cooperative pause\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rnd} rounds; messages={len(self.env.history)} verified_streak={self._streak}\")\n        summary = f\"Project '{self.idea}' completed after {rnd} rounds with {len(self.env.history)} messages. verifier_streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "bd8b781f-0011-470b-be1d-ccd70eb9a7c4", "generation": 4, "timestamp": 1754658272.4340236, "iteration_found": 0, "metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.16666666666666666, "avg_failures_per_task": 5.0, "total_failures": 30.0, "successful_runs": 6.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 1, "migrant": true}, "artifacts_json": null, "artifact_dir": null}