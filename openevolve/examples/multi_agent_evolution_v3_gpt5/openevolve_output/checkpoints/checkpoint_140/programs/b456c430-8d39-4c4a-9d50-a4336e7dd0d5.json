{"id": "b456c430-8d39-4c4a-9d50-a4336e7dd0d5", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# Evolved multi-agent logic focusing on clarity, robustness, and reduced failure modes.\n\nimport asyncio\nimport ast\nimport random\nimport time\nfrom typing import Iterable, Tuple\n\n# Tunable parameters\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nVERIFICATION_STABLE_REQUIRED = 2\nNO_PROGRESS_LIMIT = 2  # rounds\n\n# Utility helpers\ndef _to_set_send_to(msg: Message) -> Set[str]:\n    s = getattr(msg, \"send_to\", None)\n    if s is None:\n        s = getattr(msg, \"sent_to\", None) or set()\n    if isinstance(s, (list, tuple)):\n        return set(s)\n    if isinstance(s, str):\n        return {s}\n    return set(s or set())\n\ndef _strip_fences(text: Optional[str]) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    t = text.strip()\n    # remove common fences\n    if t.startswith(\"", "language": "python", "parent_id": "2816b034-6620-4512-b94a-51136a4388cd", "generation": 5, "timestamp": 1754658104.4716513, "iteration_found": 127, "metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "unterminated string literal (detected at line 191) (tmpjkiukj9c.py, line 191)"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "unterminated string literal (detected at line 186) (tmptxgl594i.py, line 186)"}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.0000\n- combined_score: 0.0000\n- avg_failures_per_task: 14.0000\n- error: unterminated string literal (detected at line 186) (tmptxgl594i.py, line 186)\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: avg_failures_per_task. Consider continuing with similar changes.\n- Metrics showing regression: runs_successfully, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 4\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2400, avg_failures_per_task: 3.1667, total_failures: 19.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2727, avg_failures_per_task: 2.6667, total_failures: 16.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2857, avg_failures_per_task: 2.5000, total_failures: 15.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 3.8304)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport random\nimport time\n\nclass Action(ABC):\n    \"\"\"\n    Base action class.\n    - Provides robust LLM call with exponential backoff, jitter, and clear error handling.\n    - Actions are pure units of work that take inputs and return outputs (strings).\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Call the LLM with retries, exponential backoff and jitter.\n        Returns either the LLM string response or a structured error string starting with \"LLM_ERROR:\".\n        \"\"\"\n        import asyncio\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if not self.llm:\n                    # Deterministic fallback for offline runs\n                    response = \"LLM_FALLBACK: no-llm-available\"\n                else:\n                    response = await self.llm.ask(messages)\n\n                # Detect common LLM error patterns\n                if not isinstance(response, str) or response.strip() == \"\":\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response from LLM\")\n                if response.strip().lower().startswith(\"error\") or \"http\" in response and \"error\" in response.lower():\n                    last_err = response\n                    raise RuntimeError(f\"LLM returned error-like text: {response[:200]}\")\n\n                # Log success\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} succeeded (len={len(response)})\")\n                return response\n\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                # Backoff with jitter\n                if attempt < self.max_retries:\n                    backoff = self.base_backoff * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n                else:\n                    if self.context and getattr(self.context, \"tracer\", None):\n                        self.context.tracer.log(\"LLM_GIVEUP\", self.name, f\"Giving up after {self.max_retries} attempts: {last_err[:200]}\")\n        return f\"LLM_ERROR: {last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result.\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating code for idea (len={len(idea)})\")\n        prompt = (\n            \"You are an expert Python developer.\\n\"\n            \"Task:\\n\"\n            f\"{idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide production-ready Python code.\\n\"\n            \"- Include docstrings and input validation where appropriate.\\n\"\n            \"- Keep functions small and testable.\\n\"\n            \"- Return only the Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        # Basic sanity checks and fallback\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = f\"# ERROR: unable to generate code automatically. {result}\\n\\n# Placeholder function\\n\\ndef placeholder():\\n    \\\"\\\"\\\"Placeholder due to LLM failure.\\\"\\\"\\\"\\n    return None\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder code due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating tests for code (len={len(code)})\")\n        truncated = (code or \"\")[:4000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the provided Python code.\\n\\n\"\n            \"Code:\\n\"\n            f\"{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest test functions with clear assertions and docstrings.\\n\"\n            \"- Cover typical, boundary and error cases when applicable.\\n\"\n            \"- Return only pytest-compatible Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            note = f\"# ERROR_GENERATING_TESTS: {result}\\n# Tests not generated due to LLM error.\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder test note due to LLM error\")\n            return note\n        return result\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: recommended manual review.\"\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review and a readiness verdict.\\n\\n\"\n            \"Code (truncated):\\n\"\n            f\"{(code or '')[:2000]}\\n\\n\"\n            \"Tests (truncated):\\n\"\n            f\"{(tests or '')[:2000]}\\n\\n\"\n            \"Return:\\n- A short list of issues (if any)\\n- Checklist of fixes\\n- VERDICT: READY or NOT_READY (single line at the end prefixed by VERDICT:)\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = \"REVIEW_ERROR: Review could not be completed due to LLM failure.\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Review fallback due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"\n        Deterministic verification using static analysis heuristics.\n        Returns a structured verification result string.\n        \"\"\"\n        import ast\n        issues: List[str] = []\n        code_ok = False\n        tests_ok = False\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Starting verification\")\n\n        # Code syntax check\n        if not code or not code.strip():\n            issues.append(\"code_missing_or_empty\")\n        else:\n            try:\n                parsed = ast.parse(code)\n                code_ok = True\n                fn_names = [n.name for n in parsed.body if isinstance(n, ast.FunctionDef)]\n            except Exception as e:\n                issues.append(f\"code_syntax_error: {e}\")\n                fn_names = []\n\n        # Tests syntax and heuristics\n        if not tests or not tests.strip():\n            issues.append(\"tests_missing_or_empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristics: tests must contain 'assert' and at least one function named test_\n                contains_assert = \"assert \" in tests or \"pytest\" in tests.lower()\n                test_fns = [n.name for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\")]\n                tests_ok = bool(contains_assert and test_fns)\n                if not contains_assert:\n                    issues.append(\"tests_missing_asserts\")\n                if not test_fns:\n                    issues.append(\"tests_missing_test_functions\")\n            except Exception as e:\n                issues.append(f\"tests_syntax_error: {e}\")\n\n        # Ensure tests reference code functions when possible\n        references_code = False\n        if code_ok and tests_ok and fn_names:\n            for fn in fn_names:\n                if fn and fn in (tests or \"\"):\n                    references_code = True\n                    break\n            if not references_code:\n                issues.append(\"tests_do_not_reference_code\")\n\n        verified = code_ok and tests_ok and (references_code or not fn_names)\n        result = {\n            \"verified\": verified,\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok,\n            \"issues\": issues\n        }\n        summary = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | details: {result}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_END\", self.name, summary)\n        return summary\n\n\nclass Role(ABC):\n    \"\"\"\n    Clear role definition and responsibilities.\n    - Each role has a small set of actions.\n    - Each role maintains processed message ids to avoid duplicate work.\n    - Roles define watch_list (action names) and default recipients for produced messages.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # watch action names\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n        self._processed_message_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: List[Type[Action]]):\n        self.watch_list = [a.name for a in actions]\n\n    def should_respond(self, message: Message) -> bool:\n        \"\"\"\n        Decide whether the role should respond:\n        - Not already processed\n        - Explicitly addressed via send_to or sent_to\n        - Message cause_by matches watched actions\n        - Human user instructions target coders by default\n        \"\"\"\n        if not message:\n            return False\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # explicit addressing: either send_to set contains profile/name, or sent_to string matches\n        sent_to_set = getattr(message, \"send_to\", None)\n        if sent_to_set:\n            if isinstance(sent_to_set, (set, list)) and (self.profile in sent_to_set or self.name in sent_to_set or \"*\" in sent_to_set):\n                return True\n        sent_to_str = getattr(message, \"sent_to\", None)\n        if isinstance(sent_to_str, str) and (sent_to_str == self.profile or sent_to_str == self.name or sent_to_str == \"*\"):\n            return True\n        # watched action trigger\n        if getattr(message, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # default: user input goes to coders\n        if getattr(message, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Core action executor:\n        - Picks first applicable action and runs it.\n        - Records processed message id.\n        - Returns a Message with content, cause_by and intended send_to recipients.\n        - Robust error handling with retries for transient failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Received message id={(getattr(message,'id',None))} cause_by={(getattr(message,'cause_by',None))}\")\n\n        # find message to act on (if provided)\n        if message is not None and not self.should_respond(message):\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n\n        action = self.actions[0]  # single-responsibility per role; keep simple\n        attempts = 0\n        last_err = None\n        while attempts < 2:\n            attempts += 1\n            try:\n                # Build inputs based on action type\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    # Prefer code from message or find latest code in environment\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                    if not code_text and getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                                break\n                    result = await action.run(code_text)\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # Acquire latest code and tests from env if not supplied\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    # collect latest code/tests\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"Team\"}\n                else:\n                    result = await action.run()\n                    recipients = {\"Team\"}\n                # Mark message processed\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Create response message with clear routing\n                response = Message(\n                    content=result,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message cause_by={response.cause_by} send_to={recipients}\")\n                return response\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # small backoff\n                time.sleep(0.1 * attempts)\n        # If here, role failed reliably\n        fail_msg = f\"ROLE_FAILED: {self.name} after retries. Error={last_err}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"Unknown\"),\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])  # primarily triggered by UserInput or explicit addressing\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])  # run when code is available\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"\n    Environment handles message publication and routing.\n    - Maintains history (ordered).\n    - Provides messages relevant to a role using explicit send_to and watch_list rules.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Ensure ID exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"From {message.sent_from} cause_by={message.cause_by} send_to={getattr(message,'send_to',None)} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages a role should consider:\n        - Explicitly addressed messages (send_to / sent_to)\n        - Messages whose cause_by matches role.watch_list\n        - Exclude messages already processed by the role\n        \"\"\"\n        relevant: List[Message] = []\n        for msg in self.history:\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # explicit addressing via send_to (preferred)\n            sent_to = getattr(msg, \"send_to\", None)\n            if sent_to:\n                if isinstance(sent_to, (set, list)) and (role.profile in sent_to or role.name in sent_to or \"*\" in sent_to):\n                    relevant.append(msg)\n                    continue\n            # explicit sent_to string field\n            sent_to_str = getattr(msg, \"sent_to\", None)\n            if isinstance(sent_to_str, str) and (sent_to_str == role.profile or sent_to_str == role.name or sent_to_str == \"*\"):\n                relevant.append(msg)\n                continue\n            # watch_list triggers\n            if getattr(msg, \"cause_by\", \"\") in role.watch_list:\n                relevant.append(msg)\n                continue\n        return relevant\n\n\nclass Team:\n    \"\"\"\n    Team orchestrates roles, sequencing, termination, and verification confirmation logic.\n    - Requires multiple independent verification confirmations to avoid premature termination.\n    - Tracks progress and stops on verification PASS or prolonged no-progress.\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # require confirmations from verifiers (could be same verifier across rounds)\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2\n        # track unique verifiers or rounds that produced PASS to reduce false positives\n        self._verify_pass_rounds: Set[int] = set()\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        import asyncio\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._verify_confirm_needed} confirmations to stop early\")\n\n        # Initial User instruction directed to coder(s)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for round_idx in range(n_round):\n            round_num = round_idx + 1\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            progress_made = False\n\n            # Evaluate each role; roles decide if they act based on environment messages\n            for role in list(self.env.roles):\n                # Gather messages relevant to this role\n                msgs = self.env.get_messages_for_role(role)\n                # On first round, ensure coder sees the initial instruction even if not in msgs\n                if isinstance(role, SimpleCoder) and round_idx == 0:\n                    msgs = [initial_msg] + msgs\n                # Process messages in order; roles may produce one message per input to keep steps atomic\n                for msg in msgs:\n                    try:\n                        resp = await role.act(msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            progress_made = True\n                            # If verifier response contains a PASS, count confirmation\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    self._verify_confirm_count += 1\n                                    self._verify_pass_rounds.add(round_idx)\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                    if self._verify_confirm_count >= self._verify_confirm_needed:\n                                        verified = True\n                                elif \"VERIFICATION_RESULT: FAIL\" in resp.content:\n                                    # reset confirmations on explicit fail\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_RESET\", \"Team\", f\"Verifier {role.name} reported FAIL; confirmations reset\")\n                            # Log role failures directed to team\n                            if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                                self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure: {resp.content[:200]}\")\n                    except Exception as e:\n                        self.tracer.log(\"ROUND_ERROR\", role.name, f\"Exception during role.act: {e}\")\n\n            # Determine progress/no-progress and update termination conditions\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} complete (progress={progress_made})\")\n\n            # Termination: require at least one full round and required confirmations\n            if verified and round_num >= 1:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed after {self._verify_confirm_count} confirmations; stopping\")\n                break\n\n            # Stop if no progress for multiple rounds to avoid wasting cycles\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds; terminating early\")\n                break\n\n            # allow small async pause\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' finished after {round_num} rounds with {len(self.env.history)} messages. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.3158), Performs well on avg_failures_per_task (2.1667), Performs well on total_failures (13.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 2 (Score: 4.2143)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2857), Performs well on avg_failures_per_task (2.5000), Performs well on total_failures (15.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 3 (Score: 4.4066)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and (resp.strip() == \"\" or resp.strip().lower().startswith(\"error\")):\n                    last_err = resp or \"empty_response\"\n                    raise RuntimeError(last_err)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            return\n        for m in msgs:\n            try:\n                resp = await role.act(m)\n            finally:\n                # mark processed whether or not action succeeded to avoid infinite loops\n                self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet processed initial instruction\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no activity in this round, nudge coder proactively\n            if not any(m.cause_by in (SimpleWriteTest.name, SimpleWriteCode.name, SimpleWriteReview.name, SimpleVerify.name) for m in self.env.history[-4:]):\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2727), Performs well on avg_failures_per_task (2.6667), Performs well on total_failures (16.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 4 (Score: 4.9844)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2400), Performs well on avg_failures_per_task (3.1667), Performs well on total_failures (19.0000), Performs well on successful_runs (6.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 7.1111)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D2 (Score: 4.6667)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport random\nfrom typing import Tuple\n\n# Goals implemented:\n# - Clear roles and responsibilities\n# - Explicit triggers and routing (send_to)\n# - Deterministic orchestration with per-role processed tracking\n# - Robust LLM retry + fallback\n# - Strong verification and confirmation + stable termination (consecutive passes)\n# - Error handling and retry across role actions\n\nDEFAULT_VERIFICATION_STREAK = 2\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.8  # seconds\nMAX_MESSAGE_ATTEMPTS = 6\n\nclass Action(ABC):\n    \"\"\"Base action with LLM retry, backoff, validation and fallback semantics.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    backoff_base: float = LLM_BACKOFF_BASE\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def call_llm(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns string result or an explicit error token.\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # Deterministic fallback to avoid hard failure\n                    fallback = \"LLM_UNAVAILABLE: deterministic fallback\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # jittered backoff\n                await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)) + random.uniform(0, 0.25))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce a validated Python module from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            # clear signal for empty idea\n            fallback = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module implementing the described task. \"\n            \"Return only valid Python source code, no markdown fences or explanations. Include docstrings and input validation.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        resp = await self.call_llm(messages)\n        # If LLM failed, return explicit failure so downstream can react\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            fallback = f\"# CODE_GEN_ERROR: {resp}\\n# Please retry or provide a human-coded fallback.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning error sentinel\")\n            return fallback\n\n        # Try to sanitize common code fences\n        code = self._strip_code_fences(resp)\n        # Validate syntax\n        try:\n            ast.parse(code)\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Code syntax ok\")\n            return code\n        except Exception as e:\n            # attempt small fix: wrap into function if possible\n            try:\n                wrapper = \"def _generated_wrapper():\\n\"\n                for line in code.splitlines():\n                    wrapper += \"    \" + line + \"\\n\"\n                ast.parse(wrapper)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FIX\", self.name, \"Applied safe wrapper to fix syntax\")\n                return wrapper\n            except Exception:\n                err = f\"# CODE_PARSE_ERROR: {str(e)[:160]}\\n# Raw Output:\\n{code}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Code parse failed: {str(e)[:200]}\")\n                return err\n\n    def _strip_code_fences(self, text: Optional[str]) -> str:\n        if not text:\n            return \"\"\n        t = text.strip()\n        # remove triple backticks\n        if t.startswith(\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to combined_score\n\n\n### Program D3 (Score: 7.1111)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n\n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n\n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Iterable\n\n# Tunable parameters to improve robustness\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nROLE_ACTION_TIMEOUT = 30  # seconds\nROLE_MAX_ATTEMPTS = 2\nVERIFY_STABLE_REQUIRED = 2\nNO_PROGRESS_GRACE = 2  # rounds without progress before nudging/stop\n\n# ---------------------------\n# Actions\n# ---------------------------\n\nclass Action(ABC):\n    \"\"\"Base Action with LLM-safe call and tracing.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, backoff, jitter, and deterministic fallback on failure.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface missing; using deterministic fallback\")\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n\n        for attempt in range(1, LLM_MAX_RETRIES + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{LLM_MAX_RETRIES}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                # success\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} success len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}:{str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < LLM_MAX_RETRIES:\n                    backoff = LLM_BACKOFF_BASE * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n        # exhausted\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, f\"Failed after {LLM_MAX_RETRIES} attempts: {last_err}\")\n        return f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No idea, returning deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Produce a concise, testable Python module implementing the task.\\n\"\n            \"Constraints: return only Python source, include docstrings and input validation where appropriate.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        # Deterministic fallback if LLM failed\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback implementation due to LLM error.\\\"\\\"\\\"\\n\"\n                \"    if value is None:\\n\"\n                \"        return None\\n\"\n                \"    return value\\n\"\n            )\n        # Validate python\n        try:\n            ast.parse(resp)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, f\"AST parse failed: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback because generated code did not parse.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code -> placeholder test\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        # extract top-level symbols to guide test generation\n        symbols = []\n        try:\n            parsed = ast.parse(code)\n            for node in parsed.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)) and not node.name.startswith(\"_\"):\n                    symbols.append(node.name)\n        except Exception:\n            symbols = []\n        prompt = (\n            \"You are an expert QA engineer. Given the implementation, produce pytest tests covering normal and edge cases.\\n\"\n            f\"Public symbols: {', '.join(symbols[:6]) or '(none)'}\\n\\nCode (truncated):\\n{(code or '')[:3000]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic test fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        # Validate tests include assert or test functions\n        try:\n            parsed_tests = ast.parse(resp)\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = \"assert\" in resp\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, \"Generated tests invalid -> fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # quick static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{str(e)[:160]}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: manual inspection recommended; \" + (\"; \".join(issues) if issues else \"no static issues\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review and end with a single-line VERDICT: APPROVE or VERDICT: REQUEST_CHANGES.\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\nCode (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> request changes\")\n            return \"VERDICT: REQUEST_CHANGES\\nAutomated reviewer: failed to produce review.\"\n        if \"VERDICT:\" not in resp:\n            verdict = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            resp = resp.strip() + f\"\\n\\nVERDICT: {verdict}\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(resp)}\")\n        return resp\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Running deterministic verification\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n        code_defs = set()\n\n        # code parse\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            code_defs = {n.name for n in parsed_code.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            details.append(f\"code_defs:{len(code_defs)}\")\n        except Exception as e:\n            details.append(f\"code_parse_error:{str(e)[:160]}\")\n\n        # tests parse & heuristics\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            details.append(\"tests_present\" if tests_ok else \"tests_missing_asserts_or_fns\")\n        except Exception as e:\n            details.append(f\"tests_parse_error:{str(e)[:160]}\")\n\n        # reference check\n        if code_defs and tests_ok:\n            txt = tests or \"\"\n            for nm in code_defs:\n                if nm and nm in txt:\n                    references_ok = True\n                    break\n            details.append(\"tests_reference_ok\" if references_ok else \"tests_do_not_reference_code\")\n        else:\n            details.append(\"tests_reference_check_skipped\")\n\n        verified = code_ok and tests_ok and references_ok\n        # produce digest for stability\n        try:\n            digest_src = (code or \"\").encode(\"utf-8\") + b\"||\" + (tests or \"\").encode(\"utf-8\")\n            digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# ---------------------------\n# Roles\n# ---------------------------\n\nclass Role(ABC):\n    \"\"\"Clear role definition with watch/trigger and idempotency.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: Iterable[Type[Action]]):\n        self.watch_list = [getattr(a, \"name\", str(a)) for a in actions]\n\n    def should_handle(self, msg: Message) -> bool:\n        \"\"\"Decide whether to handle a message.\"\"\"\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # do not handle own messages\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # explicit routing (send_to has priority)\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None)\n        if targets:\n            try:\n                if isinstance(targets, (set, list)):\n                    if self.name in targets or self.profile in targets or \"*\" in targets:\n                        return True\n                elif isinstance(targets, str):\n                    if targets in (self.name, self.profile, \"*\"):\n                        return True\n            except Exception:\n                pass\n            # if explicitly addressed elsewhere, and not this role, don't handle\n            return False\n        # watchlist trigger\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        # default: user input to coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action for this role; return produced Message or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg={getattr(message,'id',None)}\")\n            return None\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Running {action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                out = await action.run(idea)\n                send_to = {\"SimpleTester\"}\n            elif isinstance(action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and getattr(message, \"content\", None) else \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest.content if latest else \"\"\n                out = await action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(action, SimpleWriteReview):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                lowered = (out or \"\").lower()\n                if \"request\" in lowered or \"reject\" in lowered or \"request_changes\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(action, SimpleVerify):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = set()  # broadcast semantics handled by orchestrator\n            else:\n                out = await action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n            # mark processed to avoid duplicates\n            if message and getattr(message, \"id\", None):\n                self._processed_ids.add(message.id)\n            resp = Message(content=out, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n            if tracer:\n                tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg {getattr(resp,'id',None)} send_to={send_to}\")\n            return resp\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            resp = Message(content=err, role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to={\"Team\"})\n            return resp\n\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])\n\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\n# ---------------------------\n# Environment & Team\n# ---------------------------\n\nclass Environment:\n    \"\"\"Message bus with delivery tracking and artifact lookup.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._delivered: Dict[str, Set[str]] = {}\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} -> {list(getattr(message,'send_to',set()))} preview={snippet}\")\n\n    def mark_delivered(self, role: Role, message: Message):\n        if not getattr(message, \"id\", None):\n            return\n        self._delivered.setdefault(role.name, set()).add(message.id)\n        if self.tracer:\n            self.tracer.log(\"ENV_MARK_DELIVERED\", \"Environment\", f\"{role.name} delivered {message.id}\")\n\n    def get_pending_for_role(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            # explicit targeting\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            targeted = False\n            try:\n                if isinstance(targets, (set, list)):\n                    if role.name in targets or role.profile in targets or \"*\" in targets:\n                        targeted = True\n                elif isinstance(targets, str):\n                    if targets in (role.name, role.profile, \"*\"):\n                        targeted = True\n            except Exception:\n                targeted = False\n            if targeted:\n                out.append(msg)\n                seen.add(mid)\n                continue\n            # watch-list trigger\n            if getattr(msg, \"cause_by\", None) in getattr(role, \"watch_list\", []):\n                out.append(msg)\n                seen.add(mid)\n                continue\n        return out\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        msgs = self._by_cause.get(cause, [])\n        return msgs[-1] if msgs else None\n\n\nclass Team:\n    \"\"\"Orchestrator that enforces deterministic ordering, verification stability, and robust retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_stable_passes: int = VERIFY_STABLE_REQUIRED\n        self._max_role_attempts_per_message: int = ROLE_MAX_ATTEMPTS\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        attempts = 0\n        while attempts < self._max_role_attempts_per_message:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=ROLE_ACTION_TIMEOUT)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempts} for msg {getattr(msg,'id',None)}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempts} for msg {getattr(msg,'id',None)}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.05 * attempts)\n        # publish an error message to keep traceability\n        err = Message(content=f\"ERROR: role {role.name} failed processing message {getattr(msg,'id',None)} after {attempts} attempts\",\n                      role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._required_stable_passes} stable verification passes\")\n        # initial user message targeted to coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial_msg = Message(content=f\"Let's work on this project: {self.idea}\",\n                              instruct_content=self.idea,\n                              role=\"Human\",\n                              sent_from=\"User\",\n                              cause_by=\"UserInput\",\n                              send_to=coder_profiles)\n        self.env.publish_message(initial_msg)\n\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            new_messages = 0\n            for role_type in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles:\n                    pending = self.env.get_pending_for_role(role)\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and rnd == 1:\n                        if initial_msg not in pending and initial_msg.id not in self.env._delivered.get(role.name, set()):\n                            pending = [initial_msg] + pending\n                    for msg in pending:\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            self.env.mark_delivered(role, msg)\n                            continue\n                        resp = await self._invoke_role(role, msg)\n                        # mark delivered irrespective of resp to avoid livelock\n                        self.env.mark_delivered(role, msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            new_messages += 1\n                            # verifier handling: update streak based on digest\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                content = resp.content\n                                if \"VERIFICATION_RESULT: PASS\" in content:\n                                    digest = None\n                                    for token in content.split(\"|\"):\n                                        token = token.strip()\n                                        if token.startswith(\"digest=\"):\n                                            digest = token.split(\"=\", 1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    else:\n                                        # no digest: treat as single pass but not stable\n                                        self._last_digest = None\n                                        self._streak = 1\n                                else:\n                                    if self._streak > 0:\n                                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                                    self._streak = 0\n                                    self._last_digest = None\n            # progress check\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed; new_messages={new_messages} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require stable consecutive verification passes and at least one round\n            if self._streak >= self._required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping early\")\n                break\n\n            # no progress handling: nudge coder(s) if grace exceeded; stop if prolonged stagnation\n            if new_messages == 0:\n                if no_progress_rounds >= NO_PROGRESS_GRACE:\n                    self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds; terminating early\")\n                    break\n                # gentle nudge\n                self.tracer.log(\"TEAM_NUDGE\", \"Team\", \"Nudging coder(s) due to lack of progress\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please refine implementation for: {self.idea}\",\n                                        instruct_content=self.idea,\n                                        role=\"System\",\n                                        sent_from=\"Orchestrator\",\n                                        cause_by=\"Nudge\",\n                                        send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # allow immediate small processing window\n                await asyncio.sleep(0.01)\n            else:\n                # allow cooperative pause\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rnd} rounds; messages={len(self.env.history)} verified_streak={self._streak}\")\n        summary = f\"Project '{self.idea}' completed after {rnd} rounds with {len(self.env.history)} messages. verifier_streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D4 (Score: 4.6667)\n```python\n# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n#\n# Goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit send_to and subscriptions\n# - Strong verification/validation and stable termination\n# - Defensive error handling and LLM/API retry logic\n# - Deterministic orchestration to reduce nondeterministic failure modes\n\nimport asyncio\nimport ast\nimport hashlib\nimport time\nfrom collections import defaultdict\nfrom typing import List, Dict, Optional, Set, Tuple, Type\n\n# Utility for short previews in logs\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = text.strip()\n    return (t[:n] + \"...\") if len(t) > n else t\n\n# Base Action class: encapsulates LLM calls with retries, logging and deterministic fallback\nclass Action(ABC):\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper for LLM calls:\n        - Retries with exponential backoff\n        - Logs attempts and failures\n        - Returns deterministic fallback if LLM unavailable or exhausted\n        \"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            # Deterministic fallback string that downstream actions recognize\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        last_exc = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_exc = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, _preview(resp, 200))\n                    # backoff and retry\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # treat empty responses as failure\n                if not resp or not isinstance(resp, str):\n                    last_exc = \"empty_response\"\n                    if tracer:\n                        tracer.log(\"LLM_EMPTY\", self.name, f\"Empty response on attempt {attempt}\")\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # success\n                return resp\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:300]}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_exc)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                continue\n\n        # exhausted retries\n        failure_msg = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_exc}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure_msg)\n        # stable, deterministic fallback\n        return f\"LLM_FAILURE_FALLBACK: {failure_msg}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\n# Concrete Actions: Code, Tests, Review, Verify\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_preview={_preview(idea)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module that implements the requested task.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no markdown).\\n\"\n            \"- Include docstrings and input validation where applicable.\\n\"\n            \"- Provide at least one function or class.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        code = await self.safe_ask(messages)\n        # quick heuristic validation; if invalid, return deterministic safe fallback\n        try:\n            ast.parse(code)\n            ok = True\n        except Exception as e:\n            ok = False\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Generated code failed parse: {e}\")\n        if not ok or \"LLM_FAILURE_FALLBACK\" in code or code.startswith(\"LLM_UNAVAILABLE_FALLBACK\"):\n            # deterministic safe minimal implementation\n            fallback = (\n                \"def placeholder(input_data=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback implementation.\\\"\\\"\\\"\\n\"\n                \"    return input_data\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using deterministic fallback code\")\n            code = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        snippet = (code or \"\")[:3000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the given Python module.\\n\\n\"\n            f\"Module (truncated):\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Include at least one positive and one negative test.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        tests = await self.safe_ask(messages)\n        # heuristic: ensure tests include 'assert' otherwise provide deterministic placeholder\n        if not tests or \"assert \" not in tests:\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback test\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using deterministic fallback tests\")\n            tests = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_DECISION: APPROVE\\nHuman-simulated approval.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review simulated APPROVE\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a short review and an explicit decision line starting with REVIEW_DECISION: APPROVE or REVIEW_DECISION: REJECT.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\\n\\n\"\n            \"Be concise and actionable.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing code reviews.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        review = await self.safe_ask(messages)\n        # Ensure explicit decision\n        if not review or \"REVIEW_DECISION:\" not in review:\n            # conservative default\n            decision = \"REVIEW_DECISION: REJECT\"\n            review = (review or \"Automated review: missing explicit decision.\") + \"\\n\\n\" + decision\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"No explicit decision from LLM; defaulting to REJECT\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Starting deterministic verification\")\n\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Code parse failed: {e}\")\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # check for assertions\n            tests_ok = bool(tests and (\"assert \" in tests or \"pytest\" in tests))\n            if tests_ok:\n                details.append(\"tests_syntax: ok\")\n            else:\n                details.append(\"tests_syntax: fail (no asserts found)\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Tests parse failed: {e}\")\n\n        # Structural checks: code has functions/classes, tests reference them\n        referenced = False\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(f\"code_entities: {sorted(list(code_entities))[:6]}\")\n        else:\n            details.append(\"code_entities: none\")\n\n        if parsed_tests and code_entities:\n            names_in_tests = set()\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Name):\n                    names_in_tests.add(node.id)\n            inter = code_entities & names_in_tests\n            referenced = len(inter) > 0\n            details.append(f\"tests_reference_matches: {sorted(list(inter))[:6]}\")\n        else:\n            details.append(\"tests_reference_matches: none\")\n\n        passed = all([code_ok, tests_ok, bool(code_entities), referenced])\n\n        # compute digest for stability detection\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if passed else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# Roles: each role has a single responsibility and explicit watch list + idempotency\n\nclass Role(ABC):\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()  # action names\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env: Optional[\"Environment\"] = kwargs.get(\"env\")\n        self._processed_message_ids: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: List[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", \"\") for a in actions}\n\n    def should_process(self, message: Optional[Message]) -> bool:\n        if message is None:\n            return False\n        # Direct addressing\n        targets = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n        if targets:\n            if isinstance(targets, (list, set)):\n                if self.name in targets or self.profile in targets:\n                    return True\n            else:\n                if targets == self.name or targets == self.profile:\n                    return True\n        # Watch list match\n        if getattr(message, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        # idempotency: skip processing if already done\n        if msg_id and msg_id in self._processed_message_ids:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping already processed message {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Processing message id={msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Decide inputs depending on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or (message.content if message else \"\")\n                result = await self.action.run(idea or \"\")\n            elif isinstance(self.action, SimpleWriteTest):\n                # prefer message content if it is code, else fetch latest code\n                code_src = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_src = message.content\n                elif getattr(self, \"env\", None):\n                    code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code_src)\n            elif isinstance(self.action, SimpleWriteReview):\n                env = getattr(self, \"env\", None)\n                code_text = env.find_latest_content_by_cause(SimpleWriteCode.name) if env else \"\"\n                tests_text = env.find_latest_content_by_cause(SimpleWriteTest.name) if env else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            elif isinstance(self.action, SimpleVerify):\n                env = getattr(self, \"env\", None)\n                code_text = env.find_latest_content_by_cause(SimpleWriteCode.name) if env else \"\"\n                tests_text = env.find_latest_content_by_cause(SimpleWriteTest.name) if env else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                # generic fallback\n                payload = message.content if message else \"\"\n                result = await self.action.run(payload)\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:300]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark as processed to prevent repeated failures\n            if msg_id:\n                self._processed_message_ids.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build outgoing message; include send_to empty set (environment will route to subscribers)\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(self.action, \"name\", \"\"),\n            sent_from=self.name,\n            send_to=set()\n        )\n\n        # mark input message as processed for idempotency\n        if msg_id:\n            self._processed_message_ids.add(msg_id)\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={response.id} cause_by={response.cause_by} preview={_preview(response.content,120)}\")\n        return response\n\n# Concrete role classes with explicit responsibilities\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        # coder responds to explicit user input or nudges\n        self.watch([type(\"UserInputDummy\", (), {\"name\": \"UserInput\"}), type(\"NudgeDummy\", (), {\"name\": \"Nudge\"})])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview])\n\n# Environment: message bus with deterministic routing, subscriptions and delivery tracking\n\nclass Environment:\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # map action_name -> set(role.name) who subscribe to that action\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)\n        # track delivered messages: message_id -> set(role.name)\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        # set environment reference on role\n        role.env = self\n        self.roles.append(role)\n        # register subscriptions\n        for action_name in getattr(role, \"watch_list\", set()):\n            self.subscriptions[action_name].add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile}) watching {sorted(list(getattr(role,'watch_list',[]))) }\")\n\n    def publish_message(self, message: Message):\n        # ensure id exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        # normalize send_to\n        if getattr(message, \"send_to\", None) is None:\n            message.send_to = set()\n        elif isinstance(message.send_to, (list, tuple)):\n            message.send_to = set(message.send_to)\n        self.history.append(message)\n        # initialize delivered tracking\n        self.delivered.setdefault(message.id, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published message {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content)} send_to={sorted(list(message.send_to))}\")\n\n    def find_latest_content_by_cause(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return msg.content\n        return None\n\n    def get_routable_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages that the role should process:\n        - Directly targeted via send_to or sent_to\n        - OR messages caused by actions the role watches\n        Exclude messages already delivered to the role.\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            if getattr(msg, \"send_to\", None):\n                # if message explicitly targets this role\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    targeted = True\n            # watch-based routing\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\n# Team orchestrator: deterministic pipeline, robust act calls, stable termination\n\nclass Team:\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        # termination stability: require same digest twice\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = 2\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {_preview(idea,200)}\")\n\n    async def _safe_act_call(self, role: Role, message: Optional[Message], timeout: float = 30.0, max_retries: int = 2) -> Optional[Message]:\n        \"\"\"\n        Invoke role.act with timeout and retries. Returns a Message even on error to keep pipeline robust.\n        \"\"\"\n        tracer = self.tracer\n        attempt = 0\n        last_exc = None\n        while attempt <= max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"ACT_ATTEMPT\", role.name, f\"Attempt {attempt} on message {getattr(message,'id',None)}\")\n                coro = role.act(message)\n                resp = await asyncio.wait_for(coro, timeout=timeout)\n                if resp:\n                    # mark as delivered/processed for this role\n                    if message:\n                        self.env.delivered.setdefault(message.id, set()).add(role.name)\n                    return resp\n                last_exc = \"empty_response\"\n                if tracer:\n                    tracer.log(\"ACT_EMPTY\", role.name, f\"Empty response attempt {attempt}\")\n            except asyncio.TimeoutError:\n                last_exc = \"timeout\"\n                if tracer:\n                    tracer.log(\"ACT_TIMEOUT\", role.name, f\"Timeout attempt {attempt}\")\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:300]}\"\n                if tracer:\n                    tracer.log(\"ACT_EXCEPTION\", role.name, f\"Exception attempt {attempt}: {last_exc}\")\n            await asyncio.sleep(0.2 * attempt)\n        # failed after retries\n        if tracer:\n            tracer.log(\"ACT_FAIL\", role.name, f\"Failed after {max_retries+1} attempts: {last_exc}\")\n        return Message(content=f\"ERROR: role {role.name} failed after retries: {last_exc}\", role=role.profile, cause_by=\"System\", sent_from=role.name)\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Kickoff message targeted at coders explicitly\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds_executed = 0\n\n        # deterministic order\n        order: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            for role_type in order:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    msgs = self.env.get_routable_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # avoid self-processing\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n                        response = await self._safe_act_call(role, msg)\n                        if not response:\n                            continue\n                        # ensure cause_by annotation\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.action, \"name\", \"\") if getattr(role, \"action\", None) else \"\"\n                        # routing: if send_to empty, route to subscribers of this action\n                        if not getattr(response, \"send_to\", None):\n                            subs = self.env.subscriptions.get(response.cause_by, set())\n                            response.send_to = set(subs)\n                        self.env.publish_message(response)\n                        any_activity = True\n\n                        # handle verification pass detection and stability\n                        if response.cause_by == SimpleVerify.name and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            # extract digest\n                            digest = None\n                            for part in response.content.split(\"|\"):\n                                p = part.strip()\n                                if p.startswith(\"digest=\"):\n                                    digest = p.split(\"=\", 1)[1].strip()\n                                    break\n                            if digest:\n                                if digest == self._last_digest:\n                                    self._streak += 1\n                                else:\n                                    self._last_digest = digest\n                                    self._streak = 1\n                                self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                if self._streak >= self._required_streak:\n                                    verified = True\n                            else:\n                                # no digest -> not stable\n                                self._streak = 0\n                                self._last_digest = None\n                                self.tracer.log(\"VERIFIER\", \"Team\", \"Verifier PASS without digest -> not considered stable\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} complete any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # no progress -> nudge coder(s) deterministically\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No activity this round; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: propose code for '{_preview(self.idea,120)}'\",\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.name}\n                        )\n                        self.env.publish_message(nudge)\n                # small sleep to allow potential async LLMs in other contexts\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds_executed} rounds verified={verified} messages={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds_executed} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 3.8304, Type: Migrant)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport random\nimport time\n\nclass Action(ABC):\n    \"\"\"\n    Base action class.\n    - Provides robust LLM call with exponential backoff, jitter, and clear error handling.\n    - Actions are pure units of work that take inputs and return outputs (strings).\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Call the LLM with retries, exponential backoff and jitter.\n        Returns either the LLM string response or a structured error string starting with \"LLM_ERROR:\".\n        \"\"\"\n        import asyncio\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if not self.llm:\n                    # Deterministic fallback for offline runs\n                    response = \"LLM_FALLBACK: no-llm-available\"\n                else:\n                    response = await self.llm.ask(messages)\n\n                # Detect common LLM error patterns\n                if not isinstance(response, str) or response.strip() == \"\":\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response from LLM\")\n                if response.strip().lower().startswith(\"error\") or \"http\" in response and \"error\" in response.lower():\n                    last_err = response\n                    raise RuntimeError(f\"LLM returned error-like text: {response[:200]}\")\n\n                # Log success\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} succeeded (len={len(response)})\")\n                return response\n\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                # Backoff with jitter\n                if attempt < self.max_retries:\n                    backoff = self.base_backoff * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n                else:\n                    if self.context and getattr(self.context, \"tracer\", None):\n                        self.context.tracer.log(\"LLM_GIVEUP\", self.name, f\"Giving up after {self.max_retries} attempts: {last_err[:200]}\")\n        return f\"LLM_ERROR: {last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result.\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating code for idea (len={len(idea)})\")\n        prompt = (\n            \"You are an expert Python developer.\\n\"\n            \"Task:\\n\"\n            f\"{idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide production-ready Python code.\\n\"\n            \"- Include docstrings and input validation where appropriate.\\n\"\n            \"- Keep functions small and testable.\\n\"\n            \"- Return only the Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        # Basic sanity checks and fallback\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = f\"# ERROR: unable to generate code automatically. {result}\\n\\n# Placeholder function\\n\\ndef placeholder():\\n    \\\"\\\"\\\"Placeholder due to LLM failure.\\\"\\\"\\\"\\n    return None\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder code due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating tests for code (len={len(code)})\")\n        truncated = (code or \"\")[:4000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the provided Python code.\\n\\n\"\n            \"Code:\\n\"\n            f\"{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest test functions with clear assertions and docstrings.\\n\"\n            \"- Cover typical, boundary and error cases when applicable.\\n\"\n            \"- Return only pytest-compatible Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            note = f\"# ERROR_GENERATING_TESTS: {result}\\n# Tests not generated due to LLM error.\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder test note due to LLM error\")\n            return note\n        return result\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: recommended manual review.\"\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review and a readiness verdict.\\n\\n\"\n            \"Code (truncated):\\n\"\n            f\"{(code or '')[:2000]}\\n\\n\"\n            \"Tests (truncated):\\n\"\n            f\"{(tests or '')[:2000]}\\n\\n\"\n            \"Return:\\n- A short list of issues (if any)\\n- Checklist of fixes\\n- VERDICT: READY or NOT_READY (single line at the end prefixed by VERDICT:)\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = \"REVIEW_ERROR: Review could not be completed due to LLM failure.\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Review fallback due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"\n        Deterministic verification using static analysis heuristics.\n        Returns a structured verification result string.\n        \"\"\"\n        import ast\n        issues: List[str] = []\n        code_ok = False\n        tests_ok = False\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Starting verification\")\n\n        # Code syntax check\n        if not code or not code.strip():\n            issues.append(\"code_missing_or_empty\")\n        else:\n            try:\n                parsed = ast.parse(code)\n                code_ok = True\n                fn_names = [n.name for n in parsed.body if isinstance(n, ast.FunctionDef)]\n            except Exception as e:\n                issues.append(f\"code_syntax_error: {e}\")\n                fn_names = []\n\n        # Tests syntax and heuristics\n        if not tests or not tests.strip():\n            issues.append(\"tests_missing_or_empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristics: tests must contain 'assert' and at least one function named test_\n                contains_assert = \"assert \" in tests or \"pytest\" in tests.lower()\n                test_fns = [n.name for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\")]\n                tests_ok = bool(contains_assert and test_fns)\n                if not contains_assert:\n                    issues.append(\"tests_missing_asserts\")\n                if not test_fns:\n                    issues.append(\"tests_missing_test_functions\")\n            except Exception as e:\n                issues.append(f\"tests_syntax_error: {e}\")\n\n        # Ensure tests reference code functions when possible\n        references_code = False\n        if code_ok and tests_ok and fn_names:\n            for fn in fn_names:\n                if fn and fn in (tests or \"\"):\n                    references_code = True\n                    break\n            if not references_code:\n                issues.append(\"tests_do_not_reference_code\")\n\n        verified = code_ok and tests_ok and (references_code or not fn_names)\n        result = {\n            \"verified\": verified,\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok,\n            \"issues\": issues\n        }\n        summary = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | details: {result}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_END\", self.name, summary)\n        return summary\n\n\nclass Role(ABC):\n    \"\"\"\n    Clear role definition and responsibilities.\n    - Each role has a small set of actions.\n    - Each role maintains processed message ids to avoid duplicate work.\n    - Roles define watch_list (action names) and default recipients for produced messages.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # watch action names\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n        self._processed_message_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: List[Type[Action]]):\n        self.watch_list = [a.name for a in actions]\n\n    def should_respond(self, message: Message) -> bool:\n        \"\"\"\n        Decide whether the role should respond:\n        - Not already processed\n        - Explicitly addressed via send_to or sent_to\n        - Message cause_by matches watched actions\n        - Human user instructions target coders by default\n        \"\"\"\n        if not message:\n            return False\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # explicit addressing: either send_to set contains profile/name, or sent_to string matches\n        sent_to_set = getattr(message, \"send_to\", None)\n        if sent_to_set:\n            if isinstance(sent_to_set, (set, list)) and (self.profile in sent_to_set or self.name in sent_to_set or \"*\" in sent_to_set):\n                return True\n        sent_to_str = getattr(message, \"sent_to\", None)\n        if isinstance(sent_to_str, str) and (sent_to_str == self.profile or sent_to_str == self.name or sent_to_str == \"*\"):\n            return True\n        # watched action trigger\n        if getattr(message, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # default: user input goes to coders\n        if getattr(message, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Core action executor:\n        - Picks first applicable action and runs it.\n        - Records processed message id.\n        - Returns a Message with content, cause_by and intended send_to recipients.\n        - Robust error handling with retries for transient failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Received message id={(getattr(message,'id',None))} cause_by={(getattr(message,'cause_by',None))}\")\n\n        # find message to act on (if provided)\n        if message is not None and not self.should_respond(message):\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n\n        action = self.actions[0]  # single-responsibility per role; keep simple\n        attempts = 0\n        last_err = None\n        while attempts < 2:\n            attempts += 1\n            try:\n                # Build inputs based on action type\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    # Prefer code from message or find latest code in environment\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                    if not code_text and getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                                break\n                    result = await action.run(code_text)\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # Acquire latest code and tests from env if not supplied\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    # collect latest code/tests\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"Team\"}\n                else:\n                    result = await action.run()\n                    recipients = {\"Team\"}\n                # Mark message processed\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Create response message with clear routing\n                response = Message(\n                    content=result,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message cause_by={response.cause_by} send_to={recipients}\")\n                return response\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # small backoff\n                time.sleep(0.1 * attempts)\n        # If here, role failed reliably\n        fail_msg = f\"ROLE_FAILED: {self.name} after retries. Error={last_err}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"Unknown\"),\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])  # primarily triggered by UserInput or explicit addressing\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])  # run when code is available\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"\n    Environment handles message publication and routing.\n    - Maintains history (ordered).\n    - Provides messages relevant to a role using explicit send_to and watch_list rules.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Ensure ID exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"From {message.sent_from} cause_by={message.cause_by} send_to={getattr(message,'send_to',None)} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages a role should consider:\n        - Explicitly addressed messages (send_to / sent_to)\n        - Messages whose cause_by matches role.watch_list\n        - Exclude messages already processed by the role\n        \"\"\"\n        relevant: List[Message] = []\n        for msg in self.history:\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # explicit addressing via send_to (preferred)\n            sent_to = getattr(msg, \"send_to\", None)\n            if sent_to:\n                if isinstance(sent_to, (set, list)) and (role.profile in sent_to or role.name in sent_to or \"*\" in sent_to):\n                    relevant.append(msg)\n                    continue\n            # explicit sent_to string field\n            sent_to_str = getattr(msg, \"sent_to\", None)\n            if isinstance(sent_to_str, str) and (sent_to_str == role.profile or sent_to_str == role.name or sent_to_str == \"*\"):\n                relevant.append(msg)\n                continue\n            # watch_list triggers\n            if getattr(msg, \"cause_by\", \"\") in role.watch_list:\n                relevant.append(msg)\n                continue\n        return relevant\n\n\nclass Team:\n    \"\"\"\n    Team orchestrates roles, sequencing, termination, and verification confirmation logic.\n    - Requires multiple independent verification confirmations to avoid premature termination.\n    - Tracks progress and stops on verification PASS or prolonged no-progress.\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # require confirmations from verifiers (could be same verifier across rounds)\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2\n        # track unique verifiers or rounds that produced PASS to reduce false positives\n        self._verify_pass_rounds: Set[int] = set()\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        import asyncio\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._verify_confirm_needed} confirmations to stop early\")\n\n        # Initial User instruction directed to coder(s)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for round_idx in range(n_round):\n            round_num = round_idx + 1\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            progress_made = False\n\n            # Evaluate each role; roles decide if they act based on environment messages\n            for role in list(self.env.roles):\n                # Gather messages relevant to this role\n                msgs = self.env.get_messages_for_role(role)\n                # On first round, ensure coder sees the initial instruction even if not in msgs\n                if isinstance(role, SimpleCoder) and round_idx == 0:\n                    msgs = [initial_msg] + msgs\n                # Process messages in order; roles may produce one message per input to keep steps atomic\n                for msg in msgs:\n                    try:\n                        resp = await role.act(msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            progress_made = True\n                            # If verifier response contains a PASS, count confirmation\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    self._verify_confirm_count += 1\n                                    self._verify_pass_rounds.add(round_idx)\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                    if self._verify_confirm_count >= self._verify_confirm_needed:\n                                        verified = True\n                                elif \"VERIFICATION_RESULT: FAIL\" in resp.content:\n                                    # reset confirmations on explicit fail\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_RESET\", \"Team\", f\"Verifier {role.name} reported FAIL; confirmations reset\")\n                            # Log role failures directed to team\n                            if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                                self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure: {resp.content[:200]}\")\n                    except Exception as e:\n                        self.tracer.log(\"ROUND_ERROR\", role.name, f\"Exception during role.act: {e}\")\n\n            # Determine progress/no-progress and update termination conditions\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} complete (progress={progress_made})\")\n\n            # Termination: require at least one full round and required confirmations\n            if verified and round_num >= 1:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed after {self._verify_confirm_count} confirmations; stopping\")\n                break\n\n            # Stop if no progress for multiple rounds to avoid wasting cycles\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds; terminating early\")\n                break\n\n            # allow small async pause\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' finished after {round_num} rounds with {len(self.env.history)} messages. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Excellent avg_failures_per_task (2.167), Excellent total_failures (13.000)\n\n\n### Inspiration 2 (Score: 7.1111, Type: High-Performer)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n\n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n\n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Iterable\n\n# Tunable parameters to improve robustness\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nROLE_ACTION_TIMEOUT = 30  # seconds\nROLE_MAX_ATTEMPTS = 2\nVERIFY_STABLE_REQUIRED = 2\nNO_PROGRESS_GRACE = 2  # rounds without progress before nudging/stop\n\n# ---------------------------\n# Actions\n# ---------------------------\n\nclass Action(ABC):\n    \"\"\"Base Action with LLM-safe call and tracing.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, backoff, jitter, and deterministic fallback on failure.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface missing; using deterministic fallback\")\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n\n        for attempt in range(1, LLM_MAX_RETRIES + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{LLM_MAX_RETRIES}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                # success\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} success len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}:{str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < LLM_MAX_RETRIES:\n                    backoff = LLM_BACKOFF_BASE * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n        # exhausted\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, f\"Failed after {LLM_MAX_RETRIES} attempts: {last_err}\")\n        return f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No idea, returning deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Produce a concise, testable Python module implementing the task.\\n\"\n            \"Constraints: return only Python source, include docstrings and input validation where appropriate.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        # Deterministic fallback if LLM failed\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic fallback\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback implementation due to LLM error.\\\"\\\"\\\"\\n\"\n                \"    if value is None:\\n\"\n                \"        return None\\n\"\n                \"    return value\\n\"\n            )\n        # Validate python\n        try:\n            ast.parse(resp)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, f\"AST parse failed: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback because generated code did not parse.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        if not code or not code.strip():\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code -> placeholder test\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        # extract top-level symbols to guide test generation\n        symbols = []\n        try:\n            parsed = ast.parse(code)\n            for node in parsed.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)) and not node.name.startswith(\"_\"):\n                    symbols.append(node.name)\n        except Exception:\n            symbols = []\n        prompt = (\n            \"You are an expert QA engineer. Given the implementation, produce pytest tests covering normal and edge cases.\\n\"\n            f\"Public symbols: {', '.join(symbols[:6]) or '(none)'}\\n\\nCode (truncated):\\n{(code or '')[:3000]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> deterministic test fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        # Validate tests include assert or test functions\n        try:\n            parsed_tests = ast.parse(resp)\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = \"assert\" in resp\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, \"Generated tests invalid -> fallback\")\n            target = symbols[0] if symbols else \"placeholder\"\n            return f\"def test_{target}_exists():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_generated_len={len(resp)}\")\n        return resp\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # quick static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{str(e)[:160]}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: manual inspection recommended; \" + (\"; \".join(issues) if issues else \"no static issues\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review and end with a single-line VERDICT: APPROVE or VERDICT: REQUEST_CHANGES.\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\nCode (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self.llm_call(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed -> request changes\")\n            return \"VERDICT: REQUEST_CHANGES\\nAutomated reviewer: failed to produce review.\"\n        if \"VERDICT:\" not in resp:\n            verdict = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            resp = resp.strip() + f\"\\n\\nVERDICT: {verdict}\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(resp)}\")\n        return resp\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Running deterministic verification\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n        code_defs = set()\n\n        # code parse\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            code_defs = {n.name for n in parsed_code.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            details.append(f\"code_defs:{len(code_defs)}\")\n        except Exception as e:\n            details.append(f\"code_parse_error:{str(e)[:160]}\")\n\n        # tests parse & heuristics\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            details.append(\"tests_present\" if tests_ok else \"tests_missing_asserts_or_fns\")\n        except Exception as e:\n            details.append(f\"tests_parse_error:{str(e)[:160]}\")\n\n        # reference check\n        if code_defs and tests_ok:\n            txt = tests or \"\"\n            for nm in code_defs:\n                if nm and nm in txt:\n                    references_ok = True\n                    break\n            details.append(\"tests_reference_ok\" if references_ok else \"tests_do_not_reference_code\")\n        else:\n            details.append(\"tests_reference_check_skipped\")\n\n        verified = code_ok and tests_ok and references_ok\n        # produce digest for stability\n        try:\n            digest_src = (code or \"\").encode(\"utf-8\") + b\"||\" + (tests or \"\").encode(\"utf-8\")\n            digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# ---------------------------\n# Roles\n# ---------------------------\n\nclass Role(ABC):\n    \"\"\"Clear role definition with watch/trigger and idempotency.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: Iterable[Type[Action]]):\n        self.watch_list = [getattr(a, \"name\", str(a)) for a in actions]\n\n    def should_handle(self, msg: Message) -> bool:\n        \"\"\"Decide whether to handle a message.\"\"\"\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # do not handle own messages\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # explicit routing (send_to has priority)\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None)\n        if targets:\n            try:\n                if isinstance(targets, (set, list)):\n                    if self.name in targets or self.profile in targets or \"*\" in targets:\n                        return True\n                elif isinstance(targets, str):\n                    if targets in (self.name, self.profile, \"*\"):\n                        return True\n            except Exception:\n                pass\n            # if explicitly addressed elsewhere, and not this role, don't handle\n            return False\n        # watchlist trigger\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        # default: user input to coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action for this role; return produced Message or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping msg={getattr(message,'id',None)}\")\n            return None\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Running {action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                out = await action.run(idea)\n                send_to = {\"SimpleTester\"}\n            elif isinstance(action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and getattr(message, \"content\", None) else \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest.content if latest else \"\"\n                out = await action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(action, SimpleWriteReview):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                lowered = (out or \"\").lower()\n                if \"request\" in lowered or \"reject\" in lowered or \"request_changes\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(action, SimpleVerify):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = set()  # broadcast semantics handled by orchestrator\n            else:\n                out = await action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n            # mark processed to avoid duplicates\n            if message and getattr(message, \"id\", None):\n                self._processed_ids.add(message.id)\n            resp = Message(content=out, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n            if tracer:\n                tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg {getattr(resp,'id',None)} send_to={send_to}\")\n            return resp\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            resp = Message(content=err, role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to={\"Team\"})\n            return resp\n\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])\n\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\n# ---------------------------\n# Environment & Team\n# ---------------------------\n\nclass Environment:\n    \"\"\"Message bus with delivery tracking and artifact lookup.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._delivered: Dict[str, Set[str]] = {}\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} -> {list(getattr(message,'send_to',set()))} preview={snippet}\")\n\n    def mark_delivered(self, role: Role, message: Message):\n        if not getattr(message, \"id\", None):\n            return\n        self._delivered.setdefault(role.name, set()).add(message.id)\n        if self.tracer:\n            self.tracer.log(\"ENV_MARK_DELIVERED\", \"Environment\", f\"{role.name} delivered {message.id}\")\n\n    def get_pending_for_role(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            # explicit targeting\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            targeted = False\n            try:\n                if isinstance(targets, (set, list)):\n                    if role.name in targets or role.profile in targets or \"*\" in targets:\n                        targeted = True\n                elif isinstance(targets, str):\n                    if targets in (role.name, role.profile, \"*\"):\n                        targeted = True\n            except Exception:\n                targeted = False\n            if targeted:\n                out.append(msg)\n                seen.add(mid)\n                continue\n            # watch-list trigger\n            if getattr(msg, \"cause_by\", None) in getattr(role, \"watch_list\", []):\n                out.append(msg)\n                seen.add(mid)\n                continue\n        return out\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        msgs = self._by_cause.get(cause, [])\n        return msgs[-1] if msgs else None\n\n\nclass Team:\n    \"\"\"Orchestrator that enforces deterministic ordering, verification stability, and robust retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_stable_passes: int = VERIFY_STABLE_REQUIRED\n        self._max_role_attempts_per_message: int = ROLE_MAX_ATTEMPTS\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        attempts = 0\n        while attempts < self._max_role_attempts_per_message:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=ROLE_ACTION_TIMEOUT)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempts} for msg {getattr(msg,'id',None)}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempts} for msg {getattr(msg,'id',None)}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.05 * attempts)\n        # publish an error message to keep traceability\n        err = Message(content=f\"ERROR: role {role.name} failed processing message {getattr(msg,'id',None)} after {attempts} attempts\",\n                      role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._required_stable_passes} stable verification passes\")\n        # initial user message targeted to coder(s)\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial_msg = Message(content=f\"Let's work on this project: {self.idea}\",\n                              instruct_content=self.idea,\n                              role=\"Human\",\n                              sent_from=\"User\",\n                              cause_by=\"UserInput\",\n                              send_to=coder_profiles)\n        self.env.publish_message(initial_msg)\n\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            new_messages = 0\n            for role_type in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles:\n                    pending = self.env.get_pending_for_role(role)\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and rnd == 1:\n                        if initial_msg not in pending and initial_msg.id not in self.env._delivered.get(role.name, set()):\n                            pending = [initial_msg] + pending\n                    for msg in pending:\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            self.env.mark_delivered(role, msg)\n                            continue\n                        resp = await self._invoke_role(role, msg)\n                        # mark delivered irrespective of resp to avoid livelock\n                        self.env.mark_delivered(role, msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            new_messages += 1\n                            # verifier handling: update streak based on digest\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                content = resp.content\n                                if \"VERIFICATION_RESULT: PASS\" in content:\n                                    digest = None\n                                    for token in content.split(\"|\"):\n                                        token = token.strip()\n                                        if token.startswith(\"digest=\"):\n                                            digest = token.split(\"=\", 1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                    else:\n                                        # no digest: treat as single pass but not stable\n                                        self._last_digest = None\n                                        self._streak = 1\n                                else:\n                                    if self._streak > 0:\n                                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                                    self._streak = 0\n                                    self._last_digest = None\n            # progress check\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed; new_messages={new_messages} history_len={len(self.env.history)} streak={self._streak}\")\n\n            # termination: require stable consecutive verification passes and at least one round\n            if self._streak >= self._required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping early\")\n                break\n\n            # no progress handling: nudge coder(s) if grace exceeded; stop if prolonged stagnation\n            if new_messages == 0:\n                if no_progress_rounds >= NO_PROGRESS_GRACE:\n                    self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds; terminating early\")\n                    break\n                # gentle nudge\n                self.tracer.log(\"TEAM_NUDGE\", \"Team\", \"Nudging coder(s) due to lack of progress\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(content=f\"Nudge: please refine implementation for: {self.idea}\",\n                                        instruct_content=self.idea,\n                                        role=\"System\",\n                                        sent_from=\"Orchestrator\",\n                                        cause_by=\"Nudge\",\n                                        send_to={r.profile})\n                        self.env.publish_message(nudge)\n                # allow immediate small processing window\n                await asyncio.sleep(0.01)\n            else:\n                # allow cooperative pause\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rnd} rounds; messages={len(self.env.history)} verified_streak={self._streak}\")\n        summary = f\"Project '{self.idea}' completed after {rnd} rounds with {len(self.env.history)} messages. verifier_streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (5.000)\n\n\n### Inspiration 3 (Score: 4.6667, Type: High-Performer)\n```python\n# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nimport time\nimport ast\nimport hashlib\nfrom typing import List, Optional, Set, Dict, Any, Tuple\n\n# Goals applied:\n# - Clear role responsibilities and minimal surface area per role\n# - Robust inter-agent communication with explicit send_to routing and watch triggers\n# - Idempotent delivery tracking to avoid duplicates\n# - LLM/API calls with retries, exponential backoff + jitter, and deterministic fallback\n# - Strong verification with syntax + test heuristics and stable digest-based termination\n# - Nudge/timeout handling to avoid deadlocks\n\nclass Action:\n    \"\"\"Base Action with LLM safe call wrapper and simple contract: run(...) -> str\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retry, exponential backoff and jitter. Deterministic fallback if no LLM.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"No LLM - using deterministic fallback\")\n            return fallback\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                # treat some error patterns as failures to retry\n                if not isinstance(resp, str) or resp.strip() == \"\":\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty LLM response\")\n                if resp.strip().lower().startswith(\"error\") or \"error communicating\" in resp.lower():\n                    last_err = resp\n                    raise RuntimeError(f\"LLM returned error-like response: {resp[:200]}\")\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"LLM responded len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                # backoff + jitter\n                if attempt < self.max_retries:\n                    backoff = self.base_backoff * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.2)\n                    await asyncio.sleep(backoff + jitter)\n                else:\n                    await asyncio.sleep(0)  # yield\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a self-contained Python module implementing the task. \"\n            \"Return only valid Python source. Include docstrings and reasonable defensive checks. \"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self.safe_ask(messages)\n        # Validate syntactic correctness; fallback to placeholder if invalid\n        try:\n            if not isinstance(code, str):\n                raise ValueError(\"Non-string response\")\n            ast.parse(code)\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed OK\")\n            return code\n        except Exception as e:\n            fallback = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation due to code generation failure.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback code: {type(e).__name__}: {str(e)[:200]}\")\n            return fallback\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the provided Python module. \"\n            \"Return only pytest-compatible Python code with test_ functions or clear asserts.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self.safe_ask(messages)\n        # Heuristic validation\n        if not isinstance(tests, str) or (\"def test_\" not in tests and \"assert \" not in tests and \"pytest\" not in tests.lower()):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback tests due to weak LLM output\")\n            return fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated tests len={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if self.is_human:\n            review = \"HUMAN_REVIEW: manual review requested.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Simulated human review\")\n            return review\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Reviewing artifacts\")\n        prompt = (\n            \"You are a senior code reviewer. Provide a short actionable review of code and tests, \"\n            \"and include a one-line decision 'REVIEW_DECISION: APPROVE' or 'REVIEW_DECISION: REQUEST_CHANGES'.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        review = await self.safe_ask(messages)\n        if not isinstance(review, str) or \"REVIEW_DECISION:\" not in review:\n            # derive conservative decision\n            decision = \"APPROVE\" if (\"def test_\" in (tests or \"\") or \"assert \" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REQUEST_CHANGES\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Inferred review decision {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        cross_ref = False\n\n        # syntax checks\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # heuristics\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n            if has_test_fn or has_assert:\n                tests_ok = True\n                details.append(\"tests_syntax_and_presence: ok\")\n            else:\n                details.append(\"tests_syntax_and_presence: fail (no test_ or assert)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # cross reference\n        if code_ok and tests_ok:\n            try:\n                parsed_code = ast.parse(code or \"\")\n                code_defs = {n.name for n in parsed_code.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n                for nm in code_defs:\n                    if nm and nm in (tests or \"\"):\n                        cross_ref = True\n                        break\n                details.append(f\"cross_reference: {cross_ref}\")\n            except Exception as e:\n                details.append(f\"cross_reference_check_error: {str(e)[:120]}\")\n\n        verified = bool(code_ok and tests_ok and cross_ref)\n        # digest for stability\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--TESTS--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        status = \"PASS\" if verified else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role:\n    \"\"\"Base role: single primary action, watch list of cause_by tokens, processed tracking\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()  # cause_by tokens\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = None\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: List[type]):\n        self.watch_list = {a.name for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        \"\"\"Decide whether the role should process this message.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if msg is None:\n            return False\n        mid = getattr(msg, \"id\", None)\n        if mid and mid in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed {mid}\")\n            return False\n        # explicit routing via send_to (set) or sent_to (string)\n        send_to = getattr(msg, \"send_to\", None)\n        if not send_to:\n            send_to = set(getattr(msg, \"sent_to\", set()) or set())\n        try:\n            if isinstance(send_to, (set, list)) and (self.profile in send_to or self.name in send_to or \"*\" in send_to):\n                return True\n            if isinstance(send_to, str) and (send_to == self.profile or send_to == self.name or send_to == \"*\"):\n                return True\n        except Exception:\n            pass\n        # watch triggers by cause_by\n        if getattr(msg, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # user input default to coder profile\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Message not for role; id={getattr(message,'id',None)}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing {self.action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                out = await self.action.run(idea)\n                send_to = {\"SimpleTester\"}\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message else \"\"\n                if not code_text and self.env:\n                    code_text = self.env.find_latest_artifact(SimpleWriteCode.name) or \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleWriteReview):\n                code_text = self.env.find_latest_artifact(SimpleWriteCode.name) or \"\"\n                tests_text = self.env.find_latest_artifact(SimpleWriteTest.name) or \"\"\n                out = await self.action.run(code_text, tests_text)\n                send_to = {\"SimpleVerifier\"}\n                if \"REQUEST_CHANGE\" in (out or \"\") or \"REQUEST_CHANGES\" in (out or \"\"):\n                    send_to.update({\"SimpleCoder\", \"SimpleTester\"})\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleVerify):\n                code_text = self.env.find_latest_artifact(SimpleWriteCode.name) or \"\"\n                tests_text = self.env.find_latest_artifact(SimpleWriteTest.name) or \"\"\n                out = await self.action.run(code_text, tests_text)\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=set())\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=set())\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            resp = Message(content=err, role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to=set())\n\n        # mark processed input idempotently\n        if message and getattr(message, \"id\", None):\n            self._processed.add(message.id)\n        # mark produced message as processed by this role to avoid self-loop\n        try:\n            self._processed.add(getattr(resp, \"id\", \"\"))\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={getattr(resp,'id',None)} cause_by={resp.cause_by} send_to={getattr(resp,'send_to',set())}\")\n        return resp\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self.watch([])\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Holds messages, delivery state, and provides artifact helpers.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # message.id -> set(role.name) delivered\n        self.delivered: Dict[str, Set[str]] = {}\n        # simple FIFO queue for messages to dispatch\n        self.queue: List[Message] = []\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # normalize send_to into a set\n        try:\n            if getattr(message, \"send_to\", None) is None:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            else:\n                # ensure set type\n                if not isinstance(message.send_to, set):\n                    message.send_to = set(message.send_to)\n        except Exception:\n            try:\n                message.send_to = set()\n            except Exception:\n                message.send_to = set()\n        # ensure id exists (pydantic variant will)\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self.delivered.setdefault(getattr(message, \"id\", \"\"), set())\n        self.queue.append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Published msg {getattr(message,'id','')} from {message.sent_from} cause_by={message.cause_by} preview={snippet}\")\n\n    def find_latest_artifact(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return getattr(msg, \"content\", \"\")\n        return None\n\n    def get_relevant_roles(self, message: Message) -> List[Role]:\n        \"\"\"Return roles that should receive this message (not yet delivered).\"\"\"\n        relevant: List[Role] = []\n        targets = getattr(message, \"send_to\", None) or set()\n        # explicit targeting first\n        if targets:\n            for r in self.roles:\n                if r.profile in targets or r.name in targets:\n                    if r.name not in self.delivered.get(getattr(message, \"id\", \"\"), set()):\n                        relevant.append(r)\n            return relevant\n        # else deliver to watchers subscribed to cause_by\n        cause = getattr(message, \"cause_by\", \"\")\n        for r in self.roles:\n            if cause in getattr(r, \"watch_list\", set()):\n                if r.name not in self.delivered.get(getattr(message, \"id\", \"\"), set()):\n                    relevant.append(r)\n        return relevant\n\n    def mark_delivered(self, message: Message, role: Role):\n        mid = getattr(message, \"id\", None)\n        if mid:\n            self.delivered.setdefault(mid, set()).add(role.name)\n            if self.tracer:\n                self.tracer.log(\"ENV_DELIVERED\", \"Environment\", f\"Message {mid} delivered to {role.name}\")\n\n\nclass Team:\n    \"\"\"Orchestrates roles, drains message queue deterministically, and applies stable verification termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea: str = \"\"\n        # require consecutive identical verification digests\n        self._last_digest: Optional[str] = None\n        self._digest_streak: int = 0\n        self._required_streak: int = 2\n        # safety\n        self._max_steps_per_round = 500\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        # placeholder for budget usage\n        pass\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _dispatch_message(self, message: Message) -> bool:\n        \"\"\"Dispatch message to relevant roles. Returns True if verification stability reached.\"\"\"\n        verified_now = False\n        relevant = self.env.get_relevant_roles(message)\n        # fallback: if no explicit relevant roles, let any role that watches cause_by handle\n        if not relevant:\n            for r in self.env.roles:\n                if getattr(message, \"cause_by\", \"\") in getattr(r, \"watch_list\", set()):\n                    if r.name not in self.env.delivered.get(getattr(message, \"id\", \"\"), set()):\n                        relevant.append(r)\n        for role in relevant:\n            try:\n                if self.tracer:\n                    self.tracer.log(\"TEAM_DISPATCH\", \"Team\", f\"Dispatching msg={getattr(message,'id','')} to role={role.name}\")\n                resp = await role.act(message)\n                self.env.mark_delivered(message, role)\n                if resp:\n                    self.env.publish_message(resp)\n                    # detect verification results\n                    if getattr(resp, \"cause_by\", \"\") == SimpleVerify.name and isinstance(resp.content, str):\n                        content = resp.content or \"\"\n                        if \"VERIFICATION_RESULT: PASS\" in content:\n                            # find digest token\n                            digest = None\n                            for part in content.split(\"|\"):\n                                p = part.strip()\n                                if p.startswith(\"digest=\"):\n                                    digest = p.split(\"=\", 1)[1]\n                                    break\n                            if digest:\n                                if digest == self._last_digest:\n                                    self._digest_streak += 1\n                                else:\n                                    self._last_digest = digest\n                                    self._digest_streak = 1\n                                self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"digest={digest} streak={self._digest_streak}\")\n                                if self._digest_streak >= self._required_streak:\n                                    verified_now = True\n                            else:\n                                # non-stable pass\n                                self._digest_streak = 0\n                                self._last_digest = None\n                                self.tracer.log(\"VERIFIER_NONSTABLE\", \"Team\", \"Verifier PASS but no digest found\")\n                        else:\n                            # reset on fail\n                            self._digest_streak = 0\n                            self._last_digest = None\n            except Exception as e:\n                self.tracer.log(\"TEAM_ROLE_EXCEPT\", \"Team\", f\"Role {role.name} exception: {type(e).__name__}: {str(e)[:200]}\")\n                continue\n        return verified_now\n\n    async def _drain_queue(self, max_steps: int) -> bool:\n        steps = 0\n        while self.env.queue and steps < max_steps:\n            steps += 1\n            msg = self.env.queue.pop(0)\n            if self.tracer:\n                snippet = (msg.content or \"\")[:120].replace(\"\\n\", \" \")\n                self.tracer.log(\"QUEUE_DEQUEUE\", \"Team\", f\"Dequeued msg={getattr(msg,'id','')} cause_by={msg.cause_by} preview={snippet}\")\n            verified = await self._dispatch_message(msg)\n            # yield to allow async LLM calls to proceed\n            await asyncio.sleep(0)\n            if verified:\n                return True\n        if steps >= max_steps:\n            if self.tracer:\n                self.tracer.log(\"QUEUE_MAX\", \"Team\", f\"Drained max steps {max_steps}\")\n        return False\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {_required_streak if ( _required_streak := self._required_streak) else self._required_streak} stable passes\")\n        # initial kickoff targeted to coder profile\n        initial = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        for round_idx in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_idx}/{n_round}\")\n            # drain cluster of messages\n            stable = await self._drain_queue(max_steps=self._max_steps_per_round)\n            if stable:\n                verified = True\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Stable verification achieved at round {round_idx}\")\n                break\n\n            # if no messages produced (queue empty) attempt a nudge to coder(s) once per round\n            if not self.env.queue:\n                self.tracer.log(\"ROUND_NO_PROGRESS\", \"Team\", \"No messages in queue; nudging coders\")\n                for coder in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                    nudge = Message(\n                        content=f\"Nudge: please refine or propose implementation for '{(self.idea or '')[:120]}'\",\n                        instruct_content=self.idea,\n                        role=\"System\",\n                        sent_from=\"Orchestrator\",\n                        cause_by=\"Nudge\",\n                        send_to={coder.profile}\n                    )\n                    self.env.publish_message(nudge)\n                # process any messages produced by nudges\n                more_stable = await self._drain_queue(max_steps=200)\n                if more_stable:\n                    verified = True\n                    break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_idx} completed; history_len={len(self.env.history)}\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Execution finished. Verified={verified} messages={len(self.env.history)}\")\n        summary = f\"Project '{self.idea}' ended. Rounds={round_idx if 'round_idx' in locals() else 0} Verified={verified} Messages={len(self.env.history)}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n### Inspiration 4 (Score: 4.6667, Type: High-Performer)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport random\nfrom typing import Tuple\n\n# Goals implemented:\n# - Clear roles and responsibilities\n# - Explicit triggers and routing (send_to)\n# - Deterministic orchestration with per-role processed tracking\n# - Robust LLM retry + fallback\n# - Strong verification and confirmation + stable termination (consecutive passes)\n# - Error handling and retry across role actions\n\nDEFAULT_VERIFICATION_STREAK = 2\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.8  # seconds\nMAX_MESSAGE_ATTEMPTS = 6\n\nclass Action(ABC):\n    \"\"\"Base action with LLM retry, backoff, validation and fallback semantics.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    backoff_base: float = LLM_BACKOFF_BASE\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def call_llm(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns string result or an explicit error token.\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # Deterministic fallback to avoid hard failure\n                    fallback = \"LLM_UNAVAILABLE: deterministic fallback\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # jittered backoff\n                await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)) + random.uniform(0, 0.25))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce a validated Python module from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            # clear signal for empty idea\n            fallback = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module implementing the described task. \"\n            \"Return only valid Python source code, no markdown fences or explanations. Include docstrings and input validation.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        resp = await self.call_llm(messages)\n        # If LLM failed, return explicit failure so downstream can react\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            fallback = f\"# CODE_GEN_ERROR: {resp}\\n# Please retry or provide a human-coded fallback.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning error sentinel\")\n            return fallback\n\n        # Try to sanitize common code fences\n        code = self._strip_code_fences(resp)\n        # Validate syntax\n        try:\n            ast.parse(code)\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Code syntax ok\")\n            return code\n        except Exception as e:\n            # attempt small fix: wrap into function if possible\n            try:\n                wrapper = \"def _generated_wrapper():\\n\"\n                for line in code.splitlines():\n                    wrapper += \"    \" + line + \"\\n\"\n                ast.parse(wrapper)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FIX\", self.name, \"Applied safe wrapper to fix syntax\")\n                return wrapper\n            except Exception:\n                err = f\"# CODE_PARSE_ERROR: {str(e)[:160]}\\n# Raw Output:\\n{code}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Code parse failed: {str(e)[:200]}\")\n                return err\n\n    def _strip_code_fences(self, text: Optional[str]) -> str:\n        if not text:\n            return \"\"\n        t = text.strip()\n        # remove triple backticks\n        if t.startswith(\"\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n### Inspiration 5 (Score: 7.1111, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (5.000), Excellent total_failures (30.000)\n\n\n\n# Current Program\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nfrom typing import Tuple, Iterable\n\n# Goals realized:\n# - Clear roles and single-action responsibility\n# - Explicit routing via send_to and watch/trigger logic\n# - Robust LLM retries with deterministic fallbacks\n# - Strong but practical verification (syntax + asserts + cross-reference)\n# - Stable termination: require consecutive PASS with same digest\n# - Simplified, readable orchestration and environment\n\nDEFAULT_LLM_RETRIES = 3\nDEFAULT_LLM_BACKOFF = 0.4\nREQUIRED_STABLE_PASSES = 2\n\ndef _normalize_send_to_field(msg: Message) -> Set[str]:\n    s = getattr(msg, \"send_to\", None)\n    if s is None:\n        s = set(getattr(msg, \"sent_to\", set()) or set())\n    return set(s or set())\n\ndef _strip_code_fences(text: Optional[str]) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    s = text.strip()\n    if s.startswith(\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# Evolved multi-agent logic focusing on clarity, robustness, and reduced failure modes.\n\nimport asyncio\nimport ast\nimport random\nimport time\nfrom typing import Iterable, Tuple\n\n# Tunable parameters\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nVERIFICATION_STABLE_REQUIRED = 2\nNO_PROGRESS_LIMIT = 2  # rounds\n\n# Utility helpers\ndef _to_set_send_to(msg: Message) -> Set[str]:\n    s = getattr(msg, \"send_to\", None)\n    if s is None:\n        s = getattr(msg, \"sent_to\", None) or set()\n    if isinstance(s, (list, tuple)):\n        return set(s)\n    if isinstance(s, str):\n        return {s}\n    return set(s or set())\n\ndef _strip_fences(text: Optional[str]) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    t = text.strip()\n    # remove common fences\n    if t.startswith(\"```\") and \"```\" in t[3:]:\n        # remove first and last fence block\n        parts = t.split(\"```\")\n        # join inner content pieces (if language specified it appears as first after fence)\n        inner = \"```\".join(parts[1:-1]) if len(parts) > 2 else parts[1]\n        return inner.strip()\n    return t\n\n# Base Action\nclass Action(ABC):\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    backoff_base: float = LLM_BACKOFF_BASE\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _call_llm(self, messages: List[Dict[str, str]]) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        if not self.llm:\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, \"LLMInterface missing; using deterministic fallback\")\n            return \"LLM_UNAVAILABLE_FALLBACK\"\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response\")\n                low = resp.strip().lower()\n                # treat clear error patterns as failures\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Success len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}:{str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < self.max_retries:\n                    backoff = self.backoff_base * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.2)\n                    await asyncio.sleep(backoff + jitter)\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, f\"Exhausted retries: {last_err}\")\n        return f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\n# Concrete actions\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"Empty idea provided\")\n            return \"def placeholder():\\n    \\\"\\\"\\\"Placeholder implementation due to empty idea.\\\"\\\"\\\"\\n    return None\\n\"\n        prompt = (\n            \"You are an expert Python developer. Produce a concise, production-quality Python module implementing the task. \"\n            \"Return only the Python source code (no markdown). Include docstrings and input validation where appropriate.\\n\\n\"\n            f\"Task: {idea}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self._call_llm(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; providing deterministic fallback code\")\n            return \"def placeholder():\\n    \\\"\\\"\\\"Fallback implementation due to LLM failure.\\\"\\\"\\\"\\n    return None\\n\"\n        code = _strip_fences(resp)\n        # validate syntax\n        try:\n            ast.parse(code)\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, f\"Generated code len={len(code)}\")\n            return code\n        except Exception as e:\n            # attempt simple wrapper fix\n            try:\n                wrapper = \"def _generated_wrapper():\\n\"\n                for ln in code.splitlines():\n                    wrapper += \"    \" + ln + \"\\n\"\n                ast.parse(wrapper)\n                if tracer:\n                    tracer.log(\"ACTION_FIX\", self.name, \"Wrapped generated code to fix syntax\")\n                return wrapper\n            except Exception:\n                if tracer:\n                    tracer.log(\"ACTION_ERROR\", self.name, f\"Code parse failed: {e}\")\n                return f\"# CODE_PARSE_ERROR: {str(e)[:160]}\\n# Raw LLM output:\\n{code}\"\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        snippet = (code or \"\")[:3500]\n        prompt = (\n            \"You are an expert QA engineer. Given the Python module below, write pytest-style tests that cover normal behavior, edge cases, and error conditions. \"\n            \"Return only pytest code.\\n\\n\"\n            f\"Module:\\n{snippet}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self._call_llm(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning deterministic placeholder test\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        tests = _strip_fences(resp)\n        # basic sanity: must contain 'assert' or test_ functions\n        try:\n            parsed = ast.parse(tests)\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body)\n            has_assert = \"assert \" in tests\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"No tests/asserts detected\")\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, f\"Generated tests len={len(tests)}\")\n            return tests\n        except Exception:\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE_FAIL\", self.name, \"Generated tests invalid; returning fallback\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # quick static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{str(e)[:160]}\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: manual review recommended. \" + (\"; \".join(issues) if issues else \"no static issues\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review and finish with a single line 'VERDICT: APPROVE' or 'VERDICT: REQUEST_CHANGES'. \"\n            \"Include static issues if found.\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\nCode (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        resp = await self._call_llm(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; requesting changes by default\")\n            return \"VERDICT: REQUEST_CHANGES\\nAutomated reviewer: unable to produce full review.\"\n        review = resp.strip()\n        if \"VERDICT:\" not in review:\n            # conservative default if LLM omitted verdict\n            verdict = \"REQUEST_CHANGES\" if issues else \"APPROVE\"\n            review = review + f\"\\n\\nVERDICT: {verdict}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"No verdict from LLM; defaulted to {verdict}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Deterministic verification started\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        ref_ok = False\n        parsed_code = parsed_tests = None\n\n        # code syntax\n        if not code or not code.strip():\n            details.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                details.append(\"code_syntax: ok\")\n            except Exception as e:\n                details.append(f\"code_syntax: fail ({type(e).__name__}:{str(e)[:160]})\")\n\n        # tests syntax + heuristics\n        if not tests or not tests.strip():\n            details.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert \" in tests)\n                tests_ok = bool(has_test_fn or has_assert)\n                details.append(\"tests_presence: ok\" if tests_ok else \"tests_presence: fail (no asserts/test_fns)\")\n            except Exception as e:\n                details.append(f\"tests_syntax: fail ({type(e).__name__}:{str(e)[:160]})\")\n\n        # cross-reference: do tests reference code symbols?\n        if parsed_code and parsed_tests:\n            code_symbols = {n.name for n in parsed_code.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            tests_text = tests or \"\"\n            for sym in code_symbols:\n                if sym and sym in tests_text:\n                    ref_ok = True\n                    break\n            details.append(\"tests_reference: ok\" if ref_ok else \"tests_reference: fail\")\n        else:\n            details.append(\"tests_reference: skipped\")\n\n        verified = code_ok and tests_ok and ref_ok\n        # produce short digest for stability detection\n        try:\n            digest_src = (code or \"\").encode(\"utf-8\") + b\"||\" + (tests or \"\").encode(\"utf-8\")\n            import hashlib\n            digest = hashlib.sha256(digest_src).hexdigest()[:12]\n        except Exception:\n            digest = \"nodigest\"\n\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# Role base with clear responsibilities and processed-tracking\nclass Role(ABC):\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: Set[str] = set()\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.actions = []\n        self.watch_list = set()\n        self.env: Optional[\"Environment\"] = None\n        # processed message ids to ensure idempotency\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: Iterable[Type[Action]]):\n        self.watch_list = {a.name for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # explicit routing has highest priority\n        send_to = _to_set_send_to(msg)\n        if send_to:\n            if self.name in send_to or self.profile in send_to or \"*\" in send_to:\n                return True\n            return False\n        # watch-list triggers\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        # default: user input addressed to coders\n        if getattr(msg, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={getattr(message,'id',None)}\")\n            return None\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing {action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                out = await action.run(idea)\n                send_to = {\"SimpleTester\"}\n                # If generation failed, route to reviewer for inspection and coder for retry\n                if isinstance(out, str) and (out.startswith(\"LLM_FAILED_AFTER_RETRIES\") or \"CODE_PARSE_ERROR\" in out):\n                    send_to = {self.profile}\n            elif isinstance(action, SimpleWriteTest):\n                code_text = getattr(message, \"content\", \"\") if message and getattr(message, \"content\", None) else \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest.content if latest else \"\"\n                out = await action.run(code_text)\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n            elif isinstance(action, SimpleWriteReview):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                lowered = (out or \"\").lower()\n                if \"request\" in lowered or \"reject\" in lowered or \"request_changes\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n            elif isinstance(action, SimpleVerify):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                # broadcast verification results to Team and Reviewer for trace\n                send_to = {\"Team\", \"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n            else:\n                out = await action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = {\"Team\"}\n        except Exception as e:\n            out = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            send_to = {\"Team\"}\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, out)\n        # mark input as processed\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # create response message (ensure role param is provided)\n        try:\n            resp = Message(\n                content=out,\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name,\n                send_to=set(send_to)\n            )\n        except TypeError:\n            # fallback for pydantic vs non-pydantic constructors\n            resp = Message(out, self.profile, cause_by=action.name, sent_from=self.name, send_to=set(send_to))\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={getattr(resp,'id',None)} cause_by={resp.cause_by} send_to={sorted(list(send_to))}\")\n        return resp\n\n# Concrete role implementations\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\n# Environment: message bus with routing and delivery tracking\nclass Environment:\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # delivered mapping: role.name -> set(msg.id)\n        self._delivered: Dict[str, Set[str]] = {}\n        # indexed by cause_by for quick lookup\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        try:\n            if getattr(message, \"send_to\", None) is None:\n                message.send_to = _to_set_send_to(message)\n            elif isinstance(message.send_to, (list, tuple)):\n                message.send_to = set(message.send_to)\n        except Exception:\n            try:\n                message.send_to = set()\n            except Exception:\n                message.send_to = set()\n        # ensure id exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Msg {getattr(message,'id',None)} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def get_pending_for_role(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            # explicit targeting\n            if getattr(msg, \"send_to\", None):\n                targets = _to_set_send_to(msg)\n                if role.name in targets or role.profile in targets or \"*\" in targets:\n                    out.append(msg)\n                    seen.add(mid)\n                    continue\n            # watch-list based\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n                seen.add(mid)\n                continue\n        return out\n\n    def mark_delivered(self, role: Role, message: Message):\n        mid = getattr(message, \"id\", None)\n        if not mid:\n            return\n        self._delivered.setdefault(role.name, set()).add(mid)\n        if self.tracer:\n            self.tracer.log(\"ENV_MARK_DELIVERED\", \"Environment\", f\"{role.name} delivered {mid}\")\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        lst = self._by_cause.get(cause, [])\n        return lst[-1] if lst else None\n\n# Team orchestrator: deterministic ordering, termination conditions, and retries\nclass Team:\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        # verification stability tracking\n        self._streak: int = 0\n        self._last_digest: Optional[str] = None\n        self._required_stable_passes: int = VERIFICATION_STABLE_REQUIRED\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {self.idea[:200]}\")\n\n    async def _process_role(self, role: Role):\n        pending = self.env.get_pending_for_role(role)\n        if not pending:\n            return\n        for msg in pending:\n            # mark delivered before processing to avoid duplicates in concurrent scenarios\n            self.env.mark_delivered(role, msg)\n            try:\n                resp = await role.act(msg)\n            except Exception as e:\n                self.tracer.log(\"ROLE_ACT_ERROR\", role.name, f\"Exception in act: {type(e).__name__}:{str(e)[:200]}\")\n                resp = Message(content=f\"ROLE_EXCEPTION: {type(e).__name__}\", role=role.profile, cause_by=\"RoleException\", sent_from=role.name, send_to=set())\n            if resp:\n                self.env.publish_message(resp)\n                # If verifier produced a PASS, update streak\n                if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                    content = resp.content\n                    if \"VERIFICATION_RESULT: PASS\" in content:\n                        # extract digest token\n                        digest = None\n                        for part in content.split(\"|\"):\n                            p = part.strip()\n                            if p.startswith(\"digest=\"):\n                                digest = p.split(\"=\", 1)[1].strip()\n                                break\n                        if digest:\n                            if digest == self._last_digest:\n                                self._streak += 1\n                            else:\n                                self._last_digest = digest\n                                self._streak = 1\n                            self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                        else:\n                            # treat as single pass but not stable across rounds\n                            self._last_digest = None\n                            self._streak = 1\n                    elif \"VERIFICATION_RESULT: FAIL\" in content:\n                        if self._streak > 0:\n                            self.tracer.log(\"VERIFIER_RESET\", \"Team\", \"Verifier reported FAIL; resetting streak\")\n                        self._streak = 0\n                        self._last_digest = None\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._required_stable_passes} stable verification passes\")\n        # initial instruction targeted to coders\n        initial = None\n        try:\n            initial = Message(\n                content=f\"Let's work on this project: {self.idea}\",\n                instruct_content=self.idea,\n                role=\"Human\",\n                sent_from=\"User\",\n                cause_by=\"UserInput\",\n                send_to={\"SimpleCoder\"}\n            )\n        except TypeError:\n            initial = Message(f\"Let's work on this project: {self.idea}\", \"Human\", instruct_content=self.idea, sent_from=\"User\", cause_by=\"UserInput\", send_to={\"SimpleCoder\"})\n        self.env.publish_message(initial)\n\n        # deterministic role order\n        order: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            # process roles in deterministic order\n            for role_type in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles:\n                    # ensure coder sees initial message on first round\n                    if isinstance(role, SimpleCoder) and rnd == 1:\n                        if initial and initial not in self.env.history:\n                            self.env.publish_message(initial)\n                    await self._process_role(role)\n\n            # progress detection\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} complete history_len={len(self.env.history)} verifier_streak={self._streak}\")\n\n            # termination: require stable verification passes\n            if self._streak >= self._required_stable_passes and rnd >= 1:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping early\")\n                break\n\n            # nudge / stop on no progress\n            if no_progress_rounds >= NO_PROGRESS_LIMIT:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", f\"No progress for {no_progress_rounds} rounds; terminating early\")\n                break\n            if no_progress_rounds > 0:\n                # gentle nudge to coder(s)\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        try:\n                            nudge = Message(\n                                content=f\"Nudge: please refine implementation for: {self.idea}\",\n                                instruct_content=self.idea,\n                                role=\"System\",\n                                sent_from=\"Orchestrator\",\n                                cause_by=\"Nudge\",\n                                send_to={r.name}\n                            )\n                        except TypeError:\n                            nudge = Message(f\"Nudge: please refine implementation for: {self.idea}\", \"System\", instruct_content=self.idea, sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.name})\n                        self.env.publish_message(nudge)\n            # small cooperative sleep to yield to async LLMs if present\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project finished\")\n        summary = f\"Project '{self.idea}' finished after {rnd} rounds with {len(self.env.history)} messages. verified_streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}