{"id": "b2253915-80e1-40d0-ae75-a280180c8e1c", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nimport re\nfrom typing import Tuple, Set\n\n# Tunable parameters\nRETRY_ATTEMPTS = 3\nRETRY_BACKOFF_BASE = 0.4  # seconds\nMAX_MESSAGE_ATTEMPTS = 5\nSTABLE_VERIFICATION_REQUIRED_ROUNDS = 2  # require verification stable across rounds\n\nclass Action(ABC):\n    \"\"\"Base action with clear LLM retry semantics and contextual logging.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Raises on failure.\"\"\"\n        if not self.llm:\n            # Explicit sentinel to let callers fallback gracefully.\n            return \"LLM_NOT_AVAILABLE\"\n        last_err = None\n        for attempt in range(1, RETRY_ATTEMPTS + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{RETRY_ATTEMPTS}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or resp.startswith(\"Error communicating\")):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff with jitter\n                await asyncio.sleep(RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) + random.random() * 0.15)\n        raise RuntimeError(f\"LLM call failed after {RETRY_ATTEMPTS} attempts: {last_err}\")\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\ndef _strip_code_fences(text: str) -> str:\n    \"\"\"Remove surrounding markdown code fences and common wrappers.\"\"\"\n    if not text:\n        return text or \"\"\n    # remove triple backticks blocks\n    text = re.sub(r\"", "language": "python", "parent_id": "090280dd-daa4-4d55-bc09-9880fb42f19d", "generation": 3, "timestamp": 1754655582.5405529, "iteration_found": 28, "metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "unterminated string literal (detected at line 212) (tmpx8p73t0n.py, line 212)"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.5000\n- overall_score: 0.2500\n- combined_score: 0.1000\n- avg_failures_per_task: 12.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2609, avg_failures_per_task: 2.8333, total_failures: 17.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 4.5990)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with error handling and retry support.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        self.max_retries = kwargs.get('max_retries', 2)\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Ask the LLM with retry and exponential backoff. Returns result or error string.\"\"\"\n        attempt = 0\n        last_err = None\n        while attempt <= self.max_retries:\n            attempt += 1\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_ASK\", self.name, f\"Attempt {attempt}/{self.max_retries+1}\")\n            try:\n                if not self.llm:\n                    return \"LLM_UNAVAILABLE: Using fallback response.\"\n                res = await self.llm.ask(messages)\n                # treat responses starting with \"Error:\" or \"Error communicating\" as failures\n                if isinstance(res, str) and (res.startswith(\"Error:\") or res.startswith(\"Error communicating\")):\n                    last_err = res\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error text: {res[:200]}\")\n                    # fall through to retry\n                else:\n                    return res\n            except Exception as e:\n                last_err = f\"Exception: {e}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, str(e))\n            # simple backoff\n            if attempt <= self.max_retries:\n                # we don't want to import time in evolve block; just log retry\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Retrying LLM ask (attempt {attempt + 1})\")\n        # all attempts failed\n        return last_err or \"LLM_UNKNOWN_ERROR\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea, with validation and retries\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea (len={len(idea or '')})\")\n        \n        if not idea or not idea.strip():\n            warning = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea; returning warning code\")\n            return warning\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.safe_ask(messages)\n        # Basic validation: ensure non-empty and syntactically parseable (best-effort)\n        import ast\n        try:\n            if not code or not isinstance(code, str) or code.strip() == \"\":\n                raise ValueError(\"Empty code returned\")\n            ast.parse(code)\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed successfully\")\n        except Exception as e:\n            # Return explicit error result so downstream roles can detect and trigger retries\n            err = f\"# CODE_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(code or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code, validate presence of test functions\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        if not code or not code.strip():\n            msg = \"# WARNING: No code to test. Generated placeholder tests.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"No code provided for tests\")\n            return msg\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.safe_ask(messages)\n        \n        # Basic validation: ensure at least one function called test_\n        import ast\n        try:\n            if not tests or not isinstance(tests, str) or tests.strip() == \"\":\n                raise ValueError(\"Empty tests returned\")\n            parsed = ast.parse(tests)\n            has_test = any(\n                isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body\n            )\n            if not has_test:\n                raise ValueError(\"No pytest-style test functions found (test_ prefix)\")\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Tests parsed and contain test_ functions\")\n        except Exception as e:\n            err = f\"# TEST_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(tests or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests and provide actionable items\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        \n        if self.is_human:\n            review = \"Human review: Please verify edge cases and error handling; consider input validation.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_HUMAN_REVIEW\", self.name, \"Simulated human review provided\")\n            return review\n        \n        prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode (first 1500 chars):\n{code[:1500]}\n\nTests (first 1500 chars):\n{tests[:1500]}\n\nFocus on:\n1. Code quality and best practices\n2. Test coverage and missing edge cases\n3. Potential bugs or issues\n4. Concrete suggestions for improvement\n\nProvide a concise, actionable review.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        review = await self.safe_ask(messages)\n        if not review or not isinstance(review, str):\n            review = \"REVIEW_ERROR: No review generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, \"No review returned from LLM\")\n        else:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_END\", self.name, f\"Review generated len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        # Syntax checks\n        try:\n            if not code or not code.strip():\n                raise ValueError(\"Empty code\")\n            ast.parse(code)\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({str(e)[:120]})\")\n        try:\n            if not tests or not tests.strip():\n                raise ValueError(\"Empty tests\")\n            parsed_tests = ast.parse(tests)\n            # heuristic: presence of at least one test_ function\n            has_tests = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            if has_tests:\n                tests_ok = True\n                details.append(\"tests_syntax_and_presence: ok\")\n            else:\n                details.append(\"tests_syntax_and_presence: fail (no test_ functions found)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({str(e)[:120]})\")\n        # Coverage heuristics: ensure functions in code are referenced by tests (simple name match)\n        coverage_ok = False\n        if code_ok and tests_ok:\n            try:\n                parsed_code = ast.parse(code)\n                func_names = {n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)}\n                # look for function names in test source\n                tests_text = tests\n                matched = [fn for fn in func_names if fn and fn in tests_text]\n                if func_names and matched:\n                    coverage_ok = True\n                    details.append(f\"coverage_hint: ok (matched functions: {matched[:5]})\")\n                else:\n                    details.append(\"coverage_hint: fail (no clear function usage in tests)\")\n            except Exception as e:\n                details.append(f\"coverage_check_error: {str(e)[:120]}\")\n        verified = code_ok and tests_ok and coverage_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    triggers_on: List[str] = []  # cause_by values this role listens for\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.triggers_on = kwargs.get('triggers_on', [])\n        # reference to env may be injected by Team.hire\n        self.env = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for (by action class)\"\"\"\n        self.watch_list = actions\n        # also set triggers_on strings for quick matching\n        self.triggers_on = [a.name for a in actions]\n    \n    def can_respond_to(self, msg: Message) -> bool:\n        \"\"\"Determine whether this role should respond to the message.\"\"\"\n        # If triggers_on empty, role acts proactively (e.g., coder on initial human input)\n        if not self.triggers_on:\n            return False\n        return msg.cause_by in self.triggers_on\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the role's primary action in a guarded manner.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        try:\n            # Map action type to expected inputs explicitly\n            if isinstance(action, SimpleWriteCode):\n                # coder expects instruction content if available, else full message content\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")\n                result = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # tester expects code in message.content\n                code = message.content if message else \"\"\n                result = await action.run(code)\n            elif isinstance(action, SimpleWriteReview):\n                # reviewer needs both code and tests. Get most recent code/tests from env\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # verifier obtains latest code/tests similar to reviewer\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                result = await action.run(message) if message else await action.run()\n        except Exception as e:\n            # Catch any unexpected errors, create a failure message describing it\n            err_text = f\"ROLE_EXCEPTION: {self.name} failed with exception {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err_text)\n            result = err_text\n        # Build a Message for the environment describing the result\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message caused by {response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # coder listens to direct user input\n        self._watch([])  # proactive; will be invoked explicitly on initial input\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with explicit delivery and cursors.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # per-role cursor to track which messages have been seen/consumed\n        self.role_cursors: Dict[str, int] = {}\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        # initialize cursor to 0 for this role (no messages consumed yet)\n        self.role_cursors[role.name] = 0\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message [{message.cause_by}] from {message.sent_from}: {message.content[:200]}\")\n    \n    def get_pending_messages_for_role(self, role: Role) -> List[tuple]:\n        \"\"\"Return list of (index, Message) that the role has not yet consumed and that match its triggers.\"\"\"\n        results = []\n        cursor = self.role_cursors.get(role.name, 0)\n        for idx in range(cursor, len(self.history)):\n            msg = self.history[idx]\n            # role can respond if msg.cause_by matches role's triggers\n            if role.triggers_on and msg.cause_by in role.triggers_on:\n                results.append((idx, msg))\n        return results\n    \n    def mark_consumed(self, role: Role, up_to_index: int):\n        \"\"\"Mark messages up to up_to_index (inclusive) as consumed for this role.\"\"\"\n        prev = self.role_cursors.get(role.name, 0)\n        new_cursor = max(prev, up_to_index + 1)\n        self.role_cursors[role.name] = new_cursor\n        if self.tracer:\n            self.tracer.log(\"ENV_CURSOR\", \"Environment\", f\"Role {role.name} cursor advanced to {new_cursor}\")\n\nclass Team:\n    \"\"\"Team of agents working together with improved orchestration, termination and verification logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # order of execution for each round\n        self.role_order = []\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n        # stable execution order: coder, tester, reviewer, verifier (by class)\n        # maintain roles in the order they were added if present\n        name_to_role = {r.__class__.__name__: r for r in self.env.roles}\n        ordered = []\n        for cname in (\"SimpleCoder\", \"SimpleTester\", \"SimpleReviewer\", \"SimpleVerifier\"):\n            r = name_to_role.get(cname)\n            if r:\n                ordered.append(r)\n        # fallback to any roles not listed\n        for r in self.env.roles:\n            if r not in ordered:\n                ordered.append(r)\n        self.role_order = ordered\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with robust termination rules.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        last_verification_index = -1\n        stable_verification_rounds = 0\n        max_stable_rounds_required = 1  # require verification to remain true across a round to stop\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            round_actions = []\n            # Special handling: on first round, explicitly invoke coder with the initial message\n            for role in self.role_order:\n                # For proactive coder (listens to user input), feed initial_msg on first round\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"Invoking coder {role.name} with initial idea\")\n                    response = await role.act(initial_msg)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # mark that coder has consumed initial input\n                        self.env.mark_consumed(role, len(self.env.history)-1)\n                    continue\n                # For other roles and later rounds, gather pending messages\n                pending = self.env.get_pending_messages_for_role(role)\n                if not pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"No pending messages for {role.name}\")\n                    continue\n                # Process each pending message in order\n                for idx, msg in pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"{role.name} responding to message idx={idx} cause_by={msg.cause_by}\")\n                    response = await role.act(msg)\n                    # Mark consumed up to this message for this role\n                    self.env.mark_consumed(role, idx)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # If verifier produced a pass, capture it\n                        if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            verified = True\n                            last_verification_index = len(self.env.history) - 1\n            # Post-round analysis: determine termination criteria\n            # If verification happened this round and is still the most recent verification result, count as stable\n            if verified:\n                # ensure that no new code/test messages after verification (to ensure stability)\n                newest_code_or_test_idx = -1\n                for i, msg in enumerate(self.env.history):\n                    if msg.cause_by in (SimpleWriteCode.name, SimpleWriteTest.name):\n                        newest_code_or_test_idx = max(newest_code_or_test_idx, i)\n                if newest_code_or_test_idx <= last_verification_index:\n                    stable_verification_rounds += 1\n                else:\n                    stable_verification_rounds = 0\n                    # If new code/tests appeared after verification, require re-verification\n                    verified = False\n                self.tracer.log(\"VER_STATUS\", \"Team\", f\"verified={verified} stable_rounds={stable_verification_rounds}\")\n            else:\n                stable_verification_rounds = 0\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed with {len(round_actions)} actions\")\n            # Terminate if verification stable for required number of rounds\n            if verified and stable_verification_rounds > max_stable_rounds_required:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification stable; stopping early\")\n                break\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2609), Performs well on avg_failures_per_task (2.8333), Performs well on total_failures (17.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 2 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nfrom typing import Callable, Tuple\n\nRETRY_ATTEMPTS = 3\nRETRY_BACKOFF_BASE = 0.5  # seconds\nMAX_MESSAGE_ATTEMPTS = 5\n\nclass Action(ABC):\n    \"\"\"Base action class with retry and error handling for LLM/API calls.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns response or raises.\"\"\"\n        if not self.llm:\n            # No LLM configured; return sentinel to allow caller to fallback\n            return \"LLM_NOT_AVAILABLE\"\n        last_err = None\n        for attempt in range(1, RETRY_ATTEMPTS + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}\")\n                resp = await self.llm.ask(messages)\n                # Basic failure detection: LLMInterface returns string starting with \"Error\"\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff with jitter\n                await asyncio.sleep(RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) + random.random() * 0.1)\n        # All retries failed\n        raise RuntimeError(f\"LLM call failed after {RETRY_ATTEMPTS} attempts: {last_err}\")\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce a compilable code artifact from a short instruction.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea={(idea or '')[:120]}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a single Python module that implements the described functionality. \"\n            \"Keep functions small and documented. Ensure code is parseable by ast.parse and does not include extraneous text.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n1. Clean, functional Python code\\n2. Proper error handling\\n3. Docstrings and comments\\n4. Production-ready\\n\\n\"\n            \"Provide only the Python code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = None\n        try:\n            resp = await self._llm_call_with_retries(messages)\n            if resp == \"LLM_NOT_AVAILABLE\":\n                raise RuntimeError(\"LLM not available\")\n            code = resp\n        except Exception as e:\n            # Fallback minimal code to keep pipeline moving\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n            code = (\n                f\"# Fallback implementation for: {idea}\\n\\n\"\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n\n        # Validate that generated code parses\n        parsed_ok = False\n        try:\n            import ast\n            ast.parse(code or \"\")\n            parsed_ok = True\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"AST parse failed: {str(e)[:200]}\")\n            # Attempt a minimal corrective step: wrap in a safe function if possible\n            try:\n                corrective = \"def _safe_wrapper():\\n\"\n                for line in (code or \"\").splitlines():\n                    corrective += \"    \" + line + \"\\n\"\n                corrective += \"\\n\"\n                import ast as _ast\n                _ast.parse(corrective)\n                code = corrective\n                parsed_ok = True\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_VALIDATION_FIX\", self.name, \"Applied simple wrapper to fix parse issues\")\n            except Exception:\n                parsed_ok = False\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(code or '')}; parsed_ok={parsed_ok}\")\n        return code or \"\"\n\nclass SimpleWriteTest(Action):\n    \"\"\"Produce pytest-style tests targeting functions present in the code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        # Extract function names to direct tests\n        func_names = []\n        try:\n            import ast\n            mod = ast.parse(code or \"\")\n            func_names = [n.name for n in ast.walk(mod) if isinstance(n, ast.FunctionDef)]\n        except Exception:\n            func_names = []\n\n        prompt = (\n            \"You are a QA engineer that writes pytest tests. Produce pytest tests for the given module. \"\n            \"If function names are available, write at least one positive and one negative test per function. \"\n            \"Include docstrings for each test. Provide only the Python test code.\"\n        )\n        if func_names:\n            prompt += f\"\\nTarget functions: {', '.join(func_names[:8])}\"\n        prompt += \"\\n\\nCode:\\n\" + (code[:2000] if code else \"(empty)\")\n\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer who writes pytest tests.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = None\n        try:\n            resp = await self._llm_call_with_retries(messages)\n            if resp == \"LLM_NOT_AVAILABLE\":\n                raise RuntimeError(\"LLM not available\")\n            tests = resp\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder_exists():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n\n        # Validate tests parse\n        tests_ok = False\n        try:\n            import ast\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(tests or '')}; parsed_ok={tests_ok}\")\n        return tests or \"\"\n\nclass SimpleWriteReview(Action):\n    \"\"\"Produce concise, actionable review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Basic sanity checks performed. Consider adding edge-case tests and clearer error handling.\"\n        else:\n            prompt = (\n                \"You are a senior software engineer. Provide a concise actionable review focused on code quality, test completeness, \"\n                \"and likely bugs. Provide a short prioritized list of suggestions.\\n\\n\"\n                f\"Code:\\n{code[:1500]}\\n\\nTests:\\n{tests[:1500]}\"\n            )\n            messages = [{\"role\": \"system\", \"content\": \"You are a senior code reviewer.\"},\n                        {\"role\": \"user\", \"content\": prompt}]\n            try:\n                resp = await self._llm_call_with_retries(messages)\n                if resp == \"LLM_NOT_AVAILABLE\":\n                    raise RuntimeError(\"LLM not available\")\n                review = resp\n            except Exception as e:\n                review = \"Automated review fallback: Unable to contact reviewer LLM. Please perform a manual review.\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Verify syntactic and basic semantic alignment between code and tests.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"\")\n        diagnostics = []\n        code_ok = False\n        tests_ok = False\n        try:\n            import ast\n            code_ast = ast.parse(code or \"\")\n            defs = [n for n in code_ast.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            if defs:\n                code_ok = True\n                diagnostics.append(f\"code_defs:{len(defs)}\")\n            else:\n                diagnostics.append(\"code_defs:none\")\n        except Exception as e:\n            diagnostics.append(f\"code_parse_error:{str(e)[:180]}\")\n\n        try:\n            import ast\n            tests_ast = ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n            if tests_ok and code_ok:\n                test_names = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n                code_names = {n.name for n in ast.walk(code_ast) if isinstance(n, ast.FunctionDef)}\n                referenced = code_names & test_names\n                diagnostics.append(f\"tests_refs:{len(referenced)}\")\n                if not referenced:\n                    diagnostics.append(\"tests_refs:none\")\n            else:\n                diagnostics.append(\"tests_parse:empty_or_invalid\")\n        except Exception as e:\n            diagnostics.append(f\"tests_parse_error:{str(e)[:180]}\")\n\n        verified = code_ok and tests_ok and any(\"tests_refs\" in d and not d.endswith(\":0\") for d in diagnostics) == False or (code_ok and tests_ok)\n        # The above line ensures we require both parseable code and tests; we keep it lenient but informative.\n        result = f\"VERIFICATION_RESULT: {'PASS' if (code_ok and tests_ok) else 'FAIL'} | \" + \"; \".join(diagnostics)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with explicit responsibilities and inbox semantics.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # list of action names to watch\n    env: Optional[\"Environment\"] = None  # assigned at hire\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, action_types: List[Type[Action]]):\n        self.watch_list = [t.name for t in action_types]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"action={action.name}; msg_id={(message.id if message else 'None')}\")\n        try:\n            # Clear responsibility mapping here\n            if isinstance(action, SimpleWriteCode):\n                prompt = (message.instruct_content if (message and getattr(message, \"instruct_content\", None)) else (message.content if message else \"\"))\n                result = await action.run(prompt or \"\")\n            elif isinstance(action, SimpleWriteTest):\n                code_text = message.content if message else \"\"\n                result = await action.run(code_text)\n            elif isinstance(action, SimpleWriteReview):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            elif isinstance(action, SimpleVerify):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            else:\n                result = \"Action completed\"\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"exception: {str(e)[:200]}\")\n            result = f\"ERROR: {str(e)}\"\n\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n\n        # Mark processed to avoid duplicate processing by same role\n        if message and self.env:\n            self.env.mark_processed(message, self)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"created_msg_id={getattr(response, 'id', 'N/A')}; len={len(result)}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Tracks messages, processing state, and attempts to reduce race conditions.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._processed: Dict[str, Set[str]] = {}  # message.id -> set(role.name)\n        self._attempts: Dict[str, int] = {}       # message.id -> attempts count\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"{role.name}:{role.profile}\")\n\n    def publish_message(self, message: Message):\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        self._attempts.setdefault(message.id, 0)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"from={message.sent_from}; cause_by={message.cause_by}; snippet={(message.content or '')[:140]}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        self._processed.setdefault(message.id, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"msg={message.id}; by={role.name}\")\n\n    def increment_attempt(self, message: Message) -> int:\n        self._attempts[message.id] = self._attempts.get(message.id, 0) + 1\n        return self._attempts[message.id]\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        results = []\n        for msg in self.history:\n            if msg.cause_by in role.watch_list:\n                processed = self._processed.get(msg.id, set())\n                if role.name not in processed:\n                    results.append(msg)\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str) -> Tuple[Optional[Message], Optional[Message]]:\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and msg.cause_by == code_cause:\n                code_msg = msg\n            if not tests_msg and msg.cause_by == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Team orchestrator with clear pipeline, explicit watch/trigger logic, and robust termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        self.pipeline: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"idea={idea}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"up_to_rounds={n_round}\")\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        last_verified_round = -1\n        last_history_len = len(self.env.history)\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"round={round_num}\")\n            for role_type in self.pipeline:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # Determine inbox for this role\n                    if isinstance(role, SimpleCoder) and round_num == 1:\n                        inbox = [initial_msg]\n                    else:\n                        inbox = self.env.get_unprocessed_messages_for_role(role)\n\n                    for msg in inbox:\n                        attempts = self.env.increment_attempt(msg)\n                        if attempts > MAX_MESSAGE_ATTEMPTS:\n                            if self.tracer:\n                                self.tracer.log(\"ENV_SKIP\", \"Environment\", f\"skip msg={msg.id} for role={role.name} after_attempts={attempts}\")\n                            self.env.mark_processed(msg, role)\n                            continue\n\n                        response = await role.act(msg)\n                        if response:\n                            self.env.publish_message(response)\n                            # If verifier produced PASS, do confirmation\n                            if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                # Run a confirmation verification locally to avoid transient success\n                                try:\n                                    verifier_action = role.actions[0]\n                                    code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                                    confirm = await verifier_action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                                    if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                        verified = True\n                                        last_verified_round = round_num\n                                        self.tracer.log(\"VERIFIED_CONFIRMED\", \"Team\", f\"round={round_num}\")\n                                    else:\n                                        self.tracer.log(\"VERIFIED_REJECTED\", \"Team\", f\"round={round_num}; confirm={confirm[:200]}\")\n                                except Exception as e:\n                                    if self.tracer:\n                                        self.tracer.log(\"VERIFIED_ERROR\", \"Team\", f\"confirm exception: {str(e)[:200]}\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"round={round_num}\")\n            # Check for stable verification: require verification and no new messages after one extra round\n            if verified:\n                # If history length hasn't changed since verification, we can stop\n                if len(self.env.history) == last_history_len:\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"stable verified at round={round_num}\")\n                    break\n                else:\n                    # record current history length and allow one more round\n                    last_history_len = len(self.env.history)\n            else:\n                last_history_len = len(self.env.history)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 4.5990, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with error handling and retry support.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        self.max_retries = kwargs.get('max_retries', 2)\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Ask the LLM with retry and exponential backoff. Returns result or error string.\"\"\"\n        attempt = 0\n        last_err = None\n        while attempt <= self.max_retries:\n            attempt += 1\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_ASK\", self.name, f\"Attempt {attempt}/{self.max_retries+1}\")\n            try:\n                if not self.llm:\n                    return \"LLM_UNAVAILABLE: Using fallback response.\"\n                res = await self.llm.ask(messages)\n                # treat responses starting with \"Error:\" or \"Error communicating\" as failures\n                if isinstance(res, str) and (res.startswith(\"Error:\") or res.startswith(\"Error communicating\")):\n                    last_err = res\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error text: {res[:200]}\")\n                    # fall through to retry\n                else:\n                    return res\n            except Exception as e:\n                last_err = f\"Exception: {e}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, str(e))\n            # simple backoff\n            if attempt <= self.max_retries:\n                # we don't want to import time in evolve block; just log retry\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Retrying LLM ask (attempt {attempt + 1})\")\n        # all attempts failed\n        return last_err or \"LLM_UNKNOWN_ERROR\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea, with validation and retries\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea (len={len(idea or '')})\")\n        \n        if not idea or not idea.strip():\n            warning = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea; returning warning code\")\n            return warning\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.safe_ask(messages)\n        # Basic validation: ensure non-empty and syntactically parseable (best-effort)\n        import ast\n        try:\n            if not code or not isinstance(code, str) or code.strip() == \"\":\n                raise ValueError(\"Empty code returned\")\n            ast.parse(code)\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed successfully\")\n        except Exception as e:\n            # Return explicit error result so downstream roles can detect and trigger retries\n            err = f\"# CODE_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(code or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code, validate presence of test functions\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        if not code or not code.strip():\n            msg = \"# WARNING: No code to test. Generated placeholder tests.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"No code provided for tests\")\n            return msg\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.safe_ask(messages)\n        \n        # Basic validation: ensure at least one function called test_\n        import ast\n        try:\n            if not tests or not isinstance(tests, str) or tests.strip() == \"\":\n                raise ValueError(\"Empty tests returned\")\n            parsed = ast.parse(tests)\n            has_test = any(\n                isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body\n            )\n            if not has_test:\n                raise ValueError(\"No pytest-style test functions found (test_ prefix)\")\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Tests parsed and contain test_ functions\")\n        except Exception as e:\n            err = f\"# TEST_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(tests or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests and provide actionable items\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        \n        if self.is_human:\n            review = \"Human review: Please verify edge cases and error handling; consider input validation.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_HUMAN_REVIEW\", self.name, \"Simulated human review provided\")\n            return review\n        \n        prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode (first 1500 chars):\n{code[:1500]}\n\nTests (first 1500 chars):\n{tests[:1500]}\n\nFocus on:\n1. Code quality and best practices\n2. Test coverage and missing edge cases\n3. Potential bugs or issues\n4. Concrete suggestions for improvement\n\nProvide a concise, actionable review.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        review = await self.safe_ask(messages)\n        if not review or not isinstance(review, str):\n            review = \"REVIEW_ERROR: No review generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, \"No review returned from LLM\")\n        else:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_END\", self.name, f\"Review generated len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        # Syntax checks\n        try:\n            if not code or not code.strip():\n                raise ValueError(\"Empty code\")\n            ast.parse(code)\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({str(e)[:120]})\")\n        try:\n            if not tests or not tests.strip():\n                raise ValueError(\"Empty tests\")\n            parsed_tests = ast.parse(tests)\n            # heuristic: presence of at least one test_ function\n            has_tests = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            if has_tests:\n                tests_ok = True\n                details.append(\"tests_syntax_and_presence: ok\")\n            else:\n                details.append(\"tests_syntax_and_presence: fail (no test_ functions found)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({str(e)[:120]})\")\n        # Coverage heuristics: ensure functions in code are referenced by tests (simple name match)\n        coverage_ok = False\n        if code_ok and tests_ok:\n            try:\n                parsed_code = ast.parse(code)\n                func_names = {n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)}\n                # look for function names in test source\n                tests_text = tests\n                matched = [fn for fn in func_names if fn and fn in tests_text]\n                if func_names and matched:\n                    coverage_ok = True\n                    details.append(f\"coverage_hint: ok (matched functions: {matched[:5]})\")\n                else:\n                    details.append(\"coverage_hint: fail (no clear function usage in tests)\")\n            except Exception as e:\n                details.append(f\"coverage_check_error: {str(e)[:120]}\")\n        verified = code_ok and tests_ok and coverage_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    triggers_on: List[str] = []  # cause_by values this role listens for\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.triggers_on = kwargs.get('triggers_on', [])\n        # reference to env may be injected by Team.hire\n        self.env = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for (by action class)\"\"\"\n        self.watch_list = actions\n        # also set triggers_on strings for quick matching\n        self.triggers_on = [a.name for a in actions]\n    \n    def can_respond_to(self, msg: Message) -> bool:\n        \"\"\"Determine whether this role should respond to the message.\"\"\"\n        # If triggers_on empty, role acts proactively (e.g., coder on initial human input)\n        if not self.triggers_on:\n            return False\n        return msg.cause_by in self.triggers_on\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the role's primary action in a guarded manner.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        try:\n            # Map action type to expected inputs explicitly\n            if isinstance(action, SimpleWriteCode):\n                # coder expects instruction content if available, else full message content\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")\n                result = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # tester expects code in message.content\n                code = message.content if message else \"\"\n                result = await action.run(code)\n            elif isinstance(action, SimpleWriteReview):\n                # reviewer needs both code and tests. Get most recent code/tests from env\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # verifier obtains latest code/tests similar to reviewer\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                result = await action.run(message) if message else await action.run()\n        except Exception as e:\n            # Catch any unexpected errors, create a failure message describing it\n            err_text = f\"ROLE_EXCEPTION: {self.name} failed with exception {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err_text)\n            result = err_text\n        # Build a Message for the environment describing the result\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message caused by {response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # coder listens to direct user input\n        self._watch([])  # proactive; will be invoked explicitly on initial input\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with explicit delivery and cursors.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # per-role cursor to track which messages have been seen/consumed\n        self.role_cursors: Dict[str, int] = {}\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        # initialize cursor to 0 for this role (no messages consumed yet)\n        self.role_cursors[role.name] = 0\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message [{message.cause_by}] from {message.sent_from}: {message.content[:200]}\")\n    \n    def get_pending_messages_for_role(self, role: Role) -> List[tuple]:\n        \"\"\"Return list of (index, Message) that the role has not yet consumed and that match its triggers.\"\"\"\n        results = []\n        cursor = self.role_cursors.get(role.name, 0)\n        for idx in range(cursor, len(self.history)):\n            msg = self.history[idx]\n            # role can respond if msg.cause_by matches role's triggers\n            if role.triggers_on and msg.cause_by in role.triggers_on:\n                results.append((idx, msg))\n        return results\n    \n    def mark_consumed(self, role: Role, up_to_index: int):\n        \"\"\"Mark messages up to up_to_index (inclusive) as consumed for this role.\"\"\"\n        prev = self.role_cursors.get(role.name, 0)\n        new_cursor = max(prev, up_to_index + 1)\n        self.role_cursors[role.name] = new_cursor\n        if self.tracer:\n            self.tracer.log(\"ENV_CURSOR\", \"Environment\", f\"Role {role.name} cursor advanced to {new_cursor}\")\n\nclass Team:\n    \"\"\"Team of agents working together with improved orchestration, termination and verification logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # order of execution for each round\n        self.role_order = []\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n        # stable execution order: coder, tester, reviewer, verifier (by class)\n        # maintain roles in the order they were added if present\n        name_to_role = {r.__class__.__name__: r for r in self.env.roles}\n        ordered = []\n        for cname in (\"SimpleCoder\", \"SimpleTester\", \"SimpleReviewer\", \"SimpleVerifier\"):\n            r = name_to_role.get(cname)\n            if r:\n                ordered.append(r)\n        # fallback to any roles not listed\n        for r in self.env.roles:\n            if r not in ordered:\n                ordered.append(r)\n        self.role_order = ordered\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with robust termination rules.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        last_verification_index = -1\n        stable_verification_rounds = 0\n        max_stable_rounds_required = 1  # require verification to remain true across a round to stop\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            round_actions = []\n            # Special handling: on first round, explicitly invoke coder with the initial message\n            for role in self.role_order:\n                # For proactive coder (listens to user input), feed initial_msg on first round\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"Invoking coder {role.name} with initial idea\")\n                    response = await role.act(initial_msg)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # mark that coder has consumed initial input\n                        self.env.mark_consumed(role, len(self.env.history)-1)\n                    continue\n                # For other roles and later rounds, gather pending messages\n                pending = self.env.get_pending_messages_for_role(role)\n                if not pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"No pending messages for {role.name}\")\n                    continue\n                # Process each pending message in order\n                for idx, msg in pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"{role.name} responding to message idx={idx} cause_by={msg.cause_by}\")\n                    response = await role.act(msg)\n                    # Mark consumed up to this message for this role\n                    self.env.mark_consumed(role, idx)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # If verifier produced a pass, capture it\n                        if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            verified = True\n                            last_verification_index = len(self.env.history) - 1\n            # Post-round analysis: determine termination criteria\n            # If verification happened this round and is still the most recent verification result, count as stable\n            if verified:\n                # ensure that no new code/test messages after verification (to ensure stability)\n                newest_code_or_test_idx = -1\n                for i, msg in enumerate(self.env.history):\n                    if msg.cause_by in (SimpleWriteCode.name, SimpleWriteTest.name):\n                        newest_code_or_test_idx = max(newest_code_or_test_idx, i)\n                if newest_code_or_test_idx <= last_verification_index:\n                    stable_verification_rounds += 1\n                else:\n                    stable_verification_rounds = 0\n                    # If new code/tests appeared after verification, require re-verification\n                    verified = False\n                self.tracer.log(\"VER_STATUS\", \"Team\", f\"verified={verified} stable_rounds={stable_verification_rounds}\")\n            else:\n                stable_verification_rounds = 0\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed with {len(round_actions)} actions\")\n            # Terminate if verification stable for required number of rounds\n            if verified and stable_verification_rounds > max_stable_rounds_required:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification stable; stopping early\")\n                break\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (2.833)\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nfrom typing import Callable, Tuple\n\nRETRY_ATTEMPTS = 3\nRETRY_BACKOFF_BASE = 0.5  # seconds\nMAX_MESSAGE_ATTEMPTS = 5\n\nclass Action(ABC):\n    \"\"\"Base action class with retry and error handling for LLM/API calls.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns response or raises.\"\"\"\n        if not self.llm:\n            # No LLM configured; return sentinel to allow caller to fallback\n            return \"LLM_NOT_AVAILABLE\"\n        last_err = None\n        for attempt in range(1, RETRY_ATTEMPTS + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}\")\n                resp = await self.llm.ask(messages)\n                # Basic failure detection: LLMInterface returns string starting with \"Error\"\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff with jitter\n                await asyncio.sleep(RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) + random.random() * 0.1)\n        # All retries failed\n        raise RuntimeError(f\"LLM call failed after {RETRY_ATTEMPTS} attempts: {last_err}\")\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce a compilable code artifact from a short instruction.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea={(idea or '')[:120]}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a single Python module that implements the described functionality. \"\n            \"Keep functions small and documented. Ensure code is parseable by ast.parse and does not include extraneous text.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n1. Clean, functional Python code\\n2. Proper error handling\\n3. Docstrings and comments\\n4. Production-ready\\n\\n\"\n            \"Provide only the Python code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = None\n        try:\n            resp = await self._llm_call_with_retries(messages)\n            if resp == \"LLM_NOT_AVAILABLE\":\n                raise RuntimeError(\"LLM not available\")\n            code = resp\n        except Exception as e:\n            # Fallback minimal code to keep pipeline moving\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n            code = (\n                f\"# Fallback implementation for: {idea}\\n\\n\"\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n\n        # Validate that generated code parses\n        parsed_ok = False\n        try:\n            import ast\n            ast.parse(code or \"\")\n            parsed_ok = True\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"AST parse failed: {str(e)[:200]}\")\n            # Attempt a minimal corrective step: wrap in a safe function if possible\n            try:\n                corrective = \"def _safe_wrapper():\\n\"\n                for line in (code or \"\").splitlines():\n                    corrective += \"    \" + line + \"\\n\"\n                corrective += \"\\n\"\n                import ast as _ast\n                _ast.parse(corrective)\n                code = corrective\n                parsed_ok = True\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_VALIDATION_FIX\", self.name, \"Applied simple wrapper to fix parse issues\")\n            except Exception:\n                parsed_ok = False\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(code or '')}; parsed_ok={parsed_ok}\")\n        return code or \"\"\n\nclass SimpleWriteTest(Action):\n    \"\"\"Produce pytest-style tests targeting functions present in the code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        # Extract function names to direct tests\n        func_names = []\n        try:\n            import ast\n            mod = ast.parse(code or \"\")\n            func_names = [n.name for n in ast.walk(mod) if isinstance(n, ast.FunctionDef)]\n        except Exception:\n            func_names = []\n\n        prompt = (\n            \"You are a QA engineer that writes pytest tests. Produce pytest tests for the given module. \"\n            \"If function names are available, write at least one positive and one negative test per function. \"\n            \"Include docstrings for each test. Provide only the Python test code.\"\n        )\n        if func_names:\n            prompt += f\"\\nTarget functions: {', '.join(func_names[:8])}\"\n        prompt += \"\\n\\nCode:\\n\" + (code[:2000] if code else \"(empty)\")\n\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer who writes pytest tests.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = None\n        try:\n            resp = await self._llm_call_with_retries(messages)\n            if resp == \"LLM_NOT_AVAILABLE\":\n                raise RuntimeError(\"LLM not available\")\n            tests = resp\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder_exists():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n\n        # Validate tests parse\n        tests_ok = False\n        try:\n            import ast\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(tests or '')}; parsed_ok={tests_ok}\")\n        return tests or \"\"\n\nclass SimpleWriteReview(Action):\n    \"\"\"Produce concise, actionable review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Basic sanity checks performed. Consider adding edge-case tests and clearer error handling.\"\n        else:\n            prompt = (\n                \"You are a senior software engineer. Provide a concise actionable review focused on code quality, test completeness, \"\n                \"and likely bugs. Provide a short prioritized list of suggestions.\\n\\n\"\n                f\"Code:\\n{code[:1500]}\\n\\nTests:\\n{tests[:1500]}\"\n            )\n            messages = [{\"role\": \"system\", \"content\": \"You are a senior code reviewer.\"},\n                        {\"role\": \"user\", \"content\": prompt}]\n            try:\n                resp = await self._llm_call_with_retries(messages)\n                if resp == \"LLM_NOT_AVAILABLE\":\n                    raise RuntimeError(\"LLM not available\")\n                review = resp\n            except Exception as e:\n                review = \"Automated review fallback: Unable to contact reviewer LLM. Please perform a manual review.\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Verify syntactic and basic semantic alignment between code and tests.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"\")\n        diagnostics = []\n        code_ok = False\n        tests_ok = False\n        try:\n            import ast\n            code_ast = ast.parse(code or \"\")\n            defs = [n for n in code_ast.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            if defs:\n                code_ok = True\n                diagnostics.append(f\"code_defs:{len(defs)}\")\n            else:\n                diagnostics.append(\"code_defs:none\")\n        except Exception as e:\n            diagnostics.append(f\"code_parse_error:{str(e)[:180]}\")\n\n        try:\n            import ast\n            tests_ast = ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n            if tests_ok and code_ok:\n                test_names = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n                code_names = {n.name for n in ast.walk(code_ast) if isinstance(n, ast.FunctionDef)}\n                referenced = code_names & test_names\n                diagnostics.append(f\"tests_refs:{len(referenced)}\")\n                if not referenced:\n                    diagnostics.append(\"tests_refs:none\")\n            else:\n                diagnostics.append(\"tests_parse:empty_or_invalid\")\n        except Exception as e:\n            diagnostics.append(f\"tests_parse_error:{str(e)[:180]}\")\n\n        verified = code_ok and tests_ok and any(\"tests_refs\" in d and not d.endswith(\":0\") for d in diagnostics) == False or (code_ok and tests_ok)\n        # The above line ensures we require both parseable code and tests; we keep it lenient but informative.\n        result = f\"VERIFICATION_RESULT: {'PASS' if (code_ok and tests_ok) else 'FAIL'} | \" + \"; \".join(diagnostics)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with explicit responsibilities and inbox semantics.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # list of action names to watch\n    env: Optional[\"Environment\"] = None  # assigned at hire\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, action_types: List[Type[Action]]):\n        self.watch_list = [t.name for t in action_types]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"action={action.name}; msg_id={(message.id if message else 'None')}\")\n        try:\n            # Clear responsibility mapping here\n            if isinstance(action, SimpleWriteCode):\n                prompt = (message.instruct_content if (message and getattr(message, \"instruct_content\", None)) else (message.content if message else \"\"))\n                result = await action.run(prompt or \"\")\n            elif isinstance(action, SimpleWriteTest):\n                code_text = message.content if message else \"\"\n                result = await action.run(code_text)\n            elif isinstance(action, SimpleWriteReview):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            elif isinstance(action, SimpleVerify):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            else:\n                result = \"Action completed\"\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"exception: {str(e)[:200]}\")\n            result = f\"ERROR: {str(e)}\"\n\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n\n        # Mark processed to avoid duplicate processing by same role\n        if message and self.env:\n            self.env.mark_processed(message, self)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"created_msg_id={getattr(response, 'id', 'N/A')}; len={len(result)}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Tracks messages, processing state, and attempts to reduce race conditions.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._processed: Dict[str, Set[str]] = {}  # message.id -> set(role.name)\n        self._attempts: Dict[str, int] = {}       # message.id -> attempts count\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"{role.name}:{role.profile}\")\n\n    def publish_message(self, message: Message):\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        self._attempts.setdefault(message.id, 0)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"from={message.sent_from}; cause_by={message.cause_by}; snippet={(message.content or '')[:140]}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        self._processed.setdefault(message.id, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"msg={message.id}; by={role.name}\")\n\n    def increment_attempt(self, message: Message) -> int:\n        self._attempts[message.id] = self._attempts.get(message.id, 0) + 1\n        return self._attempts[message.id]\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        results = []\n        for msg in self.history:\n            if msg.cause_by in role.watch_list:\n                processed = self._processed.get(msg.id, set())\n                if role.name not in processed:\n                    results.append(msg)\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str) -> Tuple[Optional[Message], Optional[Message]]:\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and msg.cause_by == code_cause:\n                code_msg = msg\n            if not tests_msg and msg.cause_by == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Team orchestrator with clear pipeline, explicit watch/trigger logic, and robust termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        self.pipeline: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"idea={idea}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"up_to_rounds={n_round}\")\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        last_verified_round = -1\n        last_history_len = len(self.env.history)\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"round={round_num}\")\n            for role_type in self.pipeline:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # Determine inbox for this role\n                    if isinstance(role, SimpleCoder) and round_num == 1:\n                        inbox = [initial_msg]\n                    else:\n                        inbox = self.env.get_unprocessed_messages_for_role(role)\n\n                    for msg in inbox:\n                        attempts = self.env.increment_attempt(msg)\n                        if attempts > MAX_MESSAGE_ATTEMPTS:\n                            if self.tracer:\n                                self.tracer.log(\"ENV_SKIP\", \"Environment\", f\"skip msg={msg.id} for role={role.name} after_attempts={attempts}\")\n                            self.env.mark_processed(msg, role)\n                            continue\n\n                        response = await role.act(msg)\n                        if response:\n                            self.env.publish_message(response)\n                            # If verifier produced PASS, do confirmation\n                            if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                # Run a confirmation verification locally to avoid transient success\n                                try:\n                                    verifier_action = role.actions[0]\n                                    code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                                    confirm = await verifier_action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                                    if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                        verified = True\n                                        last_verified_round = round_num\n                                        self.tracer.log(\"VERIFIED_CONFIRMED\", \"Team\", f\"round={round_num}\")\n                                    else:\n                                        self.tracer.log(\"VERIFIED_REJECTED\", \"Team\", f\"round={round_num}; confirm={confirm[:200]}\")\n                                except Exception as e:\n                                    if self.tracer:\n                                        self.tracer.log(\"VERIFIED_ERROR\", \"Team\", f\"confirm exception: {str(e)[:200]}\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"round={round_num}\")\n            # Check for stable verification: require verification and no new messages after one extra round\n            if verified:\n                # If history length hasn't changed since verification, we can stop\n                if len(self.env.history) == last_history_len:\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"stable verified at round={round_num}\")\n                    break\n                else:\n                    # record current history length and allow one more round\n                    last_history_len = len(self.env.history)\n            else:\n                last_history_len = len(self.env.history)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nimport re\nfrom typing import Tuple, Set\n\n# Tunable parameters\nRETRY_ATTEMPTS = 3\nRETRY_BACKOFF_BASE = 0.4  # seconds\nMAX_MESSAGE_ATTEMPTS = 5\nSTABLE_VERIFICATION_REQUIRED_ROUNDS = 2  # require verification stable across rounds\n\nclass Action(ABC):\n    \"\"\"Base action with clear LLM retry semantics and contextual logging.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Raises on failure.\"\"\"\n        if not self.llm:\n            # Explicit sentinel to let callers fallback gracefully.\n            return \"LLM_NOT_AVAILABLE\"\n        last_err = None\n        for attempt in range(1, RETRY_ATTEMPTS + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{RETRY_ATTEMPTS}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or resp.startswith(\"Error communicating\")):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff with jitter\n                await asyncio.sleep(RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) + random.random() * 0.15)\n        raise RuntimeError(f\"LLM call failed after {RETRY_ATTEMPTS} attempts: {last_err}\")\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\ndef _strip_code_fences(text: str) -> str:\n    \"\"\"Remove surrounding markdown code fences and common wrappers.\"\"\"\n    if not text:\n        return text or \"\"\n    # remove triple backticks blocks\n    text = re.sub(r\"```(?:python)?\\n\", \"\", text)\n    text = re.sub(r\"\\n```$\", \"\", text)\n    # If there are leading comments like \"Here's the code:\" remove up to first line that looks like code (heuristic)\n    lines = text.splitlines()\n    # find first line containing 'def ' or 'class ' or common import\n    for i, ln in enumerate(lines):\n        if re.search(r'^\\s*(def |class |import |from )', ln):\n            return \"\\n\".join(lines[i:])\n    return text\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generates a parseable Python module from a short instruction.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            warning = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea - returning warning\")\n            return warning\n\n        prompt = (\n            \"You are a professional Python developer. Produce a single, self-contained Python module that implements the described functionality. \"\n            \"Ensure the output is valid Python code (parseable by ast.parse), contains no explanations, and contains appropriate docstrings and error handling.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Clean, functional Python code\\n\"\n            \"2. Proper error handling\\n\"\n            \"3. Docstrings and comments\\n\"\n            \"4. Production-ready\\n\\n\"\n            \"Return only the Python code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = \"\"\n        try:\n            resp = await self._llm_call_with_retries(messages)\n            if resp == \"LLM_NOT_AVAILABLE\":\n                raise RuntimeError(\"LLM not available\")\n            code = _strip_code_fences(resp)\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n            # Provide a minimal, safe fallback that will allow downstream tasks to proceed.\n            code = (\n                f\"# Fallback implementation for: {idea}\\n\\n\"\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n\n        # Validate parseability and attempt small automated fixes if needed\n        parsed_ok = False\n        try:\n            import ast\n            ast.parse(code)\n            parsed_ok = True\n        except Exception as parse_err:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Initial AST parse failed: {str(parse_err)[:200]}\")\n            # Try heuristics: wrap code in function if that helps\n            try:\n                wrapped = \"def _evolv_wrapper():\\n\"\n                for line in code.splitlines():\n                    wrapped += \"    \" + line + \"\\n\"\n                wrapped += \"\\n\"\n                import ast as _ast\n                _ast.parse(wrapped)\n                code = wrapped\n                parsed_ok = True\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_VALIDATION_FIX\", self.name, \"Applied wrapper fix to make code parseable\")\n            except Exception:\n                parsed_ok = False\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(code or '')} parsed_ok={parsed_ok}\")\n        return code or \"\"\n\nclass SimpleWriteTest(Action):\n    \"\"\"Creates pytest-style tests targeted at functions found in the module.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        func_names = []\n        try:\n            import ast\n            parsed = ast.parse(code or \"\")\n            func_names = [n.name for n in ast.walk(parsed) if isinstance(n, ast.FunctionDef)]\n        except Exception:\n            func_names = []\n\n        prompt = (\n            \"You are a QA engineer that writes pytest tests. Produce pytest tests for the provided module. \"\n            \"Write at least one positive and one negative test per function when function names are known. \"\n            \"Include docstrings for each test and ensure tests use assert statements. Provide only Python test code.\"\n        )\n        if func_names:\n            prompt += f\"\\nTarget functions: {', '.join(func_names[:8])}\"\n        prompt += \"\\n\\nCode:\\n\" + (code[:2000] if code else \"(empty)\")\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer who writes pytest tests.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        tests = \"\"\n        try:\n            resp = await self._llm_call_with_retries(messages)\n            if resp == \"LLM_NOT_AVAILABLE\":\n                raise RuntimeError(\"LLM not available\")\n            tests = _strip_code_fences(resp)\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder_exists():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n\n        # Basic validation: parseable and contains at least one test_ function and an assert\n        tests_ok = False\n        try:\n            import ast\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n            tests_ok = bool(has_test_fn and has_assert)\n            if not tests_ok and self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_WARN\", self.name, f\"Tests parseable={bool(parsed_tests)} has_test_fn={has_test_fn} has_assert={has_assert}\")\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests AST parse failed: {str(e)[:200]}\")\n            tests_ok = False\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(tests or '')} parsed_ok={tests_ok}\")\n        return tests or \"\"\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provides an actionable, prioritized review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"is_human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Please validate edge cases, input validation, and error handling manually.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_HUMAN\", self.name, \"Provided simulated human review\")\n            return review\n\n        prompt = (\n            \"You are a senior software engineer. Provide a concise, prioritized review focused on code quality, test completeness, and likely bugs. \"\n            \"Return a short list of concrete suggestions and priority (high/medium/low).\"\n            f\"\\n\\nCode:\\n{code[:1500]}\\n\\nTests:\\n{tests[:1500]}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior code reviewer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        review = \"\"\n        try:\n            resp = await self._llm_call_with_retries(messages)\n            if resp == \"LLM_NOT_AVAILABLE\":\n                raise RuntimeError(\"LLM not available\")\n            review = resp\n        except Exception as e:\n            review = \"Automated review fallback: Unable to contact reviewer LLM. Manual review recommended.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"LLM failure: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Performs strong verification and returns PASS/FAIL with diagnostics.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Starting verification\")\n        diagnostics: List[str] = []\n        code_ok = False\n        tests_ok = False\n        coverage_ok = False\n\n        # Parse code\n        try:\n            import ast\n            code_ast = ast.parse(code or \"\")\n            defs = [n for n in code_ast.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            if defs:\n                code_ok = True\n                diagnostics.append(f\"code_defs:{len(defs)}\")\n            else:\n                diagnostics.append(\"code_defs:none\")\n        except Exception as e:\n            diagnostics.append(f\"code_parse_error:{str(e)[:180]}\")\n            code_ast = None\n\n        # Parse tests\n        try:\n            import ast\n            tests_ast = ast.parse(tests or \"\")\n            has_test_fns = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in tests_ast.body)\n            has_asserts = any(isinstance(n, ast.Assert) for n in ast.walk(tests_ast))\n            tests_ok = bool(has_test_fns and has_asserts)\n            diagnostics.append(f\"tests_fns:{'yes' if has_test_fns else 'no'} asserts:{'yes' if has_asserts else 'no'}\")\n        except Exception as e:\n            diagnostics.append(f\"tests_parse_error:{str(e)[:180]}\")\n            tests_ast = None\n\n        # Simple coverage heuristic: do function names from code appear referenced in tests AST names\n        try:\n            if code_ok and tests_ok and code_ast is not None and tests_ast is not None:\n                import ast\n                code_names = {n.name for n in ast.walk(code_ast) if isinstance(n, ast.FunctionDef)}\n                test_names = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n                referenced = sorted(list(code_names & test_names))\n                if referenced:\n                    coverage_ok = True\n                    diagnostics.append(f\"coverage_refs:{len(referenced)}->{referenced[:6]}\")\n                else:\n                    diagnostics.append(\"coverage_refs:none\")\n        except Exception as e:\n            diagnostics.append(f\"coverage_check_error:{str(e)[:120]}\")\n\n        verified = code_ok and tests_ok and coverage_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(diagnostics)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class with clear responsibilities, watchlist and inbox semantics.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # causes this role listens for\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, action_types: List[Type[Action]]):\n        self.watch_list = [t.name for t in action_types]\n\n    def can_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide if the role should respond to a message.\"\"\"\n        # If watch_list empty, role is proactive and will be triggered explicitly (e.g., coder on initial input)\n        if not self.watch_list:\n            return False\n        return message.cause_by in self.watch_list\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action of the role.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"action={action.name}; msg_id={(getattr(message, 'id', None))}\")\n        try:\n            # Map explicit responsibilities by action class\n            if isinstance(action, SimpleWriteCode):\n                # coder uses instruct_content if provided\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")\n                result = await action.run(idea or \"\")\n            elif isinstance(action, SimpleWriteTest):\n                # tester expects code content (from latest code message if message is absent)\n                code_text = message.content if message else \"\"\n                result = await action.run(code_text)\n            elif isinstance(action, SimpleWriteReview):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            elif isinstance(action, SimpleVerify):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            else:\n                result = \"NO_ACTION\"\n        except Exception as e:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"exception: {str(e)[:200]}\")\n            result = f\"ROLE_EXCEPTION: {str(e)}\"\n\n        # Build outgoing message. Set send_to to recipients that watch this action\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name,\n            send_to=set()\n        )\n\n        # Determine recipients: roles that have this action name in their watch_list\n        if self.env:\n            recipients = {r.name for r in self.env.roles if (action and action.name in r.watch_list)}\n            response.send_to = recipients\n            response.sent_to = \",\".join(sorted(recipients)) if recipients else None\n\n        # Mark processed for the input message so we don't reprocess\n        if message and self.env:\n            self.env.mark_processed(message, self)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"produced_cause={getattr(response, 'cause_by','')} recipients={response.send_to}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # proactive; will be invoked on initial user input explicitly\n        self._watch([])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks messages, processing state, and routes messages to intended recipients deterministically.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # message.id -> set(role.name) that processed it\n        self._processed: Dict[str, Set[str]] = {}\n        # message.id -> attempts count\n        self._attempts: Dict[str, int] = {}\n        # per-role cursor index (last seen index +1)\n        self.role_cursors: Dict[str, int] = {}\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        self.role_cursors.setdefault(role.name, 0)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}:{role.profile}\")\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message and route to recipients. If send_to empty, compute subscribers based on cause_by.\"\"\"\n        # compute recipients if not provided\n        if not getattr(message, \"send_to\", None):\n            recipients = {r.name for r in self.roles if message.cause_by in r.watch_list}\n            message.send_to = recipients\n            message.sent_to = \",\".join(sorted(recipients)) if recipients else None\n\n        # append to history and initialize bookkeeping\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        self._attempts.setdefault(message.id, 0)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"msg_id={message.id} from={message.sent_from} cause_by={message.cause_by} to={message.send_to} snippet={(message.content or '')[:140]}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        self._processed.setdefault(message.id, set()).add(role.name)\n        # advance cursor for this role to avoid reading older messages repeatedly\n        idx = self.history.index(message) if message in self.history else None\n        if idx is not None:\n            self.role_cursors[role.name] = max(self.role_cursors.get(role.name, 0), idx + 1)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"msg={message.id}; by={role.name}; cursor={self.role_cursors.get(role.name)}\")\n\n    def increment_attempt(self, message: Message) -> int:\n        self._attempts[message.id] = self._attempts.get(message.id, 0) + 1\n        return self._attempts[message.id]\n\n    def get_pending_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages that are intended for this role and not yet processed by it, starting at the role's cursor.\"\"\"\n        results: List[Message] = []\n        cursor = self.role_cursors.get(role.name, 0)\n        for idx in range(cursor, len(self.history)):\n            msg = self.history[idx]\n            # only consider messages that list this role as recipient or cause matches watch list\n            intended = (not msg.send_to) or (role.name in (msg.send_to or set()))\n            if not intended:\n                continue\n            processed_by = self._processed.get(msg.id, set())\n            if role.name not in processed_by:\n                # Only allow roles to respond to messages that match their watch list (unless proactive)\n                if role.watch_list:\n                    if msg.cause_by in role.watch_list:\n                        results.append(msg)\n                else:\n                    # proactive roles must be triggered explicitly by orchestrator (Team). So skip here.\n                    continue\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str) -> Tuple[Optional[Message], Optional[Message]]:\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and msg.cause_by == code_cause:\n                code_msg = msg\n            if not tests_msg and msg.cause_by == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Orchestrates the collaboration pipeline with explicit watch/trigger logic and robust termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # stable pipeline order\n        self.pipeline: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"idea={idea}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"up_to_rounds={n_round}\")\n        # initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        # publish initial message (recipients computed by environment)\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        stable_verification_rounds = 0\n        last_verification_index = -1\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"round={round_num}\")\n            actions_this_round = 0\n\n            # iterate roles in stable pipeline order\n            for role_cls in self.pipeline:\n                # find concrete roles of this class\n                for role in [r for r in self.env.roles if isinstance(r, role_cls)]:\n                    # coder is proactive and should be invoked explicitly on the first round\n                    if isinstance(role, SimpleCoder) and round_num == 1:\n                        if self.tracer:\n                            self.tracer.log(\"ORCH\", \"Team\", f\"Invoking {role.name} (coder) explicitly with initial input\")\n                        response = await role.act(initial_msg)\n                        if response:\n                            self.env.publish_message(response)\n                            actions_this_round += 1\n                            # mark the initial message processed by coder\n                            self.env.mark_processed(initial_msg, role)\n                        continue\n\n                    # fetch pending messages for this role\n                    inbox = self.env.get_pending_messages_for_role(role)\n                    if not inbox:\n                        if self.tracer:\n                            self.tracer.log(\"ORCH\", \"Team\", f\"No pending messages for {role.name}\")\n                        continue\n\n                    for msg in inbox:\n                        attempts = self.env.increment_attempt(msg)\n                        if attempts > MAX_MESSAGE_ATTEMPTS:\n                            # skip message if retried too many times\n                            self.env.mark_processed(msg, role)\n                            if self.tracer:\n                                self.tracer.log(\"ENV_SKIP\", \"Environment\", f\"Skipping msg={msg.id} for {role.name} after {attempts} attempts\")\n                            continue\n\n                        if self.tracer:\n                            self.tracer.log(\"ORCH\", \"Team\", f\"{role.name} processing msg_id={msg.id} cause_by={msg.cause_by}\")\n                        response = await role.act(msg)\n                        # mark the incoming message as processed by this role\n                        self.env.mark_processed(msg, role)\n                        if response:\n                            self.env.publish_message(response)\n                            actions_this_round += 1\n                            # If verifier produced a PASS, do immediate confirmation to avoid transient success\n                            if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                                # confirm using verifier action directly\n                                try:\n                                    verifier_action = role.actions[0]\n                                    code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                                    confirm = await verifier_action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                                    if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                        verified = True\n                                        last_verification_index = len(self.env.history) - 1\n                                        if self.tracer:\n                                            self.tracer.log(\"VERIFIED_CONFIRMED\", \"Team\", f\"round={round_num} idx={last_verification_index}\")\n                                    else:\n                                        # If confirmation fails, continue iterations (do not mark verified)\n                                        if self.tracer:\n                                            self.tracer.log(\"VERIFIED_REJECTED\", \"Team\", f\"round={round_num} confirm={confirm[:200]}\")\n                                except Exception as e:\n                                    if self.tracer:\n                                        self.tracer.log(\"VERIFIED_ERROR\", \"Team\", f\"confirmation exception: {str(e)[:200]}\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"round={round_num} actions={actions_this_round}\")\n\n            # Post-round termination logic: require verification to be stable across multiple rounds and no new code/test messages\n            if verified:\n                # Determine index of newest code/test message\n                newest_code_or_test_idx = -1\n                for i, msg in enumerate(self.env.history):\n                    if msg.cause_by in (SimpleWriteCode.name, SimpleWriteTest.name):\n                        newest_code_or_test_idx = max(newest_code_or_test_idx, i)\n                if newest_code_or_test_idx <= last_verification_index:\n                    stable_verification_rounds += 1\n                else:\n                    # New code/tests after verification -> reset stability and require re-verification\n                    stable_verification_rounds = 0\n                    verified = False\n                    if self.tracer:\n                        self.tracer.log(\"VER_STATUS\", \"Team\", f\"verification invalidated by new artifacts after idx={last_verification_index}\")\n                if self.tracer:\n                    self.tracer.log(\"VER_STATUS\", \"Team\", f\"verified={verified} stable_rounds={stable_verification_rounds}\")\n            else:\n                stable_verification_rounds = 0\n\n            # If verification has been stable for required rounds, stop early\n            if verified and stable_verification_rounds >= STABLE_VERIFICATION_REQUIRED_ROUNDS:\n                if self.tracer:\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {stable_verification_rounds} rounds; stopping early at round {round_num}\")\n                break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}