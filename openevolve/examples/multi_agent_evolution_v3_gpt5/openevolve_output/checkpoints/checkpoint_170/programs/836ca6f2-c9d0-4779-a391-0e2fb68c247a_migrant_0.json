{"id": "836ca6f2-c9d0-4779-a391-0e2fb68c247a_migrant_0", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic response\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Tuple, Iterable\n\n# Evolution goals implemented:\n# - Clear role boundaries and single responsibility per role\n# - Robust inter-agent messaging with normalized send_to and per-role delivery tracking\n# - Stable termination: require consecutive identical verification digests\n# - Strong verification with syntax + tests + cross-reference heuristics\n# - LLM call retries with backoff, jitter and deterministic fallback\n# - Error containment and retry for role execution with timeouts\n\nLLM_MAX_RETRIES = 3\nLLM_BASE_BACKOFF = 0.4\nVERIFICATION_STABLE_REQUIRED = 2\nROLE_EXECUTE_RETRIES = 2\nROLE_EXECUTE_TIMEOUT = 30.0\n\ndef _normalize_targets(raw) -> Set[str]:\n    if raw is None:\n        return set()\n    if isinstance(raw, (set, list, tuple)):\n        return set(raw)\n    if isinstance(raw, str):\n        return {raw}\n    try:\n        return set(raw)\n    except Exception:\n        return set()\n\nclass Action(ABC):\n    \"\"\"Action base with LLM safety helpers and responsibilities documented.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    backoff_base: float = LLM_BASE_BACKOFF\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def ask_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    fallback = \"LLM_UNAVAILABLE: deterministic fallback\"\n                    if tracer:\n                        tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or resp.strip() == \"\":\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty LLM response\")\n                low = resp.strip().lower()\n                if low.startswith(\"error\") or \"error communicating\" in low:\n                    last_err = resp\n                    raise RuntimeError(resp)\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Received {len(resp)} chars\")\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                if attempt < self.max_retries:\n                    backoff = self.backoff_base * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n        fail_msg = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, fail_msg)\n        return fail_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Idea preview: {(idea or '')[:120]}\")\n        if not idea:\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"No idea provided; returning deterministic placeholder\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback implementation.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        prompt = (\n            \"You are an expert Python developer. Return only Python source code implementing the described task.\\n\"\n            \"Include docstrings and basic input validation. Keep functions small and testable.\\n\\n\"\n            f\"Task:\\n{idea}\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self.ask_with_retries(messages)\n        # Validate parseable code; fallback if invalid\n        try:\n            if isinstance(code, str) and code.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                raise RuntimeError(code)\n            ast.parse(code or \"\")\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_INVALID\", self.name, f\"Generated code failed to parse: {e}\")\n            return (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback: generated code invalid.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code preview len={(len(code or ''))}\")\n        if not code:\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"No code provided; returning placeholder test\")\n            return \"def test_placeholder():\\n    assert True\\n\"\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the provided module. Return only test code.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self.ask_with_retries(messages)\n        # Validate tests contain assert or test_ functions\n        try:\n            if isinstance(tests, str) and tests.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                raise RuntimeError(tests)\n            parsed = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed))\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"No tests/asserts found\")\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ACTION_INVALID\", self.name, f\"Generated tests insufficient: {e}\")\n            # fallback simple test\n            return \"def test_placeholder():\\n    assert True\\n\"\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated tests len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error:{str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error:{str(e)[:160]}\")\n        if self.is_human:\n            verdict = \"VERDICT: REQUEST_CHANGES\" if issues else \"VERDICT: PASS\"\n            return (\"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\") + f\"\\n{verdict}\")\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review and end with a single-line VERDICT: PASS or VERDICT: REQUEST_CHANGES.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        review = await self.ask_with_retries(messages)\n        if not isinstance(review, str) or \"VERDICT:\" not in review:\n            # infer decision heuristically\n            decision = \"REQUEST_CHANGES\"\n            if (\"def \" in (code or \"\") or \"class \" in (code or \"\")) and (\"assert\" in (tests or \"\")):\n                decision = \"PASS\"\n            review = (review or \"Automated review.\") + f\"\\n\\nVERDICT: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Inferred decision {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        details = []\n        verified = False\n        code_ok = False\n        tests_ok = False\n        referenced = False\n        code_names = set()\n\n        # code syntax and definitions\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            code_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            details.append(f\"code_entities:{len(code_names)}\")\n        except Exception as e:\n            details.append(f\"code_syntax_error:{str(e)[:160]}\")\n\n        # tests syntax and asserts\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"assert\" in (tests or \"\"))\n            tests_ok = bool(has_test_fn or has_assert)\n            details.append(\"tests_presence_and_syntax:ok\" if tests_ok else \"tests_presence_and_syntax:fail\")\n        except Exception as e:\n            details.append(f\"tests_syntax_error:{str(e)[:160]}\")\n\n        # cross-reference\n        try:\n            if code_names and tests:\n                for name in code_names:\n                    if name and name in (tests or \"\"):\n                        referenced = True\n                        break\n                details.append(\"tests_reference:ok\" if referenced else \"tests_reference:none\")\n            else:\n                details.append(\"tests_reference:skipped\")\n        except Exception as e:\n            details.append(f\"reference_error:{str(e)[:160]}\")\n\n        verified = bool(code_ok and tests_ok and referenced)\n        digest = hashlib.sha256(((code or \"\") + \"\\n--\\n\" + (tests or \"\")).encode(\"utf-8\")).hexdigest()[:12]\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role: one primary Action, explicit watches, idempotent handling, and clear routing.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n    _processed: Set[str] = set()\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = kwargs.get(\"env\", None)\n        self._processed = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch_actions(self, actions: Iterable[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", str(a)) for a in actions}\n\n    def should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed:\n            return False\n        targets = _normalize_targets(getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None))\n        if targets:\n            if self.name in targets or self.profile in targets or \"*\" in targets:\n                return True\n            return False\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n\n        if message and not self.should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message {getattr(message,'id',None)} not relevant\")\n            # mark as processed to avoid repeated checks\n            if getattr(message, \"id\", None):\n                self._processed.add(message.id)\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing {self.action.name} for message {msg_id}\")\n\n        # attempt execution with retries and timeout\n        last_err = None\n        for attempt in range(1, ROLE_EXECUTE_RETRIES + 1):\n            try:\n                if isinstance(self.action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or (message.content if message else \"\")\n                    out = await asyncio.wait_for(self.action.run(instruct or \"\"), timeout=ROLE_EXECUTE_TIMEOUT)\n                    send_to = {\"SimpleTester\"}\n                elif isinstance(self.action, SimpleWriteTest):\n                    code_text = getattr(message, \"content\", \"\") if message and message.cause_by == SimpleWriteCode.name else \"\"\n                    if not code_text and self.env:\n                        latest = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                        code_text = latest.content if latest else \"\"\n                    out = await asyncio.wait_for(self.action.run(code_text), timeout=ROLE_EXECUTE_TIMEOUT)\n                    send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(self.action, SimpleWriteReview):\n                    code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                    tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                    out = await asyncio.wait_for(self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\"), timeout=ROLE_EXECUTE_TIMEOUT)\n                    low = (out or \"\").lower()\n                    if \"request\" in low or \"reject\" in low or \"fail\" in low:\n                        send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                    else:\n                        send_to = {\"SimpleVerifier\"}\n                elif isinstance(self.action, SimpleVerify):\n                    code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                    tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                    out = await asyncio.wait_for(self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\"), timeout=ROLE_EXECUTE_TIMEOUT)\n                    send_to = set()  # orchestrator will inspect verification messages\n                else:\n                    out = await asyncio.wait_for(self.action.run(getattr(message, \"content\", \"\") if message else \"\"), timeout=ROLE_EXECUTE_TIMEOUT)\n                    send_to = set()\n                # success, break\n                break\n            except asyncio.TimeoutError:\n                last_err = \"timeout\"\n                if tracer:\n                    tracer.log(\"ROLE_TIMEOUT\", self.name, f\"Attempt {attempt} timed out for msg {msg_id}\")\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n            # small backoff before retry\n            await asyncio.sleep(0.02 * attempt)\n        else:\n            # exhausted attempts\n            out = f\"ROLE_FAILED: {self.name} after retries: {last_err}\"\n            send_to = {\"SimpleCoder\"}  # route failure to coder for recovery\n            if tracer:\n                tracer.log(\"ROLE_FAIL\", self.name, out)\n\n        # mark processed for idempotency\n        if msg_id:\n            self._processed.add(msg_id)\n\n        response = Message(\n            content=out or \"\",\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"NoAction\",\n            sent_from=self.name,\n            send_to=set(send_to)\n        )\n        # avoid self-processing\n        try:\n            self._processed.add(response.id)\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg {getattr(response,'id',None)} cause_by={response.cause_by} send_to={sorted(list(response.send_to))}\")\n        return response\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch_actions([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch_actions([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Message bus: history, per-role delivered tracking, and artifact index by cause_by.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self._delivered: Dict[str, Set[str]] = {}  # role.name -> set(message.id)\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._delivered.setdefault(role.name, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile}) watching {sorted(list(role.watch_list))}\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to normalized\n        try:\n            message.send_to = _normalize_targets(getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None))\n        except Exception:\n            message.send_to = set()\n        # ensure id\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        if getattr(message, \"cause_by\", None):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Msg {getattr(message,'id',None)[:8]} from {message.sent_from} cause_by={message.cause_by} to={sorted(list(message.send_to))} preview={preview}\")\n\n    def get_pending_for(self, role: Role) -> List[Message]:\n        out: List[Message] = []\n        seen = self._delivered.setdefault(role.name, set())\n        for msg in self.history:\n            mid = getattr(msg, \"id\", None)\n            if not mid or mid in seen:\n                continue\n            # never deliver a role its own messages\n            if getattr(msg, \"sent_from\", None) == role.name:\n                seen.add(mid)\n                continue\n            targeted = bool(msg.send_to and (role.name in msg.send_to or role.profile in msg.send_to or \"*\" in msg.send_to))\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                seen.add(mid)\n        return out\n\n    def get_latest_by_cause(self, cause_names: Iterable[str]) -> Optional[Message]:\n        for cname in cause_names:\n            msgs = self._by_cause.get(cname, [])\n            if msgs:\n                return msgs[-1]\n        return None\n\nclass Team:\n    \"\"\"Orchestrator implementing deterministic sequencing, stable verification and nudges.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea: str = \"\"\n        self._required_stable = VERIFICATION_STABLE_REQUIRED\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _invoke_role(self, role: Role, msg: Message) -> Optional[Message]:\n        attempts = 0\n        while attempts < ROLE_EXECUTE_RETRIES:\n            attempts += 1\n            try:\n                coro = role.act(msg)\n                resp = await asyncio.wait_for(coro, timeout=ROLE_EXECUTE_TIMEOUT + 2.0)\n                return resp\n            except asyncio.TimeoutError:\n                self.tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempts} for msg {getattr(msg,'id',None)[:8]}\")\n            except Exception as e:\n                self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception on attempt {attempts}: {type(e).__name__}:{str(e)[:200]}\")\n            await asyncio.sleep(0.02 * attempts)\n        # give up -> produce error artifact\n        err = Message(content=f\"ERROR: role {role.name} failed to process message {getattr(msg,'id',None)[:8]}\", role=role.profile, cause_by=\"RoleProcessingFailure\", sent_from=\"Team\", send_to=set())\n        return err\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; stable_required={self._required_stable}\")\n        # kickoff targeted to coders\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)} or {\"SimpleCoder\"}\n        initial = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for rnd in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            produced = 0\n            for RoleClass in order:\n                roles = [r for r in self.env.roles if isinstance(r, RoleClass)]\n                for role in roles:\n                    pending = self.env.get_pending_for(role)\n                    # ensure coder sees initial msg first round\n                    if isinstance(role, SimpleCoder) and rnd == 1 and not pending:\n                        pending = [initial]\n                        # mark delivered for coder to avoid duplication\n                        self.env._delivered.setdefault(role.name, set()).add(initial.id)\n                    for msg in pending:\n                        resp = await self._invoke_role(role, msg)\n                        # always mark delivered for the input (handled inside get_pending_for via seen)\n                        if resp:\n                            self.env.publish_message(resp)\n                            produced += 1\n                            # update verification streak if verifier produced PASS\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                # extract digest\n                                digest = None\n                                for part in resp.content.split(\"|\"):\n                                    p = part.strip()\n                                    if p.startswith(\"digest=\"):\n                                        digest = p.split(\"=\", 1)[1]\n                                        break\n                                if digest and digest == self._last_digest:\n                                    self._streak += 1\n                                else:\n                                    self._last_digest = digest\n                                    self._streak = 1\n                                self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"streak={self._streak} digest={digest}\")\n                            elif isinstance(role, SimpleVerifier):\n                                # any non-pass resets streak\n                                if self._streak > 0:\n                                    self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                                self._streak = 0\n                                self._last_digest = None\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed produced={produced} history={len(self.env.history)} streak={self._streak}\")\n            # termination: require consecutive stable passes\n            if self._streak >= self._required_stable:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable (streak={self._streak}) - stopping\")\n                verified = True\n                break\n\n            # nudge coder if no production\n            if produced == 0:\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: please refine implementation for: {self.idea}\",\n                            instruct_content=self.idea,\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.profile}\n                        )\n                        self.env.publish_message(nudge)\n                # small pause for async processing\n                await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {rnd} rounds with {len(self.env.history)} messages. verified={verified} streak={self._streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "836ca6f2-c9d0-4779-a391-0e2fb68c247a", "generation": 2, "timestamp": 1754659078.4165573, "iteration_found": 0, "metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.1764705882352941, "avg_failures_per_task": 4.666666666666667, "total_failures": 28.0, "successful_runs": 6.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.24000000000000005, "avg_failures_per_task": 3.1666666666666665, "total_failures": 19.0, "successful_runs": 6.0}, "island": 0, "migrant": true}, "artifacts_json": null, "artifact_dir": null}