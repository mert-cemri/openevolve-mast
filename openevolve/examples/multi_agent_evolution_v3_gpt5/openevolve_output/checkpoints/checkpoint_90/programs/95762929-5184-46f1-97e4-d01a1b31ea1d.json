{"id": "95762929-5184-46f1-97e4-d01a1b31ea1d", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "69785ac0-24f1-4922-aa1b-6a2a94165d53", "generation": 3, "timestamp": 1754656601.9121237, "iteration_found": 60, "metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.24000000000000005, "avg_failures_per_task": 3.1666666666666665, "total_failures": 19.0, "successful_runs": 6.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 3}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.5000\n- overall_score: 0.2500\n- combined_score: 0.1000\n- avg_failures_per_task: 12.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: avg_failures_per_task. Consider continuing with similar changes.\n- Metrics showing regression: runs_successfully, overall_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 4\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.1622, avg_failures_per_task: 5.1667, total_failures: 31.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2222, avg_failures_per_task: 3.5000, total_failures: 21.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2609, avg_failures_per_task: 2.8333, total_failures: 17.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 3.4477)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.3529), Performs well on avg_failures_per_task (1.8333), Performs well on total_failures (11.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 2 (Score: 4.5990)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with error handling and retry support.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        self.max_retries = kwargs.get('max_retries', 2)\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Ask the LLM with retry and exponential backoff. Returns result or error string.\"\"\"\n        attempt = 0\n        last_err = None\n        while attempt <= self.max_retries:\n            attempt += 1\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_ASK\", self.name, f\"Attempt {attempt}/{self.max_retries+1}\")\n            try:\n                if not self.llm:\n                    return \"LLM_UNAVAILABLE: Using fallback response.\"\n                res = await self.llm.ask(messages)\n                # treat responses starting with \"Error:\" or \"Error communicating\" as failures\n                if isinstance(res, str) and (res.startswith(\"Error:\") or res.startswith(\"Error communicating\")):\n                    last_err = res\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error text: {res[:200]}\")\n                    # fall through to retry\n                else:\n                    return res\n            except Exception as e:\n                last_err = f\"Exception: {e}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, str(e))\n            # simple backoff\n            if attempt <= self.max_retries:\n                # we don't want to import time in evolve block; just log retry\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Retrying LLM ask (attempt {attempt + 1})\")\n        # all attempts failed\n        return last_err or \"LLM_UNKNOWN_ERROR\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea, with validation and retries\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea (len={len(idea or '')})\")\n        \n        if not idea or not idea.strip():\n            warning = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea; returning warning code\")\n            return warning\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.safe_ask(messages)\n        # Basic validation: ensure non-empty and syntactically parseable (best-effort)\n        import ast\n        try:\n            if not code or not isinstance(code, str) or code.strip() == \"\":\n                raise ValueError(\"Empty code returned\")\n            ast.parse(code)\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed successfully\")\n        except Exception as e:\n            # Return explicit error result so downstream roles can detect and trigger retries\n            err = f\"# CODE_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(code or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code, validate presence of test functions\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        if not code or not code.strip():\n            msg = \"# WARNING: No code to test. Generated placeholder tests.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"No code provided for tests\")\n            return msg\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.safe_ask(messages)\n        \n        # Basic validation: ensure at least one function called test_\n        import ast\n        try:\n            if not tests or not isinstance(tests, str) or tests.strip() == \"\":\n                raise ValueError(\"Empty tests returned\")\n            parsed = ast.parse(tests)\n            has_test = any(\n                isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body\n            )\n            if not has_test:\n                raise ValueError(\"No pytest-style test functions found (test_ prefix)\")\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Tests parsed and contain test_ functions\")\n        except Exception as e:\n            err = f\"# TEST_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(tests or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests and provide actionable items\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        \n        if self.is_human:\n            review = \"Human review: Please verify edge cases and error handling; consider input validation.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_HUMAN_REVIEW\", self.name, \"Simulated human review provided\")\n            return review\n        \n        prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode (first 1500 chars):\n{code[:1500]}\n\nTests (first 1500 chars):\n{tests[:1500]}\n\nFocus on:\n1. Code quality and best practices\n2. Test coverage and missing edge cases\n3. Potential bugs or issues\n4. Concrete suggestions for improvement\n\nProvide a concise, actionable review.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        review = await self.safe_ask(messages)\n        if not review or not isinstance(review, str):\n            review = \"REVIEW_ERROR: No review generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, \"No review returned from LLM\")\n        else:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_END\", self.name, f\"Review generated len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        # Syntax checks\n        try:\n            if not code or not code.strip():\n                raise ValueError(\"Empty code\")\n            ast.parse(code)\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({str(e)[:120]})\")\n        try:\n            if not tests or not tests.strip():\n                raise ValueError(\"Empty tests\")\n            parsed_tests = ast.parse(tests)\n            # heuristic: presence of at least one test_ function\n            has_tests = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            if has_tests:\n                tests_ok = True\n                details.append(\"tests_syntax_and_presence: ok\")\n            else:\n                details.append(\"tests_syntax_and_presence: fail (no test_ functions found)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({str(e)[:120]})\")\n        # Coverage heuristics: ensure functions in code are referenced by tests (simple name match)\n        coverage_ok = False\n        if code_ok and tests_ok:\n            try:\n                parsed_code = ast.parse(code)\n                func_names = {n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)}\n                # look for function names in test source\n                tests_text = tests\n                matched = [fn for fn in func_names if fn and fn in tests_text]\n                if func_names and matched:\n                    coverage_ok = True\n                    details.append(f\"coverage_hint: ok (matched functions: {matched[:5]})\")\n                else:\n                    details.append(\"coverage_hint: fail (no clear function usage in tests)\")\n            except Exception as e:\n                details.append(f\"coverage_check_error: {str(e)[:120]}\")\n        verified = code_ok and tests_ok and coverage_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    triggers_on: List[str] = []  # cause_by values this role listens for\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.triggers_on = kwargs.get('triggers_on', [])\n        # reference to env may be injected by Team.hire\n        self.env = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for (by action class)\"\"\"\n        self.watch_list = actions\n        # also set triggers_on strings for quick matching\n        self.triggers_on = [a.name for a in actions]\n    \n    def can_respond_to(self, msg: Message) -> bool:\n        \"\"\"Determine whether this role should respond to the message.\"\"\"\n        # If triggers_on empty, role acts proactively (e.g., coder on initial human input)\n        if not self.triggers_on:\n            return False\n        return msg.cause_by in self.triggers_on\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the role's primary action in a guarded manner.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        try:\n            # Map action type to expected inputs explicitly\n            if isinstance(action, SimpleWriteCode):\n                # coder expects instruction content if available, else full message content\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")\n                result = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # tester expects code in message.content\n                code = message.content if message else \"\"\n                result = await action.run(code)\n            elif isinstance(action, SimpleWriteReview):\n                # reviewer needs both code and tests. Get most recent code/tests from env\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # verifier obtains latest code/tests similar to reviewer\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                result = await action.run(message) if message else await action.run()\n        except Exception as e:\n            # Catch any unexpected errors, create a failure message describing it\n            err_text = f\"ROLE_EXCEPTION: {self.name} failed with exception {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err_text)\n            result = err_text\n        # Build a Message for the environment describing the result\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message caused by {response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # coder listens to direct user input\n        self._watch([])  # proactive; will be invoked explicitly on initial input\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with explicit delivery and cursors.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # per-role cursor to track which messages have been seen/consumed\n        self.role_cursors: Dict[str, int] = {}\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        # initialize cursor to 0 for this role (no messages consumed yet)\n        self.role_cursors[role.name] = 0\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message [{message.cause_by}] from {message.sent_from}: {message.content[:200]}\")\n    \n    def get_pending_messages_for_role(self, role: Role) -> List[tuple]:\n        \"\"\"Return list of (index, Message) that the role has not yet consumed and that match its triggers.\"\"\"\n        results = []\n        cursor = self.role_cursors.get(role.name, 0)\n        for idx in range(cursor, len(self.history)):\n            msg = self.history[idx]\n            # role can respond if msg.cause_by matches role's triggers\n            if role.triggers_on and msg.cause_by in role.triggers_on:\n                results.append((idx, msg))\n        return results\n    \n    def mark_consumed(self, role: Role, up_to_index: int):\n        \"\"\"Mark messages up to up_to_index (inclusive) as consumed for this role.\"\"\"\n        prev = self.role_cursors.get(role.name, 0)\n        new_cursor = max(prev, up_to_index + 1)\n        self.role_cursors[role.name] = new_cursor\n        if self.tracer:\n            self.tracer.log(\"ENV_CURSOR\", \"Environment\", f\"Role {role.name} cursor advanced to {new_cursor}\")\n\nclass Team:\n    \"\"\"Team of agents working together with improved orchestration, termination and verification logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # order of execution for each round\n        self.role_order = []\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n        # stable execution order: coder, tester, reviewer, verifier (by class)\n        # maintain roles in the order they were added if present\n        name_to_role = {r.__class__.__name__: r for r in self.env.roles}\n        ordered = []\n        for cname in (\"SimpleCoder\", \"SimpleTester\", \"SimpleReviewer\", \"SimpleVerifier\"):\n            r = name_to_role.get(cname)\n            if r:\n                ordered.append(r)\n        # fallback to any roles not listed\n        for r in self.env.roles:\n            if r not in ordered:\n                ordered.append(r)\n        self.role_order = ordered\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with robust termination rules.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        last_verification_index = -1\n        stable_verification_rounds = 0\n        max_stable_rounds_required = 1  # require verification to remain true across a round to stop\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            round_actions = []\n            # Special handling: on first round, explicitly invoke coder with the initial message\n            for role in self.role_order:\n                # For proactive coder (listens to user input), feed initial_msg on first round\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"Invoking coder {role.name} with initial idea\")\n                    response = await role.act(initial_msg)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # mark that coder has consumed initial input\n                        self.env.mark_consumed(role, len(self.env.history)-1)\n                    continue\n                # For other roles and later rounds, gather pending messages\n                pending = self.env.get_pending_messages_for_role(role)\n                if not pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"No pending messages for {role.name}\")\n                    continue\n                # Process each pending message in order\n                for idx, msg in pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"{role.name} responding to message idx={idx} cause_by={msg.cause_by}\")\n                    response = await role.act(msg)\n                    # Mark consumed up to this message for this role\n                    self.env.mark_consumed(role, idx)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # If verifier produced a pass, capture it\n                        if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            verified = True\n                            last_verification_index = len(self.env.history) - 1\n            # Post-round analysis: determine termination criteria\n            # If verification happened this round and is still the most recent verification result, count as stable\n            if verified:\n                # ensure that no new code/test messages after verification (to ensure stability)\n                newest_code_or_test_idx = -1\n                for i, msg in enumerate(self.env.history):\n                    if msg.cause_by in (SimpleWriteCode.name, SimpleWriteTest.name):\n                        newest_code_or_test_idx = max(newest_code_or_test_idx, i)\n                if newest_code_or_test_idx <= last_verification_index:\n                    stable_verification_rounds += 1\n                else:\n                    stable_verification_rounds = 0\n                    # If new code/tests appeared after verification, require re-verification\n                    verified = False\n                self.tracer.log(\"VER_STATUS\", \"Team\", f\"verified={verified} stable_rounds={stable_verification_rounds}\")\n            else:\n                stable_verification_rounds = 0\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed with {len(round_actions)} actions\")\n            # Terminate if verification stable for required number of rounds\n            if verified and stable_verification_rounds > max_stable_rounds_required:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification stable; stopping early\")\n                break\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2609), Performs well on avg_failures_per_task (2.8333), Performs well on total_failures (17.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 3 (Score: 5.3704)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with clear responsibilities and LLM retry wrapper\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with exponential backoff and simple error detection.\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}\")\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM not available: fallback response.\"\n                resp = await self.llm.ask(messages)\n                # Detect common error patterns returned by LLMInterface\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or \"Error communicating\" in resp):\n                    last_err = resp\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {resp[:200]}\")\n                    # retry\n                    continue\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, f\"Attempt {attempt} exception: {last_err}\")\n        # All retries exhausted\n        return f\"LLM_FAILURE: {last_err or 'unknown'}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea (len={len(idea)})\")\n        prompt = (\n            \"You are a professional Python programmer. Produce clean, well-commented, \"\n            \"production-ready Python code for the task described.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Correct syntax\\n\"\n            \"2. Defensive error handling\\n\"\n            \"3. Clear docstrings/comments\\n\"\n            \"4. No surrounding backticks or explanation, only the code\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self._llm_call_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code size={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code (len={len(code)})\")\n        snippet = (code or \"\")[:3000]\n        prompt = (\n            \"You are an experienced QA engineer. Write pytest-style tests for the provided Python code.\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Cover normal and edge cases\\n\"\n            \"2. Include negative tests when appropriate\\n\"\n            \"3. Use clear docstrings for each test\\n\"\n            \"4. Return only the test code\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self._llm_call_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests size={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests and return concise actionable feedback\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing artifacts (human={self.is_human})\")\n        if self.is_human:\n            review = \"Human review simulated: consider more input validation and docstrings.\"\n        else:\n            snippet_code = (code or \"\")[:2000]\n            snippet_tests = (tests or \"\")[:2000]\n            prompt = (\n                \"You are a senior engineer performing a concise code + test review.\\n\\n\"\n                f\"Code:\\n{snippet_code}\\n\\nTests:\\n{snippet_tests}\\n\\n\"\n                \"Focus on:\\n\"\n                \"1. Correctness and likely runtime issues\\n\"\n                \"2. Test coverage gaps\\n\"\n                \"3. Practical suggestions (1-3 items)\\n\"\n                \"Return a short review.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self._llm_call_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        issues: List[str] = []\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Starting verification\")\n\n        # Basic non-empty checks\n        if not (code and code.strip()):\n            issues.append(\"code_empty\")\n        if not (tests and tests.strip()):\n            issues.append(\"tests_empty\")\n\n        # Syntax checks\n        code_ok = False\n        tests_ok = False\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:200]}\")\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = True\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:200]}\")\n\n        # Cross-reference: ensure tests mention at least one function/class name from code\n        try:\n            code_ast = ast.parse(code or \"\")\n            def_names = {n.name for n in ast.walk(code_ast) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            tests_ast = ast.parse(tests or \"\")\n            tests_identifiers = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n            if def_names and def_names.isdisjoint(tests_identifiers):\n                issues.append(\"tests_may_not_reference_code_defs\")\n        except Exception:\n            # already captured syntax errors above, ignore here\n            pass\n\n        verified = (code_ok and tests_ok and not any(i.startswith(\"tests_may_not_reference\") for i in issues))\n        status = {\n            \"verified\": verified,\n            \"issues\": issues,\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok\n        }\n        result_lines = [f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'}\"]\n        if issues:\n            result_lines.append(\"ISSUES: \" + \"; \".join(issues))\n        result = \" | \".join(result_lines)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit watch/trigger logic and idempotency\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track processed message ids to avoid reprocessing\n        self._processed_message_ids: Set[str] = set()\n        # env reference will be attached by Team.hire\n        self.env = getattr(self, 'env', None)\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide if this role should respond to the given message\"\"\"\n        if message is None:\n            return False\n        # If message explicitly targeted this role by name/profile\n        if getattr(message, \"send_to\", None):\n            targets = set(message.send_to)\n            if self.name in targets or self.profile in targets:\n                return True\n        # If role watches the causing action type\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # Also ignore messages we've already processed\n        if getattr(message, \"id\", None) in self._processed_message_ids:\n            return False\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action for this role based on the message.\n        Returns a Message or None.\n        This base implementation supports single-action roles.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Preparing to execute {action.name}\")\n\n        # If message provided but role decides it should not respond, skip\n        if message and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message {getattr(message, 'id', '')}\")\n            return None\n\n        try:\n            # Dispatch to appropriate behavior by action name\n            if action.name == SimpleWriteCode.name:\n                idea = (message.instruct_content or message.content) if message else \"\"\n                out = await action.run(idea)\n                # Create message routing to Tester\n                send_to = {\"SimpleTester\"}\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # Prefer to act on the latest code artifact visible\n                code_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteCode.name])\n                code_text = code_msg.content if code_msg else \"\"\n                out = await action.run(code_text)\n                # Route to Reviewer and Verifier\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # Gather latest code and tests\n                code_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteCode.name])\n                tests_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteTest.name])\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                out = await action.run(code_text, tests_text)\n                # Route review to Verifier and Coder for improvements\n                send_to = {\"SimpleVerifier\", \"SimpleCoder\"}\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # Gather latest code and tests\n                code_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteCode.name])\n                tests_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteTest.name])\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                out = await action.run(code_text, tests_text)\n                # Verification messages are broadcast for team decision\n                send_to = set()  # broadcast\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                out = \"Action executed (noop)\"\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=set()\n                )\n        except Exception as e:\n            # Robust error handling: log and create a failure message\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, f\"Exception during act: {str(e)}\")\n            response = Message(\n                content=f\"ERROR: {str(e)}\",\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to=set()\n            )\n\n        # Mark the input message as processed to avoid reprocessing\n        if message and getattr(message, \"id\", None):\n            self._processed_message_ids.add(message.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message {getattr(response, 'id', '')[:8]} cause_by={response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder initiates on UserInput\n        self._watch([ ])  # empty; will respond to messages explicitly targeted\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watches code-writing actions\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        # Watches tests to provide review\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        # Watches tests (and reviews implicitly)\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with improved routing\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # quick index of messages by cause_by for artifact lookup\n        self._index_by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        # attach env on the role instance\n        setattr(role, 'env', self)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and index it\"\"\"\n        # Ensure message has an id (pydantic variant already does)\n        if not getattr(message, \"id\", None):\n            message.id = str(uuid.uuid4())\n        self.history.append(message)\n        # index by cause_by\n        cb = getattr(message, \"cause_by\", \"\")\n        if cb:\n            self._index_by_cause.setdefault(cb, []).append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:200].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {message.sent_from} cause_by={cb} send_to={getattr(message, 'send_to', set())} content={snippet}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            # skip messages the role already processed\n            if getattr(msg, \"id\", None) in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # explicit routing takes precedence\n            if getattr(msg, \"send_to\", None):\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    relevant_messages.append(msg)\n                    continue\n            # otherwise use watch_list matching cause_by\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\n    def get_latest_artifact(self, cause_names: List[str]) -> Optional[Message]:\n        \"\"\"Return the most recent message whose cause_by is in cause_names\"\"\"\n        for name in cause_names:\n            msgs = self._index_by_cause.get(name, [])\n            if msgs:\n                return msgs[-1]\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together with robust orchestration and termination logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # track verification stability: require N consecutive PASS to accept\n        self._consecutive_verification_passes = 0\n        self._verification_threshold = 2  # require two consecutive passes to avoid fluke\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with clear orchestration, retries, and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Initial message with the idea targeted at the coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"Alice\", \"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified_overall = False\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            new_messages_this_round = 0\n\n            # Iterate over a fixed, orchestrated order to reduce race conditions:\n            orchestration = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n            for RoleClass in orchestration:\n                for role in [r for r in self.env.roles if isinstance(r, RoleClass)]:\n                    # get messages that role should handle\n                    incoming = self.env.get_messages_for_role(role)\n                    if not incoming:\n                        # allow coder to be triggered on first round by initial message\n                        if RoleClass is SimpleCoder and round_num == 1:\n                            incoming = [initial_msg]\n                    # Process each incoming message (deterministic order: newest first)\n                    for msg in incoming:\n                        # Attempt action with limited retries\n                        attempts = 0\n                        max_attempts = 2\n                        while attempts < max_attempts:\n                            try:\n                                attempts += 1\n                                response = await role.act(msg)\n                                if response:\n                                    self.env.publish_message(response)\n                                    new_messages_this_round += 1\n                                    # If verifier produced a PASS, update counters\n                                    if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                        self._consecutive_verification_passes += 1\n                                        self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"Consecutive passes={self._consecutive_verification_passes}\")\n                                    elif isinstance(role, SimpleVerifier):\n                                        # reset if fail\n                                        self._consecutive_verification_passes = 0\n                                break  # success or handled, break retry loop\n                            except Exception as e:\n                                # Log and decide to retry\n                                self.tracer.log(\"ROLE_RUN_ERROR\", role.name, f\"Attempt {attempts} failed: {str(e)}\")\n                                if attempts >= max_attempts:\n                                    # produce an error message into environment\n                                    err_msg = Message(\n                                        content=f\"ERROR: role {role.name} failed after {attempts} attempts: {str(e)}\",\n                                        role=role.profile,\n                                        cause_by=\"RoleRunError\",\n                                        sent_from=role.name,\n                                        send_to=set()\n                                    )\n                                    self.env.publish_message(err_msg)\n                                    new_messages_this_round += 1\n                                else:\n                                    # small implicit backoff - next loop iteration will retry\n                                    continue\n\n            # After all roles, determine termination conditions\n            if self._consecutive_verification_passes >= self._verification_threshold:\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Verification stable for {self._verification_threshold} rounds, stopping\")\n                verified_overall = True\n                break\n\n            if new_messages_this_round == 0:\n                # no progress made this round; stop to avoid infinite loop\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No new messages produced this round; stopping early\")\n                break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed with {new_messages_this_round} new messages\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' ended. Rounds executed={round_num}. Messages exchanged={len(self.env.history)}. Verified={verified_overall}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2222), Performs well on avg_failures_per_task (3.5000), Performs well on total_failures (21.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 4 (Score: 7.3048)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport hashlib\nimport ast\nfrom collections import defaultdict\n\nclass Action(ABC):\n    \"\"\"Base action class\n\n    Responsibilities:\n    - Provide a run(...) coroutine that performs the action.\n    - Provide safe_ask(...) wrapper to call LLM with retries and logging.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM.ask with retry and basic error detection.\"\"\"\n        if not self.llm:\n            # No LLM configured, return a helpful fallback\n            fallback = \"LLM not available: fallback response.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        while attempt < self.max_retries:\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt+1}\")\n                resp = await self.llm.ask(messages)\n                # If LLMInterface returns an error string, consider retrying\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Received error: {resp[:200]}\")\n                    attempt += 1\n                    await asyncio.sleep(self.retry_backoff * attempt)\n                    continue\n                return resp\n            except Exception as e:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, f\"{type(e).__name__}: {str(e)[:200]}\")\n                attempt += 1\n                await asyncio.sleep(self.retry_backoff * attempt)\n        # Exhausted retries\n        err = \"LLM request failed after retries.\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err)\n        return err\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\n\n    Inputs: idea text\n    Outputs: code text\n    \"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea: {idea[:120]}\")\n\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module that implements the \"\n            \"requested functionality. Focus on clarity, docstrings, error handling, and testability.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Provide only the Python code for the implementation (no surrounding backticks).\\n\"\n            \"- Keep the implementation self-contained and avoid external network calls.\\n\"\n            \"- Include docstrings and comments for functions.\\n\"\n            \"- Ensure the code defines at least one function or class.\\n\\n\"\n            \"Return the code only.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        code = await self.safe_ask(messages)\n\n        # Basic validation: non-empty and contains def or class\n        if not code or not any(token in code for token in (\"def \", \"class \")):\n            fallback = f\"# Fallback implementation for: {idea}\\n\\n\" \\\n                       \"def placeholder():\\n\" \\\n                       \"    '''Fallback placeholder implementation.'''\\n\" \\\n                       \"    return None\\n\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated code missing definitions; using fallback\")\n            code = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\n\n    Inputs: code text\n    Outputs: pytest-style test code\n    \"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code (len={len(code)})\")\n\n        # Extract top-level function/class names to suggest tests reference them\n        try:\n            parsed = ast.parse(code or \"\")\n            names = [n.name for n in parsed.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            names_snippet = \", \".join(names[:5]) if names else \"main\"\n        except Exception:\n            names_snippet = \"main\"\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style test cases for the following Python module. \"\n            \"Aim for clear, focused tests that exercise core behavior and edge cases. \"\n            \"Include docstrings for each test.\\n\\n\"\n            f\"Module summary: top-level names -> {names_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible test code only.\\n\"\n            \"- Include both positive and negative tests when applicable.\\n\"\n            \"- Use assert statements.\\n\\n\"\n            \"Return only the test code.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        tests = await self.safe_ask(messages)\n\n        # Basic validation: ensure there is at least one 'assert' or 'pytest'\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    '''Fallback test: ensures placeholder returns None.'''\\n\"\n                \"    from placeholder_module import placeholder if False else None\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated tests missing asserts; using fallback\")\n            tests = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\n\n    Inputs: code text, tests text\n    Outputs: review text (short) - includes REVIEW_DECISION token when possible\n    \"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: APPROVE. The code looks acceptable; consider edge-case tests.\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Provide a concise review with actionable items and an explicit \"\n                \"'REVIEW_DECISION: APPROVE' or 'REVIEW_DECISION: REJECT' line.\\n\\n\"\n                \"Code (first 2000 chars):\\n\"\n                f\"{(code or '')[:2000]}\\n\\n\"\n                \"Tests (first 2000 chars):\\n\"\n                f\"{(tests or '')[:2000]}\\n\\n\"\n                \"Focus on: code quality, test coverage, potential bugs, and a final decision line.\\n\"\n                \"Return the review text only.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self.safe_ask(messages)\n\n            # If the LLM reply lacks decision token, derive a simple heuristic\n            if \"REVIEW_DECISION:\" not in review:\n                decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REJECT\"\n                review = f\"{review}\\n\\nREVIEW_DECISION: {decision}\"\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed length={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\n\n    Inputs: code text, tests text\n    Outputs: structured verification result string starting with VERIFICATION_RESULT: PASS/FAIL\n    \"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        result_parts = []\n        code_ok = False\n        tests_ok = False\n        details = []\n\n        # Syntax checks\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = True if (tests and tests.strip()) else False\n            details.append(\"tests_syntax: ok\" if tests_ok else \"tests_syntax: fail (empty or invalid)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            tests_ok = False\n\n        # Semantic checks: ensure at least one function/class in code and at least one assert in tests\n        code_has_def = False\n        try:\n            parsed = ast.parse(code or \"\")\n            code_has_def = any(isinstance(n, (ast.FunctionDef, ast.ClassDef)) for n in parsed.body)\n            details.append(\"code_has_def: ok\" if code_has_def else \"code_has_def: fail\")\n        except Exception:\n            details.append(\"code_has_def: fail (parse error)\")\n\n        tests_has_assert = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # search for Assert nodes or pytest import\n            tests_has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"pytest\" in (tests or \"\"))\n            details.append(\"tests_has_assert: ok\" if tests_has_assert else \"tests_has_assert: fail\")\n        except Exception:\n            details.append(\"tests_has_assert: fail (parse error)\")\n\n        # Cross-reference: confirm tests reference at least one name defined in code\n        cross_ref_ok = False\n        try:\n            code_names = {n.name for n in ast.parse(code or \"\").body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            tests_text = tests or \"\"\n            if code_names:\n                for nm in code_names:\n                    if nm in tests_text:\n                        cross_ref_ok = True\n                        break\n            details.append(\"cross_reference: ok\" if cross_ref_ok else \"cross_reference: fail\")\n        except Exception:\n            details.append(\"cross_reference: fail (error)\")\n\n        verified = all([code_ok, tests_ok, code_has_def, tests_has_assert, cross_ref_ok])\n        status_line = \"VERIFICATION_RESULT: PASS\" if verified else \"VERIFICATION_RESULT: FAIL\"\n        # Compute a digest of code+tests to detect stability across rounds\n        digest = hashlib.sha256((code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")).hexdigest()[:12]\n        result = f\"{status_line} | digest={digest} | \" + \"; \".join(details)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\n\n    Responsibilities:\n    - Maintain clear responsibilities (single primary action).\n    - Track processed messages to avoid duplicate processing.\n    - Provide act(message) which handles errors and returns a Message.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # Track message ids we've processed\n        self._processed_ids: Set[str] = set()\n        # Environment reference may be set by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action in response to a message.\n\n        The role will not reprocess messages (idempotency), and will log failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        # pick primary action (roles are designed for single-action)\n        action = self.actions[0]\n\n        # If message is provided but already processed, skip\n        if message and message.id in self._processed_ids:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {message.id}\")\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message id={getattr(message, 'id', None)}\")\n\n        try:\n            # Dispatch based on action type; keep logic explicit\n            if isinstance(action, SimpleWriteCode):\n                inp = (message.instruct_content or message.content) if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteTest):\n                # Expect to receive the latest code message (message.content holds code or reference)\n                inp = message.content if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteReview):\n                # Expects a message that contains code and/or tests combined or references to both.\n                # Try to lookup latest code and test messages in environment if message is not explicit\n                code_text = \"\"\n                tests_text = \"\"\n                if message and message.cause_by == SimpleWriteTest.name:\n                    tests_text = message.content\n                    # find latest code\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteCode.name:\n                                code_text = msg.content\n                                break\n                elif message and message.cause_by == SimpleWriteCode.name:\n                    code_text = message.content\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name:\n                                tests_text = msg.content\n                                break\n                else:\n                    # fallback: try to find both in env\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = msg.content\n                            if msg.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = msg.content\n                            if code_text and tests_text:\n                                break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # Find latest code and tests from environment\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_text and msg.cause_by == SimpleWriteCode.name:\n                            code_text = msg.content\n                        if not tests_text and msg.cause_by == SimpleWriteTest.name:\n                            tests_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            else:\n                result = \"Action completed\"\n\n            # mark message processed\n            if message:\n                self._processed_ids.add(message.id)\n\n            # create response message\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name if action else \"\",\n                sent_from=self.name\n            )\n\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created id={response.id}\")\n            return response\n\n        except Exception as e:\n            # catch-all to avoid crashing the orchestrator\n            err_text = f\"Role {self.name} failed executing {action.name}: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err_text)\n            response = Message(\n                content=err_text,\n                role=self.profile,\n                cause_by=\"Error\",\n                sent_from=self.name\n            )\n            return response\n\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\n\n    Responsibilities:\n    - Store message history.\n    - Maintain subscriptions mapping from action names to roles that watch them.\n    - Provide role-specific unprocessed messages.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Map action_name -> list of roles that watch it\n        self.subscriptions: Dict[str, List[Role]] = defaultdict(list)\n        # Track which messages have been delivered to which role ids\n        self._delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n        # Register subscriptions based on watch_list\n        for watched in role.watch_list:\n            self.subscriptions[watched.name].append(role)\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment (append to history)\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {message.sent_from} ({message.cause_by}): {message.content[:200]} id={message.id}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get new messages that a role should respond to.\n\n        Criteria:\n        - Messages explicitly targeted to the role (send_to contains role.name)\n        - Messages caused by actions that this role watches\n        - Excludes messages already delivered to this role (idempotency)\n        \"\"\"\n        relevant_messages = []\n        seen = self._delivered.get(role.name, set())\n        for msg in self.history:\n            # Skip if already delivered to this role\n            if msg.id in seen:\n                continue\n            targeted = False\n            if hasattr(msg, \"send_to\") and msg.send_to:\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    targeted = True\n            # If it's targeted or it's from a watched action, include\n            if targeted or any(msg.cause_by == watched.name for watched in role.watch_list):\n                relevant_messages.append(msg)\n                seen.add(msg.id)\n        # record delivery\n        if relevant_messages:\n            self._delivered[role.name] = seen\n        return relevant_messages\n\n\nclass Team:\n    \"\"\"Team of agents working together\n\n    Improvements:\n    - Deterministic orchestration order\n    - No duplicate processing\n    - Explicit termination criteria: require stable verification (consecutive passes)\n    - Robust error handling and tracing\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Orchestration order\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # Track consecutive verification stability\n        self._last_verified_digest: Optional[str] = None\n        self._verified_streak: int = 0\n        self._required_consecutive_verifications: int = 2  # require stability across rounds\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\n\n        Termination:\n        - Stop early if verifier reports PASS for the same digest _required_consecutive_verifications_ times.\n        - Otherwise proceed up to n_round rounds.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n\n            # For each role type in orchestration order, find all roles of that type and let them act on new messages\n            for role_type in self.order:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # find messages for role\n                    messages = self.env.get_messages_for_role(role)\n                    # Choose the latest message (if multiple) to act upon, but allow acting on each new message once\n                    for msg in messages:\n                        if msg.id in getattr(role, \"_processed_ids\", set()):\n                            continue\n                        response = await role.act(msg)\n                        if response:\n                            # Tag responses to indicate they should be considered by watchers\n                            # Responses will have cause_by set by role.act\n                            response.sent_to = None\n                            self.env.publish_message(response)\n\n            # After roles acted, let verifier run (could have been triggered above)\n            # Check latest verifier messages to determine verification status\n            verifier_roles = [r for r in self.env.roles if isinstance(r, SimpleVerifier)]\n            for verifier in verifier_roles:\n                # get messages intended for verifier (env.get_messages_for_role will return new relevant ones)\n                v_msgs = self.env.get_messages_for_role(verifier)\n                for vmsg in v_msgs:\n                    if vmsg.id in getattr(verifier, \"_processed_ids\", set()):\n                        continue\n                    resp = await verifier.act(vmsg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        # parse verification result\n                        content = resp.content or \"\"\n                        if \"VERIFICATION_RESULT: PASS\" in content:\n                            # extract digest\n                            digest_part = None\n                            for tok in content.split(\"|\"):\n                                tok = tok.strip()\n                                if tok.startswith(\"digest=\"):\n                                    digest_part = tok.split(\"=\", 1)[1]\n                                    break\n                            if digest_part:\n                                if digest_part == self._last_verified_digest:\n                                    self._verified_streak += 1\n                                else:\n                                    self._last_verified_digest = digest_part\n                                    self._verified_streak = 1\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", f\"Digest={digest_part} streak={self._verified_streak}\")\n                                if self._verified_streak >= self._required_consecutive_verifications:\n                                    verified = True\n                            else:\n                                # If no digest, count as one pass but not stable\n                                self._verified_streak = 1\n                                verified = False\n                                self._last_verified_digest = None\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Pass without digest; continuing\")\n                        else:\n                            # Reset streak on fail\n                            self._verified_streak = 0\n                            self._last_verified_digest = None\n                            self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Verification failed\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed; verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_consecutive_verifications} rounds, stopping early\")\n                break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project ended after {round_num} rounds; verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1622), Performs well on avg_failures_per_task (5.1667), Performs well on total_failures (31.0000), Performs well on successful_runs (6.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class. Actions return structured results (dict) when possible.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 4  # increased retries for robustness\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def ask_with_retry(self, messages: List[Dict[str, str]], timeout_s: float = 2.0) -> str:\n        \"\"\"Call LLM with exponential backoff, jitter, and improved error detection.\"\"\"\n        import asyncio\n        import random\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_UNUSED: fallback response\"\n                resp = await self.llm.ask(messages)\n                if resp is None:\n                    last_err = \"LLM returned None\"\n                else:\n                    # Detect common error patterns and too-short answers\n                    if isinstance(resp, str) and (resp.startswith(\"Error\") or len(resp.strip()) < 8):\n                        last_err = resp\n                    else:\n                        return resp\n            except Exception as e:\n                last_err = str(e)\n            # log retry\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(last_err)[:200]}\")\n            # exponential backoff with jitter\n            await asyncio.sleep(timeout_s * (2 ** (attempt - 1)) + random.uniform(0, 0.5))\n        # All retries exhausted\n        err_msg = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action and return a structured dict if possible.\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> Dict[str, Any]:\n        \"\"\"Generate code based on the idea. Returns dict with status and payload.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.ask_with_retry(messages)\n        status = \"ok\" if code and not code.startswith(\"Error\") and not code.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code) if isinstance(code,str) else 0} characters of code; status={status}\")\n        return {\"status\": status, \"payload\": code or \"\", \"meta\": {\"idea\": idea}}\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> Dict[str, Any]:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        # Truncate large code to keep prompt reasonable\n        code_snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code_snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.ask_with_retry(messages)\n        status = \"ok\" if tests and not tests.startswith(\"Error\") and not tests.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests) if isinstance(tests,str) else 0} characters of tests; status={status}\")\n        return {\"status\": status, \"payload\": tests or \"\", \"meta\": {\"code_summary\": code_snippet[:200]}}\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Review the code and tests. Returns {'status': 'ok'/'needs_changes', 'payload': review_text, 'meta': {...}}\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            status = \"ok\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nReturn a short structured verdict line at the top: VERDICT: ok OR VERDICT: needs_changes\nThen provide actionable comments. Keep it concise.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            review = await self.ask_with_retry(messages)\n            if isinstance(review, str) and review.strip().startswith(\"VERDICT:\"):\n                first_line = review.splitlines()[0].strip()\n                verdict = first_line.replace(\"VERDICT:\", \"\").strip().lower()\n                status = \"ok\" if verdict == \"ok\" else \"needs_changes\"\n            else:\n                # fallback heuristic\n                status = \"needs_changes\" if \"bug\" in (review or \"\").lower() or \"issue\" in (review or \"\").lower() else \"ok\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters; status={status}\")\n        \n        return {\"status\": status, \"payload\": review or \"\", \"meta\": {}}\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Return a structured verification result with diagnostics.\"\"\"\n        import ast, re, textwrap\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        fn_names = []\n        try:\n            # Verify code syntax\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            fn_names = [n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)]\n            details.append(f\"functions:{','.join(fn_names) if fn_names else 'none'}\")\n        except Exception as e:\n            details.append(f\"code_syntax_error:{str(e)[:200]}\")\n            fn_names = []\n            code_ok = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # Heuristics: tests must have at least one test_ function and an assert\n            contains_assert = bool(re.search(r\"\\bassert\\b\", tests or \"\"))\n            contains_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            tests_ok = contains_assert and contains_testfn\n            if not contains_assert:\n                details.append(\"tests_missing_asserts\")\n            if not contains_testfn:\n                details.append(\"tests_missing_test_functions\")\n        except Exception as e:\n            details.append(f\"tests_syntax_error:{str(e)[:200]}\")\n            tests_ok = False\n        # Ensure tests reference code symbols\n        references_code = False\n        try:\n            if fn_names:\n                for fn in fn_names:\n                    # simple substring check is conservative but quick\n                    if fn and fn in (tests or \"\"):\n                        references_code = True\n                        break\n                if not references_code:\n                    details.append(\"tests_do_not_reference_code\")\n            else:\n                # If no functions in code, accept tests if tests parse and have asserts/test fns\n                references_code = True if tests_ok else False\n        except Exception:\n            details.append(\"tests_reference_check_failed\")\n            references_code = False\n        verified = code_ok and tests_ok and references_code\n        status = \"PASS\" if verified else \"FAIL\"\n        # Add a coverage heuristic: count asserts and test functions\n        try:\n            num_asserts = (tests or \"\").count(\"assert\")\n            num_test_fns = 0\n            parsed_tests = ast.parse(tests or \"\")\n            num_test_fns = sum(1 for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\"))\n            details.append(f\"asserts:{num_asserts}\")\n            details.append(f\"test_functions:{num_test_fns}\")\n        except Exception:\n            pass\n        result_payload = {\"status\": status, \"details\": details, \"verified\": verified}\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"VERIFICATION_RESULT: {status} | details={';'.join(details)}\")\n        return result_payload\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibilities, watch/trigger logic, and retries\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track messages already processed to avoid duplicates\n        self._processed_message_ids: Set[str] = set()\n        # role maintains a small cache of last outputs to avoid repeating work\n        self._last_outputs: List[str] = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message based on watch list and send_to.\"\"\"\n        # Skip if already processed\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # If message explicitly addressed to this role/profile\n        if getattr(message, \"send_to\", None):\n            if self.profile in message.send_to or self.name in message.send_to:\n                return True\n            # addressed to everyone\n            if \"*\" in message.send_to:\n                return True\n        # If message cause_by is one of the watched actions\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # If message is human instruction (UserInput) coders should respond\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and self.profile.lower().find(\"coder\") >= 0:\n            return True\n        return False\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Perform an action based on the message with robust error handling, retries,\n        and standardized structured processing of action results.\n        \"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        \n        # If message exists but this role should not respond, skip\n        if message is not None and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n        \n        # Prepare inputs to action depending on action type, with safe defaults\n        def _gather_code_tests_from_env():\n            env = getattr(self, 'env', None)\n            code = \"\"\n            tests = \"\"\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteTest.name and not tests:\n                        tests = msg.content\n                    if msg.cause_by == SimpleWriteCode.name and not code:\n                        code = msg.content\n                    if code and tests:\n                        break\n            return code, tests\n        \n        attempts = 0\n        last_err = None\n        from asyncio import sleep\n        max_attempts = 3\n        while attempts < max_attempts:\n            attempts += 1\n            try:\n                # Determine input for action types\n                result = None\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                elif isinstance(action, SimpleWriteTest):\n                    # Expect code content to be in the message or env\n                    content = getattr(message, \"content\", \"\") or \"\"\n                    if not content:\n                        code, _ = _gather_code_tests_from_env()\n                        content = code\n                    result = await action.run(content)\n                elif isinstance(action, SimpleWriteReview):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message is tests, prefer message content as tests\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        tests = getattr(message, \"content\", tests)\n                    result = await action.run(code, tests)\n                elif isinstance(action, SimpleVerify):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message provides tests or code, prefer them\n                    if message:\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                            tests = getattr(message, \"content\", tests)\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                            code = getattr(message, \"content\", code)\n                    result = await action.run(code, tests)\n                else:\n                    # Generic action\n                    result = await action.run()  # type: ignore\n                # Normalize result to structured dict\n                if isinstance(result, dict):\n                    status = result.get(\"status\") or (\"ok\" if result.get(\"verified\") else \"unknown\")\n                    payload = result.get(\"payload\") if \"payload\" in result else (str(result))\n                    meta = result.get(\"meta\", {})\n                else:\n                    # older behavior: string\n                    payload = str(result or \"\")\n                    status = \"ok\" if not payload.startswith(\"Error\") and \"VERIFICATION_RESULT: PASS\" not in payload else (\"pass\" if \"PASS\" in payload else \"error\")\n                    meta = {}\n                \n                # Mark message processed to avoid double handling\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Keep last outputs (small history)\n                try:\n                    self._last_outputs.append(payload)\n                    if len(self._last_outputs) > 8:\n                        self._last_outputs = self._last_outputs[-8:]\n                except Exception:\n                    pass\n                \n                # Decide recipients based on action type and status\n                recipients = set()\n                cause_name = action.name if action else \"\"\n                if isinstance(action, SimpleWriteCode):\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # If review says ok -> verifier & coder, else coder primarily\n                    if status == \"ok\" or status == \"ok\":\n                        recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                    else:\n                        recipients = {\"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    recipients = {\"Team\"}\n                else:\n                    recipients = {\"Team\"}\n                \n                # Build standardized message content for downstream parsing\n                # Use a short header and include payload (full payload may be long)\n                header = f\"RESULT|{cause_name}|{status}\"\n                content_str = header + \"\\n\" + (payload or \"\")\n                response = Message(\n                    content=content_str,\n                    role=self.profile,\n                    cause_by=cause_name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action succeeded, created message id={(getattr(response,'id',None))}; status={status}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # Backoff before retrying\n                await sleep(0.5 * attempts)\n        # If we reach here, action failed consistently\n        fail_msg = f\"ROLE_FAILED: {self.name} could not complete action after {attempts} attempts. Error={last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with clear message routing and deduplication\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and trace it\"\"\"\n        # Prevent duplicate identical messages (by content + sender) flooding\n        try:\n            if any(m.id == message.id for m in self.history):\n                # already published\n                return\n        except Exception:\n            pass\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:200]} | cause_by={getattr(message,'cause_by',None)} | send_to={getattr(message,'send_to',None)}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Get messages that a role should respond to.\n        This respects explicit addressing (send_to) and the role's watch_list.\n        It also filters messages already processed by the role.\n        \"\"\"\n        relevant_messages = []\n        for msg in list(self.history):\n            # Skip messages the role already processed\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # If explicitly addressed\n            if getattr(msg, \"send_to\", None):\n                if role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to:\n                    relevant_messages.append(msg)\n                    continue\n            # If message cause_by matches watch_list\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        # Return in chronological order (oldest first) to preserve causal flow\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together with robust termination and verification logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification confirmation count to avoid premature termination\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2  # require two independent confirmations\n        self._review_ok_count = 0\n        self._stable_rounds_after_verify = 0\n        self._required_stable_rounds = 1  # require a round of stability after verification\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with stronger orchestration and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (verify confirmations needed={self._verify_confirm_needed})\")\n        \n        # Initial message with the idea, explicitly addressed to the coder role\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        # We'll track rounds where no progress is made to avoid infinite loops\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            progress_made = False\n            \n            # Orchestrated sequence: evaluate each role each round; roles pick relevant messages\n            for role in list(self.env.roles):\n                relevant = self.env.get_messages_for_role(role)\n                # Ensure coder receives the initial instruction on first round\n                msgs_to_process = relevant\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    msgs_to_process = [initial_msg] + [m for m in relevant if m.id != initial_msg.id]\n                for msg in msgs_to_process:\n                    resp = await role.act(msg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        progress_made = True\n                        # Process verifier outputs\n                        if isinstance(role, SimpleVerifier):\n                            # standardized content begins with RESULT|SimpleVerify|PASS/FAIL\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"PASS\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content):\n                                    self._verify_confirm_count += 1\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} reported PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                elif \"FAIL\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: FAIL\" in resp.content):\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_FAIL\", \"Team\", f\"Verifier {role.name} reported FAIL; resetting confirmations\")\n                            except Exception as e:\n                                self.tracer.log(\"VERIFY_ERROR\", \"Team\", f\"Could not parse verifier result: {e}\")\n                        # Process reviewer outputs for acceptance\n                        if isinstance(role, SimpleReviewer):\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"VERDICT: ok\" in resp.content.lower() or \"result|simplewritereview|ok\" in header.lower():\n                                    self._review_ok_count += 1\n                                    self.tracer.log(\"REVIEW_OK\", \"Team\", f\"Reviewer {role.name} returned ok ({self._review_ok_count})\")\n                                else:\n                                    # reviewer requested changes -> reset verifier confirmations to force rework\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"REVIEW_NEEDS_CHANGES\", \"Team\", f\"Reviewer {role.name} requested changes; resetting verify confirmations\")\n                            except Exception:\n                                pass\n                        # Handle explicit role failures\n                        if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                            self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure noted: {resp.content[:200]}\")\n            # detect progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n            \n            # Check for stable verification: require multiple verifier confirmations and at least one reviewer ok\n            if self._verify_confirm_count >= self._verify_confirm_needed and self._review_ok_count >= 1:\n                self._stable_rounds_after_verify += 1\n                self.tracer.log(\"TEAM_VERIFY_STABLE\", \"Team\", f\"Stable verification observed for {self._stable_rounds_after_verify} rounds\")\n                if self._stable_rounds_after_verify >= self._required_stable_rounds:\n                    verified = True\n            else:\n                self._stable_rounds_after_verify = 0\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed (progress_made={progress_made})\")\n            # Termination conditions\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification and review confirmed; stopping early at round {round_num + 1}\")\n                break\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds, stopping early to conserve resources\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified} (verify_confirms={self._verify_confirm_count}, review_ok={self._review_ok_count})\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D2 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with robust LLM call wrapper and retries.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Wrapper around llm.ask with retries, backoff and error handling.\"\"\"\n        import asyncio\n        if not self.llm:\n            # No real LLM available - return deterministic fallback\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, \"No LLM available, using fallback response\")\n            return \"LLM_FALLBACK_RESPONSE\"\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt} calling LLM\")\n                resp = await self.llm.ask(messages)\n                # LLMInterface returns error strings starting with \"Error\"\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM error returned: {resp[:200]}\")\n                    # retry on LLM error\n                    await asyncio.sleep(0.5 * attempt)\n                    continue\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, f\"Exception during LLM call: {last_err}\")\n                await asyncio.sleep(0.5 * attempt)\n        # after retries, return an explicit failure marker\n        failure_msg = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_ABORT\", self.name, failure_msg)\n        return failure_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea, with LLM retries and fallback.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {artifact_preview(idea)}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self._ask_with_retry(messages)\n        if code is None:\n            code = \"\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        truncated_code = code or \"\"\n        if len(truncated_code) > 2000:\n            truncated_code = truncated_code[:2000]\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{truncated_code}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self._ask_with_retry(messages)\n        if tests is None:\n            tests = \"\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests; for human reviewers, simulate a detailed checklist.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            review = \"Human review: The code looks good overall. Consider adding more error handling and clearer docstrings for public functions.\"\n        else:\n            truncated_code = (code or \"\")[:1500]\n            truncated_tests = (tests or \"\")[:1500]\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{truncated_code}\n\nTests:\n{truncated_tests}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            review = await self._ask_with_retry(messages)\n            if review is None:\n                review = \"REVIEW_FAILED\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        verified = False\n        # Basic syntax checks\n        try:\n            code_ast = ast.parse(code or \"\")\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            code_ast = None\n            details.append(f\"code_syntax: fail ({str(e)[:120]})\")\n        try:\n            tests_ast = ast.parse(tests or \"\")\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            tests_ast = None\n            details.append(f\"tests_syntax: fail ({str(e)[:120]})\")\n        \n        # Semantic checks: ensure code defines at least one function/class\n        functions = []\n        classes = []\n        if code_ast is not None:\n            for node in ast.walk(code_ast):\n                if isinstance(node, ast.FunctionDef):\n                    functions.append(node.name)\n                if isinstance(node, ast.ClassDef):\n                    classes.append(node.name)\n            if functions or classes:\n                details.append(f\"code_entities: functions={functions[:5]}, classes={classes[:5]}\")\n            else:\n                details.append(\"code_entities: none_detected\")\n        \n        # Tests should reference at least one function/class name or contain assert statements\n        test_asserts = False\n        referenced = []\n        if tests_ast is not None:\n            for node in ast.walk(tests_ast):\n                if isinstance(node, ast.Assert):\n                    test_asserts = True\n                # Check Name nodes to find references\n                if isinstance(node, ast.Name):\n                    referenced.append(node.id)\n            # Check intersection between referenced names and functions/classes\n            intersect = set(referenced) & set(functions + classes)\n            if test_asserts or intersect:\n                details.append(f\"tests_relevance: asserts={test_asserts}, references={list(intersect)[:5]}\")\n            else:\n                details.append(\"tests_relevance: no_asserts_or_references\")\n        \n        # Final decision heuristic\n        if (\"code_syntax: ok\" in details) and (\"tests_syntax: ok\" in details):\n            # If tests reference code entities or contain asserts, consider pass\n            relevant = any(d.startswith(\"tests_relevance: asserts=True\") or \"references=\" in d and \"[]\" not in d for d in details)\n            if relevant:\n                verified = True\n            else:\n                verified = False\n        else:\n            verified = False\n        \n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\ndef artifact_preview(text: Optional[str], length: int = 80) -> str:\n    if not text:\n        return \"\"\n    return (text[:length] + \"...\") if len(text) > length else text\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibilities and idempotent processing.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # env is injected by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Default act implementation - runs the first action with sensible input extraction.\n        Roles are expected to override this if they need special logic.\n        \"\"\"\n        import asyncio\n        if not self.actions:\n            return None\n\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message {getattr(message, 'id', None)}\")\n\n        # Retry the action.run in case of transient failures (not LLM failures which are handled inside).\n        attempt = 0\n        last_err = None\n        while attempt < 2:\n            attempt += 1\n            try:\n                # Basic routing depending on action type - subclasses may override\n                if isinstance(action, SimpleWriteCode):\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")\n                    result = await action.run(idea)\n                    # When code produced, route to Testers\n                    send_to = {r.name for r in (self.env.roles if self.env else []) if any(isinstance(a, SimpleWriteTest) for a in r.actions)}\n                    response = Message(content=result, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n                elif isinstance(action, SimpleWriteTest):\n                    # Expect to receive code in message.content\n                    code = getattr(message, \"content\", \"\")\n                    result = await action.run(code)\n                    # Route tests to Reviewers and Verifiers\n                    send_to = {r.name for r in (self.env.roles if self.env else []) if any(isinstance(a, SimpleWriteReview) for a in r.actions) or any(isinstance(a, SimpleVerify) for a in r.actions)}\n                    response = Message(content=result, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n                elif isinstance(action, SimpleWriteReview):\n                    # Need both code and tests - attempt to fetch latest unprocessed messages\n                    code_msg, tests_msg = self._find_latest_code_and_tests()\n                    code = code_msg.content if code_msg else \"\"\n                    tests = tests_msg.content if tests_msg else \"\"\n                    result = await action.run(code, tests)\n                    # Reviews get sent to Verifier\n                    send_to = {r.name for r in (self.env.roles if self.env else []) if any(isinstance(a, SimpleVerify) for a in r.actions)}\n                    response = Message(content=result, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n                elif isinstance(action, SimpleVerify):\n                    code_msg, tests_msg = self._find_latest_code_and_tests()\n                    code = code_msg.content if code_msg else \"\"\n                    tests = tests_msg.content if tests_msg else \"\"\n                    result = await action.run(code, tests)\n                    # Verification result is broadcast to all roles (final)\n                    send_to = {r.name for r in (self.env.roles if self.env else [])}\n                    response = Message(content=result, role=self.profile, cause_by=action.name, sent_from=self.name, send_to=send_to)\n                else:\n                    result = \"Action completed\"\n                    response = Message(content=result, role=self.profile, cause_by=action.name, sent_from=self.name)\n                # Log and return\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action {action.name} completed, message created {getattr(response,'id',None)}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempt} failed with error: {last_err}\")\n                await asyncio.sleep(0.2 * attempt)\n        # If reached, produce an error message\n        err_content = f\"ROLE_ACTION_FAILED: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ABORT\", self.name, err_content)\n        return Message(content=err_content, role=self.profile, cause_by=action.name, sent_from=self.name)\n\n    def _find_latest_code_and_tests(self):\n        \"\"\"Helper to find latest code and tests messages from environment history.\"\"\"\n        code_msg = None\n        tests_msg = None\n        if not self.env:\n            return (None, None)\n        for msg in reversed(self.env.history):\n            if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                code_msg = msg\n            if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return (code_msg, tests_msg)\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with explicit message processing state.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Map message_id -> set of role names that processed it\n        self.processed_map: Dict[str, Set[str]] = {}\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        # Ensure send_to is a set\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set()\n            except Exception:\n                pass\n        self.history.append(message)\n        self.processed_map[message.id] = set()\n        if self.tracer:\n            sender = message.sent_from or \"Unknown\"\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message {message.id} from {sender}: {artifact_preview(message.content)} -> send_to={getattr(message,'send_to',set())}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        \"\"\"Mark a message as processed by a role to ensure idempotence.\"\"\"\n        if message.id not in self.processed_map:\n            self.processed_map[message.id] = set()\n        self.processed_map[message.id].add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"Message {message.id} processed by {role.name}\")\n\n    def has_been_processed_by(self, message: Message, role: Role) -> bool:\n        return role.name in self.processed_map.get(message.id, set())\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Get messages that a role should respond to:\n        - If the message explicitly targets the role via send_to\n        - OR the message cause_by matches any action in the role's watch_list\n        - Exclude messages the role already processed\n        \"\"\"\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            if self.has_been_processed_by(msg, role):\n                continue\n            # If send_to explicitly targets this role\n            targets = getattr(msg, \"send_to\", None) or set()\n            if role.name in targets:\n                relevant_messages.append(msg)\n                continue\n            # If role watches the action that caused this message\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together with robust orchestration and termination logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment/context\"\"\"\n        for role in roles:\n            role.context = self.context\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {artifact_preview(idea, 200)}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration until verification passes or rounds exhausted.\"\"\"\n        import asyncio\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        \n        # Initial message with the idea targeting coder(s)\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        rounds_completed = 0\n        for round_num in range(n_round):\n            rounds_completed = round_num + 1\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rounds_completed}/{n_round}\")\n            any_actions = False\n            # Process each role in deterministic order\n            for role in list(self.env.roles):\n                # Get unprocessed messages for this role\n                msgs = self.env.get_unprocessed_messages_for_role(role)\n                if not msgs:\n                    # Some roles (like coder) may initiate without incoming messages if no code exists yet\n                    # Allow coder to act when there is a UserInput message that they haven't processed\n                    # We'll attempt to fetch any initial user input addressed to them\n                    continue\n                for msg in msgs:\n                    # Execute role action for this message\n                    try:\n                        response = await role.act(msg)\n                        # Mark input message processed by role to avoid reprocessing\n                        self.env.mark_processed(msg, role)\n                        any_actions = True\n                        if response:\n                            self.env.publish_message(response)\n                            # If verifier produced PASS, set flag\n                            if response.cause_by == SimpleVerify.name and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                verified = True\n                    except Exception as e:\n                        # Log and continue - do not allow single role failure to stop the run\n                        if self.tracer:\n                            self.tracer.log(\"TEAM_ROLE_EXCEPTION\", \"Team\", f\"Role {role.name} exception: {str(e)[:200]}\")\n                        continue\n\n            # If no actions occurred this round (deadlock), allow coders to re-attempt generation once\n            if not any_actions:\n                # Try to trigger coder(s) if they haven't processed initial idea\n                for role in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                    msgs = self.env.get_unprocessed_messages_for_role(role)\n                    if msgs:\n                        # will be processed next loop\n                        continue\n                    # nothing to do; continue\n                # small pause to simulate processing latency\n                await asyncio.sleep(0.05)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rounds_completed} completed; verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {rounds_completed} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D3 (Score: 3.2125)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nfrom collections import defaultdict\nfrom typing import Tuple\n\ndef _preview(text: Optional[str], length: int = 120) -> str:\n    if not text:\n        return \"\"\n    return text if len(text) <= length else text[:length] + \"...\"\n\ndef _normalize_send_to(message: Message) -> Set[str]:\n    s = getattr(message, \"send_to\", None)\n    if s is None:\n        s = set(getattr(message, \"sent_to\", set()) or set())\n    return set(s or set())\n\nclass Action(ABC):\n    \"\"\"Base Action: clear contract, robust LLM calls with retries/backoff and deterministic fallbacks.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    backoff_base: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            try:\n                self.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self.llm = None\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, exponential backoff, error detection, logging, deterministic fallback.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and (resp.strip().lower().startswith(\"error\") or \"error communicating\" in resp.lower()):\n                    last_err = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error-ish response: {resp[:200]}\")\n                    await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n                    continue\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"LLM responded (len={len(resp)}) on attempt {attempt}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, f\"Attempt {attempt} exception: {last_err[:200]}\")\n                await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n                continue\n        final = f\"LLM_CALL_FAILED: {last_err or 'unknown'}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Responsible: generate an initial implementation for the idea, validate syntactic correctness.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_preview={_preview(idea,200)}\")\n        prompt = (\n            \"You are an expert Python programmer. Produce a single Python module implementing the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no surrounding markdown).\\n\"\n            \"- Include docstrings, basic input validation and error handling.\\n\"\n            \"- Ensure at least one function or class is defined.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = await self.safe_ask(messages)\n\n        # Validate syntax; fallback to deterministic placeholder on failure\n        try:\n            if not isinstance(code, str):\n                raise ValueError(\"Non-string LLM response\")\n            ast.parse(code)\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed successfully\")\n        except Exception as e:\n            fallback = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation: LLM failed to produce valid code.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback code due to parse error: {type(e).__name__}: {str(e)[:200]}\")\n            code = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"produced_len={len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Responsible: produce pytest-style tests for a module, with heuristics and fallback.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided Python module.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Include docstrings and clear asserts.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = await self.safe_ask(messages)\n\n        # Heuristic validation: ensure tests contain 'def test_' or 'assert'\n        if not isinstance(tests, str) or (\"def test_\" not in tests and \"assert \" not in tests and \"pytest\" not in tests.lower()):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback tests due to insufficient LLM output\")\n            tests = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Responsible: review code and tests and produce an explicit decision line.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_SUMMARY: Human review - OK with minor suggestions.\\nREVIEW_DECISION: APPROVE\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review and conclude with an explicit line:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGE\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\\n\\n\"\n            \"Return plain text; place the decision on a line starting with REVIEW_DECISION:.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        review = await self.safe_ask(messages)\n\n        if not isinstance(review, str) or \"REVIEW_DECISION:\" not in review:\n            # Heuristic decision to avoid blocking pipeline\n            decision = \"APPROVE\" if (\"def test_\" in (tests or \"\") or \"assert \" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REQUEST_CHANGE\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"No explicit decision from LLM; inferred {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Responsible: deterministic verification, strong validation, and stability digest.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        referenced = False\n\n        # Syntax check for code\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # Syntax + content check for tests\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            if \"def test_\" in (tests or \"\") or \"assert \" in (tests or \"\"):\n                tests_ok = True\n                details.append(\"tests_presence_and_syntax: ok\")\n            else:\n                details.append(\"tests_presence_and_syntax: fail (no pytest tests or asserts found)\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # Extract code entities and check references\n        code_entities: Set[str] = set()\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(f\"code_entities_count: {len(code_entities)}\")\n\n        if parsed_tests and code_entities:\n            tests_text = tests or \"\"\n            for ent in code_entities:\n                if ent and ent in tests_text:\n                    referenced = True\n                    break\n            details.append(f\"tests_reference_code_entities: {referenced}\")\n\n        verified = bool(code_ok and tests_ok and referenced)\n\n        # Stable digest for artifacts\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--TESTS--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if verified else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base Role:\n    - Single primary responsibility\n    - Explicit watch/trigger list (strings)\n    - Idempotent processing using processed set\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: List[str] = []  # list of cause_by strings\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = [a.name if hasattr(a, \"name\") else str(a) for a in actions]\n\n    def should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not message:\n            return False\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed {msg_id}\")\n            return False\n        # explicit addressing\n        targets = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n        if targets:\n            try:\n                if isinstance(targets, (set, list)):\n                    if self.name in targets or self.profile in targets:\n                        return True\n                else:\n                    if targets == self.name or targets == self.profile:\n                        return True\n            except Exception:\n                pass\n        # watched cause_by\n        if getattr(message, \"cause_by\", None) in self.watch_list:\n            return True\n        # human input defaults to coder\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute role's primary action if message applicable. Returns Message or None.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        if message and not self.should_respond_to(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Message not relevant cause_by={getattr(message,'cause_by',None)}\")\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing {self.action.name} on message {msg_id or 'N/A'}\")\n\n        try:\n            # Dispatch inputs according to action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or (getattr(message, \"content\", \"\") if message else \"\")\n                out = await self.action.run(idea or \"\")\n                send_to = {\"SimpleTester\"}\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleWriteTest):\n                # prefer code in message, else fetch latest code artifact\n                code_text = getattr(message, \"content\", \"\") if message else \"\"\n                if not code_text and self.env:\n                    code_text = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                out = await self.action.run(code_text or \"\")\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleWriteReview):\n                code_text = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests_text = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                out = await self.action.run(code_text, tests_text)\n                # route to verifier by default, to coder/tester if review requests changes\n                send_to: Set[str] = {\"SimpleVerifier\"}\n                if \"REVIEW_DECISION: REQUEST_CHANGE\" in (out or \"\"):\n                    send_to.update({\"SimpleCoder\", \"SimpleTester\"})\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleVerify):\n                code_text = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests_text = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                out = await self.action.run(code_text, tests_text)\n                # verification broadcast to all roles (no explicit send_to required)\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=set())\n            else:\n                # generic\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name if self.action else \"\", sent_from=self.name, send_to=set())\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            resp = Message(content=err, role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to=set())\n\n        # Mark processed to ensure idempotency\n        if msg_id:\n            self._processed.add(msg_id)\n        # Also mark produced message as processed by this role (avoid self-reception)\n        try:\n            self._processed.add(getattr(resp, \"id\", \"\"))\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message {getattr(resp,'id',None)[:8]} cause_by={resp.cause_by} send_to={_normalize_send_to(resp)}\")\n        return resp\n\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # proactive / triggered by user input\n\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Environment: deterministic queue, subscriptions, delivered tracking, artifact helpers.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)  # cause_by -> set of role.profile\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)  # message.id -> set of role.name\n        self.message_queue: List[Message] = []\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n        for watched in getattr(role, \"watch_list\", []):\n            self.subscriptions.setdefault(watched, set()).add(role.profile)\n\n    def publish_message(self, message: Message):\n        # Normalize send_to\n        try:\n            message.send_to = _normalize_send_to(message)\n        except Exception:\n            message.send_to = set()\n        # Ensure id exists (pydantic does) otherwise assign\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self.delivered.setdefault(getattr(message, \"id\", \"\"), set())\n        self.message_queue.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Published msg {getattr(message,'id','')} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content,120)} send_to={sorted(list(message.send_to))[:10]}\")\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return getattr(msg, \"content\", \"\")\n        return None\n\n    def get_relevant_roles(self, message: Message) -> List[Role]:\n        \"\"\"Return roles that should receive the message based on explicit send_to or subscriptions.\"\"\"\n        targets = set(getattr(message, \"send_to\", set()) or set())\n        relevant: List[Role] = []\n        if targets:\n            for r in self.roles:\n                if r.profile in targets:\n                    if r.name not in self.delivered.get(getattr(message, \"id\", \"\"), set()):\n                        relevant.append(r)\n            return relevant\n        # else use subscriptions (watchers)\n        watchers = self.subscriptions.get(getattr(message, \"cause_by\", \"\"), set())\n        for r in self.roles:\n            if r.profile in watchers:\n                if r.name not in self.delivered.get(getattr(message, \"id\", \"\"), set()):\n                    relevant.append(r)\n        return relevant\n\n    def mark_delivered(self, message: Message, role: Role):\n        mid = getattr(message, \"id\", None)\n        if mid:\n            self.delivered.setdefault(mid, set()).add(role.name)\n\n\nclass Team:\n    \"\"\"\n    Team orchestrator:\n    - Deterministic message queue draining\n    - Requires stable verification (identical digest) for consecutive confirmations\n    - Nudges to avoid deadlock\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = 2  # require two consecutive identical PASS digests\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {_preview(idea,200)}\")\n\n    async def _process_one_message(self, message: Message) -> bool:\n        \"\"\"Dispatch a message to relevant roles. Return True if stable verification achieved.\"\"\"\n        verified_detected = False\n        relevant = self.env.get_relevant_roles(message)\n        if not relevant:\n            # fallback: roles that watch the cause_by\n            relevant = [r for r in self.env.roles if getattr(message, \"cause_by\", \"\") in r.watch_list]\n        for role in relevant:\n            try:\n                if self.tracer:\n                    self.tracer.log(\"TEAM_DISPATCH\", \"Team\", f\"Dispatching {getattr(message,'id','')} to {role.name}\")\n                resp = await role.act(message)\n                self.env.mark_delivered(message, role)\n                if resp:\n                    self.env.publish_message(resp)\n                    # detect verification pass\n                    if getattr(resp, \"cause_by\", \"\") == SimpleVerify.name and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                        # extract digest\n                        digest = None\n                        for part in (resp.content or \"\").split(\"|\"):\n                            p = part.strip()\n                            if p.startswith(\"digest=\"):\n                                digest = p.split(\"=\",1)[1]\n                                break\n                        if digest:\n                            if digest == self._last_digest:\n                                self._streak += 1\n                            else:\n                                self._last_digest = digest\n                                self._streak = 1\n                            self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                            if self._streak >= self._required_streak:\n                                verified_detected = True\n                        else:\n                            # treat as non-stable pass\n                            self._streak = 0\n                            self._last_digest = None\n                            self.tracer.log(\"VERIFIER_NONSTABLE\", \"Team\", \"Verifier PASS without digest - not stable\")\n            except Exception as e:\n                self.tracer.log(\"TEAM_ROLE_EXCEPTION\", \"Team\", f\"Role {role.name} exception: {type(e).__name__}: {str(e)[:200]}\")\n                continue\n        return verified_detected\n\n    async def _drain_queue(self, max_steps: int = 1000) -> bool:\n        steps = 0\n        while self.env.message_queue and steps < max_steps:\n            steps += 1\n            message = self.env.message_queue.pop(0)\n            if self.tracer:\n                self.tracer.log(\"QUEUE_DEQUEUE\", \"Team\", f\"Dequeued {getattr(message,'id','')} cause_by={message.cause_by} preview={_preview(message.content,100)}\")\n            verified = await self._process_one_message(message)\n            # allow loop to yield for async LLM calls\n            await asyncio.sleep(0)\n            if verified:\n                return True\n        if steps >= max_steps:\n            if self.tracer:\n                self.tracer.log(\"QUEUE_MAX\", \"Team\", f\"Reached max steps {max_steps} while draining queue\")\n        return False\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Main run: publish initial kickoff, process queue until stable verification achieved, nudge if deadlocked.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_required={self._required_streak})\")\n        # initial kickoff targeted to coders\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial)\n        verified_overall = False\n        rounds_executed = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            stable = await self._drain_queue(max_steps=500)\n            if stable:\n                verified_overall = True\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Stable verification achieved at round {rnd}\")\n                break\n\n            # If drained with no queue entries produced, nudge coders to avoid deadlock\n            if not self.env.message_queue:\n                self.tracer.log(\"ROUND_NO_PROGRESS\", \"Team\", \"No messages in queue after drain; issuing nudges\")\n                for coder in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                    nudge = Message(\n                        content=f\"Nudge: please propose or refine implementation for '{_preview(self.idea,120)}'\",\n                        instruct_content=self.idea,\n                        role=\"System\",\n                        sent_from=\"Orchestrator\",\n                        cause_by=\"Nudge\",\n                        send_to={coder.profile}\n                    )\n                    self.env.publish_message(nudge)\n                # process nudges\n                more_stable = await self._drain_queue(max_steps=200)\n                if more_stable:\n                    verified_overall = True\n                    break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed. history_len={len(self.env.history)}\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds_executed} rounds. Verified={verified_overall} messages={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds_executed} verified={verified_overall} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D4 (Score: 4.6667)\n```python\n# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport re\nfrom types import SimpleNamespace\n\n# Default safe fallbacks\n_DEFAULT_CODE = (\n    \"def solve(input_data):\\n\"\n    \"    \\\"\\\"\\\"Safe fallback: echo the input. Minimal, well-formed implementation.\\\"\\\"\\\"\\n\"\n    \"    return input_data\\n\"\n)\n_DEFAULT_TESTS = (\n    \"def _run_sanity_checks():\\n\"\n    \"    # Basic sanity checks for the fallback solve function\\n\"\n    \"    assert solve(1) == 1\\n\"\n    \"    assert solve('x') == 'x'\\n\"\n    \"\\n\"\n    \"if __name__ == '__main__':\\n\"\n    \"    _run_sanity_checks()\\n\"\n)\n\ndef _clean_code_fences(text: Optional[str]) -> str:\n    \"\"\"Strip Markdown or triple-backtick fences and leading/trailing whitespace.\"\"\"\n    if not text:\n        return \"\"\n    t = text.strip()\n    # Remove triple backticks and language hints\n    t = re.sub(r\"^\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 3.4477, Type: Migrant)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Excellent avg_failures_per_task (1.833), Excellent total_failures (11.000)\n\n\n### Inspiration 2 (Score: 7.3048, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport hashlib\nimport ast\nfrom collections import defaultdict\n\nclass Action(ABC):\n    \"\"\"Base action class\n\n    Responsibilities:\n    - Provide a run(...) coroutine that performs the action.\n    - Provide safe_ask(...) wrapper to call LLM with retries and logging.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM.ask with retry and basic error detection.\"\"\"\n        if not self.llm:\n            # No LLM configured, return a helpful fallback\n            fallback = \"LLM not available: fallback response.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        while attempt < self.max_retries:\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt+1}\")\n                resp = await self.llm.ask(messages)\n                # If LLMInterface returns an error string, consider retrying\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Received error: {resp[:200]}\")\n                    attempt += 1\n                    await asyncio.sleep(self.retry_backoff * attempt)\n                    continue\n                return resp\n            except Exception as e:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, f\"{type(e).__name__}: {str(e)[:200]}\")\n                attempt += 1\n                await asyncio.sleep(self.retry_backoff * attempt)\n        # Exhausted retries\n        err = \"LLM request failed after retries.\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err)\n        return err\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\n\n    Inputs: idea text\n    Outputs: code text\n    \"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea: {idea[:120]}\")\n\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module that implements the \"\n            \"requested functionality. Focus on clarity, docstrings, error handling, and testability.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Provide only the Python code for the implementation (no surrounding backticks).\\n\"\n            \"- Keep the implementation self-contained and avoid external network calls.\\n\"\n            \"- Include docstrings and comments for functions.\\n\"\n            \"- Ensure the code defines at least one function or class.\\n\\n\"\n            \"Return the code only.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        code = await self.safe_ask(messages)\n\n        # Basic validation: non-empty and contains def or class\n        if not code or not any(token in code for token in (\"def \", \"class \")):\n            fallback = f\"# Fallback implementation for: {idea}\\n\\n\" \\\n                       \"def placeholder():\\n\" \\\n                       \"    '''Fallback placeholder implementation.'''\\n\" \\\n                       \"    return None\\n\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated code missing definitions; using fallback\")\n            code = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\n\n    Inputs: code text\n    Outputs: pytest-style test code\n    \"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code (len={len(code)})\")\n\n        # Extract top-level function/class names to suggest tests reference them\n        try:\n            parsed = ast.parse(code or \"\")\n            names = [n.name for n in parsed.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            names_snippet = \", \".join(names[:5]) if names else \"main\"\n        except Exception:\n            names_snippet = \"main\"\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style test cases for the following Python module. \"\n            \"Aim for clear, focused tests that exercise core behavior and edge cases. \"\n            \"Include docstrings for each test.\\n\\n\"\n            f\"Module summary: top-level names -> {names_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible test code only.\\n\"\n            \"- Include both positive and negative tests when applicable.\\n\"\n            \"- Use assert statements.\\n\\n\"\n            \"Return only the test code.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        tests = await self.safe_ask(messages)\n\n        # Basic validation: ensure there is at least one 'assert' or 'pytest'\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    '''Fallback test: ensures placeholder returns None.'''\\n\"\n                \"    from placeholder_module import placeholder if False else None\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated tests missing asserts; using fallback\")\n            tests = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\n\n    Inputs: code text, tests text\n    Outputs: review text (short) - includes REVIEW_DECISION token when possible\n    \"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: APPROVE. The code looks acceptable; consider edge-case tests.\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Provide a concise review with actionable items and an explicit \"\n                \"'REVIEW_DECISION: APPROVE' or 'REVIEW_DECISION: REJECT' line.\\n\\n\"\n                \"Code (first 2000 chars):\\n\"\n                f\"{(code or '')[:2000]}\\n\\n\"\n                \"Tests (first 2000 chars):\\n\"\n                f\"{(tests or '')[:2000]}\\n\\n\"\n                \"Focus on: code quality, test coverage, potential bugs, and a final decision line.\\n\"\n                \"Return the review text only.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self.safe_ask(messages)\n\n            # If the LLM reply lacks decision token, derive a simple heuristic\n            if \"REVIEW_DECISION:\" not in review:\n                decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REJECT\"\n                review = f\"{review}\\n\\nREVIEW_DECISION: {decision}\"\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed length={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\n\n    Inputs: code text, tests text\n    Outputs: structured verification result string starting with VERIFICATION_RESULT: PASS/FAIL\n    \"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        result_parts = []\n        code_ok = False\n        tests_ok = False\n        details = []\n\n        # Syntax checks\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = True if (tests and tests.strip()) else False\n            details.append(\"tests_syntax: ok\" if tests_ok else \"tests_syntax: fail (empty or invalid)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            tests_ok = False\n\n        # Semantic checks: ensure at least one function/class in code and at least one assert in tests\n        code_has_def = False\n        try:\n            parsed = ast.parse(code or \"\")\n            code_has_def = any(isinstance(n, (ast.FunctionDef, ast.ClassDef)) for n in parsed.body)\n            details.append(\"code_has_def: ok\" if code_has_def else \"code_has_def: fail\")\n        except Exception:\n            details.append(\"code_has_def: fail (parse error)\")\n\n        tests_has_assert = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # search for Assert nodes or pytest import\n            tests_has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests)) or (\"pytest\" in (tests or \"\"))\n            details.append(\"tests_has_assert: ok\" if tests_has_assert else \"tests_has_assert: fail\")\n        except Exception:\n            details.append(\"tests_has_assert: fail (parse error)\")\n\n        # Cross-reference: confirm tests reference at least one name defined in code\n        cross_ref_ok = False\n        try:\n            code_names = {n.name for n in ast.parse(code or \"\").body if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            tests_text = tests or \"\"\n            if code_names:\n                for nm in code_names:\n                    if nm in tests_text:\n                        cross_ref_ok = True\n                        break\n            details.append(\"cross_reference: ok\" if cross_ref_ok else \"cross_reference: fail\")\n        except Exception:\n            details.append(\"cross_reference: fail (error)\")\n\n        verified = all([code_ok, tests_ok, code_has_def, tests_has_assert, cross_ref_ok])\n        status_line = \"VERIFICATION_RESULT: PASS\" if verified else \"VERIFICATION_RESULT: FAIL\"\n        # Compute a digest of code+tests to detect stability across rounds\n        digest = hashlib.sha256((code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")).hexdigest()[:12]\n        result = f\"{status_line} | digest={digest} | \" + \"; \".join(details)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\n\n    Responsibilities:\n    - Maintain clear responsibilities (single primary action).\n    - Track processed messages to avoid duplicate processing.\n    - Provide act(message) which handles errors and returns a Message.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # Track message ids we've processed\n        self._processed_ids: Set[str] = set()\n        # Environment reference may be set by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action in response to a message.\n\n        The role will not reprocess messages (idempotency), and will log failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        # pick primary action (roles are designed for single-action)\n        action = self.actions[0]\n\n        # If message is provided but already processed, skip\n        if message and message.id in self._processed_ids:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed message {message.id}\")\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message id={getattr(message, 'id', None)}\")\n\n        try:\n            # Dispatch based on action type; keep logic explicit\n            if isinstance(action, SimpleWriteCode):\n                inp = (message.instruct_content or message.content) if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteTest):\n                # Expect to receive the latest code message (message.content holds code or reference)\n                inp = message.content if message else \"\"\n                result = await action.run(inp)\n            elif isinstance(action, SimpleWriteReview):\n                # Expects a message that contains code and/or tests combined or references to both.\n                # Try to lookup latest code and test messages in environment if message is not explicit\n                code_text = \"\"\n                tests_text = \"\"\n                if message and message.cause_by == SimpleWriteTest.name:\n                    tests_text = message.content\n                    # find latest code\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteCode.name:\n                                code_text = msg.content\n                                break\n                elif message and message.cause_by == SimpleWriteCode.name:\n                    code_text = message.content\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name:\n                                tests_text = msg.content\n                                break\n                else:\n                    # fallback: try to find both in env\n                    if self.env:\n                        for msg in reversed(self.env.history):\n                            if msg.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = msg.content\n                            if msg.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = msg.content\n                            if code_text and tests_text:\n                                break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # Find latest code and tests from environment\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_text and msg.cause_by == SimpleWriteCode.name:\n                            code_text = msg.content\n                        if not tests_text and msg.cause_by == SimpleWriteTest.name:\n                            tests_text = msg.content\n                        if code_text and tests_text:\n                            break\n                result = await action.run(code_text, tests_text)\n            else:\n                result = \"Action completed\"\n\n            # mark message processed\n            if message:\n                self._processed_ids.add(message.id)\n\n            # create response message\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name if action else \"\",\n                sent_from=self.name\n            )\n\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created id={response.id}\")\n            return response\n\n        except Exception as e:\n            # catch-all to avoid crashing the orchestrator\n            err_text = f\"Role {self.name} failed executing {action.name}: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err_text)\n            response = Message(\n                content=err_text,\n                role=self.profile,\n                cause_by=\"Error\",\n                sent_from=self.name\n            )\n            return response\n\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\n\n    Responsibilities:\n    - Store message history.\n    - Maintain subscriptions mapping from action names to roles that watch them.\n    - Provide role-specific unprocessed messages.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Map action_name -> list of roles that watch it\n        self.subscriptions: Dict[str, List[Role]] = defaultdict(list)\n        # Track which messages have been delivered to which role ids\n        self._delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n        # Register subscriptions based on watch_list\n        for watched in role.watch_list:\n            self.subscriptions[watched.name].append(role)\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment (append to history)\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {message.sent_from} ({message.cause_by}): {message.content[:200]} id={message.id}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get new messages that a role should respond to.\n\n        Criteria:\n        - Messages explicitly targeted to the role (send_to contains role.name)\n        - Messages caused by actions that this role watches\n        - Excludes messages already delivered to this role (idempotency)\n        \"\"\"\n        relevant_messages = []\n        seen = self._delivered.get(role.name, set())\n        for msg in self.history:\n            # Skip if already delivered to this role\n            if msg.id in seen:\n                continue\n            targeted = False\n            if hasattr(msg, \"send_to\") and msg.send_to:\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    targeted = True\n            # If it's targeted or it's from a watched action, include\n            if targeted or any(msg.cause_by == watched.name for watched in role.watch_list):\n                relevant_messages.append(msg)\n                seen.add(msg.id)\n        # record delivery\n        if relevant_messages:\n            self._delivered[role.name] = seen\n        return relevant_messages\n\n\nclass Team:\n    \"\"\"Team of agents working together\n\n    Improvements:\n    - Deterministic orchestration order\n    - No duplicate processing\n    - Explicit termination criteria: require stable verification (consecutive passes)\n    - Robust error handling and tracing\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Orchestration order\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # Track consecutive verification stability\n        self._last_verified_digest: Optional[str] = None\n        self._verified_streak: int = 0\n        self._required_consecutive_verifications: int = 2  # require stability across rounds\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\n\n        Termination:\n        - Stop early if verifier reports PASS for the same digest _required_consecutive_verifications_ times.\n        - Otherwise proceed up to n_round rounds.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n\n            # For each role type in orchestration order, find all roles of that type and let them act on new messages\n            for role_type in self.order:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # find messages for role\n                    messages = self.env.get_messages_for_role(role)\n                    # Choose the latest message (if multiple) to act upon, but allow acting on each new message once\n                    for msg in messages:\n                        if msg.id in getattr(role, \"_processed_ids\", set()):\n                            continue\n                        response = await role.act(msg)\n                        if response:\n                            # Tag responses to indicate they should be considered by watchers\n                            # Responses will have cause_by set by role.act\n                            response.sent_to = None\n                            self.env.publish_message(response)\n\n            # After roles acted, let verifier run (could have been triggered above)\n            # Check latest verifier messages to determine verification status\n            verifier_roles = [r for r in self.env.roles if isinstance(r, SimpleVerifier)]\n            for verifier in verifier_roles:\n                # get messages intended for verifier (env.get_messages_for_role will return new relevant ones)\n                v_msgs = self.env.get_messages_for_role(verifier)\n                for vmsg in v_msgs:\n                    if vmsg.id in getattr(verifier, \"_processed_ids\", set()):\n                        continue\n                    resp = await verifier.act(vmsg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        # parse verification result\n                        content = resp.content or \"\"\n                        if \"VERIFICATION_RESULT: PASS\" in content:\n                            # extract digest\n                            digest_part = None\n                            for tok in content.split(\"|\"):\n                                tok = tok.strip()\n                                if tok.startswith(\"digest=\"):\n                                    digest_part = tok.split(\"=\", 1)[1]\n                                    break\n                            if digest_part:\n                                if digest_part == self._last_verified_digest:\n                                    self._verified_streak += 1\n                                else:\n                                    self._last_verified_digest = digest_part\n                                    self._verified_streak = 1\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", f\"Digest={digest_part} streak={self._verified_streak}\")\n                                if self._verified_streak >= self._required_consecutive_verifications:\n                                    verified = True\n                            else:\n                                # If no digest, count as one pass but not stable\n                                self._verified_streak = 1\n                                verified = False\n                                self._last_verified_digest = None\n                                self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Pass without digest; continuing\")\n                        else:\n                            # Reset streak on fail\n                            self._verified_streak = 0\n                            self._last_verified_digest = None\n                            self.tracer.log(\"VERIFIER_STATE\", \"Team\", \"Verification failed\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed; verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_consecutive_verifications} rounds, stopping early\")\n                break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project ended after {round_num} rounds; verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (5.167)\n\n\n### Inspiration 3 (Score: 4.5990, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with error handling and retry support.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        self.max_retries = kwargs.get('max_retries', 2)\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Ask the LLM with retry and exponential backoff. Returns result or error string.\"\"\"\n        attempt = 0\n        last_err = None\n        while attempt <= self.max_retries:\n            attempt += 1\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_ASK\", self.name, f\"Attempt {attempt}/{self.max_retries+1}\")\n            try:\n                if not self.llm:\n                    return \"LLM_UNAVAILABLE: Using fallback response.\"\n                res = await self.llm.ask(messages)\n                # treat responses starting with \"Error:\" or \"Error communicating\" as failures\n                if isinstance(res, str) and (res.startswith(\"Error:\") or res.startswith(\"Error communicating\")):\n                    last_err = res\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error text: {res[:200]}\")\n                    # fall through to retry\n                else:\n                    return res\n            except Exception as e:\n                last_err = f\"Exception: {e}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, str(e))\n            # simple backoff\n            if attempt <= self.max_retries:\n                # we don't want to import time in evolve block; just log retry\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Retrying LLM ask (attempt {attempt + 1})\")\n        # all attempts failed\n        return last_err or \"LLM_UNKNOWN_ERROR\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea, with validation and retries\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea (len={len(idea or '')})\")\n        \n        if not idea or not idea.strip():\n            warning = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea; returning warning code\")\n            return warning\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.safe_ask(messages)\n        # Basic validation: ensure non-empty and syntactically parseable (best-effort)\n        import ast\n        try:\n            if not code or not isinstance(code, str) or code.strip() == \"\":\n                raise ValueError(\"Empty code returned\")\n            ast.parse(code)\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed successfully\")\n        except Exception as e:\n            # Return explicit error result so downstream roles can detect and trigger retries\n            err = f\"# CODE_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(code or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code, validate presence of test functions\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        if not code or not code.strip():\n            msg = \"# WARNING: No code to test. Generated placeholder tests.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"No code provided for tests\")\n            return msg\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.safe_ask(messages)\n        \n        # Basic validation: ensure at least one function called test_\n        import ast\n        try:\n            if not tests or not isinstance(tests, str) or tests.strip() == \"\":\n                raise ValueError(\"Empty tests returned\")\n            parsed = ast.parse(tests)\n            has_test = any(\n                isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body\n            )\n            if not has_test:\n                raise ValueError(\"No pytest-style test functions found (test_ prefix)\")\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Tests parsed and contain test_ functions\")\n        except Exception as e:\n            err = f\"# TEST_GENERATION_ERROR: {str(e)}\\n# Raw Output:\\n{(tests or '')}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Validation failed: {e}\")\n            return err\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests and provide actionable items\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        \n        if self.is_human:\n            review = \"Human review: Please verify edge cases and error handling; consider input validation.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_HUMAN_REVIEW\", self.name, \"Simulated human review provided\")\n            return review\n        \n        prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode (first 1500 chars):\n{code[:1500]}\n\nTests (first 1500 chars):\n{tests[:1500]}\n\nFocus on:\n1. Code quality and best practices\n2. Test coverage and missing edge cases\n3. Potential bugs or issues\n4. Concrete suggestions for improvement\n\nProvide a concise, actionable review.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        review = await self.safe_ask(messages)\n        if not review or not isinstance(review, str):\n            review = \"REVIEW_ERROR: No review generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, \"No review returned from LLM\")\n        else:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_END\", self.name, f\"Review generated len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        # Syntax checks\n        try:\n            if not code or not code.strip():\n                raise ValueError(\"Empty code\")\n            ast.parse(code)\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({str(e)[:120]})\")\n        try:\n            if not tests or not tests.strip():\n                raise ValueError(\"Empty tests\")\n            parsed_tests = ast.parse(tests)\n            # heuristic: presence of at least one test_ function\n            has_tests = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            if has_tests:\n                tests_ok = True\n                details.append(\"tests_syntax_and_presence: ok\")\n            else:\n                details.append(\"tests_syntax_and_presence: fail (no test_ functions found)\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({str(e)[:120]})\")\n        # Coverage heuristics: ensure functions in code are referenced by tests (simple name match)\n        coverage_ok = False\n        if code_ok and tests_ok:\n            try:\n                parsed_code = ast.parse(code)\n                func_names = {n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)}\n                # look for function names in test source\n                tests_text = tests\n                matched = [fn for fn in func_names if fn and fn in tests_text]\n                if func_names and matched:\n                    coverage_ok = True\n                    details.append(f\"coverage_hint: ok (matched functions: {matched[:5]})\")\n                else:\n                    details.append(\"coverage_hint: fail (no clear function usage in tests)\")\n            except Exception as e:\n                details.append(f\"coverage_check_error: {str(e)[:120]}\")\n        verified = code_ok and tests_ok and coverage_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    triggers_on: List[str] = []  # cause_by values this role listens for\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.triggers_on = kwargs.get('triggers_on', [])\n        # reference to env may be injected by Team.hire\n        self.env = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for (by action class)\"\"\"\n        self.watch_list = actions\n        # also set triggers_on strings for quick matching\n        self.triggers_on = [a.name for a in actions]\n    \n    def can_respond_to(self, msg: Message) -> bool:\n        \"\"\"Determine whether this role should respond to the message.\"\"\"\n        # If triggers_on empty, role acts proactively (e.g., coder on initial human input)\n        if not self.triggers_on:\n            return False\n        return msg.cause_by in self.triggers_on\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the role's primary action in a guarded manner.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        try:\n            # Map action type to expected inputs explicitly\n            if isinstance(action, SimpleWriteCode):\n                # coder expects instruction content if available, else full message content\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")\n                result = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # tester expects code in message.content\n                code = message.content if message else \"\"\n                result = await action.run(code)\n            elif isinstance(action, SimpleWriteReview):\n                # reviewer needs both code and tests. Get most recent code/tests from env\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # verifier obtains latest code/tests similar to reviewer\n                code_msg, tests_msg = None, None\n                if self.env:\n                    for msg in reversed(self.env.history):\n                        if not code_msg and msg.cause_by == SimpleWriteCode.name:\n                            code_msg = msg\n                        if not tests_msg and msg.cause_by == SimpleWriteTest.name:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                result = await action.run(message) if message else await action.run()\n        except Exception as e:\n            # Catch any unexpected errors, create a failure message describing it\n            err_text = f\"ROLE_EXCEPTION: {self.name} failed with exception {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err_text)\n            result = err_text\n        # Build a Message for the environment describing the result\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message caused by {response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # coder listens to direct user input\n        self._watch([])  # proactive; will be invoked explicitly on initial input\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with explicit delivery and cursors.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # per-role cursor to track which messages have been seen/consumed\n        self.role_cursors: Dict[str, int] = {}\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        # initialize cursor to 0 for this role (no messages consumed yet)\n        self.role_cursors[role.name] = 0\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message [{message.cause_by}] from {message.sent_from}: {message.content[:200]}\")\n    \n    def get_pending_messages_for_role(self, role: Role) -> List[tuple]:\n        \"\"\"Return list of (index, Message) that the role has not yet consumed and that match its triggers.\"\"\"\n        results = []\n        cursor = self.role_cursors.get(role.name, 0)\n        for idx in range(cursor, len(self.history)):\n            msg = self.history[idx]\n            # role can respond if msg.cause_by matches role's triggers\n            if role.triggers_on and msg.cause_by in role.triggers_on:\n                results.append((idx, msg))\n        return results\n    \n    def mark_consumed(self, role: Role, up_to_index: int):\n        \"\"\"Mark messages up to up_to_index (inclusive) as consumed for this role.\"\"\"\n        prev = self.role_cursors.get(role.name, 0)\n        new_cursor = max(prev, up_to_index + 1)\n        self.role_cursors[role.name] = new_cursor\n        if self.tracer:\n            self.tracer.log(\"ENV_CURSOR\", \"Environment\", f\"Role {role.name} cursor advanced to {new_cursor}\")\n\nclass Team:\n    \"\"\"Team of agents working together with improved orchestration, termination and verification logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # order of execution for each round\n        self.role_order = []\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n        # stable execution order: coder, tester, reviewer, verifier (by class)\n        # maintain roles in the order they were added if present\n        name_to_role = {r.__class__.__name__: r for r in self.env.roles}\n        ordered = []\n        for cname in (\"SimpleCoder\", \"SimpleTester\", \"SimpleReviewer\", \"SimpleVerifier\"):\n            r = name_to_role.get(cname)\n            if r:\n                ordered.append(r)\n        # fallback to any roles not listed\n        for r in self.env.roles:\n            if r not in ordered:\n                ordered.append(r)\n        self.role_order = ordered\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with robust termination rules.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        last_verification_index = -1\n        stable_verification_rounds = 0\n        max_stable_rounds_required = 1  # require verification to remain true across a round to stop\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            round_actions = []\n            # Special handling: on first round, explicitly invoke coder with the initial message\n            for role in self.role_order:\n                # For proactive coder (listens to user input), feed initial_msg on first round\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"Invoking coder {role.name} with initial idea\")\n                    response = await role.act(initial_msg)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # mark that coder has consumed initial input\n                        self.env.mark_consumed(role, len(self.env.history)-1)\n                    continue\n                # For other roles and later rounds, gather pending messages\n                pending = self.env.get_pending_messages_for_role(role)\n                if not pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"No pending messages for {role.name}\")\n                    continue\n                # Process each pending message in order\n                for idx, msg in pending:\n                    if self.tracer:\n                        self.tracer.log(\"ORCH\", \"Team\", f\"{role.name} responding to message idx={idx} cause_by={msg.cause_by}\")\n                    response = await role.act(msg)\n                    # Mark consumed up to this message for this role\n                    self.env.mark_consumed(role, idx)\n                    if response:\n                        self.env.publish_message(response)\n                        round_actions.append((role, response))\n                        # If verifier produced a pass, capture it\n                        if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            verified = True\n                            last_verification_index = len(self.env.history) - 1\n            # Post-round analysis: determine termination criteria\n            # If verification happened this round and is still the most recent verification result, count as stable\n            if verified:\n                # ensure that no new code/test messages after verification (to ensure stability)\n                newest_code_or_test_idx = -1\n                for i, msg in enumerate(self.env.history):\n                    if msg.cause_by in (SimpleWriteCode.name, SimpleWriteTest.name):\n                        newest_code_or_test_idx = max(newest_code_or_test_idx, i)\n                if newest_code_or_test_idx <= last_verification_index:\n                    stable_verification_rounds += 1\n                else:\n                    stable_verification_rounds = 0\n                    # If new code/tests appeared after verification, require re-verification\n                    verified = False\n                self.tracer.log(\"VER_STATUS\", \"Team\", f\"verified={verified} stable_rounds={stable_verification_rounds}\")\n            else:\n                stable_verification_rounds = 0\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed with {len(round_actions)} actions\")\n            # Terminate if verification stable for required number of rounds\n            if verified and stable_verification_rounds > max_stable_rounds_required:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification stable; stopping early\")\n                break\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (2.833)\n\n\n### Inspiration 4 (Score: 5.3704, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with clear responsibilities and LLM retry wrapper\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 2\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with exponential backoff and simple error detection.\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}\")\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM not available: fallback response.\"\n                resp = await self.llm.ask(messages)\n                # Detect common error patterns returned by LLMInterface\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or \"Error communicating\" in resp):\n                    last_err = resp\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {resp[:200]}\")\n                    # retry\n                    continue\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, f\"Attempt {attempt} exception: {last_err}\")\n        # All retries exhausted\n        return f\"LLM_FAILURE: {last_err or 'unknown'}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea (len={len(idea)})\")\n        prompt = (\n            \"You are a professional Python programmer. Produce clean, well-commented, \"\n            \"production-ready Python code for the task described.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Correct syntax\\n\"\n            \"2. Defensive error handling\\n\"\n            \"3. Clear docstrings/comments\\n\"\n            \"4. No surrounding backticks or explanation, only the code\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self._llm_call_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated code size={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code (len={len(code)})\")\n        snippet = (code or \"\")[:3000]\n        prompt = (\n            \"You are an experienced QA engineer. Write pytest-style tests for the provided Python code.\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Cover normal and edge cases\\n\"\n            \"2. Include negative tests when appropriate\\n\"\n            \"3. Use clear docstrings for each test\\n\"\n            \"4. Return only the test code\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self._llm_call_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated tests size={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests and return concise actionable feedback\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing artifacts (human={self.is_human})\")\n        if self.is_human:\n            review = \"Human review simulated: consider more input validation and docstrings.\"\n        else:\n            snippet_code = (code or \"\")[:2000]\n            snippet_tests = (tests or \"\")[:2000]\n            prompt = (\n                \"You are a senior engineer performing a concise code + test review.\\n\\n\"\n                f\"Code:\\n{snippet_code}\\n\\nTests:\\n{snippet_tests}\\n\\n\"\n                \"Focus on:\\n\"\n                \"1. Correctness and likely runtime issues\\n\"\n                \"2. Test coverage gaps\\n\"\n                \"3. Practical suggestions (1-3 items)\\n\"\n                \"Return a short review.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self._llm_call_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        issues: List[str] = []\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Starting verification\")\n\n        # Basic non-empty checks\n        if not (code and code.strip()):\n            issues.append(\"code_empty\")\n        if not (tests and tests.strip()):\n            issues.append(\"tests_empty\")\n\n        # Syntax checks\n        code_ok = False\n        tests_ok = False\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:200]}\")\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = True\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:200]}\")\n\n        # Cross-reference: ensure tests mention at least one function/class name from code\n        try:\n            code_ast = ast.parse(code or \"\")\n            def_names = {n.name for n in ast.walk(code_ast) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            tests_ast = ast.parse(tests or \"\")\n            tests_identifiers = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n            if def_names and def_names.isdisjoint(tests_identifiers):\n                issues.append(\"tests_may_not_reference_code_defs\")\n        except Exception:\n            # already captured syntax errors above, ignore here\n            pass\n\n        verified = (code_ok and tests_ok and not any(i.startswith(\"tests_may_not_reference\") for i in issues))\n        status = {\n            \"verified\": verified,\n            \"issues\": issues,\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok\n        }\n        result_lines = [f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'}\"]\n        if issues:\n            result_lines.append(\"ISSUES: \" + \"; \".join(issues))\n        result = \" | \".join(result_lines)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit watch/trigger logic and idempotency\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track processed message ids to avoid reprocessing\n        self._processed_message_ids: Set[str] = set()\n        # env reference will be attached by Team.hire\n        self.env = getattr(self, 'env', None)\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide if this role should respond to the given message\"\"\"\n        if message is None:\n            return False\n        # If message explicitly targeted this role by name/profile\n        if getattr(message, \"send_to\", None):\n            targets = set(message.send_to)\n            if self.name in targets or self.profile in targets:\n                return True\n        # If role watches the causing action type\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # Also ignore messages we've already processed\n        if getattr(message, \"id\", None) in self._processed_message_ids:\n            return False\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action for this role based on the message.\n        Returns a Message or None.\n        This base implementation supports single-action roles.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Preparing to execute {action.name}\")\n\n        # If message provided but role decides it should not respond, skip\n        if message and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message {getattr(message, 'id', '')}\")\n            return None\n\n        try:\n            # Dispatch to appropriate behavior by action name\n            if action.name == SimpleWriteCode.name:\n                idea = (message.instruct_content or message.content) if message else \"\"\n                out = await action.run(idea)\n                # Create message routing to Tester\n                send_to = {\"SimpleTester\"}\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # Prefer to act on the latest code artifact visible\n                code_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteCode.name])\n                code_text = code_msg.content if code_msg else \"\"\n                out = await action.run(code_text)\n                # Route to Reviewer and Verifier\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # Gather latest code and tests\n                code_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteCode.name])\n                tests_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteTest.name])\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                out = await action.run(code_text, tests_text)\n                # Route review to Verifier and Coder for improvements\n                send_to = {\"SimpleVerifier\", \"SimpleCoder\"}\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # Gather latest code and tests\n                code_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteCode.name])\n                tests_msg = self.env.get_latest_artifact(cause_names=[SimpleWriteTest.name])\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                out = await action.run(code_text, tests_text)\n                # Verification messages are broadcast for team decision\n                send_to = set()  # broadcast\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                out = \"Action executed (noop)\"\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=set()\n                )\n        except Exception as e:\n            # Robust error handling: log and create a failure message\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, f\"Exception during act: {str(e)}\")\n            response = Message(\n                content=f\"ERROR: {str(e)}\",\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to=set()\n            )\n\n        # Mark the input message as processed to avoid reprocessing\n        if message and getattr(message, \"id\", None):\n            self._processed_message_ids.add(message.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message {getattr(response, 'id', '')[:8]} cause_by={response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder initiates on UserInput\n        self._watch([ ])  # empty; will respond to messages explicitly targeted\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watches code-writing actions\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        # Watches tests to provide review\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        # Watches tests (and reviews implicitly)\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with improved routing\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # quick index of messages by cause_by for artifact lookup\n        self._index_by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        # attach env on the role instance\n        setattr(role, 'env', self)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and index it\"\"\"\n        # Ensure message has an id (pydantic variant already does)\n        if not getattr(message, \"id\", None):\n            message.id = str(uuid.uuid4())\n        self.history.append(message)\n        # index by cause_by\n        cb = getattr(message, \"cause_by\", \"\")\n        if cb:\n            self._index_by_cause.setdefault(cb, []).append(message)\n        if self.tracer:\n            snippet = (message.content or \"\")[:200].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {message.sent_from} cause_by={cb} send_to={getattr(message, 'send_to', set())} content={snippet}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            # skip messages the role already processed\n            if getattr(msg, \"id\", None) in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # explicit routing takes precedence\n            if getattr(msg, \"send_to\", None):\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    relevant_messages.append(msg)\n                    continue\n            # otherwise use watch_list matching cause_by\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\n    def get_latest_artifact(self, cause_names: List[str]) -> Optional[Message]:\n        \"\"\"Return the most recent message whose cause_by is in cause_names\"\"\"\n        for name in cause_names:\n            msgs = self._index_by_cause.get(name, [])\n            if msgs:\n                return msgs[-1]\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together with robust orchestration and termination logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # track verification stability: require N consecutive PASS to accept\n        self._consecutive_verification_passes = 0\n        self._verification_threshold = 2  # require two consecutive passes to avoid fluke\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with clear orchestration, retries, and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Initial message with the idea targeted at the coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"Alice\", \"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified_overall = False\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            new_messages_this_round = 0\n\n            # Iterate over a fixed, orchestrated order to reduce race conditions:\n            orchestration = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n            for RoleClass in orchestration:\n                for role in [r for r in self.env.roles if isinstance(r, RoleClass)]:\n                    # get messages that role should handle\n                    incoming = self.env.get_messages_for_role(role)\n                    if not incoming:\n                        # allow coder to be triggered on first round by initial message\n                        if RoleClass is SimpleCoder and round_num == 1:\n                            incoming = [initial_msg]\n                    # Process each incoming message (deterministic order: newest first)\n                    for msg in incoming:\n                        # Attempt action with limited retries\n                        attempts = 0\n                        max_attempts = 2\n                        while attempts < max_attempts:\n                            try:\n                                attempts += 1\n                                response = await role.act(msg)\n                                if response:\n                                    self.env.publish_message(response)\n                                    new_messages_this_round += 1\n                                    # If verifier produced a PASS, update counters\n                                    if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                        self._consecutive_verification_passes += 1\n                                        self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"Consecutive passes={self._consecutive_verification_passes}\")\n                                    elif isinstance(role, SimpleVerifier):\n                                        # reset if fail\n                                        self._consecutive_verification_passes = 0\n                                break  # success or handled, break retry loop\n                            except Exception as e:\n                                # Log and decide to retry\n                                self.tracer.log(\"ROLE_RUN_ERROR\", role.name, f\"Attempt {attempts} failed: {str(e)}\")\n                                if attempts >= max_attempts:\n                                    # produce an error message into environment\n                                    err_msg = Message(\n                                        content=f\"ERROR: role {role.name} failed after {attempts} attempts: {str(e)}\",\n                                        role=role.profile,\n                                        cause_by=\"RoleRunError\",\n                                        sent_from=role.name,\n                                        send_to=set()\n                                    )\n                                    self.env.publish_message(err_msg)\n                                    new_messages_this_round += 1\n                                else:\n                                    # small implicit backoff - next loop iteration will retry\n                                    continue\n\n            # After all roles, determine termination conditions\n            if self._consecutive_verification_passes >= self._verification_threshold:\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Verification stable for {self._verification_threshold} rounds, stopping\")\n                verified_overall = True\n                break\n\n            if new_messages_this_round == 0:\n                # no progress made this round; stop to avoid infinite loop\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No new messages produced this round; stopping early\")\n                break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed with {new_messages_this_round} new messages\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' ended. Rounds executed={round_num}. Messages exchanged={len(self.env.history)}. Verified={verified_overall}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (3.500)\n\n\n### Inspiration 5 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class. Actions return structured results (dict) when possible.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 4  # increased retries for robustness\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def ask_with_retry(self, messages: List[Dict[str, str]], timeout_s: float = 2.0) -> str:\n        \"\"\"Call LLM with exponential backoff, jitter, and improved error detection.\"\"\"\n        import asyncio\n        import random\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_UNUSED: fallback response\"\n                resp = await self.llm.ask(messages)\n                if resp is None:\n                    last_err = \"LLM returned None\"\n                else:\n                    # Detect common error patterns and too-short answers\n                    if isinstance(resp, str) and (resp.startswith(\"Error\") or len(resp.strip()) < 8):\n                        last_err = resp\n                    else:\n                        return resp\n            except Exception as e:\n                last_err = str(e)\n            # log retry\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(last_err)[:200]}\")\n            # exponential backoff with jitter\n            await asyncio.sleep(timeout_s * (2 ** (attempt - 1)) + random.uniform(0, 0.5))\n        # All retries exhausted\n        err_msg = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action and return a structured dict if possible.\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> Dict[str, Any]:\n        \"\"\"Generate code based on the idea. Returns dict with status and payload.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.ask_with_retry(messages)\n        status = \"ok\" if code and not code.startswith(\"Error\") and not code.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code) if isinstance(code,str) else 0} characters of code; status={status}\")\n        return {\"status\": status, \"payload\": code or \"\", \"meta\": {\"idea\": idea}}\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> Dict[str, Any]:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        # Truncate large code to keep prompt reasonable\n        code_snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code_snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.ask_with_retry(messages)\n        status = \"ok\" if tests and not tests.startswith(\"Error\") and not tests.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests) if isinstance(tests,str) else 0} characters of tests; status={status}\")\n        return {\"status\": status, \"payload\": tests or \"\", \"meta\": {\"code_summary\": code_snippet[:200]}}\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Review the code and tests. Returns {'status': 'ok'/'needs_changes', 'payload': review_text, 'meta': {...}}\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            status = \"ok\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nReturn a short structured verdict line at the top: VERDICT: ok OR VERDICT: needs_changes\nThen provide actionable comments. Keep it concise.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            review = await self.ask_with_retry(messages)\n            if isinstance(review, str) and review.strip().startswith(\"VERDICT:\"):\n                first_line = review.splitlines()[0].strip()\n                verdict = first_line.replace(\"VERDICT:\", \"\").strip().lower()\n                status = \"ok\" if verdict == \"ok\" else \"needs_changes\"\n            else:\n                # fallback heuristic\n                status = \"needs_changes\" if \"bug\" in (review or \"\").lower() or \"issue\" in (review or \"\").lower() else \"ok\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters; status={status}\")\n        \n        return {\"status\": status, \"payload\": review or \"\", \"meta\": {}}\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Return a structured verification result with diagnostics.\"\"\"\n        import ast, re, textwrap\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        fn_names = []\n        try:\n            # Verify code syntax\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            fn_names = [n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)]\n            details.append(f\"functions:{','.join(fn_names) if fn_names else 'none'}\")\n        except Exception as e:\n            details.append(f\"code_syntax_error:{str(e)[:200]}\")\n            fn_names = []\n            code_ok = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # Heuristics: tests must have at least one test_ function and an assert\n            contains_assert = bool(re.search(r\"\\bassert\\b\", tests or \"\"))\n            contains_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            tests_ok = contains_assert and contains_testfn\n            if not contains_assert:\n                details.append(\"tests_missing_asserts\")\n            if not contains_testfn:\n                details.append(\"tests_missing_test_functions\")\n        except Exception as e:\n            details.append(f\"tests_syntax_error:{str(e)[:200]}\")\n            tests_ok = False\n        # Ensure tests reference code symbols\n        references_code = False\n        try:\n            if fn_names:\n                for fn in fn_names:\n                    # simple substring check is conservative but quick\n                    if fn and fn in (tests or \"\"):\n                        references_code = True\n                        break\n                if not references_code:\n                    details.append(\"tests_do_not_reference_code\")\n            else:\n                # If no functions in code, accept tests if tests parse and have asserts/test fns\n                references_code = True if tests_ok else False\n        except Exception:\n            details.append(\"tests_reference_check_failed\")\n            references_code = False\n        verified = code_ok and tests_ok and references_code\n        status = \"PASS\" if verified else \"FAIL\"\n        # Add a coverage heuristic: count asserts and test functions\n        try:\n            num_asserts = (tests or \"\").count(\"assert\")\n            num_test_fns = 0\n            parsed_tests = ast.parse(tests or \"\")\n            num_test_fns = sum(1 for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\"))\n            details.append(f\"asserts:{num_asserts}\")\n            details.append(f\"test_functions:{num_test_fns}\")\n        except Exception:\n            pass\n        result_payload = {\"status\": status, \"details\": details, \"verified\": verified}\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"VERIFICATION_RESULT: {status} | details={';'.join(details)}\")\n        return result_payload\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibilities, watch/trigger logic, and retries\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track messages already processed to avoid duplicates\n        self._processed_message_ids: Set[str] = set()\n        # role maintains a small cache of last outputs to avoid repeating work\n        self._last_outputs: List[str] = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message based on watch list and send_to.\"\"\"\n        # Skip if already processed\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # If message explicitly addressed to this role/profile\n        if getattr(message, \"send_to\", None):\n            if self.profile in message.send_to or self.name in message.send_to:\n                return True\n            # addressed to everyone\n            if \"*\" in message.send_to:\n                return True\n        # If message cause_by is one of the watched actions\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # If message is human instruction (UserInput) coders should respond\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and self.profile.lower().find(\"coder\") >= 0:\n            return True\n        return False\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Perform an action based on the message with robust error handling, retries,\n        and standardized structured processing of action results.\n        \"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        \n        # If message exists but this role should not respond, skip\n        if message is not None and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n        \n        # Prepare inputs to action depending on action type, with safe defaults\n        def _gather_code_tests_from_env():\n            env = getattr(self, 'env', None)\n            code = \"\"\n            tests = \"\"\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteTest.name and not tests:\n                        tests = msg.content\n                    if msg.cause_by == SimpleWriteCode.name and not code:\n                        code = msg.content\n                    if code and tests:\n                        break\n            return code, tests\n        \n        attempts = 0\n        last_err = None\n        from asyncio import sleep\n        max_attempts = 3\n        while attempts < max_attempts:\n            attempts += 1\n            try:\n                # Determine input for action types\n                result = None\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                elif isinstance(action, SimpleWriteTest):\n                    # Expect code content to be in the message or env\n                    content = getattr(message, \"content\", \"\") or \"\"\n                    if not content:\n                        code, _ = _gather_code_tests_from_env()\n                        content = code\n                    result = await action.run(content)\n                elif isinstance(action, SimpleWriteReview):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message is tests, prefer message content as tests\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        tests = getattr(message, \"content\", tests)\n                    result = await action.run(code, tests)\n                elif isinstance(action, SimpleVerify):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message provides tests or code, prefer them\n                    if message:\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                            tests = getattr(message, \"content\", tests)\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                            code = getattr(message, \"content\", code)\n                    result = await action.run(code, tests)\n                else:\n                    # Generic action\n                    result = await action.run()  # type: ignore\n                # Normalize result to structured dict\n                if isinstance(result, dict):\n                    status = result.get(\"status\") or (\"ok\" if result.get(\"verified\") else \"unknown\")\n                    payload = result.get(\"payload\") if \"payload\" in result else (str(result))\n                    meta = result.get(\"meta\", {})\n                else:\n                    # older behavior: string\n                    payload = str(result or \"\")\n                    status = \"ok\" if not payload.startswith(\"Error\") and \"VERIFICATION_RESULT: PASS\" not in payload else (\"pass\" if \"PASS\" in payload else \"error\")\n                    meta = {}\n                \n                # Mark message processed to avoid double handling\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Keep last outputs (small history)\n                try:\n                    self._last_outputs.append(payload)\n                    if len(self._last_outputs) > 8:\n                        self._last_outputs = self._last_outputs[-8:]\n                except Exception:\n                    pass\n                \n                # Decide recipients based on action type and status\n                recipients = set()\n                cause_name = action.name if action else \"\"\n                if isinstance(action, SimpleWriteCode):\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # If review says ok -> verifier & coder, else coder primarily\n                    if status == \"ok\" or status == \"ok\":\n                        recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                    else:\n                        recipients = {\"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    recipients = {\"Team\"}\n                else:\n                    recipients = {\"Team\"}\n                \n                # Build standardized message content for downstream parsing\n                # Use a short header and include payload (full payload may be long)\n                header = f\"RESULT|{cause_name}|{status}\"\n                content_str = header + \"\\n\" + (payload or \"\")\n                response = Message(\n                    content=content_str,\n                    role=self.profile,\n                    cause_by=cause_name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action succeeded, created message id={(getattr(response,'id',None))}; status={status}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # Backoff before retrying\n                await sleep(0.5 * attempts)\n        # If we reach here, action failed consistently\n        fail_msg = f\"ROLE_FAILED: {self.name} could not complete action after {attempts} attempts. Error={last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with clear message routing and deduplication\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and trace it\"\"\"\n        # Prevent duplicate identical messages (by content + sender) flooding\n        try:\n            if any(m.id == message.id for m in self.history):\n                # already published\n                return\n        except Exception:\n            pass\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:200]} | cause_by={getattr(message,'cause_by',None)} | send_to={getattr(message,'send_to',None)}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Get messages that a role should respond to.\n        This respects explicit addressing (send_to) and the role's watch_list.\n        It also filters messages already processed by the role.\n        \"\"\"\n        relevant_messages = []\n        for msg in list(self.history):\n            # Skip messages the role already processed\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # If explicitly addressed\n            if getattr(msg, \"send_to\", None):\n                if role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to:\n                    relevant_messages.append(msg)\n                    continue\n            # If message cause_by matches watch_list\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        # Return in chronological order (oldest first) to preserve causal flow\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together with robust termination and verification logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification confirmation count to avoid premature termination\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2  # require two independent confirmations\n        self._review_ok_count = 0\n        self._stable_rounds_after_verify = 0\n        self._required_stable_rounds = 1  # require a round of stability after verification\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with stronger orchestration and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (verify confirmations needed={self._verify_confirm_needed})\")\n        \n        # Initial message with the idea, explicitly addressed to the coder role\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        # We'll track rounds where no progress is made to avoid infinite loops\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            progress_made = False\n            \n            # Orchestrated sequence: evaluate each role each round; roles pick relevant messages\n            for role in list(self.env.roles):\n                relevant = self.env.get_messages_for_role(role)\n                # Ensure coder receives the initial instruction on first round\n                msgs_to_process = relevant\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    msgs_to_process = [initial_msg] + [m for m in relevant if m.id != initial_msg.id]\n                for msg in msgs_to_process:\n                    resp = await role.act(msg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        progress_made = True\n                        # Process verifier outputs\n                        if isinstance(role, SimpleVerifier):\n                            # standardized content begins with RESULT|SimpleVerify|PASS/FAIL\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"PASS\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content):\n                                    self._verify_confirm_count += 1\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} reported PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                elif \"FAIL\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: FAIL\" in resp.content):\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_FAIL\", \"Team\", f\"Verifier {role.name} reported FAIL; resetting confirmations\")\n                            except Exception as e:\n                                self.tracer.log(\"VERIFY_ERROR\", \"Team\", f\"Could not parse verifier result: {e}\")\n                        # Process reviewer outputs for acceptance\n                        if isinstance(role, SimpleReviewer):\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"VERDICT: ok\" in resp.content.lower() or \"result|simplewritereview|ok\" in header.lower():\n                                    self._review_ok_count += 1\n                                    self.tracer.log(\"REVIEW_OK\", \"Team\", f\"Reviewer {role.name} returned ok ({self._review_ok_count})\")\n                                else:\n                                    # reviewer requested changes -> reset verifier confirmations to force rework\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"REVIEW_NEEDS_CHANGES\", \"Team\", f\"Reviewer {role.name} requested changes; resetting verify confirmations\")\n                            except Exception:\n                                pass\n                        # Handle explicit role failures\n                        if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                            self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure noted: {resp.content[:200]}\")\n            # detect progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n            \n            # Check for stable verification: require multiple verifier confirmations and at least one reviewer ok\n            if self._verify_confirm_count >= self._verify_confirm_needed and self._review_ok_count >= 1:\n                self._stable_rounds_after_verify += 1\n                self.tracer.log(\"TEAM_VERIFY_STABLE\", \"Team\", f\"Stable verification observed for {self._stable_rounds_after_verify} rounds\")\n                if self._stable_rounds_after_verify >= self._required_stable_rounds:\n                    verified = True\n            else:\n                self._stable_rounds_after_verify = 0\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed (progress_made={progress_made})\")\n            # Termination conditions\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification and review confirmed; stopping early at round {round_num + 1}\")\n                break\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds, stopping early to conserve resources\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified} (verify_confirms={self._verify_confirm_count}, review_ok={self._review_ok_count})\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach, Alternative combined_score approach, Excellent avg_failures_per_task (12.000)\n\n\n\n# Current Program\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nfrom collections import defaultdict\nfrom typing import Tuple\n\ndef _preview(text: Optional[str], length: int = 120) -> str:\n    if not text:\n        return \"\"\n    return text if len(text) <= length else text[:length] + \"...\"\n\ndef _normalize_send_to(message: Message) -> Set[str]:\n    s = getattr(message, \"send_to\", None)\n    if s is None:\n        s = set(getattr(message, \"sent_to\", set()) or set())\n    return set(s or set())\n\nclass Action(ABC):\n    \"\"\"Base Action: clear contract, robust LLM calls with retries/backoff and deterministic fallbacks.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    backoff_base: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            try:\n                self.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self.llm = None\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, exponential backoff, error detection, logging, deterministic fallback.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and (resp.strip().lower().startswith(\"error\") or \"error communicating\" in resp.lower()):\n                    last_err = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error-ish response: {resp[:200]}\")\n                    await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n                    continue\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"LLM responded (len={len(resp)}) on attempt {attempt}\")\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, f\"Attempt {attempt} exception: {last_err[:200]}\")\n                await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)))\n                continue\n        final = f\"LLM_CALL_FAILED: {last_err or 'unknown'}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Responsible: generate an initial implementation for the idea, validate syntactic correctness.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_preview={_preview(idea,200)}\")\n        prompt = (\n            \"You are an expert Python programmer. Produce a single Python module implementing the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no surrounding markdown).\\n\"\n            \"- Include docstrings, basic input validation and error handling.\\n\"\n            \"- Ensure at least one function or class is defined.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        code = await self.safe_ask(messages)\n\n        # Validate syntax; fallback to deterministic placeholder on failure\n        try:\n            if not isinstance(code, str):\n                raise ValueError(\"Non-string LLM response\")\n            ast.parse(code)\n            if tracer:\n                tracer.log(\"ACTION_VALIDATE\", self.name, \"Code parsed successfully\")\n        except Exception as e:\n            fallback = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation: LLM failed to produce valid code.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback code due to parse error: {type(e).__name__}: {str(e)[:200]}\")\n            code = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"produced_len={len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Responsible: produce pytest-style tests for a module, with heuristics and fallback.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided Python module.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Include docstrings and clear asserts.\\n\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        tests = await self.safe_ask(messages)\n\n        # Heuristic validation: ensure tests contain 'def test_' or 'assert'\n        if not isinstance(tests, str) or (\"def test_\" not in tests and \"assert \" not in tests and \"pytest\" not in tests.lower()):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using fallback tests due to insufficient LLM output\")\n            tests = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Responsible: review code and tests and produce an explicit decision line.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_SUMMARY: Human review - OK with minor suggestions.\\nREVIEW_DECISION: APPROVE\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n\n        prompt = (\n            \"You are a senior code reviewer. Provide a concise review and conclude with an explicit line:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGE\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:2000]}\\n\\nTests (truncated):\\n{(tests or '')[:2000]}\\n\\n\"\n            \"Return plain text; place the decision on a line starting with REVIEW_DECISION:.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        review = await self.safe_ask(messages)\n\n        if not isinstance(review, str) or \"REVIEW_DECISION:\" not in review:\n            # Heuristic decision to avoid blocking pipeline\n            decision = \"APPROVE\" if (\"def test_\" in (tests or \"\") or \"assert \" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REQUEST_CHANGE\"\n            review = (review or \"Automated review.\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"No explicit decision from LLM; inferred {decision}\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Responsible: deterministic verification, strong validation, and stability digest.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        referenced = False\n\n        # Syntax check for code\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # Syntax + content check for tests\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            if \"def test_\" in (tests or \"\") or \"assert \" in (tests or \"\"):\n                tests_ok = True\n                details.append(\"tests_presence_and_syntax: ok\")\n            else:\n                details.append(\"tests_presence_and_syntax: fail (no pytest tests or asserts found)\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # Extract code entities and check references\n        code_entities: Set[str] = set()\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(f\"code_entities_count: {len(code_entities)}\")\n\n        if parsed_tests and code_entities:\n            tests_text = tests or \"\"\n            for ent in code_entities:\n                if ent and ent in tests_text:\n                    referenced = True\n                    break\n            details.append(f\"tests_reference_code_entities: {referenced}\")\n\n        verified = bool(code_ok and tests_ok and referenced)\n\n        # Stable digest for artifacts\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--TESTS--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if verified else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base Role:\n    - Single primary responsibility\n    - Explicit watch/trigger list (strings)\n    - Idempotent processing using processed set\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: List[str] = []  # list of cause_by strings\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = [a.name if hasattr(a, \"name\") else str(a) for a in actions]\n\n    def should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not message:\n            return False\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed {msg_id}\")\n            return False\n        # explicit addressing\n        targets = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n        if targets:\n            try:\n                if isinstance(targets, (set, list)):\n                    if self.name in targets or self.profile in targets:\n                        return True\n                else:\n                    if targets == self.name or targets == self.profile:\n                        return True\n            except Exception:\n                pass\n        # watched cause_by\n        if getattr(message, \"cause_by\", None) in self.watch_list:\n            return True\n        # human input defaults to coder\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute role's primary action if message applicable. Returns Message or None.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        if message and not self.should_respond_to(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Message not relevant cause_by={getattr(message,'cause_by',None)}\")\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing {self.action.name} on message {msg_id or 'N/A'}\")\n\n        try:\n            # Dispatch inputs according to action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or (getattr(message, \"content\", \"\") if message else \"\")\n                out = await self.action.run(idea or \"\")\n                send_to = {\"SimpleTester\"}\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleWriteTest):\n                # prefer code in message, else fetch latest code artifact\n                code_text = getattr(message, \"content\", \"\") if message else \"\"\n                if not code_text and self.env:\n                    code_text = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                out = await self.action.run(code_text or \"\")\n                send_to = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleWriteReview):\n                code_text = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests_text = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                out = await self.action.run(code_text, tests_text)\n                # route to verifier by default, to coder/tester if review requests changes\n                send_to: Set[str] = {\"SimpleVerifier\"}\n                if \"REVIEW_DECISION: REQUEST_CHANGE\" in (out or \"\"):\n                    send_to.update({\"SimpleCoder\", \"SimpleTester\"})\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=send_to)\n            elif isinstance(self.action, SimpleVerify):\n                code_text = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests_text = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                out = await self.action.run(code_text, tests_text)\n                # verification broadcast to all roles (no explicit send_to required)\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name, sent_from=self.name, send_to=set())\n            else:\n                # generic\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                resp = Message(content=out, role=self.profile, cause_by=self.action.name if self.action else \"\", sent_from=self.name, send_to=set())\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {type(e).__name__}: {str(e)[:200]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            resp = Message(content=err, role=self.profile, cause_by=\"RoleException\", sent_from=self.name, send_to=set())\n\n        # Mark processed to ensure idempotency\n        if msg_id:\n            self._processed.add(msg_id)\n        # Also mark produced message as processed by this role (avoid self-reception)\n        try:\n            self._processed.add(getattr(resp, \"id\", \"\"))\n        except Exception:\n            pass\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message {getattr(resp,'id',None)[:8]} cause_by={resp.cause_by} send_to={_normalize_send_to(resp)}\")\n        return resp\n\n\nclass SimpleCoder(Role):\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # proactive / triggered by user input\n\n\nclass SimpleTester(Role):\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\n\nclass SimpleVerifier(Role):\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"Environment: deterministic queue, subscriptions, delivered tracking, artifact helpers.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)  # cause_by -> set of role.profile\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)  # message.id -> set of role.name\n        self.message_queue: List[Message] = []\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n        for watched in getattr(role, \"watch_list\", []):\n            self.subscriptions.setdefault(watched, set()).add(role.profile)\n\n    def publish_message(self, message: Message):\n        # Normalize send_to\n        try:\n            message.send_to = _normalize_send_to(message)\n        except Exception:\n            message.send_to = set()\n        # Ensure id exists (pydantic does) otherwise assign\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self.delivered.setdefault(getattr(message, \"id\", \"\"), set())\n        self.message_queue.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_PUBLISH\", \"Environment\", f\"Published msg {getattr(message,'id','')} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content,120)} send_to={sorted(list(message.send_to))[:10]}\")\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return getattr(msg, \"content\", \"\")\n        return None\n\n    def get_relevant_roles(self, message: Message) -> List[Role]:\n        \"\"\"Return roles that should receive the message based on explicit send_to or subscriptions.\"\"\"\n        targets = set(getattr(message, \"send_to\", set()) or set())\n        relevant: List[Role] = []\n        if targets:\n            for r in self.roles:\n                if r.profile in targets:\n                    if r.name not in self.delivered.get(getattr(message, \"id\", \"\"), set()):\n                        relevant.append(r)\n            return relevant\n        # else use subscriptions (watchers)\n        watchers = self.subscriptions.get(getattr(message, \"cause_by\", \"\"), set())\n        for r in self.roles:\n            if r.profile in watchers:\n                if r.name not in self.delivered.get(getattr(message, \"id\", \"\"), set()):\n                    relevant.append(r)\n        return relevant\n\n    def mark_delivered(self, message: Message, role: Role):\n        mid = getattr(message, \"id\", None)\n        if mid:\n            self.delivered.setdefault(mid, set()).add(role.name)\n\n\nclass Team:\n    \"\"\"\n    Team orchestrator:\n    - Deterministic message queue draining\n    - Requires stable verification (identical digest) for consecutive confirmations\n    - Nudges to avoid deadlock\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = 2  # require two consecutive identical PASS digests\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {_preview(idea,200)}\")\n\n    async def _process_one_message(self, message: Message) -> bool:\n        \"\"\"Dispatch a message to relevant roles. Return True if stable verification achieved.\"\"\"\n        verified_detected = False\n        relevant = self.env.get_relevant_roles(message)\n        if not relevant:\n            # fallback: roles that watch the cause_by\n            relevant = [r for r in self.env.roles if getattr(message, \"cause_by\", \"\") in r.watch_list]\n        for role in relevant:\n            try:\n                if self.tracer:\n                    self.tracer.log(\"TEAM_DISPATCH\", \"Team\", f\"Dispatching {getattr(message,'id','')} to {role.name}\")\n                resp = await role.act(message)\n                self.env.mark_delivered(message, role)\n                if resp:\n                    self.env.publish_message(resp)\n                    # detect verification pass\n                    if getattr(resp, \"cause_by\", \"\") == SimpleVerify.name and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                        # extract digest\n                        digest = None\n                        for part in (resp.content or \"\").split(\"|\"):\n                            p = part.strip()\n                            if p.startswith(\"digest=\"):\n                                digest = p.split(\"=\",1)[1]\n                                break\n                        if digest:\n                            if digest == self._last_digest:\n                                self._streak += 1\n                            else:\n                                self._last_digest = digest\n                                self._streak = 1\n                            self.tracer.log(\"VERIFIER_UPDATE\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                            if self._streak >= self._required_streak:\n                                verified_detected = True\n                        else:\n                            # treat as non-stable pass\n                            self._streak = 0\n                            self._last_digest = None\n                            self.tracer.log(\"VERIFIER_NONSTABLE\", \"Team\", \"Verifier PASS without digest - not stable\")\n            except Exception as e:\n                self.tracer.log(\"TEAM_ROLE_EXCEPTION\", \"Team\", f\"Role {role.name} exception: {type(e).__name__}: {str(e)[:200]}\")\n                continue\n        return verified_detected\n\n    async def _drain_queue(self, max_steps: int = 1000) -> bool:\n        steps = 0\n        while self.env.message_queue and steps < max_steps:\n            steps += 1\n            message = self.env.message_queue.pop(0)\n            if self.tracer:\n                self.tracer.log(\"QUEUE_DEQUEUE\", \"Team\", f\"Dequeued {getattr(message,'id','')} cause_by={message.cause_by} preview={_preview(message.content,100)}\")\n            verified = await self._process_one_message(message)\n            # allow loop to yield for async LLM calls\n            await asyncio.sleep(0)\n            if verified:\n                return True\n        if steps >= max_steps:\n            if self.tracer:\n                self.tracer.log(\"QUEUE_MAX\", \"Team\", f\"Reached max steps {max_steps} while draining queue\")\n        return False\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Main run: publish initial kickoff, process queue until stable verification achieved, nudge if deadlocked.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_required={self._required_streak})\")\n        # initial kickoff targeted to coders\n        coder_profiles = {r.profile for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_profiles\n        )\n        self.env.publish_message(initial)\n        verified_overall = False\n        rounds_executed = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            stable = await self._drain_queue(max_steps=500)\n            if stable:\n                verified_overall = True\n                self.tracer.log(\"TEAM_VERIFIED\", \"Team\", f\"Stable verification achieved at round {rnd}\")\n                break\n\n            # If drained with no queue entries produced, nudge coders to avoid deadlock\n            if not self.env.message_queue:\n                self.tracer.log(\"ROUND_NO_PROGRESS\", \"Team\", \"No messages in queue after drain; issuing nudges\")\n                for coder in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                    nudge = Message(\n                        content=f\"Nudge: please propose or refine implementation for '{_preview(self.idea,120)}'\",\n                        instruct_content=self.idea,\n                        role=\"System\",\n                        sent_from=\"Orchestrator\",\n                        cause_by=\"Nudge\",\n                        send_to={coder.profile}\n                    )\n                    self.env.publish_message(nudge)\n                # process nudges\n                more_stable = await self._drain_queue(max_steps=200)\n                if more_stable:\n                    verified_overall = True\n                    break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed. history_len={len(self.env.history)}\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds_executed} rounds. Verified={verified_overall} messages={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds_executed} verified={verified_overall} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}