{"id": "8286f366-9a74-4b55-952f-e76b7c9f8003_migrant_3", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry and robust error handling\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    retry_backoff: float = 0.5  # base seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Call LLM with retries and backoff. Treat known error patterns as failures to retry.\n        Returns a string with result or an explicit error message.\n        \"\"\"\n        import asyncio\n        attempt = 0\n        last_error = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if not self.llm:\n                    # Local fallback\n                    response = \"LLM_NOT_AVAILABLE: fallback response\"\n                else:\n                    response = await self.llm.ask(messages)\n                # Treat structured error responses as failures\n                if isinstance(response, str) and response.startswith(\"Error\"):\n                    last_error = response\n                    raise RuntimeError(response)\n                # Success\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_OK\", self.name, f\"LLM responded (len={len(response)}) on attempt {attempt}\")\n                return response\n            except Exception as e:\n                last_error = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_FAIL\", self.name,\n                                            f\"Attempt {attempt} failed: {last_error}\")\n                if attempt < self.max_retries:\n                    await asyncio.sleep(self.retry_backoff * attempt)\n                else:\n                    # final give up\n                    break\n        # Final failure\n        err_msg = f\"LLM_FAILURE after {self.max_retries} attempts: {last_error}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_GIVEUP\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea with robust prompting and error handling\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:120]}\")\n\n        prompt = f\"\"\"You are a professional programmer. Write production-ready Python code for the following task.\nTask:\n{idea}\n\nRequirements:\n- Write clean, functional Python code.\n- Include error handling and docstrings.\n- Keep functions small and testable.\n- Include a short usage example in comments.\nReturn only the Python code. Do not include explanatory text.\"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        code = await self._llm_call(messages)\n\n        # Basic post-processing: ensure we return a non-empty string\n        if not code or code.startswith(\"LLM_FAILURE\") or code.startswith(\"Error\"):\n            fallback = f\"# ERROR_GENERATING_CODE: {code[:200]}\\n# Please check LLM logs.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Falling back to placeholder code\")\n            code = fallback\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} chars\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code, with heuristics and retries\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n\n        truncated_code = (code or \"\")[:4000]\n        prompt = f\"\"\"You are a QA engineer. Write pytest-style tests for the following Python code.\n\nCode:\n{truncated_code}\n\nRequirements:\n- Provide pytest test functions covering typical cases and edge cases.\n- Use clear assertions and include docstrings for tests.\n- If code cannot be tested because it's placeholder or missing, indicate that clearly.\n\nReturn only the pytest code.\"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        tests = await self._llm_call(messages)\n\n        # Heuristic validation: ensure tests contain 'assert' or 'pytest'\n        if not tests or (isinstance(tests, str) and \"assert\" not in tests and \"pytest\" not in tests and \"unittest\" not in tests):\n            note = f\"# GENERATED_TESTS_INCOMPLETE: LLM output may be insufficient. Raw: {tests[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Generated tests may be insufficient\")\n            tests = (tests or \"\") + \"\\n\\n\" + note\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} chars of tests\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests, produce actionable checklist and summary\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: manual check recommended.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Provide a concise actionable review.\n\nCode (truncated):\n{(code or '')[:2000]}\n\nTests (truncated):\n{(tests or '')[:2000]}\n\nProvide:\n- Short summary of major issues (if any).\n- A checklist of fixes or improvements.\n- A single-line readiness verdict: READY or NOT_READY.\n\nReturn as plain text with the verdict on the last line prefixed by VERDICT:\"\"\"\n\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n\n            review = await self._llm_call(messages)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n        return review\n\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n    max_attempts: int = 3\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"\n        Perform static verification and heuristics for readiness.\n        Returns a structured verification result string.\n        \"\"\"\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        code_ok = False\n        tests_ok = False\n        issues = []\n\n        # Syntax check for code\n        if code and code.strip():\n            try:\n                ast.parse(code)\n                code_ok = True\n            except Exception as e:\n                issues.append(f\"code_syntax_error: {str(e)}\")\n                code_ok = False\n        else:\n            issues.append(\"code_missing_or_empty\")\n\n        # Syntax and heuristic checks for tests\n        if tests and tests.strip():\n            try:\n                ast.parse(tests)\n                # heuristics: look for 'assert' or 'pytest' or 'unittest'\n                lower = tests.lower()\n                if \"assert\" in tests or \"pytest\" in lower or \"unittest\" in lower:\n                    tests_ok = True\n                else:\n                    issues.append(\"tests_lack_asserts_or_framework_usage\")\n                    tests_ok = False\n            except Exception as e:\n                issues.append(f\"tests_syntax_error: {str(e)}\")\n                tests_ok = False\n        else:\n            issues.append(\"tests_missing_or_empty\")\n            tests_ok = False\n\n        verified = code_ok and tests_ok\n        status = {\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok,\n            \"issues\": issues,\n            \"verified\": verified\n        }\n\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | details: {status}\"\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibilities, watch/trigger logic\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n\n    def should_respond_to(self, message: Message) -> bool:\n        \"\"\"\n        Determine if the role should respond to the message.\n        Default: respond if message.cause_by matches any watched action name OR message is addressed to role.\n        \"\"\"\n        try:\n            if not message:\n                return False\n            # addressed to this role explicitly\n            if getattr(message, \"sent_to\", None):\n                if isinstance(message.sent_to, (list, set)) and (self.name in message.sent_to or self.profile in message.sent_to):\n                    return True\n                if isinstance(message.sent_to, str) and (message.sent_to == self.name or message.sent_to == self.profile):\n                    return True\n            # matches watched action\n            for watched in self.watch_list:\n                if message.cause_by == watched.name:\n                    return True\n            return False\n        except Exception:\n            return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform appropriate action(s) based on message and role responsibilities.\"\"\"\n        if not self.actions:\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Act called with message cause_by={getattr(message,'cause_by',None)}\")\n\n        # Try each action (ordered) and produce a single response message per call\n        final_result = None\n        chosen_action = None\n\n        try:\n            for action in self.actions:\n                # Determine if this action should run given the message\n                run_action = False\n                # If no message, allow starter roles (like coder on first round) to run\n                if message is None:\n                    run_action = True\n                else:\n                    run_action = self.should_respond_to(message)\n\n                if not run_action:\n                    # skip this action because message not relevant\n                    continue\n\n                chosen_action = action\n\n                # Determine inputs based on action type\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) if message else None\n                    # If no instruct content, try to find latest user instruction in env\n                    if not instruct and getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == \"UserInput\" or m.role.lower() == \"human\":\n                                instruct = getattr(m, \"instruct_content\", None) or m.content\n                                break\n                    result = await action.run(instruct or \"\")\n                elif isinstance(action, SimpleWriteTest):\n                    # Find the most recent code message in environment\n                    code_msg = None\n                    if message and message.cause_by == SimpleWriteCode.name and getattr(message, \"content\", None):\n                        code_msg = message\n                    elif getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name:\n                                code_msg = m\n                                break\n                    code_text = code_msg.content if code_msg else \"\"\n                    result = await action.run(code_text)\n                elif isinstance(action, SimpleWriteReview):\n                    # Need both code and tests\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if not code_text and m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                            if not tests_text and m.cause_by == SimpleWriteTest.name:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                elif isinstance(action, SimpleVerify):\n                    # Collect latest code/tests and run verification\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if not code_text and m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                            if not tests_text and m.cause_by == SimpleWriteTest.name:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    # Try verification possibly multiple times until stable or attempts exhausted\n                    attempt = 0\n                    verification_result = None\n                    while attempt < action.max_attempts:\n                        attempt += 1\n                        verification_result = await action.run(code_text, tests_text)\n                        if isinstance(verification_result, str) and \"VERIFICATION_RESULT: PASS\" in verification_result:\n                            result = verification_result\n                            break\n                        # If fail, try once more if there is a reviewer or tester messages to re-trigger improvements\n                        # but here we just record the latest failure\n                        result = verification_result\n                else:\n                    # Generic action\n                    result = await action.run(message) if message else await action.run()\n\n                final_result = result\n                # After a successful action run, break (roles execute one logical step per call)\n                break\n\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION in {self.name}: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err)\n            final_result = err\n\n        # Package response as Message\n        response = Message(\n            content=final_result or \"\",\n            role=self.profile,\n            cause_by=chosen_action.name if chosen_action else \"NoAction\",\n            sent_from=self.name\n        )\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed: {response.cause_by}\")\n        return response\n\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with improved message routing\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        # Provide environment reference to role for history lookups\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        # Ensure message has id (pydantic version already has)\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                          f\"Message from {message.sent_from}: cause_by={message.cause_by} content_preview={(message.content or '')[:120]}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to using explicit watch/trigger rules.\"\"\"\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            # If message explicitly addressed to role/profile\n            if getattr(msg, \"sent_to\", None):\n                if isinstance(msg.sent_to, (list, set)) and (role.name in msg.sent_to or role.profile in msg.sent_to):\n                    relevant_messages.append(msg)\n                    continue\n                if isinstance(msg.sent_to, str) and (msg.sent_to == role.name or msg.sent_to == role.profile):\n                    relevant_messages.append(msg)\n                    continue\n            # If role watches the cause_by action\n            for watched in role.watch_list:\n                if msg.cause_by == watched.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\n\nclass Team:\n    \"\"\"Team of agents working together with improved orchestration, termination, and validation\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with robust sequencing and termination rules\"\"\"\n        import asyncio\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        round_num = 0\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n\n            # Step 1: Coder attempts to produce/iterate code (only on first round or if re-triggered)\n            for role in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                try:\n                    # Coder acts on initial message or explicit trigger addressed to coder\n                    msg_to_coder = initial_msg if round_num == 0 else None\n                    response = await role.act(msg_to_coder)\n                    if response:\n                        self.env.publish_message(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Coder exception: {e}\")\n\n            # Step 2: Tester responds when code available\n            for role in [r for r in self.env.roles if isinstance(r, SimpleTester)]:\n                try:\n                    relevant = self.env.get_messages_for_role(role)\n                    if relevant:\n                        response = await role.act(relevant[-1])\n                        if response:\n                            self.env.publish_message(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Tester exception: {e}\")\n\n            # Step 3: Reviewer provides review when tests are produced\n            for role in [r for r in self.env.roles if isinstance(r, SimpleReviewer)]:\n                try:\n                    relevant = self.env.get_messages_for_role(role)\n                    if relevant:\n                        response = await role.act(relevant[-1])\n                        if response:\n                            self.env.publish_message(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Reviewer exception: {e}\")\n\n            # Step 4: Verifier attempts to verify; if PASS then stop\n            verifier_messages = []\n            for role in [r for r in self.env.roles if isinstance(r, SimpleVerifier)]:\n                try:\n                    relevant = self.env.get_messages_for_role(role)\n                    if relevant:\n                        response = await role.act(relevant[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            verifier_messages.append(response)\n                except Exception as e:\n                    self.tracer.log(\"ROUND_ERROR\", role.name, f\"Verifier exception: {e}\")\n\n            # Check for verification pass by scanning verifier messages\n            for msg in reversed(self.env.history):\n                if getattr(msg, \"cause_by\", \"\") == SimpleVerify.name and isinstance(msg.content, str):\n                    if \"VERIFICATION_RESULT: PASS\" in msg.content:\n                        verified = True\n                        break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed. Verified={verified}\")\n\n            # Termination: stop early only when verification PASS observed AND at least one full cycle has occurred\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n\n            # Small wait to simulate asynchronous progression and give LLM backoff time if needed\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "8286f366-9a74-4b55-952f-e76b7c9f8003", "generation": 1, "timestamp": 1754659078.4163592, "iteration_found": 0, "metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.24000000000000005, "avg_failures_per_task": 3.1666666666666665, "total_failures": 19.0, "successful_runs": 6.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.16666666666666666, "avg_failures_per_task": 5.0, "total_failures": 30.0, "successful_runs": 6.0}, "island": 3, "migrant": true}, "artifacts_json": null, "artifact_dir": null}