{"id": "0cda6f06-c597-4db4-a5d4-503db152d920", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport re\nfrom typing import Coroutine\n\nclass Action(ABC):\n    \"\"\"Base action class with common utilities (LLM retry, logging, validation)\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def call_llm_with_retry(self, messages: List[Dict[str, str]], max_retries: int = 3, backoff: float = 1.0) -> str:\n        \"\"\"Call LLM with retries and basic failure detection.\"\"\"\n        attempt = 0\n        last_err = None\n        tracer = getattr(self.context, 'tracer', None)\n        while attempt < max_retries:\n            attempt += 1\n            if tracer:\n                tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{max_retries}\")\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_NOT_AVAILABLE: fallback response\"\n                response = await self.llm.ask(messages)\n                # Treat explicit error responses as failures to retry\n                if isinstance(response, str) and (response.startswith(\"Error\") or \"Error communicating\" in response):\n                    last_err = response\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error on attempt {attempt}: {response[:200]}\")\n                    await asyncio.sleep(backoff * attempt)\n                    continue\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, f\"Exception on LLM call attempt {attempt}: {last_err}\")\n                await asyncio.sleep(backoff * attempt)\n        # Exhausted retries\n        if tracer:\n            tracer.log(\"LLM_FAIL\", self.name, f\"LLM failed after {max_retries} attempts: {last_err}\")\n        return f\"Error: LLM failed after {max_retries} attempts: {last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea length={len(idea or '')}\")\n        if not idea or not idea.strip():\n            msg = \"# No idea provided. Nothing to implement.\"\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No idea content provided\")\n            return msg\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.call_llm_with_retry(messages, max_retries=3, backoff=1.0)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code length={len(code or '')}\")\n        if not code or not code.strip():\n            msg = \"# No code provided. Cannot generate tests.\"\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code provided for tests\")\n            return msg\n        \n        snippet = code[:2000] if len(code) > 2000 else code\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.call_llm_with_retry(messages, max_retries=3, backoff=1.0)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        \n        if self.is_human:\n            review = \"Human review: The code looks good overall. Consider adding more error handling and clearer docstrings.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        \n        snippet_code = code[:1500] if code else \"\"\n        snippet_tests = tests[:1500] if tests else \"\"\n        prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{snippet_code}\n\nTests:\n{snippet_tests}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable. End with a short 'VERDICT: <PASS/FAIL>' line indicating if the submission is ready.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        review = await self.call_llm_with_retry(messages, max_retries=3, backoff=1.0)\n        # Ensure review contains a verdict line; if not, append a conservative verdict\n        if review and \"VERDICT:\" not in review:\n            review = review.strip() + \"\\n\\nVERDICT: PASS\"  # default to PASS if not given (optimistic)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests integrity\")\n        results = []\n        code_ok = False\n        tests_ok = False\n\n        # Syntax check\n        try:\n            ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n        except Exception as e:\n            results.append(f\"code_syntax: fail ({str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Code syntax error: {e}\")\n        else:\n            results.append(\"code_syntax: ok\")\n\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            results.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Tests syntax error: {e}\")\n        else:\n            results.append(\"tests_syntax: ok\")\n        \n        # Structural validation: ensure tests reference functions/classes from code and contain assertions\n        referenced = False\n        has_asserts = False\n        try:\n            # collect names from code\n            code_tree = ast.parse(code or \"\")\n            code_names = {n.name for n in ast.walk(code_tree) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            # quick check in tests text for any function/class name\n            for name in code_names:\n                if name and re.search(r'\\b' + re.escape(name) + r'\\b', tests or \"\"):\n                    referenced = True\n                    break\n            has_asserts = bool(re.search(r'\\bassert\\b', tests or \"\"))\n            if referenced:\n                results.append(\"tests_reference: ok\")\n            else:\n                results.append(\"tests_reference: fail (no test references to code symbols found)\")\n            if has_asserts:\n                results.append(\"tests_asserts: ok\")\n            else:\n                results.append(\"tests_asserts: fail (no asserts found)\")\n        except Exception as e:\n            results.append(f\"structural_check: fail ({str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_EXCEPTION\", self.name, f\"Structural check exception: {e}\")\n        \n        verified = all([\n            code_ok,\n            tests_ok,\n            referenced,\n            has_asserts\n        ])\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(results)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibility and watch/trigger logic\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # Provide environment reference if passed\n        self.env: Optional['Environment'] = kwargs.get('env')\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_act_on(self, message: Optional[Message]) -> bool:\n        \"\"\"Decide whether this role should act based on watch_list and provided message\"\"\"\n        # Coder acts on initial idea or when explicitly triggered\n        if not self.watch_list:\n            # roles with empty watch_list are initiators (like coder)\n            return True\n        if message is None:\n            return False\n        # If message cause_by matches any watched action's name, allow act\n        for watched in self.watch_list:\n            if getattr(message, 'cause_by', \"\") == watched.name:\n                return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message. Handles errors and constructs Message output.\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if not self.actions:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No actions assigned\")\n            return None\n\n        # Only act if watch/trigger conditions satisfied\n        if not self._should_act_on(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping act due to watch rules. Message cause_by={getattr(message, 'cause_by', None)}\")\n            return None\n\n        action = self.actions[0]\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} with message id={getattr(message, 'id', None)}\")\n\n        try:\n            # Map message into action inputs in an explicit way\n            if isinstance(action, SimpleWriteCode):\n                idea = (message.instruct_content or message.content) if message else \"\"\n                result = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # Prefer content coming from a code message\n                payload = message.content if message else \"\"\n                result = await action.run(payload)\n            elif isinstance(action, SimpleWriteReview):\n                # Expect a message that contains both code and tests concatenated or reference latest\n                code_text = \"\"\n                tests_text = \"\"\n                if message:\n                    # If message is a verification or test, try to find code/test in env history\n                    code_text = message.content if getattr(message, 'cause_by', \"\") == SimpleWriteCode.name else \"\"\n                    # Try to find last code/tests in env history as needed\n                # fallback to scanning environment for latest code/tests\n                if not code_text and getattr(self, 'env', None):\n                    for msg in reversed(self.env.history):\n                        if msg.cause_by == SimpleWriteCode.name:\n                            code_text = msg.content\n                            break\n                if not tests_text and getattr(self, 'env', None):\n                    for msg in reversed(self.env.history):\n                        if msg.cause_by == SimpleWriteTest.name:\n                            tests_text = msg.content\n                            break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # For verification, gather latest code and tests from environment\n                code_msg = None\n                tests_msg = None\n                env = getattr(self, 'env', None)\n                if env:\n                    for msg in reversed(env.history):\n                        if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                            code_msg = msg\n                        if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            else:\n                # Generic action invocation\n                result = await action.run(message) if message else await action.run()\n        except Exception as e:\n            # Catch unexpected errors and return an error message\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, f\"Exception executing action {action.name}: {e}\")\n            result = f\"Error: role {self.name} failed executing {action.name}: {e}\"\n\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created id={response.id}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder is an initiator; no watch_list\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watch for code produced\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        # Watch for tests produced\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        # Watch for tests produced (verification follows testing)\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        # ensure role.env points to this environment\n        setattr(role, 'env', self)\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        # Keep history and log event\n        self.history.append(message)\n        if self.tracer:\n            # Truncate content for log readability\n            preview = (message.content[:200] + '...') if len(message.content) > 200 else message.content\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from} cause_by={message.cause_by}: {preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to (explicit watch logic)\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together with robust orchestration and termination logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment/context consistently\"\"\"\n        for role in roles:\n            role.context = self.context\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def _safe_act_call(self, role: Role, message: Optional[Message], max_retries: int = 2, backoff: float = 0.5) -> Optional[Message]:\n        \"\"\"Call role.act with retries and error handling to avoid transient failures causing task collapse.\"\"\"\n        attempt = 0\n        last_exc = None\n        while attempt <= max_retries:\n            attempt += 1\n            try:\n                if self.tracer:\n                    self.tracer.log(\"ACT_ATTEMPT\", role.name, f\"Attempt {attempt} to act (message id={getattr(message, 'id', None)})\")\n                resp = await role.act(message)\n                # Basic check: ensure resp is a Message and contains content\n                if resp and getattr(resp, 'content', None):\n                    return resp\n                # If response is empty, treat as transient failure and retry\n                last_exc = \"empty_response\"\n                if self.tracer:\n                    self.tracer.log(\"ACT_EMPTY\", role.name, f\"Empty response, attempt {attempt}\")\n            except Exception as e:\n                last_exc = str(e)\n                if self.tracer:\n                    self.tracer.log(\"ACT_EXCEPTION\", role.name, f\"Exception on attempt {attempt}: {last_exc}\")\n            # backoff before retry\n            await asyncio.sleep(backoff * attempt)\n        # All retries failed\n        if self.tracer:\n            self.tracer.log(\"ACT_FAIL\", role.name, f\"Failed to act after {max_retries+1} attempts: {last_exc}\")\n        # Return a failure message to the environment to record the event\n        error_msg = Message(\n            content=f\"Error: role {role.name} failed after retries: {last_exc}\",\n            role=role.profile,\n            cause_by=\"System\",\n            sent_from=role.name\n        )\n        return error_msg\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with explicit orchestration and robust termination.\n        The loop enforces a clear sequence (Coder -> Tester -> Reviewer -> Verifier) per round.\n        Verification must pass and be accompanied by a recent review to terminate early.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        \n        # Initial message with the idea (user initiating)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        consecutive_verification_passes = 0\n        min_rounds = 1  # ensure at least one full cycle runs\n        last_reviewer_msg: Optional[Message] = None\n        last_verification_msg: Optional[Message] = None\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            # 1) Coder: only on first round or if explicitly triggered by user input or reviewer requests (not implemented)\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    msg = initial_msg if round_num == 0 else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        # Mark cause_by to indicate produced code\n                        response.cause_by = SimpleWriteCode.name\n                        self.env.publish_message(response)\n            \n            # 2) Tester: respond to latest code\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant = self.env.get_messages_for_role(role)\n                    # take latest code message if exists\n                    msg = relevant[-1] if relevant else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        response.cause_by = SimpleWriteTest.name\n                        self.env.publish_message(response)\n            \n            # 3) Reviewer: review latest tests (and code by searching history)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant = self.env.get_messages_for_role(role)\n                    msg = relevant[-1] if relevant else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        response.cause_by = SimpleWriteReview.name\n                        last_reviewer_msg = response\n                        self.env.publish_message(response)\n            \n            # 4) Verifier: verify latest code+tests\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant = self.env.get_messages_for_role(role)\n                    msg = relevant[-1] if relevant else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        response.cause_by = SimpleVerify.name\n                        last_verification_msg = response\n                        self.env.publish_message(response)\n                        # check pass indicator robustly (string contains PASS)\n                        if isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            consecutive_verification_passes += 1\n                        else:\n                            consecutive_verification_passes = 0\n\n            # Termination logic:\n            # - Require at least min_rounds cycles\n            # - Verification must PASS for two consecutive checks OR PASS once accompanied by a recent reviewer message.\n            if round_num + 1 >= min_rounds:\n                if consecutive_verification_passes >= 2:\n                    verified = True\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification passed consecutively ({consecutive_verification_passes}), stopping early\")\n                    break\n                # OR single pass plus a reviewer message in the same round\n                if last_verification_msg and isinstance(last_verification_msg.content, str) and \"VERIFICATION_RESULT: PASS\" in last_verification_msg.content:\n                    if last_reviewer_msg and last_reviewer_msg.sent_from:\n                        verified = True\n                        self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed with reviewer present, stopping early\")\n                        break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        # finalization\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project completed, Verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "3d91acaf-bcc7-43c5-88af-7196dafaee82", "generation": 1, "timestamp": 1754655193.4565916, "iteration_found": 7, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.16666666666666666, "avg_failures_per_task": 5.0, "total_failures": 30.0, "successful_runs": 6.0}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 1.0000\n- overall_score: 0.5000\n- combined_score: 0.1667\n- avg_failures_per_task: 5.0000\n- total_failures: 30.0000\n- successful_runs: 6.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.1667, avg_failures_per_task: 5.0000, total_failures: 30.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 7.1111)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1667), Performs well on avg_failures_per_task (5.0000), Performs well on total_failures (30.0000), Performs well on successful_runs (6.0000)\n\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport re\nfrom typing import Coroutine\n\nclass Action(ABC):\n    \"\"\"Base action class with common utilities (LLM retry, logging, validation)\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def call_llm_with_retry(self, messages: List[Dict[str, str]], max_retries: int = 3, backoff: float = 1.0) -> str:\n        \"\"\"Call LLM with retries and basic failure detection.\"\"\"\n        attempt = 0\n        last_err = None\n        tracer = getattr(self.context, 'tracer', None)\n        while attempt < max_retries:\n            attempt += 1\n            if tracer:\n                tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{max_retries}\")\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_NOT_AVAILABLE: fallback response\"\n                response = await self.llm.ask(messages)\n                # Treat explicit error responses as failures to retry\n                if isinstance(response, str) and (response.startswith(\"Error\") or \"Error communicating\" in response):\n                    last_err = response\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error on attempt {attempt}: {response[:200]}\")\n                    await asyncio.sleep(backoff * attempt)\n                    continue\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, f\"Exception on LLM call attempt {attempt}: {last_err}\")\n                await asyncio.sleep(backoff * attempt)\n        # Exhausted retries\n        if tracer:\n            tracer.log(\"LLM_FAIL\", self.name, f\"LLM failed after {max_retries} attempts: {last_err}\")\n        return f\"Error: LLM failed after {max_retries} attempts: {last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Writing code for idea length={len(idea or '')}\")\n        if not idea or not idea.strip():\n            msg = \"# No idea provided. Nothing to implement.\"\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No idea content provided\")\n            return msg\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.call_llm_with_retry(messages, max_retries=3, backoff=1.0)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code length={len(code or '')}\")\n        if not code or not code.strip():\n            msg = \"# No code provided. Cannot generate tests.\"\n            if tracer:\n                tracer.log(\"ACTION_SKIPPED\", self.name, \"No code provided for tests\")\n            return msg\n        \n        snippet = code[:2000] if len(code) > 2000 else code\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.call_llm_with_retry(messages, max_retries=3, backoff=1.0)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        \n        if self.is_human:\n            review = \"Human review: The code looks good overall. Consider adding more error handling and clearer docstrings.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review provided\")\n            return review\n        \n        snippet_code = code[:1500] if code else \"\"\n        snippet_tests = tests[:1500] if tests else \"\"\n        prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{snippet_code}\n\nTests:\n{snippet_tests}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable. End with a short 'VERDICT: <PASS/FAIL>' line indicating if the submission is ready.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        review = await self.call_llm_with_retry(messages, max_retries=3, backoff=1.0)\n        # Ensure review contains a verdict line; if not, append a conservative verdict\n        if review and \"VERDICT:\" not in review:\n            review = review.strip() + \"\\n\\nVERDICT: PASS\"  # default to PASS if not given (optimistic)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, 'tracer', None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests integrity\")\n        results = []\n        code_ok = False\n        tests_ok = False\n\n        # Syntax check\n        try:\n            ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n        except Exception as e:\n            results.append(f\"code_syntax: fail ({str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Code syntax error: {e}\")\n        else:\n            results.append(\"code_syntax: ok\")\n\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            results.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Tests syntax error: {e}\")\n        else:\n            results.append(\"tests_syntax: ok\")\n        \n        # Structural validation: ensure tests reference functions/classes from code and contain assertions\n        referenced = False\n        has_asserts = False\n        try:\n            # collect names from code\n            code_tree = ast.parse(code or \"\")\n            code_names = {n.name for n in ast.walk(code_tree) if isinstance(n, (ast.FunctionDef, ast.ClassDef))}\n            # quick check in tests text for any function/class name\n            for name in code_names:\n                if name and re.search(r'\\b' + re.escape(name) + r'\\b', tests or \"\"):\n                    referenced = True\n                    break\n            has_asserts = bool(re.search(r'\\bassert\\b', tests or \"\"))\n            if referenced:\n                results.append(\"tests_reference: ok\")\n            else:\n                results.append(\"tests_reference: fail (no test references to code symbols found)\")\n            if has_asserts:\n                results.append(\"tests_asserts: ok\")\n            else:\n                results.append(\"tests_asserts: fail (no asserts found)\")\n        except Exception as e:\n            results.append(f\"structural_check: fail ({str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_EXCEPTION\", self.name, f\"Structural check exception: {e}\")\n        \n        verified = all([\n            code_ok,\n            tests_ok,\n            referenced,\n            has_asserts\n        ])\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(results)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibility and watch/trigger logic\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # Provide environment reference if passed\n        self.env: Optional['Environment'] = kwargs.get('env')\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_act_on(self, message: Optional[Message]) -> bool:\n        \"\"\"Decide whether this role should act based on watch_list and provided message\"\"\"\n        # Coder acts on initial idea or when explicitly triggered\n        if not self.watch_list:\n            # roles with empty watch_list are initiators (like coder)\n            return True\n        if message is None:\n            return False\n        # If message cause_by matches any watched action's name, allow act\n        for watched in self.watch_list:\n            if getattr(message, 'cause_by', \"\") == watched.name:\n                return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message. Handles errors and constructs Message output.\"\"\"\n        tracer = getattr(self.context, 'tracer', None)\n        if not self.actions:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No actions assigned\")\n            return None\n\n        # Only act if watch/trigger conditions satisfied\n        if not self._should_act_on(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping act due to watch rules. Message cause_by={getattr(message, 'cause_by', None)}\")\n            return None\n\n        action = self.actions[0]\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} with message id={getattr(message, 'id', None)}\")\n\n        try:\n            # Map message into action inputs in an explicit way\n            if isinstance(action, SimpleWriteCode):\n                idea = (message.instruct_content or message.content) if message else \"\"\n                result = await action.run(idea)\n            elif isinstance(action, SimpleWriteTest):\n                # Prefer content coming from a code message\n                payload = message.content if message else \"\"\n                result = await action.run(payload)\n            elif isinstance(action, SimpleWriteReview):\n                # Expect a message that contains both code and tests concatenated or reference latest\n                code_text = \"\"\n                tests_text = \"\"\n                if message:\n                    # If message is a verification or test, try to find code/test in env history\n                    code_text = message.content if getattr(message, 'cause_by', \"\") == SimpleWriteCode.name else \"\"\n                    # Try to find last code/tests in env history as needed\n                # fallback to scanning environment for latest code/tests\n                if not code_text and getattr(self, 'env', None):\n                    for msg in reversed(self.env.history):\n                        if msg.cause_by == SimpleWriteCode.name:\n                            code_text = msg.content\n                            break\n                if not tests_text and getattr(self, 'env', None):\n                    for msg in reversed(self.env.history):\n                        if msg.cause_by == SimpleWriteTest.name:\n                            tests_text = msg.content\n                            break\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                # For verification, gather latest code and tests from environment\n                code_msg = None\n                tests_msg = None\n                env = getattr(self, 'env', None)\n                if env:\n                    for msg in reversed(env.history):\n                        if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                            code_msg = msg\n                        if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                            tests_msg = msg\n                        if code_msg and tests_msg:\n                            break\n                result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n            else:\n                # Generic action invocation\n                result = await action.run(message) if message else await action.run()\n        except Exception as e:\n            # Catch unexpected errors and return an error message\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, f\"Exception executing action {action.name}: {e}\")\n            result = f\"Error: role {self.name} failed executing {action.name}: {e}\"\n\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created id={response.id}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder is an initiator; no watch_list\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watch for code produced\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        # Watch for tests produced\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        # Watch for tests produced (verification follows testing)\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        # ensure role.env points to this environment\n        setattr(role, 'env', self)\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        # Keep history and log event\n        self.history.append(message)\n        if self.tracer:\n            # Truncate content for log readability\n            preview = (message.content[:200] + '...') if len(message.content) > 200 else message.content\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from} cause_by={message.cause_by}: {preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to (explicit watch logic)\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together with robust orchestration and termination logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment/context consistently\"\"\"\n        for role in roles:\n            role.context = self.context\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def _safe_act_call(self, role: Role, message: Optional[Message], max_retries: int = 2, backoff: float = 0.5) -> Optional[Message]:\n        \"\"\"Call role.act with retries and error handling to avoid transient failures causing task collapse.\"\"\"\n        attempt = 0\n        last_exc = None\n        while attempt <= max_retries:\n            attempt += 1\n            try:\n                if self.tracer:\n                    self.tracer.log(\"ACT_ATTEMPT\", role.name, f\"Attempt {attempt} to act (message id={getattr(message, 'id', None)})\")\n                resp = await role.act(message)\n                # Basic check: ensure resp is a Message and contains content\n                if resp and getattr(resp, 'content', None):\n                    return resp\n                # If response is empty, treat as transient failure and retry\n                last_exc = \"empty_response\"\n                if self.tracer:\n                    self.tracer.log(\"ACT_EMPTY\", role.name, f\"Empty response, attempt {attempt}\")\n            except Exception as e:\n                last_exc = str(e)\n                if self.tracer:\n                    self.tracer.log(\"ACT_EXCEPTION\", role.name, f\"Exception on attempt {attempt}: {last_exc}\")\n            # backoff before retry\n            await asyncio.sleep(backoff * attempt)\n        # All retries failed\n        if self.tracer:\n            self.tracer.log(\"ACT_FAIL\", role.name, f\"Failed to act after {max_retries+1} attempts: {last_exc}\")\n        # Return a failure message to the environment to record the event\n        error_msg = Message(\n            content=f\"Error: role {role.name} failed after retries: {last_exc}\",\n            role=role.profile,\n            cause_by=\"System\",\n            sent_from=role.name\n        )\n        return error_msg\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with explicit orchestration and robust termination.\n        The loop enforces a clear sequence (Coder -> Tester -> Reviewer -> Verifier) per round.\n        Verification must pass and be accompanied by a recent review to terminate early.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        \n        # Initial message with the idea (user initiating)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        consecutive_verification_passes = 0\n        min_rounds = 1  # ensure at least one full cycle runs\n        last_reviewer_msg: Optional[Message] = None\n        last_verification_msg: Optional[Message] = None\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            # 1) Coder: only on first round or if explicitly triggered by user input or reviewer requests (not implemented)\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    msg = initial_msg if round_num == 0 else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        # Mark cause_by to indicate produced code\n                        response.cause_by = SimpleWriteCode.name\n                        self.env.publish_message(response)\n            \n            # 2) Tester: respond to latest code\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant = self.env.get_messages_for_role(role)\n                    # take latest code message if exists\n                    msg = relevant[-1] if relevant else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        response.cause_by = SimpleWriteTest.name\n                        self.env.publish_message(response)\n            \n            # 3) Reviewer: review latest tests (and code by searching history)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant = self.env.get_messages_for_role(role)\n                    msg = relevant[-1] if relevant else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        response.cause_by = SimpleWriteReview.name\n                        last_reviewer_msg = response\n                        self.env.publish_message(response)\n            \n            # 4) Verifier: verify latest code+tests\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant = self.env.get_messages_for_role(role)\n                    msg = relevant[-1] if relevant else None\n                    response = await self._safe_act_call(role, msg)\n                    if response:\n                        response.cause_by = SimpleVerify.name\n                        last_verification_msg = response\n                        self.env.publish_message(response)\n                        # check pass indicator robustly (string contains PASS)\n                        if isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            consecutive_verification_passes += 1\n                        else:\n                            consecutive_verification_passes = 0\n\n            # Termination logic:\n            # - Require at least min_rounds cycles\n            # - Verification must PASS for two consecutive checks OR PASS once accompanied by a recent reviewer message.\n            if round_num + 1 >= min_rounds:\n                if consecutive_verification_passes >= 2:\n                    verified = True\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification passed consecutively ({consecutive_verification_passes}), stopping early\")\n                    break\n                # OR single pass plus a reviewer message in the same round\n                if last_verification_msg and isinstance(last_verification_msg.content, str) and \"VERIFICATION_RESULT: PASS\" in last_verification_msg.content:\n                    if last_reviewer_msg and last_reviewer_msg.sent_from:\n                        verified = True\n                        self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed with reviewer present, stopping early\")\n                        break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        # finalization\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project completed, Verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}