{"id": "5b493a34-0084-4dd2-8f1a-9d28998250a9", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class. Actions return structured results (dict) when possible.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 4  # increased retries for robustness\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def ask_with_retry(self, messages: List[Dict[str, str]], timeout_s: float = 2.0) -> str:\n        \"\"\"Call LLM with exponential backoff, jitter, and improved error detection.\"\"\"\n        import asyncio\n        import random\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_UNUSED: fallback response\"\n                resp = await self.llm.ask(messages)\n                if resp is None:\n                    last_err = \"LLM returned None\"\n                else:\n                    # Detect common error patterns and too-short answers\n                    if isinstance(resp, str) and (resp.startswith(\"Error\") or len(resp.strip()) < 8):\n                        last_err = resp\n                    else:\n                        return resp\n            except Exception as e:\n                last_err = str(e)\n            # log retry\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(last_err)[:200]}\")\n            # exponential backoff with jitter\n            await asyncio.sleep(timeout_s * (2 ** (attempt - 1)) + random.uniform(0, 0.5))\n        # All retries exhausted\n        err_msg = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action and return a structured dict if possible.\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> Dict[str, Any]:\n        \"\"\"Generate code based on the idea. Returns dict with status and payload.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.ask_with_retry(messages)\n        status = \"ok\" if code and not code.startswith(\"Error\") and not code.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code) if isinstance(code,str) else 0} characters of code; status={status}\")\n        return {\"status\": status, \"payload\": code or \"\", \"meta\": {\"idea\": idea}}\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> Dict[str, Any]:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        # Truncate large code to keep prompt reasonable\n        code_snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code_snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.ask_with_retry(messages)\n        status = \"ok\" if tests and not tests.startswith(\"Error\") and not tests.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests) if isinstance(tests,str) else 0} characters of tests; status={status}\")\n        return {\"status\": status, \"payload\": tests or \"\", \"meta\": {\"code_summary\": code_snippet[:200]}}\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Review the code and tests. Returns {'status': 'ok'/'needs_changes', 'payload': review_text, 'meta': {...}}\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            status = \"ok\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nReturn a short structured verdict line at the top: VERDICT: ok OR VERDICT: needs_changes\nThen provide actionable comments. Keep it concise.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            review = await self.ask_with_retry(messages)\n            if isinstance(review, str) and review.strip().startswith(\"VERDICT:\"):\n                first_line = review.splitlines()[0].strip()\n                verdict = first_line.replace(\"VERDICT:\", \"\").strip().lower()\n                status = \"ok\" if verdict == \"ok\" else \"needs_changes\"\n            else:\n                # fallback heuristic\n                status = \"needs_changes\" if \"bug\" in (review or \"\").lower() or \"issue\" in (review or \"\").lower() else \"ok\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters; status={status}\")\n        \n        return {\"status\": status, \"payload\": review or \"\", \"meta\": {}}\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Return a structured verification result with diagnostics.\"\"\"\n        import ast, re, textwrap\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        fn_names = []\n        try:\n            # Verify code syntax\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            fn_names = [n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)]\n            details.append(f\"functions:{','.join(fn_names) if fn_names else 'none'}\")\n        except Exception as e:\n            details.append(f\"code_syntax_error:{str(e)[:200]}\")\n            fn_names = []\n            code_ok = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # Heuristics: tests must have at least one test_ function and an assert\n            contains_assert = bool(re.search(r\"\\bassert\\b\", tests or \"\"))\n            contains_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            tests_ok = contains_assert and contains_testfn\n            if not contains_assert:\n                details.append(\"tests_missing_asserts\")\n            if not contains_testfn:\n                details.append(\"tests_missing_test_functions\")\n        except Exception as e:\n            details.append(f\"tests_syntax_error:{str(e)[:200]}\")\n            tests_ok = False\n        # Ensure tests reference code symbols\n        references_code = False\n        try:\n            if fn_names:\n                for fn in fn_names:\n                    # simple substring check is conservative but quick\n                    if fn and fn in (tests or \"\"):\n                        references_code = True\n                        break\n                if not references_code:\n                    details.append(\"tests_do_not_reference_code\")\n            else:\n                # If no functions in code, accept tests if tests parse and have asserts/test fns\n                references_code = True if tests_ok else False\n        except Exception:\n            details.append(\"tests_reference_check_failed\")\n            references_code = False\n        verified = code_ok and tests_ok and references_code\n        status = \"PASS\" if verified else \"FAIL\"\n        # Add a coverage heuristic: count asserts and test functions\n        try:\n            num_asserts = (tests or \"\").count(\"assert\")\n            num_test_fns = 0\n            parsed_tests = ast.parse(tests or \"\")\n            num_test_fns = sum(1 for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\"))\n            details.append(f\"asserts:{num_asserts}\")\n            details.append(f\"test_functions:{num_test_fns}\")\n        except Exception:\n            pass\n        result_payload = {\"status\": status, \"details\": details, \"verified\": verified}\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"VERIFICATION_RESULT: {status} | details={';'.join(details)}\")\n        return result_payload\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibilities, watch/trigger logic, and retries\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track messages already processed to avoid duplicates\n        self._processed_message_ids: Set[str] = set()\n        # role maintains a small cache of last outputs to avoid repeating work\n        self._last_outputs: List[str] = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message based on watch list and send_to.\"\"\"\n        # Skip if already processed\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # If message explicitly addressed to this role/profile\n        if getattr(message, \"send_to\", None):\n            if self.profile in message.send_to or self.name in message.send_to:\n                return True\n            # addressed to everyone\n            if \"*\" in message.send_to:\n                return True\n        # If message cause_by is one of the watched actions\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # If message is human instruction (UserInput) coders should respond\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and self.profile.lower().find(\"coder\") >= 0:\n            return True\n        return False\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Perform an action based on the message with robust error handling, retries,\n        and standardized structured processing of action results.\n        \"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        \n        # If message exists but this role should not respond, skip\n        if message is not None and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n        \n        # Prepare inputs to action depending on action type, with safe defaults\n        def _gather_code_tests_from_env():\n            env = getattr(self, 'env', None)\n            code = \"\"\n            tests = \"\"\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteTest.name and not tests:\n                        tests = msg.content\n                    if msg.cause_by == SimpleWriteCode.name and not code:\n                        code = msg.content\n                    if code and tests:\n                        break\n            return code, tests\n        \n        attempts = 0\n        last_err = None\n        from asyncio import sleep\n        max_attempts = 3\n        while attempts < max_attempts:\n            attempts += 1\n            try:\n                # Determine input for action types\n                result = None\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                elif isinstance(action, SimpleWriteTest):\n                    # Expect code content to be in the message or env\n                    content = getattr(message, \"content\", \"\") or \"\"\n                    if not content:\n                        code, _ = _gather_code_tests_from_env()\n                        content = code\n                    result = await action.run(content)\n                elif isinstance(action, SimpleWriteReview):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message is tests, prefer message content as tests\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        tests = getattr(message, \"content\", tests)\n                    result = await action.run(code, tests)\n                elif isinstance(action, SimpleVerify):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message provides tests or code, prefer them\n                    if message:\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                            tests = getattr(message, \"content\", tests)\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                            code = getattr(message, \"content\", code)\n                    result = await action.run(code, tests)\n                else:\n                    # Generic action\n                    result = await action.run()  # type: ignore\n                # Normalize result to structured dict\n                if isinstance(result, dict):\n                    status = result.get(\"status\") or (\"ok\" if result.get(\"verified\") else \"unknown\")\n                    payload = result.get(\"payload\") if \"payload\" in result else (str(result))\n                    meta = result.get(\"meta\", {})\n                else:\n                    # older behavior: string\n                    payload = str(result or \"\")\n                    status = \"ok\" if not payload.startswith(\"Error\") and \"VERIFICATION_RESULT: PASS\" not in payload else (\"pass\" if \"PASS\" in payload else \"error\")\n                    meta = {}\n                \n                # Mark message processed to avoid double handling\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Keep last outputs (small history)\n                try:\n                    self._last_outputs.append(payload)\n                    if len(self._last_outputs) > 8:\n                        self._last_outputs = self._last_outputs[-8:]\n                except Exception:\n                    pass\n                \n                # Decide recipients based on action type and status\n                recipients = set()\n                cause_name = action.name if action else \"\"\n                if isinstance(action, SimpleWriteCode):\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # If review says ok -> verifier & coder, else coder primarily\n                    if status == \"ok\" or status == \"ok\":\n                        recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                    else:\n                        recipients = {\"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    recipients = {\"Team\"}\n                else:\n                    recipients = {\"Team\"}\n                \n                # Build standardized message content for downstream parsing\n                # Use a short header and include payload (full payload may be long)\n                header = f\"RESULT|{cause_name}|{status}\"\n                content_str = header + \"\\n\" + (payload or \"\")\n                response = Message(\n                    content=content_str,\n                    role=self.profile,\n                    cause_by=cause_name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action succeeded, created message id={(getattr(response,'id',None))}; status={status}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # Backoff before retrying\n                await sleep(0.5 * attempts)\n        # If we reach here, action failed consistently\n        fail_msg = f\"ROLE_FAILED: {self.name} could not complete action after {attempts} attempts. Error={last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with clear message routing and deduplication\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and trace it\"\"\"\n        # Prevent duplicate identical messages (by content + sender) flooding\n        try:\n            if any(m.id == message.id for m in self.history):\n                # already published\n                return\n        except Exception:\n            pass\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:200]} | cause_by={getattr(message,'cause_by',None)} | send_to={getattr(message,'send_to',None)}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Get messages that a role should respond to.\n        This respects explicit addressing (send_to) and the role's watch_list.\n        It also filters messages already processed by the role.\n        \"\"\"\n        relevant_messages = []\n        for msg in list(self.history):\n            # Skip messages the role already processed\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # If explicitly addressed\n            if getattr(msg, \"send_to\", None):\n                if role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to:\n                    relevant_messages.append(msg)\n                    continue\n            # If message cause_by matches watch_list\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        # Return in chronological order (oldest first) to preserve causal flow\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together with robust termination and verification logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification confirmation count to avoid premature termination\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2  # require two independent confirmations\n        self._review_ok_count = 0\n        self._stable_rounds_after_verify = 0\n        self._required_stable_rounds = 1  # require a round of stability after verification\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with stronger orchestration and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (verify confirmations needed={self._verify_confirm_needed})\")\n        \n        # Initial message with the idea, explicitly addressed to the coder role\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        # We'll track rounds where no progress is made to avoid infinite loops\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            progress_made = False\n            \n            # Orchestrated sequence: evaluate each role each round; roles pick relevant messages\n            for role in list(self.env.roles):\n                relevant = self.env.get_messages_for_role(role)\n                # Ensure coder receives the initial instruction on first round\n                msgs_to_process = relevant\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    msgs_to_process = [initial_msg] + [m for m in relevant if m.id != initial_msg.id]\n                for msg in msgs_to_process:\n                    resp = await role.act(msg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        progress_made = True\n                        # Process verifier outputs\n                        if isinstance(role, SimpleVerifier):\n                            # standardized content begins with RESULT|SimpleVerify|PASS/FAIL\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"PASS\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content):\n                                    self._verify_confirm_count += 1\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} reported PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                elif \"FAIL\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: FAIL\" in resp.content):\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_FAIL\", \"Team\", f\"Verifier {role.name} reported FAIL; resetting confirmations\")\n                            except Exception as e:\n                                self.tracer.log(\"VERIFY_ERROR\", \"Team\", f\"Could not parse verifier result: {e}\")\n                        # Process reviewer outputs for acceptance\n                        if isinstance(role, SimpleReviewer):\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"VERDICT: ok\" in resp.content.lower() or \"result|simplewritereview|ok\" in header.lower():\n                                    self._review_ok_count += 1\n                                    self.tracer.log(\"REVIEW_OK\", \"Team\", f\"Reviewer {role.name} returned ok ({self._review_ok_count})\")\n                                else:\n                                    # reviewer requested changes -> reset verifier confirmations to force rework\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"REVIEW_NEEDS_CHANGES\", \"Team\", f\"Reviewer {role.name} requested changes; resetting verify confirmations\")\n                            except Exception:\n                                pass\n                        # Handle explicit role failures\n                        if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                            self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure noted: {resp.content[:200]}\")\n            # detect progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n            \n            # Check for stable verification: require multiple verifier confirmations and at least one reviewer ok\n            if self._verify_confirm_count >= self._verify_confirm_needed and self._review_ok_count >= 1:\n                self._stable_rounds_after_verify += 1\n                self.tracer.log(\"TEAM_VERIFY_STABLE\", \"Team\", f\"Stable verification observed for {self._stable_rounds_after_verify} rounds\")\n                if self._stable_rounds_after_verify >= self._required_stable_rounds:\n                    verified = True\n            else:\n                self._stable_rounds_after_verify = 0\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed (progress_made={progress_made})\")\n            # Termination conditions\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification and review confirmed; stopping early at round {round_num + 1}\")\n                break\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds, stopping early to conserve resources\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified} (verify_confirms={self._verify_confirm_count}, review_ok={self._review_ok_count})\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "74012c73-c9f1-4c8b-9c32-e6854b9df62f", "generation": 2, "timestamp": 1754655607.3798027, "iteration_found": 30, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.5000\n- overall_score: 0.2500\n- combined_score: 0.1000\n- avg_failures_per_task: 12.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def ask_with_retry(self, messages: List[Dict[str, str]], timeout_s: float = 2.0) -> str:\n        \"\"\"Call LLM with exponential backoff and simple error detection.\"\"\"\n        import asyncio\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_UNUSED: fallback response\"\n                resp = await self.llm.ask(messages)\n                if resp is None:\n                    last_err = \"LLM returned None\"\n                else:\n                    # Basic error detection: error prefix or too short responses\n                    if isinstance(resp, str) and (resp.startswith(\"Error\") or len(resp.strip()) < 5):\n                        last_err = resp\n                    else:\n                        return resp\n            except Exception as e:\n                last_err = str(e)\n            # log retry\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(last_err)[:200]}\")\n            await asyncio.sleep(timeout_s * attempt)\n        # All retries exhausted\n        err_msg = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            review = await self.ask_with_retry(messages)\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast, re\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        code_ok = False\n        tests_ok = False\n        details = []\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            # collect top-level function names\n            fn_names = [n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)]\n            details.append(f\"functions: {','.join(fn_names) if fn_names else 'none'}\")\n        except Exception as e:\n            details.append(f\"code_syntax_error: {str(e)[:200]}\")\n            fn_names = []\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # quick heuristic: tests should contain at least one assert or pytest usage\n            contains_assert = bool(re.search(r\"\\bassert\\b\", tests or \"\"))\n            contains_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            tests_ok = contains_assert and contains_testfn\n            if not contains_assert:\n                details.append(\"tests_missing_asserts\")\n            if not contains_testfn:\n                details.append(\"tests_missing_test_functions\")\n        except Exception as e:\n            details.append(f\"tests_syntax_error: {str(e)[:200]}\")\n            tests_ok = False\n        # Ensure tests reference at least one function from code\n        references_code = False\n        try:\n            for fn in fn_names:\n                if fn and (fn in (tests or \"\")):\n                    references_code = True\n                    break\n            if not fn_names:\n                # If no functions in code, accept tests if they contain asserts and test functions\n                references_code = True if tests_ok else False\n            if not references_code:\n                details.append(\"tests_do_not_reference_code\")\n        except Exception:\n            details.append(\"tests_reference_check_failed\")\n        verified = code_ok and tests_ok and references_code\n        status = \"PASS\" if verified else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track messages already processed to avoid duplicates\n        self._processed_message_ids: Set[str] = set()\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message based on watch list and send_to.\"\"\"\n        # Skip if already processed\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # If message explicitly addressed to this role/profile\n        if getattr(message, \"send_to\", None):\n            if self.profile in message.send_to or self.name in message.send_to:\n                return True\n            # addressed to everyone\n            if \"*\" in message.send_to:\n                return True\n        # If message cause_by is in our watch list actions\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # Special-case: Human instructions target coders\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and self.profile.lower().find(\"coder\") >= 0:\n            return True\n        return False\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message with robust error handling and retries\"\"\"\n        if not self.actions:\n            return None\n        \n        # find the first action for this role\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        \n        # If there is a message, check whether we should respond\n        if message is not None and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n        \n        # Execute with guarded try/except and limited retries for transient failures\n        from asyncio import sleep\n        attempts = 0\n        last_err = None\n        while attempts < 2:\n            attempts += 1\n            try:\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                elif isinstance(action, SimpleWriteTest):\n                    # Expect code content to be in the message\n                    content = getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(content)\n                elif isinstance(action, SimpleWriteReview):\n                    # For review, try to find code and tests from env history if not provided\n                    code = \"\"\n                    tests = \"\"\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        # message is tests; find preceding code\n                        env = getattr(self, 'env', None)\n                        if env:\n                            for msg in reversed(env.history):\n                                if msg.cause_by == SimpleWriteCode.name:\n                                    code = msg.content\n                                    break\n                        tests = message.content\n                    else:\n                        # try to extract both from history\n                        env = getattr(self, 'env', None)\n                        if env:\n                            for msg in reversed(env.history):\n                                if msg.cause_by == SimpleWriteTest.name and not tests:\n                                    tests = msg.content\n                                if msg.cause_by == SimpleWriteCode.name and not code:\n                                    code = msg.content\n                                if code and tests:\n                                    break\n                    result = await action.run(code, tests)\n                elif isinstance(action, SimpleVerify):\n                    # Verification should operate on latest code and tests in env\n                    env = getattr(self, 'env', None)\n                    code = \"\"\n                    tests = \"\"\n                    if env:\n                        for msg in reversed(env.history):\n                            if msg.cause_by == SimpleWriteCode.name and not code:\n                                code = msg.content\n                            if msg.cause_by == SimpleWriteTest.name and not tests:\n                                tests = msg.content\n                            if code and tests:\n                                break\n                    # If message supplies content, prefer it\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        tests = getattr(message, \"content\", tests)\n                    result = await action.run(code, tests)\n                else:\n                    result = \"Action completed\"\n                # Mark message processed if present\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # wrap into Message and set recipients based on role responsibilities\n                recipients = set()\n                if isinstance(action, SimpleWriteCode):\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    recipients = {\"Team\"}\n                response = Message(\n                    content=result,\n                    role=self.profile,\n                    cause_by=action.name if action else \"\",\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action succeeded, created message id={(getattr(response,'id',None))}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # small backoff before retrying\n                await sleep(0.5 * attempts)\n        # If we reach here, action failed consistently\n        fail_msg = f\"ROLE_FAILED: {self.name} could not complete action after retries. Error={last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:200]} | cause_by={getattr(message,'cause_by',None)} | send_to={getattr(message,'send_to',None)}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # If message is explicitly addressed to this role/profile\n            if getattr(msg, \"send_to\", None):\n                if role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to:\n                    if not (hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set())):\n                        relevant_messages.append(msg)\n                    continue\n            # Otherwise check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    if not (hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set())):\n                        relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification confirmation count to avoid premature termination\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2  # require two independent confirmations\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with stronger orchestration and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (verify confirmations needed={self._verify_confirm_needed})\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        # We'll track rounds where no progress is made to avoid infinite loops\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            progress_made = False\n            \n            # Orchestrated sequence: all roles evaluated each round, they decide whether to act\n            for role in list(self.env.roles):\n                # Get messages relevant to role\n                relevant = self.env.get_messages_for_role(role)\n                # If coder and it's the first round, ensure they get the initial instruction even if not explicitly selected\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    # prefer explicit initial message\n                    msgs_to_process = [initial_msg] + relevant\n                else:\n                    msgs_to_process = relevant\n                # Process each message in order\n                for msg in msgs_to_process:\n                    resp = await role.act(msg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        progress_made = True\n                        # If verifier produced a PASS, update confirmations\n                        if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                            self._verify_confirm_count += 1\n                            self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} reported PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                            if self._verify_confirm_count >= self._verify_confirm_needed:\n                                verified = True\n                        # If verifier produced a FAIL, reset confirmations\n                        if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: FAIL\" in resp.content:\n                            self._verify_confirm_count = 0\n                        # If role returned an error directed to Team, consider logging and maybe adjusting budget (simulated)\n                        if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                            self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure noted: {resp.content[:200]}\")\n            # detect progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed (progress_made={progress_made})\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed ({self._verify_confirm_count}/{self._verify_confirm_needed}), stopping early\")\n                break\n            # If no progress for 2 consecutive rounds, break to avoid wasted cycles\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 rounds, stopping early to conserve resources\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def ask_with_retry(self, messages: List[Dict[str, str]], timeout_s: float = 2.0) -> str:\n        \"\"\"Call LLM with exponential backoff and simple error detection.\"\"\"\n        import asyncio\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_UNUSED: fallback response\"\n                resp = await self.llm.ask(messages)\n                if resp is None:\n                    last_err = \"LLM returned None\"\n                else:\n                    # Basic error detection: error prefix or too short responses\n                    if isinstance(resp, str) and (resp.startswith(\"Error\") or len(resp.strip()) < 5):\n                        last_err = resp\n                    else:\n                        return resp\n            except Exception as e:\n                last_err = str(e)\n            # log retry\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(last_err)[:200]}\")\n            await asyncio.sleep(timeout_s * attempt)\n        # All retries exhausted\n        err_msg = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            review = await self.ask_with_retry(messages)\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast, re\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        code_ok = False\n        tests_ok = False\n        details = []\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            # collect top-level function names\n            fn_names = [n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)]\n            details.append(f\"functions: {','.join(fn_names) if fn_names else 'none'}\")\n        except Exception as e:\n            details.append(f\"code_syntax_error: {str(e)[:200]}\")\n            fn_names = []\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # quick heuristic: tests should contain at least one assert or pytest usage\n            contains_assert = bool(re.search(r\"\\bassert\\b\", tests or \"\"))\n            contains_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            tests_ok = contains_assert and contains_testfn\n            if not contains_assert:\n                details.append(\"tests_missing_asserts\")\n            if not contains_testfn:\n                details.append(\"tests_missing_test_functions\")\n        except Exception as e:\n            details.append(f\"tests_syntax_error: {str(e)[:200]}\")\n            tests_ok = False\n        # Ensure tests reference at least one function from code\n        references_code = False\n        try:\n            for fn in fn_names:\n                if fn and (fn in (tests or \"\")):\n                    references_code = True\n                    break\n            if not fn_names:\n                # If no functions in code, accept tests if they contain asserts and test functions\n                references_code = True if tests_ok else False\n            if not references_code:\n                details.append(\"tests_do_not_reference_code\")\n        except Exception:\n            details.append(\"tests_reference_check_failed\")\n        verified = code_ok and tests_ok and references_code\n        status = \"PASS\" if verified else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track messages already processed to avoid duplicates\n        self._processed_message_ids: Set[str] = set()\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message based on watch list and send_to.\"\"\"\n        # Skip if already processed\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # If message explicitly addressed to this role/profile\n        if getattr(message, \"send_to\", None):\n            if self.profile in message.send_to or self.name in message.send_to:\n                return True\n            # addressed to everyone\n            if \"*\" in message.send_to:\n                return True\n        # If message cause_by is in our watch list actions\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # Special-case: Human instructions target coders\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and self.profile.lower().find(\"coder\") >= 0:\n            return True\n        return False\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message with robust error handling and retries\"\"\"\n        if not self.actions:\n            return None\n        \n        # find the first action for this role\n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        \n        # If there is a message, check whether we should respond\n        if message is not None and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n        \n        # Execute with guarded try/except and limited retries for transient failures\n        from asyncio import sleep\n        attempts = 0\n        last_err = None\n        while attempts < 2:\n            attempts += 1\n            try:\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                elif isinstance(action, SimpleWriteTest):\n                    # Expect code content to be in the message\n                    content = getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(content)\n                elif isinstance(action, SimpleWriteReview):\n                    # For review, try to find code and tests from env history if not provided\n                    code = \"\"\n                    tests = \"\"\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        # message is tests; find preceding code\n                        env = getattr(self, 'env', None)\n                        if env:\n                            for msg in reversed(env.history):\n                                if msg.cause_by == SimpleWriteCode.name:\n                                    code = msg.content\n                                    break\n                        tests = message.content\n                    else:\n                        # try to extract both from history\n                        env = getattr(self, 'env', None)\n                        if env:\n                            for msg in reversed(env.history):\n                                if msg.cause_by == SimpleWriteTest.name and not tests:\n                                    tests = msg.content\n                                if msg.cause_by == SimpleWriteCode.name and not code:\n                                    code = msg.content\n                                if code and tests:\n                                    break\n                    result = await action.run(code, tests)\n                elif isinstance(action, SimpleVerify):\n                    # Verification should operate on latest code and tests in env\n                    env = getattr(self, 'env', None)\n                    code = \"\"\n                    tests = \"\"\n                    if env:\n                        for msg in reversed(env.history):\n                            if msg.cause_by == SimpleWriteCode.name and not code:\n                                code = msg.content\n                            if msg.cause_by == SimpleWriteTest.name and not tests:\n                                tests = msg.content\n                            if code and tests:\n                                break\n                    # If message supplies content, prefer it\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        tests = getattr(message, \"content\", tests)\n                    result = await action.run(code, tests)\n                else:\n                    result = \"Action completed\"\n                # Mark message processed if present\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # wrap into Message and set recipients based on role responsibilities\n                recipients = set()\n                if isinstance(action, SimpleWriteCode):\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    recipients = {\"Team\"}\n                response = Message(\n                    content=result,\n                    role=self.profile,\n                    cause_by=action.name if action else \"\",\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action succeeded, created message id={(getattr(response,'id',None))}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # small backoff before retrying\n                await sleep(0.5 * attempts)\n        # If we reach here, action failed consistently\n        fail_msg = f\"ROLE_FAILED: {self.name} could not complete action after retries. Error={last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:200]} | cause_by={getattr(message,'cause_by',None)} | send_to={getattr(message,'send_to',None)}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # If message is explicitly addressed to this role/profile\n            if getattr(msg, \"send_to\", None):\n                if role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to:\n                    if not (hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set())):\n                        relevant_messages.append(msg)\n                    continue\n            # Otherwise check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    if not (hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set())):\n                        relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification confirmation count to avoid premature termination\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2  # require two independent confirmations\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with stronger orchestration and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (verify confirmations needed={self._verify_confirm_needed})\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        # We'll track rounds where no progress is made to avoid infinite loops\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            progress_made = False\n            \n            # Orchestrated sequence: all roles evaluated each round, they decide whether to act\n            for role in list(self.env.roles):\n                # Get messages relevant to role\n                relevant = self.env.get_messages_for_role(role)\n                # If coder and it's the first round, ensure they get the initial instruction even if not explicitly selected\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    # prefer explicit initial message\n                    msgs_to_process = [initial_msg] + relevant\n                else:\n                    msgs_to_process = relevant\n                # Process each message in order\n                for msg in msgs_to_process:\n                    resp = await role.act(msg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        progress_made = True\n                        # If verifier produced a PASS, update confirmations\n                        if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content:\n                            self._verify_confirm_count += 1\n                            self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} reported PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                            if self._verify_confirm_count >= self._verify_confirm_needed:\n                                verified = True\n                        # If verifier produced a FAIL, reset confirmations\n                        if isinstance(role, SimpleVerifier) and isinstance(resp.content, str) and \"VERIFICATION_RESULT: FAIL\" in resp.content:\n                            self._verify_confirm_count = 0\n                        # If role returned an error directed to Team, consider logging and maybe adjusting budget (simulated)\n                        if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                            self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure noted: {resp.content[:200]}\")\n            # detect progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed (progress_made={progress_made})\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed ({self._verify_confirm_count}/{self._verify_confirm_needed}), stopping early\")\n                break\n            # If no progress for 2 consecutive rounds, break to avoid wasted cycles\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 rounds, stopping early to conserve resources\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class. Actions return structured results (dict) when possible.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 4  # increased retries for robustness\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    async def ask_with_retry(self, messages: List[Dict[str, str]], timeout_s: float = 2.0) -> str:\n        \"\"\"Call LLM with exponential backoff, jitter, and improved error detection.\"\"\"\n        import asyncio\n        import random\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if not self.llm:\n                    # Local fallback\n                    return \"LLM_UNUSED: fallback response\"\n                resp = await self.llm.ask(messages)\n                if resp is None:\n                    last_err = \"LLM returned None\"\n                else:\n                    # Detect common error patterns and too-short answers\n                    if isinstance(resp, str) and (resp.startswith(\"Error\") or len(resp.strip()) < 8):\n                        last_err = resp\n                    else:\n                        return resp\n            except Exception as e:\n                last_err = str(e)\n            # log retry\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {str(last_err)[:200]}\")\n            # exponential backoff with jitter\n            await asyncio.sleep(timeout_s * (2 ** (attempt - 1)) + random.uniform(0, 0.5))\n        # All retries exhausted\n        err_msg = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FAIL\", self.name, err_msg)\n        return err_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action and return a structured dict if possible.\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> Dict[str, Any]:\n        \"\"\"Generate code based on the idea. Returns dict with status and payload.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        code = await self.ask_with_retry(messages)\n        status = \"ok\" if code and not code.startswith(\"Error\") and not code.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code) if isinstance(code,str) else 0} characters of code; status={status}\")\n        return {\"status\": status, \"payload\": code or \"\", \"meta\": {\"idea\": idea}}\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> Dict[str, Any]:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        # Truncate large code to keep prompt reasonable\n        code_snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code_snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        tests = await self.ask_with_retry(messages)\n        status = \"ok\" if tests and not tests.startswith(\"Error\") and not tests.startswith(\"LLM_FAILED\") else \"error\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests) if isinstance(tests,str) else 0} characters of tests; status={status}\")\n        return {\"status\": status, \"payload\": tests or \"\", \"meta\": {\"code_summary\": code_snippet[:200]}}\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Review the code and tests. Returns {'status': 'ok'/'needs_changes', 'payload': review_text, 'meta': {...}}\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            status = \"ok\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nReturn a short structured verdict line at the top: VERDICT: ok OR VERDICT: needs_changes\nThen provide actionable comments. Keep it concise.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            review = await self.ask_with_retry(messages)\n            if isinstance(review, str) and review.strip().startswith(\"VERDICT:\"):\n                first_line = review.splitlines()[0].strip()\n                verdict = first_line.replace(\"VERDICT:\", \"\").strip().lower()\n                status = \"ok\" if verdict == \"ok\" else \"needs_changes\"\n            else:\n                # fallback heuristic\n                status = \"needs_changes\" if \"bug\" in (review or \"\").lower() or \"issue\" in (review or \"\").lower() else \"ok\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters; status={status}\")\n        \n        return {\"status\": status, \"payload\": review or \"\", \"meta\": {}}\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> Dict[str, Any]:\n        \"\"\"Return a structured verification result with diagnostics.\"\"\"\n        import ast, re, textwrap\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        fn_names = []\n        try:\n            # Verify code syntax\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            fn_names = [n.name for n in parsed_code.body if isinstance(n, ast.FunctionDef)]\n            details.append(f\"functions:{','.join(fn_names) if fn_names else 'none'}\")\n        except Exception as e:\n            details.append(f\"code_syntax_error:{str(e)[:200]}\")\n            fn_names = []\n            code_ok = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # Heuristics: tests must have at least one test_ function and an assert\n            contains_assert = bool(re.search(r\"\\bassert\\b\", tests or \"\"))\n            contains_testfn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed_tests.body)\n            tests_ok = contains_assert and contains_testfn\n            if not contains_assert:\n                details.append(\"tests_missing_asserts\")\n            if not contains_testfn:\n                details.append(\"tests_missing_test_functions\")\n        except Exception as e:\n            details.append(f\"tests_syntax_error:{str(e)[:200]}\")\n            tests_ok = False\n        # Ensure tests reference code symbols\n        references_code = False\n        try:\n            if fn_names:\n                for fn in fn_names:\n                    # simple substring check is conservative but quick\n                    if fn and fn in (tests or \"\"):\n                        references_code = True\n                        break\n                if not references_code:\n                    details.append(\"tests_do_not_reference_code\")\n            else:\n                # If no functions in code, accept tests if tests parse and have asserts/test fns\n                references_code = True if tests_ok else False\n        except Exception:\n            details.append(\"tests_reference_check_failed\")\n            references_code = False\n        verified = code_ok and tests_ok and references_code\n        status = \"PASS\" if verified else \"FAIL\"\n        # Add a coverage heuristic: count asserts and test functions\n        try:\n            num_asserts = (tests or \"\").count(\"assert\")\n            num_test_fns = 0\n            parsed_tests = ast.parse(tests or \"\")\n            num_test_fns = sum(1 for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\"))\n            details.append(f\"asserts:{num_asserts}\")\n            details.append(f\"test_functions:{num_test_fns}\")\n        except Exception:\n            pass\n        result_payload = {\"status\": status, \"details\": details, \"verified\": verified}\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"VERIFICATION_RESULT: {status} | details={';'.join(details)}\")\n        return result_payload\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibilities, watch/trigger logic, and retries\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # track messages already processed to avoid duplicates\n        self._processed_message_ids: Set[str] = set()\n        # role maintains a small cache of last outputs to avoid repeating work\n        self._last_outputs: List[str] = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    def _should_respond_to(self, message: Message) -> bool:\n        \"\"\"Decide whether to respond to a message based on watch list and send_to.\"\"\"\n        # Skip if already processed\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # If message explicitly addressed to this role/profile\n        if getattr(message, \"send_to\", None):\n            if self.profile in message.send_to or self.name in message.send_to:\n                return True\n            # addressed to everyone\n            if \"*\" in message.send_to:\n                return True\n        # If message cause_by is one of the watched actions\n        for watched in self.watch_list:\n            if getattr(message, \"cause_by\", \"\") == watched.name:\n                return True\n        # If message is human instruction (UserInput) coders should respond\n        if getattr(message, \"cause_by\", \"\") in (\"UserInput\", \"\") and self.profile.lower().find(\"coder\") >= 0:\n            return True\n        return False\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Perform an action based on the message with robust error handling, retries,\n        and standardized structured processing of action results.\n        \"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Attempting action: {action.name} on message id={(getattr(message,'id',None))}\")\n        \n        # If message exists but this role should not respond, skip\n        if message is not None and not self._should_respond_to(message):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n        \n        # Prepare inputs to action depending on action type, with safe defaults\n        def _gather_code_tests_from_env():\n            env = getattr(self, 'env', None)\n            code = \"\"\n            tests = \"\"\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteTest.name and not tests:\n                        tests = msg.content\n                    if msg.cause_by == SimpleWriteCode.name and not code:\n                        code = msg.content\n                    if code and tests:\n                        break\n            return code, tests\n        \n        attempts = 0\n        last_err = None\n        from asyncio import sleep\n        max_attempts = 3\n        while attempts < max_attempts:\n            attempts += 1\n            try:\n                # Determine input for action types\n                result = None\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                elif isinstance(action, SimpleWriteTest):\n                    # Expect code content to be in the message or env\n                    content = getattr(message, \"content\", \"\") or \"\"\n                    if not content:\n                        code, _ = _gather_code_tests_from_env()\n                        content = code\n                    result = await action.run(content)\n                elif isinstance(action, SimpleWriteReview):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message is tests, prefer message content as tests\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        tests = getattr(message, \"content\", tests)\n                    result = await action.run(code, tests)\n                elif isinstance(action, SimpleVerify):\n                    code, tests = _gather_code_tests_from_env()\n                    # If message provides tests or code, prefer them\n                    if message:\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                            tests = getattr(message, \"content\", tests)\n                        if getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                            code = getattr(message, \"content\", code)\n                    result = await action.run(code, tests)\n                else:\n                    # Generic action\n                    result = await action.run()  # type: ignore\n                # Normalize result to structured dict\n                if isinstance(result, dict):\n                    status = result.get(\"status\") or (\"ok\" if result.get(\"verified\") else \"unknown\")\n                    payload = result.get(\"payload\") if \"payload\" in result else (str(result))\n                    meta = result.get(\"meta\", {})\n                else:\n                    # older behavior: string\n                    payload = str(result or \"\")\n                    status = \"ok\" if not payload.startswith(\"Error\") and \"VERIFICATION_RESULT: PASS\" not in payload else (\"pass\" if \"PASS\" in payload else \"error\")\n                    meta = {}\n                \n                # Mark message processed to avoid double handling\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Keep last outputs (small history)\n                try:\n                    self._last_outputs.append(payload)\n                    if len(self._last_outputs) > 8:\n                        self._last_outputs = self._last_outputs[-8:]\n                except Exception:\n                    pass\n                \n                # Decide recipients based on action type and status\n                recipients = set()\n                cause_name = action.name if action else \"\"\n                if isinstance(action, SimpleWriteCode):\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # If review says ok -> verifier & coder, else coder primarily\n                    if status == \"ok\" or status == \"ok\":\n                        recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                    else:\n                        recipients = {\"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    recipients = {\"Team\"}\n                else:\n                    recipients = {\"Team\"}\n                \n                # Build standardized message content for downstream parsing\n                # Use a short header and include payload (full payload may be long)\n                header = f\"RESULT|{cause_name}|{status}\"\n                content_str = header + \"\\n\" + (payload or \"\")\n                response = Message(\n                    content=content_str,\n                    role=self.profile,\n                    cause_by=cause_name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action succeeded, created message id={(getattr(response,'id',None))}; status={status}\")\n                return response\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # Backoff before retrying\n                await sleep(0.5 * attempts)\n        # If we reach here, action failed consistently\n        fail_msg = f\"ROLE_FAILED: {self.name} could not complete action after {attempts} attempts. Error={last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with clear message routing and deduplication\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and trace it\"\"\"\n        # Prevent duplicate identical messages (by content + sender) flooding\n        try:\n            if any(m.id == message.id for m in self.history):\n                # already published\n                return\n        except Exception:\n            pass\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:200]} | cause_by={getattr(message,'cause_by',None)} | send_to={getattr(message,'send_to',None)}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Get messages that a role should respond to.\n        This respects explicit addressing (send_to) and the role's watch_list.\n        It also filters messages already processed by the role.\n        \"\"\"\n        relevant_messages = []\n        for msg in list(self.history):\n            # Skip messages the role already processed\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # If explicitly addressed\n            if getattr(msg, \"send_to\", None):\n                if role.profile in msg.send_to or role.name in msg.send_to or \"*\" in msg.send_to:\n                    relevant_messages.append(msg)\n                    continue\n            # If message cause_by matches watch_list\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        # Return in chronological order (oldest first) to preserve causal flow\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together with robust termination and verification logic\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification confirmation count to avoid premature termination\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2  # require two independent confirmations\n        self._review_ok_count = 0\n        self._stable_rounds_after_verify = 0\n        self._required_stable_rounds = 1  # require a round of stability after verification\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds with stronger orchestration and termination checks\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (verify confirmations needed={self._verify_confirm_needed})\")\n        \n        # Initial message with the idea, explicitly addressed to the coder role\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        # We'll track rounds where no progress is made to avoid infinite loops\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            progress_made = False\n            \n            # Orchestrated sequence: evaluate each role each round; roles pick relevant messages\n            for role in list(self.env.roles):\n                relevant = self.env.get_messages_for_role(role)\n                # Ensure coder receives the initial instruction on first round\n                msgs_to_process = relevant\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    msgs_to_process = [initial_msg] + [m for m in relevant if m.id != initial_msg.id]\n                for msg in msgs_to_process:\n                    resp = await role.act(msg)\n                    if resp:\n                        self.env.publish_message(resp)\n                        progress_made = True\n                        # Process verifier outputs\n                        if isinstance(role, SimpleVerifier):\n                            # standardized content begins with RESULT|SimpleVerify|PASS/FAIL\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"PASS\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: PASS\" in resp.content):\n                                    self._verify_confirm_count += 1\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} reported PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                elif \"FAIL\" in header or (isinstance(resp.content, str) and \"VERIFICATION_RESULT: FAIL\" in resp.content):\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_FAIL\", \"Team\", f\"Verifier {role.name} reported FAIL; resetting confirmations\")\n                            except Exception as e:\n                                self.tracer.log(\"VERIFY_ERROR\", \"Team\", f\"Could not parse verifier result: {e}\")\n                        # Process reviewer outputs for acceptance\n                        if isinstance(role, SimpleReviewer):\n                            try:\n                                header = (resp.content.splitlines()[0] if resp.content else \"\")\n                                if \"VERDICT: ok\" in resp.content.lower() or \"result|simplewritereview|ok\" in header.lower():\n                                    self._review_ok_count += 1\n                                    self.tracer.log(\"REVIEW_OK\", \"Team\", f\"Reviewer {role.name} returned ok ({self._review_ok_count})\")\n                                else:\n                                    # reviewer requested changes -> reset verifier confirmations to force rework\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"REVIEW_NEEDS_CHANGES\", \"Team\", f\"Reviewer {role.name} requested changes; resetting verify confirmations\")\n                            except Exception:\n                                pass\n                        # Handle explicit role failures\n                        if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                            self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure noted: {resp.content[:200]}\")\n            # detect progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n            \n            # Check for stable verification: require multiple verifier confirmations and at least one reviewer ok\n            if self._verify_confirm_count >= self._verify_confirm_needed and self._review_ok_count >= 1:\n                self._stable_rounds_after_verify += 1\n                self.tracer.log(\"TEAM_VERIFY_STABLE\", \"Team\", f\"Stable verification observed for {self._stable_rounds_after_verify} rounds\")\n                if self._stable_rounds_after_verify >= self._required_stable_rounds:\n                    verified = True\n            else:\n                self._stable_rounds_after_verify = 0\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed (progress_made={progress_made})\")\n            # Termination conditions\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification and review confirmed; stopping early at round {round_num + 1}\")\n                break\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds, stopping early to conserve resources\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified} (verify_confirms={self._verify_confirm_count}, review_ok={self._review_ok_count})\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}