{"id": "0808568d-25e4-4622-9cb4-e0b7aa9f8021", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear roles & responsibilities\n# - Robust inter-agent communication with explicit routing and watch triggers\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with deterministic digest and consecutive confirmation\n# - Retry and fallback for LLM/API failures\n# - Safe termination (require confirmed verification and stability)\n\n# Tunables\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.6\nROLE_MAX_ATTEMPTS = 3\nVERIFICATION_STABLE_PASSES = 2\n\n# Utility\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = str(text).replace(\"\\n\", \" \")\n    return (t[:n] + \"...\") if len(t) > n else t\n\nclass Action(ABC):\n    \"\"\"Base action: encapsulates LLM retries, backoff and deterministic fallback.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    base_backoff: float = LLM_BACKOFF_BASE\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retry, backoff, jitter, and logging. Returns deterministic fallback on exhaustion.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n                    if tracer:\n                        tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response from LLM\")\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} succeeded len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {_preview(last_err,200)}\")\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)) + random.uniform(0, 0.2))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Idea preview={_preview(idea,200)}\")\n        if not idea or not idea.strip():\n            fallback = (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback when no idea provided.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea; returning deterministic fallback\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module implementing the described task.\\n\"\n            \"Return only valid Python source code (no markdown fences). Include docstrings and basic input validation.\\n\\n\"\n            f\"Task:\\n{idea}\\n\"\n        )\n        messages = [{\"role\":\"system\",\"content\":\"You are an expert Python programmer.\"},\n                    {\"role\":\"user\",\"content\":prompt}]\n        resp = await self._ask_with_retry(messages)\n        # If LLM returned failure sentinel, return deterministic fallback error content\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            fallback = f\"# CODE_GEN_ERROR: {resp}\\n# Please provide manual implementation.\"\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning error sentinel\")\n            return fallback\n        # strip common fences\n        code = resp.strip()\n        if code.startswith(\"", "language": "python", "parent_id": "e205f29d-a04d-4139-8571-726a074f6e0f", "generation": 2, "timestamp": 1754657470.9587064, "iteration_found": 109, "metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "unterminated string literal (detected at line 273) (tmprbl3jyta.py, line 273)"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "name 'ABC' is not defined"}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.0000\n- combined_score: 0.0000\n- avg_failures_per_task: 14.0000\n- error: name 'ABC' is not defined\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: avg_failures_per_task. Consider continuing with similar changes.\n- Metrics showing regression: runs_successfully, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 4\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.1667, avg_failures_per_task: 5.0000, total_failures: 30.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2400, avg_failures_per_task: 3.1667, total_failures: 19.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.2857, avg_failures_per_task: 2.5000, total_failures: 15.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 3.8304)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport random\nimport time\n\nclass Action(ABC):\n    \"\"\"\n    Base action class.\n    - Provides robust LLM call with exponential backoff, jitter, and clear error handling.\n    - Actions are pure units of work that take inputs and return outputs (strings).\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Call the LLM with retries, exponential backoff and jitter.\n        Returns either the LLM string response or a structured error string starting with \"LLM_ERROR:\".\n        \"\"\"\n        import asyncio\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if not self.llm:\n                    # Deterministic fallback for offline runs\n                    response = \"LLM_FALLBACK: no-llm-available\"\n                else:\n                    response = await self.llm.ask(messages)\n\n                # Detect common LLM error patterns\n                if not isinstance(response, str) or response.strip() == \"\":\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response from LLM\")\n                if response.strip().lower().startswith(\"error\") or \"http\" in response and \"error\" in response.lower():\n                    last_err = response\n                    raise RuntimeError(f\"LLM returned error-like text: {response[:200]}\")\n\n                # Log success\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} succeeded (len={len(response)})\")\n                return response\n\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                # Backoff with jitter\n                if attempt < self.max_retries:\n                    backoff = self.base_backoff * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n                else:\n                    if self.context and getattr(self.context, \"tracer\", None):\n                        self.context.tracer.log(\"LLM_GIVEUP\", self.name, f\"Giving up after {self.max_retries} attempts: {last_err[:200]}\")\n        return f\"LLM_ERROR: {last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result.\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating code for idea (len={len(idea)})\")\n        prompt = (\n            \"You are an expert Python developer.\\n\"\n            \"Task:\\n\"\n            f\"{idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide production-ready Python code.\\n\"\n            \"- Include docstrings and input validation where appropriate.\\n\"\n            \"- Keep functions small and testable.\\n\"\n            \"- Return only the Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        # Basic sanity checks and fallback\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = f\"# ERROR: unable to generate code automatically. {result}\\n\\n# Placeholder function\\n\\ndef placeholder():\\n    \\\"\\\"\\\"Placeholder due to LLM failure.\\\"\\\"\\\"\\n    return None\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder code due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating tests for code (len={len(code)})\")\n        truncated = (code or \"\")[:4000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the provided Python code.\\n\\n\"\n            \"Code:\\n\"\n            f\"{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest test functions with clear assertions and docstrings.\\n\"\n            \"- Cover typical, boundary and error cases when applicable.\\n\"\n            \"- Return only pytest-compatible Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            note = f\"# ERROR_GENERATING_TESTS: {result}\\n# Tests not generated due to LLM error.\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder test note due to LLM error\")\n            return note\n        return result\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: recommended manual review.\"\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review and a readiness verdict.\\n\\n\"\n            \"Code (truncated):\\n\"\n            f\"{(code or '')[:2000]}\\n\\n\"\n            \"Tests (truncated):\\n\"\n            f\"{(tests or '')[:2000]}\\n\\n\"\n            \"Return:\\n- A short list of issues (if any)\\n- Checklist of fixes\\n- VERDICT: READY or NOT_READY (single line at the end prefixed by VERDICT:)\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = \"REVIEW_ERROR: Review could not be completed due to LLM failure.\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Review fallback due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"\n        Deterministic verification using static analysis heuristics.\n        Returns a structured verification result string.\n        \"\"\"\n        import ast\n        issues: List[str] = []\n        code_ok = False\n        tests_ok = False\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Starting verification\")\n\n        # Code syntax check\n        if not code or not code.strip():\n            issues.append(\"code_missing_or_empty\")\n        else:\n            try:\n                parsed = ast.parse(code)\n                code_ok = True\n                fn_names = [n.name for n in parsed.body if isinstance(n, ast.FunctionDef)]\n            except Exception as e:\n                issues.append(f\"code_syntax_error: {e}\")\n                fn_names = []\n\n        # Tests syntax and heuristics\n        if not tests or not tests.strip():\n            issues.append(\"tests_missing_or_empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristics: tests must contain 'assert' and at least one function named test_\n                contains_assert = \"assert \" in tests or \"pytest\" in tests.lower()\n                test_fns = [n.name for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\")]\n                tests_ok = bool(contains_assert and test_fns)\n                if not contains_assert:\n                    issues.append(\"tests_missing_asserts\")\n                if not test_fns:\n                    issues.append(\"tests_missing_test_functions\")\n            except Exception as e:\n                issues.append(f\"tests_syntax_error: {e}\")\n\n        # Ensure tests reference code functions when possible\n        references_code = False\n        if code_ok and tests_ok and fn_names:\n            for fn in fn_names:\n                if fn and fn in (tests or \"\"):\n                    references_code = True\n                    break\n            if not references_code:\n                issues.append(\"tests_do_not_reference_code\")\n\n        verified = code_ok and tests_ok and (references_code or not fn_names)\n        result = {\n            \"verified\": verified,\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok,\n            \"issues\": issues\n        }\n        summary = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | details: {result}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_END\", self.name, summary)\n        return summary\n\n\nclass Role(ABC):\n    \"\"\"\n    Clear role definition and responsibilities.\n    - Each role has a small set of actions.\n    - Each role maintains processed message ids to avoid duplicate work.\n    - Roles define watch_list (action names) and default recipients for produced messages.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # watch action names\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n        self._processed_message_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: List[Type[Action]]):\n        self.watch_list = [a.name for a in actions]\n\n    def should_respond(self, message: Message) -> bool:\n        \"\"\"\n        Decide whether the role should respond:\n        - Not already processed\n        - Explicitly addressed via send_to or sent_to\n        - Message cause_by matches watched actions\n        - Human user instructions target coders by default\n        \"\"\"\n        if not message:\n            return False\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # explicit addressing: either send_to set contains profile/name, or sent_to string matches\n        sent_to_set = getattr(message, \"send_to\", None)\n        if sent_to_set:\n            if isinstance(sent_to_set, (set, list)) and (self.profile in sent_to_set or self.name in sent_to_set or \"*\" in sent_to_set):\n                return True\n        sent_to_str = getattr(message, \"sent_to\", None)\n        if isinstance(sent_to_str, str) and (sent_to_str == self.profile or sent_to_str == self.name or sent_to_str == \"*\"):\n            return True\n        # watched action trigger\n        if getattr(message, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # default: user input goes to coders\n        if getattr(message, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Core action executor:\n        - Picks first applicable action and runs it.\n        - Records processed message id.\n        - Returns a Message with content, cause_by and intended send_to recipients.\n        - Robust error handling with retries for transient failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Received message id={(getattr(message,'id',None))} cause_by={(getattr(message,'cause_by',None))}\")\n\n        # find message to act on (if provided)\n        if message is not None and not self.should_respond(message):\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n\n        action = self.actions[0]  # single-responsibility per role; keep simple\n        attempts = 0\n        last_err = None\n        while attempts < 2:\n            attempts += 1\n            try:\n                # Build inputs based on action type\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    # Prefer code from message or find latest code in environment\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                    if not code_text and getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                                break\n                    result = await action.run(code_text)\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # Acquire latest code and tests from env if not supplied\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    # collect latest code/tests\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"Team\"}\n                else:\n                    result = await action.run()\n                    recipients = {\"Team\"}\n                # Mark message processed\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Create response message with clear routing\n                response = Message(\n                    content=result,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message cause_by={response.cause_by} send_to={recipients}\")\n                return response\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # small backoff\n                time.sleep(0.1 * attempts)\n        # If here, role failed reliably\n        fail_msg = f\"ROLE_FAILED: {self.name} after retries. Error={last_err}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"Unknown\"),\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])  # primarily triggered by UserInput or explicit addressing\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])  # run when code is available\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"\n    Environment handles message publication and routing.\n    - Maintains history (ordered).\n    - Provides messages relevant to a role using explicit send_to and watch_list rules.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Ensure ID exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"From {message.sent_from} cause_by={message.cause_by} send_to={getattr(message,'send_to',None)} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages a role should consider:\n        - Explicitly addressed messages (send_to / sent_to)\n        - Messages whose cause_by matches role.watch_list\n        - Exclude messages already processed by the role\n        \"\"\"\n        relevant: List[Message] = []\n        for msg in self.history:\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # explicit addressing via send_to (preferred)\n            sent_to = getattr(msg, \"send_to\", None)\n            if sent_to:\n                if isinstance(sent_to, (set, list)) and (role.profile in sent_to or role.name in sent_to or \"*\" in sent_to):\n                    relevant.append(msg)\n                    continue\n            # explicit sent_to string field\n            sent_to_str = getattr(msg, \"sent_to\", None)\n            if isinstance(sent_to_str, str) and (sent_to_str == role.profile or sent_to_str == role.name or sent_to_str == \"*\"):\n                relevant.append(msg)\n                continue\n            # watch_list triggers\n            if getattr(msg, \"cause_by\", \"\") in role.watch_list:\n                relevant.append(msg)\n                continue\n        return relevant\n\n\nclass Team:\n    \"\"\"\n    Team orchestrates roles, sequencing, termination, and verification confirmation logic.\n    - Requires multiple independent verification confirmations to avoid premature termination.\n    - Tracks progress and stops on verification PASS or prolonged no-progress.\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # require confirmations from verifiers (could be same verifier across rounds)\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2\n        # track unique verifiers or rounds that produced PASS to reduce false positives\n        self._verify_pass_rounds: Set[int] = set()\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        import asyncio\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._verify_confirm_needed} confirmations to stop early\")\n\n        # Initial User instruction directed to coder(s)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for round_idx in range(n_round):\n            round_num = round_idx + 1\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            progress_made = False\n\n            # Evaluate each role; roles decide if they act based on environment messages\n            for role in list(self.env.roles):\n                # Gather messages relevant to this role\n                msgs = self.env.get_messages_for_role(role)\n                # On first round, ensure coder sees the initial instruction even if not in msgs\n                if isinstance(role, SimpleCoder) and round_idx == 0:\n                    msgs = [initial_msg] + msgs\n                # Process messages in order; roles may produce one message per input to keep steps atomic\n                for msg in msgs:\n                    try:\n                        resp = await role.act(msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            progress_made = True\n                            # If verifier response contains a PASS, count confirmation\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    self._verify_confirm_count += 1\n                                    self._verify_pass_rounds.add(round_idx)\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                    if self._verify_confirm_count >= self._verify_confirm_needed:\n                                        verified = True\n                                elif \"VERIFICATION_RESULT: FAIL\" in resp.content:\n                                    # reset confirmations on explicit fail\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_RESET\", \"Team\", f\"Verifier {role.name} reported FAIL; confirmations reset\")\n                            # Log role failures directed to team\n                            if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                                self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure: {resp.content[:200]}\")\n                    except Exception as e:\n                        self.tracer.log(\"ROUND_ERROR\", role.name, f\"Exception during role.act: {e}\")\n\n            # Determine progress/no-progress and update termination conditions\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} complete (progress={progress_made})\")\n\n            # Termination: require at least one full round and required confirmations\n            if verified and round_num >= 1:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed after {self._verify_confirm_count} confirmations; stopping\")\n                break\n\n            # Stop if no progress for multiple rounds to avoid wasting cycles\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds; terminating early\")\n                break\n\n            # allow small async pause\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' finished after {round_num} rounds with {len(self.env.history)} messages. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.3158), Performs well on avg_failures_per_task (2.1667), Performs well on total_failures (13.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 2 (Score: 4.2143)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2857), Performs well on avg_failures_per_task (2.5000), Performs well on total_failures (15.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 3 (Score: 4.9844)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.2400), Performs well on avg_failures_per_task (3.1667), Performs well on total_failures (19.0000), Performs well on successful_runs (6.0000)\n\n\n### Program 4 (Score: 7.1111)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1667), Performs well on avg_failures_per_task (5.0000), Performs well on total_failures (30.0000), Performs well on successful_runs (6.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic fallback response.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: Malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\n\n# Utility\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = str(text).replace(\"\\n\", \" \")\n    return (t[:n] + \"...\") if len(t) > n else t\n\n# ===================== Actions =====================\n\nclass Action(ABC):\n    \"\"\"Base action with robust LLM retry/backoff and clear contract.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, backoff, and error detection. Deterministic fallback on failure.\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n            try:\n                if not self.llm:\n                    return \"LLM_UNAVAILABLE_FALLBACK\"\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"empty LLM response\")\n                if resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"{_preview(last_err, 200)}\")\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # Exhausted\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAIL\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Coder: produce parseable Python module from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            fallback = (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback when no idea is provided.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea; using fallback code\")\n            return fallback\n        prompt = (\n            \"You are an expert Python developer. Implement a single Python module for the task below.\\n\"\n            \"Return only valid Python code (no markdown/backticks). Include docstrings and basic input validation.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        code = await self._ask_with_retry(messages)\n        # Validate parseability; fallback if invalid\n        try:\n            ast.parse(code or \"\")\n        except Exception:\n            code = (\n                \"def main_task(data=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback implementation when LLM output is invalid.\\\"\\\"\\\"\\n\"\n                \"    return data\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM code invalid; using fallback\")\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Code len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Tester: generate pytest-style tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        if not code or not code.strip():\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test when no code is available.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"No code; using fallback tests\")\n            return fallback\n        # Extract top-level function/class names to improve cross-reference\n        names: List[str] = []\n        try:\n            tree = ast.parse(code)\n            for n in tree.body:\n                if isinstance(n, (ast.FunctionDef, ast.ClassDef)) and not n.name.startswith(\"_\"):\n                    names.append(n.name)\n        except Exception:\n            names = []\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided module.\\n\"\n            \"- Include positive and negative cases\\n- Use assert statements\\n- Provide only test code\\n\\n\"\n            f\"Public API (hint): {', '.join(names[:6]) or '(none)'}\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:3000]}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        tests = await self._ask_with_retry(messages)\n        # Validate tests structure; fallback if invalid\n        try:\n            parsed = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body)\n            has_assert = (\"assert \" in (tests or \"\")) or any(isinstance(n, ast.Assert) for n in ast.walk(parsed))\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"no tests/asserts found\")\n        except Exception:\n            target = names[0] if names else \"main_task\"\n            tests = (\n                f\"def test_placeholder_positive():\\n\"\n                f\"    \\\"\\\"\\\"Basic positive touching {target}.\\\"\\\"\\\"\\n\"\n                f\"    assert True\\n\\n\"\n                f\"def test_placeholder_negative():\\n\"\n                f\"    \\\"\\\"\\\"Basic negative referencing {target}.\\\"\\\"\\\"\\n\"\n                f\"    assert not False\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM tests invalid; using fallback\")\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Reviewer: provide concise actionable review with decision token.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # Static checks to seed review\n        issues: List[str] = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:140]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:140]}\")\n        if self.is_human:\n            review = (\"HUMAN_REVIEW: ok\" if not issues else \"HUMAN_REVIEW: \" + \"; \".join(issues)) + \"\\nREVIEW_DECISION: \" + (\"APPROVE\" if not issues else \"REQUEST_CHANGES\")\n            return review\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review with 3 actionable points and end with:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGES\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\n\"\n            f\"Code (first 1200 chars):\\n{(code or '')[:1200]}\\n\\n\"\n            f\"Tests (first 1200 chars):\\n{(tests or '')[:1200]}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        resp = await self._ask_with_retry(messages)\n        review = resp if isinstance(resp, str) else \"REVIEW_DECISION: REQUEST_CHANGES\"\n        if \"REVIEW_DECISION:\" not in (review or \"\"):\n            # Heuristic decision\n            decision = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            review = (review or \"Automated review.\") + f\"\\nREVIEW_DECISION: {decision}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Verifier: deterministic static verification with digest for stability checks.\"\"\"\n    name = \"SimpleVerify\"\n\n    @staticmethod\n    def _digest(code: str, tests: str) -> str:\n        h = hashlib.sha256()\n        h.update((code or \"\").encode(\"utf-8\"))\n        h.update(b\"\\n--\\n\")\n        h.update((tests or \"\").encode(\"utf-8\"))\n        return h.hexdigest()[:12]\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying artifacts\")\n        details: List[str] = []\n        # Syntax checks\n        code_ok = False\n        tests_ok = False\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({str(e)[:120]})\")\n        try:\n            ttree = ast.parse(tests or \"\")\n            tests_ok = True\n            # check tests presence\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ttree.body)\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(ttree)) or (\"assert \" in (tests or \"\"))\n            details.append(\"tests_presence: ok\" if (has_test_fn or has_assert) else \"tests_presence: questionable\")\n            tests_presence_ok = (has_test_fn or has_assert)\n        except Exception as e:\n            tests_ok = False\n            tests_presence_ok = False\n            details.append(f\"tests_syntax: fail ({str(e)[:120]})\")\n        # Code entities and cross-reference\n        entities: Set[str] = set()\n        cross_ref = False\n        if code_ok:\n            try:\n                ctree = ast.parse(code or \"\")\n                for n in ctree.body:\n                    if isinstance(n, (ast.FunctionDef, ast.ClassDef)):\n                        entities.add(n.name)\n                details.append(f\"code_entities: {len(entities)}\")\n            except Exception:\n                details.append(\"code_entities: error\")\n        if entities and tests_ok:\n            try:\n                names_in_tests = set(n.id for n in ast.walk(ast.parse(tests or \"\")) if isinstance(n, ast.Name))\n                cross_ref = len(entities & names_in_tests) > 0\n                details.append(\"cross_reference: ok\" if cross_ref else \"cross_reference: fail\")\n            except Exception:\n                details.append(\"cross_reference: error\")\n        verified = bool(code_ok and tests_ok and tests_presence_ok and entities and cross_ref)\n        digest = self._digest(code or \"\", tests or \"\")\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# ===================== Roles =====================\n\nclass Role(ABC):\n    \"\"\"Base role with single responsibility, explicit watch-list, and idempotent handling.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n    _processed_ids: Set[str] = set()\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = None\n        self._processed_ids = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = {a.name for a in actions}\n\n    def _should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # Explicit routing\n        targets = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n        if targets and (self.name in targets or self.profile in targets):\n            return True\n        # Watch-list by cause_by\n        if getattr(msg, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # Coder also listens to UserInput nudges\n        if isinstance(self, SimpleCoder) and getattr(msg, \"cause_by\", \"\") in {\"UserInput\", \"Nudge\"}:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.action:\n            return None\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Action={self.action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(self.action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                out = await self.action.run(idea)\n                send_to = {\"SimpleTester\"}\n                cause_by = SimpleWriteCode.name\n            elif isinstance(self.action, SimpleWriteTest):\n                code_text = \"\"\n                if message and getattr(message, \"content\", None):\n                    code_text = message.content\n                elif self.env:\n                    latest_code = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest_code.content if latest_code else \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                cause_by = SimpleWriteTest.name\n            elif isinstance(self.action, SimpleWriteReview):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = {\"SimpleVerifier\"}\n                cause_by = SimpleWriteReview.name\n            elif isinstance(self.action, SimpleVerify):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = {\"SimpleCoder\", \"SimpleTester\", \"SimpleReviewer\"}  # broadcast for traceability\n                cause_by = SimpleVerify.name\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n                cause_by = getattr(self.action, \"name\", \"Action\")\n            resp = Message(\n                content=out,\n                role=self.profile,\n                cause_by=cause_by,\n                sent_from=self.name,\n                send_to=set(send_to) if isinstance(send_to, (set, list)) else set()\n            )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION in {self.name}: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            resp = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n        # Mark processed\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={resp.id} to={getattr(resp,'send_to',set())}\")\n        return resp\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # acts on explicit routing or UserInput/Nudge\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n# ===================== Environment =====================\n\nclass Environment:\n    \"\"\"Message bus with explicit routing, watch triggers, and idempotent processing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs to prevent duplicate handling\n        self.processed: Set[tuple] = set()\n        # index by cause_by for quick artifact retrieval\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Normalize send_to as set\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if getattr(message, \"cause_by\", \"\"):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = _preview(getattr(message, \"content\", \"\"), 160)\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} to={list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        return (role.name, getattr(message, \"id\", None)) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages the role should handle (explicitly addressed or watched), excluding already processed.\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if self.has_processed(role, msg):\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            targets = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if targets and (role.name in targets or role.profile in targets):\n                out.append(msg)\n                continue\n            # watch-list by cause\n            if getattr(msg, \"cause_by\", \"\") in role.watch_list:\n                out.append(msg)\n                continue\n            # special: coder reacts to UserInput/Nudge\n            if isinstance(role, SimpleCoder) and getattr(msg, \"cause_by\", \"\") in {\"UserInput\", \"Nudge\"}:\n                out.append(msg)\n        return out\n\n    def get_latest_by_cause(self, cause_name: str) -> Optional[Message]:\n        lst = self._by_cause.get(cause_name, [])\n        return lst[-1] if lst else None\n\n# ===================== Team Orchestration =====================\n\nclass Team:\n    \"\"\"Orchestrates collaboration with deterministic ordering and stable termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Verification stability tracking\n        self._last_digest: Optional[str] = None\n        self._pass_streak: int = 0\n        self._required_streak: int = 2\n        self._last_verifier_index: int = -1\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_streak={self._required_streak})\")\n        # Kickoff message to coder (both by name and profile for robustness)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"Alice\", \"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        role_order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_idx in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_idx}/{n_round}\")\n            progress = False\n\n            # Detect invalidation: if new code/tests were added after last verifier pass, reset streak\n            if self._last_verifier_index >= 0:\n                for i, m in enumerate(self.env.history[self._last_verifier_index + 1 :], start=self._last_verifier_index + 1):\n                    if getattr(m, \"cause_by\", \"\") in {SimpleWriteCode.name, SimpleWriteTest.name}:\n                        if self._pass_streak > 0:\n                            self.tracer.log(\"VERIFIER_INVALIDATE\", \"Team\", f\"New artifact after PASS; reset streak {self._pass_streak}->0\")\n                        self._pass_streak = 0\n                        self._last_digest = None\n                        break\n\n            for RoleType in role_order:\n                for role in [r for r in self.env.roles if isinstance(r, RoleType)]:\n                    msgs = self.env.get_messages_for_role(role)\n                    if not msgs and isinstance(role, SimpleCoder) and round_idx == 1:\n                        msgs = [initial_msg]  # ensure coder sees initial\n                    for msg in msgs:\n                        if self.env.has_processed(role, msg):\n                            continue\n                        try:\n                            resp = await role.act(msg)\n                            self.env.mark_processed(role, msg)\n                            if resp:\n                                self.env.publish_message(resp)\n                                progress = True\n                                # track verifier passes\n                                if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                    self._last_verifier_index = len(self.env.history) - 1\n                                    content = resp.content\n                                    if \"VERIFICATION_RESULT: PASS\" in content:\n                                        # extract digest\n                                        digest = None\n                                        for part in content.split(\"|\"):\n                                            part = part.strip()\n                                            if part.startswith(\"digest=\"):\n                                                digest = part.split(\"=\", 1)[1]\n                                                break\n                                        if digest:\n                                            if digest == self._last_digest:\n                                                self._pass_streak += 1\n                                            else:\n                                                self._last_digest = digest\n                                                self._pass_streak = 1\n                                            self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"digest={digest} streak={self._pass_streak}\")\n                                        else:\n                                            self._pass_streak = 0\n                                            self._last_digest = None\n                                    else:\n                                        if self._pass_streak > 0:\n                                            self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._pass_streak}->0\")\n                                        self._pass_streak = 0\n                                        self._last_digest = None\n                        except Exception as e:\n                            self.tracer.log(\"ROLE_RUN_ERROR\", role.name, f\"{type(e).__name__}: {str(e)[:200]}\")\n                            err_msg = Message(\n                                content=f\"ERROR: {role.name} failed: {type(e).__name__}: {str(e)[:200]}\",\n                                role=role.profile,\n                                cause_by=\"RoleRunError\",\n                                sent_from=role.name,\n                                send_to={\"SimpleCoder\"}\n                            )\n                            self.env.publish_message(err_msg)\n                            progress = True\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_idx} done; progress={progress} pass_streak={self._pass_streak}\")\n\n            if self._pass_streak >= self._required_streak:\n                verified = True\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification stable; stopping\")\n                break\n\n            if not progress:\n                # Nudge coder to avoid stagnation\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"Alice\", \"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                for coder in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                    try:\n                        resp = await coder.act(nudge)\n                        if resp:\n                            self.env.publish_message(resp)\n                    except Exception as e:\n                        self.tracer.log(\"NUDGE_ERROR\", coder.name, f\"{type(e).__name__}: {str(e)[:120]}\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_idx} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D2 (Score: 3.2125)\n```python\n# -*- coding: utf-8 -*-\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nfrom typing import Tuple\n\n# Utility: compact preview for logs\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = str(text)\n    return (t[:n] + \"...\") if len(t) > n else t\n\n# Tunables\nLLM_RETRIES = 3\nLLM_BACKOFF_BASE = 0.5\nROLE_ACT_TIMEOUT = 90.0\nROLE_ACT_RETRIES = 2\nREQUIRED_STABLE_PASSES = 2  # consecutive verifier passes with same digest to stop\n\nclass Action(ABC):\n    \"\"\"Base action with clear responsibility and robust LLM retry logic.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]], retries: int = LLM_RETRIES, backoff_base: float = LLM_BACKOFF_BASE) -> str:\n        \"\"\"Call LLM with retries, exponential backoff and jitter. Returns deterministic fallback on exhaustion.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n        last_err = None\n        for attempt in range(1, retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and (resp.startswith(\"Error\") or \"Error communicating\" in resp):\n                    last_err = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, _preview(resp, 200))\n                    await asyncio.sleep(backoff_base * (2 ** (attempt - 1)) + random.random() * 0.2)\n                    continue\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    if tracer:\n                        tracer.log(\"LLM_EMPTY\", self.name, \"Empty response\")\n                    await asyncio.sleep(backoff_base * (2 ** (attempt - 1)))\n                    continue\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, _preview(last_err, 200))\n                await asyncio.sleep(backoff_base * (2 ** (attempt - 1)) + random.random() * 0.2)\n        failure = f\"LLM_FAILURE_FALLBACK: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure)\n        return failure\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Execute action and return a string.\"\"\"\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Coder: produce a parseable Python module for the idea.\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Idea={_preview(idea, 200)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module implementing the requested task.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no markdown fences).\\n\"\n            \"- Include at least one function or class.\\n\"\n            \"- Add docstrings and basic input validation where reasonable.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self.safe_ask(messages)\n        # Validate; provide safe fallback if not parseable\n        try:\n            ast.parse(code or \"\")\n            ok = True\n        except Exception as e:\n            ok = False\n            if tracer:\n                tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Code parse error: {e}\")\n        if not ok or code.startswith(\"LLM_UNAVAILABLE_FALLBACK\") or code.startswith(\"LLM_FAILURE_FALLBACK\"):\n            code = (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback implementation.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using deterministic fallback code\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Tester: create pytest tests for the provided code.\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Generate tests for code_len={len(code or '')}\")\n        snippet = (code or \"\")[:3000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the Python module below.\\n\\n\"\n            f\"Module (truncated):\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only (no markdown).\\n\"\n            \"- Include at least one positive and one edge-case test.\\n\"\n            \"- Use assert statements. Add short docstrings for tests.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self.safe_ask(messages)\n        # Validate tests are parseable and contain asserts; fallback if not\n        try:\n            ast.parse(tests or \"\")\n            has_assert = \"assert\" in (tests or \"\")\n            if not has_assert:\n                raise SyntaxError(\"No asserts found\")\n            ok = True\n        except Exception as e:\n            ok = False\n            if tracer:\n                tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests invalid: {e}\")\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)} ok={ok}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Reviewer: produce concise review with explicit decision token.\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_DECISION: APPROVE\\nHuman-simulated approval.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n            return review\n        prompt = (\n            \"You are a senior reviewer. Provide a short actionable review of the code and tests.\\n\"\n            \"End with a decision line starting with REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGES.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        review = await self.safe_ask(messages)\n        if not isinstance(review, str) or \"REVIEW_DECISION:\" not in review:\n            # Heuristic decision if missing\n            decision = \"REVIEW_DECISION: APPROVE\" if (\"assert\" in (tests or \"\") and (\"def \" in (code or \"\") or \"class \" in (code or \"\"))) else \"REVIEW_DECISION: REQUEST_CHANGES\"\n            review = (review or \"Automated review\") + \"\\n\" + decision\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"Appended heuristic REVIEW_DECISION\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Verifier: deterministic syntax + structural checks; emits digest for stability.\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Verifying artifacts\")\n\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Code syntax and entities\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(\"code_syntax: ok\")\n            details.append(f\"code_entities: {len(code_entities)}\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # Tests syntax and asserts\n        tests_has_asserts = False\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n            tests_has_asserts = \"assert\" in (tests or \"\")\n            details.append(\"tests_syntax: ok\" if tests_ok else \"tests_syntax: empty\")\n            details.append(\"tests_asserts: ok\" if tests_has_asserts else \"tests_asserts: none\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n\n        # Cross-reference: tests should reference code entities\n        referenced = False\n        if code_entities and parsed_tests:\n            names_in_tests = set()\n            for n in ast.walk(parsed_tests):\n                if isinstance(n, ast.Name):\n                    names_in_tests.add(n.id)\n            inter = code_entities & names_in_tests\n            referenced = len(inter) > 0\n            details.append(f\"tests_reference_matches: {len(inter)}\")\n        else:\n            details.append(\"tests_reference_matches: 0\")\n\n        passed = all([code_ok, tests_ok, bool(code_entities), tests_has_asserts, referenced])\n\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        result = f\"VERIFICATION_RESULT: {'PASS' if passed else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with single action, explicit watch/trigger logic, and idempotent processing.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = set()\n        self.env: Optional[\"Environment\"] = None\n        self._processed_ids: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names = set()\n        for a in actions:\n            if isinstance(a, str):\n                names.add(a)\n            else:\n                names.add(getattr(a, \"name\", str(a)))\n        self.watch_list = names\n\n    def _should_respond(self, msg: Message) -> bool:\n        if not msg:\n            return False\n        # direct addressing\n        targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None)\n        if targets:\n            if isinstance(targets, (set, list)):\n                if self.name in targets or self.profile in targets:\n                    return True\n            else:\n                if targets == self.name or targets == self.profile:\n                    return True\n        # watch by cause_by\n        if getattr(msg, \"cause_by\", \"\") in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action configured\")\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed_ids:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Already processed msg {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Acting on msg={msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Prepare inputs based on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                content = await self.action.run(idea or \"\")\n            elif isinstance(self.action, SimpleWriteTest):\n                code_src = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_src = message.content\n                elif getattr(self, \"env\", None):\n                    code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                content = await self.action.run(code_src)\n            elif isinstance(self.action, SimpleWriteReview):\n                code_text = self.env.find_latest_content_by_cause(SimpleWriteCode.name) if getattr(self, \"env\", None) else \"\"\n                tests_text = self.env.find_latest_content_by_cause(SimpleWriteTest.name) if getattr(self, \"env\", None) else \"\"\n                content = await self.action.run(code_text or \"\", tests_text or \"\")\n            elif isinstance(self.action, SimpleVerify):\n                code_text = self.env.find_latest_content_by_cause(SimpleWriteCode.name) if getattr(self, \"env\", None) else \"\"\n                tests_text = self.env.find_latest_content_by_cause(SimpleWriteTest.name) if getattr(self, \"env\", None) else \"\"\n                content = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                content = await self.action.run(payload)\n        except Exception as e:\n            if tracer:\n                tracer.log(\"ROLE_EXCEPTION\", self.name, f\"Action failed: {e}\")\n            return Message(\n                content=f\"ERROR: role {self.name} failed during {getattr(self.action, 'name', 'Unknown')}: {e}\",\n                role=self.profile,\n                cause_by=getattr(self.action, \"name\", \"\"),\n                sent_from=self.name\n            )\n\n        # Assemble response message\n        response = Message(\n            content=content,\n            role=self.profile,\n            cause_by=getattr(self.action, \"name\", \"\"),\n            sent_from=self.name,\n            send_to=set()\n        )\n\n        if msg_id:\n            self._processed_ids.add(msg_id)\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} cause_by={response.cause_by} len={len(response.content or '')}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role: produce code from idea. Watches UserInput and REQUEST_CHANGE.\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([\"UserInput\", \"REQUEST_CHANGE\"])\n\nclass SimpleTester(Role):\n    \"\"\"Role: write tests after code.\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role: review code and tests; request changes if needed.\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role: verify artifacts and signal PASS/FAIL.\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"Environment: message bus with delivery tracking and quick artifact lookup.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # subscriptions: action_name -> set(role.name)\n        self.subscriptions: Dict[str, Set[str]] = {}\n        # delivered tracking: role.name -> set(message.id)\n        self.delivered: Dict[str, Set[str]] = {}\n        # index by cause_by for quick fetch\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        role.env = self\n        # register subscriptions based on watch_list\n        for action_name in getattr(role, \"watch_list\", set()):\n            self.subscriptions.setdefault(action_name, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile}) watches={sorted(list(getattr(role,'watch_list',[])))}\")\n\n    def publish_message(self, message: Message):\n        if not getattr(message, \"id\", None):\n            message.id = str(uuid.uuid4())\n        self.history.append(message)\n        self._by_cause.setdefault(getattr(message, \"cause_by\", \"\"), []).append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content,120)} send_to={sorted(list(getattr(message,'send_to',set())))}\")\n\n    def get_routable_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages targeted at this role or matching its watch list, excluding those already delivered.\"\"\"\n        out: List[Message] = []\n        delivered_ids = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in delivered_ids:\n                continue\n            targeted = False\n            targets = getattr(msg, \"send_to\", None) or getattr(msg, \"sent_to\", None) or set()\n            if isinstance(targets, (set, list)):\n                targeted = (role.name in targets) or (role.profile in targets)\n            else:\n                targeted = targets == role.name or targets == role.profile\n            watched = getattr(msg, \"cause_by\", \"\") in role.watch_list\n            if targeted or watched or (getattr(msg, \"cause_by\", \"\") == \"UserInput\" and isinstance(role, SimpleCoder)):\n                out.append(msg)\n                delivered_ids.add(msg.id)\n        if out:\n            self.delivered[role.name] = delivered_ids\n        return out\n\n    def find_latest_message_by_cause(self, cause_by: str) -> Optional[Message]:\n        lst = self._by_cause.get(cause_by, [])\n        return lst[-1] if lst else None\n\n    def find_latest_content_by_cause(self, cause_by: str) -> Optional[str]:\n        msg = self.find_latest_message_by_cause(cause_by)\n        return msg.content if msg else None\n\nclass Team:\n    \"\"\"Team orchestrator with deterministic pipeline, robust retries/timeouts, and stable termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {_preview(idea, 200)}\")\n\n    async def _safe_act(self, role: Role, message: Optional[Message]) -> Optional[Message]:\n        tracer = self.tracer\n        last_err = None\n        for attempt in range(1, ROLE_ACT_RETRIES + 2):\n            try:\n                if tracer:\n                    tracer.log(\"ROLE_ATTEMPT\", role.name, f\"Attempt {attempt} on msg={getattr(message,'id',None)}\")\n                resp = await asyncio.wait_for(role.act(message), timeout=ROLE_ACT_TIMEOUT)\n                if resp and getattr(resp, \"content\", None):\n                    return resp\n                last_err = \"empty_response\"\n                if tracer:\n                    tracer.log(\"ROLE_EMPTY\", role.name, f\"Empty response on attempt {attempt}\")\n            except asyncio.TimeoutError:\n                last_err = \"timeout\"\n                if tracer:\n                    tracer.log(\"ROLE_TIMEOUT\", role.name, f\"Timeout on attempt {attempt}\")\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception: {_preview(last_err,200)}\")\n            await asyncio.sleep(0.2 * attempt)\n        return Message(\n            content=f\"ERROR: role {role.name} failed after retries: {last_err}\",\n            role=role.profile,\n            cause_by=\"System\",\n            sent_from=role.name\n        )\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run collaborative rounds with deterministic order and stable termination.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Kickoff message targeted to coders explicitly\n        coder_targets = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_targets or set([SimpleCoder.profile])\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        order: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            any_activity = False\n\n            # Deterministic pipeline\n            for role_type in order:\n                roles_of_type = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles_of_type:\n                    inbox = self.env.get_routable_messages_for_role(role)\n                    # Ensure coders get initial msg on first round if missed\n                    if isinstance(role, SimpleCoder) and round_num == 1 and initial_msg not in inbox:\n                        inbox.append(initial_msg)\n                    if not inbox:\n                        continue\n\n                    for msg in inbox:\n                        # Skip self-originated messages\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n\n                        response = await self._safe_act(role, msg)\n                        if not response:\n                            continue\n\n                        # Routing hints\n                        if isinstance(role, SimpleCoder):\n                            response.cause_by = SimpleWriteCode.name\n                            response.send_to = set([SimpleTester.profile])\n                        elif isinstance(role, SimpleTester):\n                            response.cause_by = SimpleWriteTest.name\n                            response.send_to = set([SimpleReviewer.profile, SimpleVerifier.profile])\n                        elif isinstance(role, SimpleReviewer):\n                            # Parse decision\n                            content_upper = (response.content or \"\").upper()\n                            if \"REVIEW_DECISION: REQUEST_CHANGES\" in content_upper or response.content.strip().upper().startswith(\"REQUEST_CHANGE\"):\n                                response.cause_by = \"REQUEST_CHANGE\"\n                                response.send_to = set([SimpleCoder.profile])\n                            else:\n                                response.cause_by = SimpleWriteReview.name\n                                response.send_to = set([SimpleVerifier.profile])\n                        elif isinstance(role, SimpleVerifier):\n                            response.cause_by = SimpleVerify.name\n                            response.send_to = set([r.profile for r in self.env.roles])\n\n                        self.env.publish_message(response)\n                        any_activity = True\n\n                        # Verification stability tracking\n                        if isinstance(role, SimpleVerifier) and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            # extract digest\n                            digest = None\n                            for part in response.content.split(\"|\"):\n                                p = part.strip()\n                                if p.startswith(\"digest=\"):\n                                    digest = p.split(\"=\", 1)[1].strip()\n                                    break\n                            if digest:\n                                if digest == self._last_digest:\n                                    self._streak += 1\n                                else:\n                                    self._last_digest = digest\n                                    self._streak = 1\n                                self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                if self._streak >= REQUIRED_STABLE_PASSES:\n                                    verified = True\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} complete any_activity={any_activity} verified={verified}\")\n\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification achieved (streak={self._streak}); stopping\")\n                break\n\n            if not any_activity:\n                # Nudge coder(s) to avoid stall\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: please produce or refine code for '{_preview(self.idea, 120)}'\",\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"REQUEST_CHANGE\",\n                            send_to={r.profile}\n                        )\n                        self.env.publish_message(nudge)\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Project completed; Verified={verified}\")\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D3 (Score: 4.6667)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport random\nfrom typing import Tuple\n\n# Goals implemented:\n# - Clear roles and responsibilities\n# - Explicit triggers and routing (send_to)\n# - Deterministic orchestration with per-role processed tracking\n# - Robust LLM retry + fallback\n# - Strong verification and confirmation + stable termination (consecutive passes)\n# - Error handling and retry across role actions\n\nDEFAULT_VERIFICATION_STREAK = 2\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.8  # seconds\nMAX_MESSAGE_ATTEMPTS = 6\n\nclass Action(ABC):\n    \"\"\"Base action with LLM retry, backoff, validation and fallback semantics.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    backoff_base: float = LLM_BACKOFF_BASE\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def call_llm(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns string result or an explicit error token.\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # Deterministic fallback to avoid hard failure\n                    fallback = \"LLM_UNAVAILABLE: deterministic fallback\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # jittered backoff\n                await asyncio.sleep(self.backoff_base * (2 ** (attempt - 1)) + random.uniform(0, 0.25))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce a validated Python module from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea_len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            # clear signal for empty idea\n            fallback = \"# WARNING: Empty idea provided. No code generated.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"Empty idea\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module implementing the described task. \"\n            \"Return only valid Python source code, no markdown fences or explanations. Include docstrings and input validation.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        resp = await self.call_llm(messages)\n        # If LLM failed, return explicit failure so downstream can react\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            fallback = f\"# CODE_GEN_ERROR: {resp}\\n# Please retry or provide a human-coded fallback.\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning error sentinel\")\n            return fallback\n\n        # Try to sanitize common code fences\n        code = self._strip_code_fences(resp)\n        # Validate syntax\n        try:\n            ast.parse(code)\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATE\", self.name, \"Code syntax ok\")\n            return code\n        except Exception as e:\n            # attempt small fix: wrap into function if possible\n            try:\n                wrapper = \"def _generated_wrapper():\\n\"\n                for line in code.splitlines():\n                    wrapper += \"    \" + line + \"\\n\"\n                ast.parse(wrapper)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FIX\", self.name, \"Applied safe wrapper to fix syntax\")\n                return wrapper\n            except Exception:\n                err = f\"# CODE_PARSE_ERROR: {str(e)[:160]}\\n# Raw Output:\\n{code}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"Code parse failed: {str(e)[:200]}\")\n                return err\n\n    def _strip_code_fences(self, text: Optional[str]) -> str:\n        if not text:\n            return \"\"\n        t = text.strip()\n        # remove triple backticks\n        if t.startswith(\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to combined_score\n\n\n### Program D4 (Score: 4.6667)\n```python\n# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n#\n# Goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit send_to and subscriptions\n# - Strong verification/validation and stable termination\n# - Defensive error handling and LLM/API retry logic\n# - Deterministic orchestration to reduce nondeterministic failure modes\n\nimport asyncio\nimport ast\nimport hashlib\nimport time\nfrom collections import defaultdict\nfrom typing import List, Dict, Optional, Set, Tuple, Type\n\n# Utility for short previews in logs\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = text.strip()\n    return (t[:n] + \"...\") if len(t) > n else t\n\n# Base Action class: encapsulates LLM calls with retries, logging and deterministic fallback\nclass Action(ABC):\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper for LLM calls:\n        - Retries with exponential backoff\n        - Logs attempts and failures\n        - Returns deterministic fallback if LLM unavailable or exhausted\n        \"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            # Deterministic fallback string that downstream actions recognize\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        last_exc = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_exc = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, _preview(resp, 200))\n                    # backoff and retry\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # treat empty responses as failure\n                if not resp or not isinstance(resp, str):\n                    last_exc = \"empty_response\"\n                    if tracer:\n                        tracer.log(\"LLM_EMPTY\", self.name, f\"Empty response on attempt {attempt}\")\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # success\n                return resp\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:300]}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_exc)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                continue\n\n        # exhausted retries\n        failure_msg = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_exc}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure_msg)\n        # stable, deterministic fallback\n        return f\"LLM_FAILURE_FALLBACK: {failure_msg}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\n# Concrete Actions: Code, Tests, Review, Verify\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_preview={_preview(idea)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module that implements the requested task.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no markdown).\\n\"\n            \"- Include docstrings and input validation where applicable.\\n\"\n            \"- Provide at least one function or class.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        code = await self.safe_ask(messages)\n        # quick heuristic validation; if invalid, return deterministic safe fallback\n        try:\n            ast.parse(code)\n            ok = True\n        except Exception as e:\n            ok = False\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Generated code failed parse: {e}\")\n        if not ok or \"LLM_FAILURE_FALLBACK\" in code or code.startswith(\"LLM_UNAVAILABLE_FALLBACK\"):\n            # deterministic safe minimal implementation\n            fallback = (\n                \"def placeholder(input_data=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback implementation.\\\"\\\"\\\"\\n\"\n                \"    return input_data\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using deterministic fallback code\")\n            code = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        snippet = (code or \"\")[:3000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the given Python module.\\n\\n\"\n            f\"Module (truncated):\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Include at least one positive and one negative test.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        tests = await self.safe_ask(messages)\n        # heuristic: ensure tests include 'assert' otherwise provide deterministic placeholder\n        if not tests or \"assert \" not in tests:\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback test\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using deterministic fallback tests\")\n            tests = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_DECISION: APPROVE\\nHuman-simulated approval.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review simulated APPROVE\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a short review and an explicit decision line starting with REVIEW_DECISION: APPROVE or REVIEW_DECISION: REJECT.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\\n\\n\"\n            \"Be concise and actionable.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing code reviews.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        review = await self.safe_ask(messages)\n        # Ensure explicit decision\n        if not review or \"REVIEW_DECISION:\" not in review:\n            # conservative default\n            decision = \"REVIEW_DECISION: REJECT\"\n            review = (review or \"Automated review: missing explicit decision.\") + \"\\n\\n\" + decision\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"No explicit decision from LLM; defaulting to REJECT\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Starting deterministic verification\")\n\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Code parse failed: {e}\")\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # check for assertions\n            tests_ok = bool(tests and (\"assert \" in tests or \"pytest\" in tests))\n            if tests_ok:\n                details.append(\"tests_syntax: ok\")\n            else:\n                details.append(\"tests_syntax: fail (no asserts found)\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Tests parse failed: {e}\")\n\n        # Structural checks: code has functions/classes, tests reference them\n        referenced = False\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(f\"code_entities: {sorted(list(code_entities))[:6]}\")\n        else:\n            details.append(\"code_entities: none\")\n\n        if parsed_tests and code_entities:\n            names_in_tests = set()\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Name):\n                    names_in_tests.add(node.id)\n            inter = code_entities & names_in_tests\n            referenced = len(inter) > 0\n            details.append(f\"tests_reference_matches: {sorted(list(inter))[:6]}\")\n        else:\n            details.append(\"tests_reference_matches: none\")\n\n        passed = all([code_ok, tests_ok, bool(code_entities), referenced])\n\n        # compute digest for stability detection\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if passed else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# Roles: each role has a single responsibility and explicit watch list + idempotency\n\nclass Role(ABC):\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()  # action names\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env: Optional[\"Environment\"] = kwargs.get(\"env\")\n        self._processed_message_ids: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: List[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", \"\") for a in actions}\n\n    def should_process(self, message: Optional[Message]) -> bool:\n        if message is None:\n            return False\n        # Direct addressing\n        targets = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n        if targets:\n            if isinstance(targets, (list, set)):\n                if self.name in targets or self.profile in targets:\n                    return True\n            else:\n                if targets == self.name or targets == self.profile:\n                    return True\n        # Watch list match\n        if getattr(message, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        # idempotency: skip processing if already done\n        if msg_id and msg_id in self._processed_message_ids:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping already processed message {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Processing message id={msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Decide inputs depending on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or (message.content if message else \"\")\n                result = await self.action.run(idea or \"\")\n            elif isinstance(self.action, SimpleWriteTest):\n                # prefer message content if it is code, else fetch latest code\n                code_src = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_src = message.content\n                elif getattr(self, \"env\", None):\n                    code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code_src)\n            elif isinstance(self.action, SimpleWriteReview):\n                env = getattr(self, \"env\", None)\n                code_text = env.find_latest_content_by_cause(SimpleWriteCode.name) if env else \"\"\n                tests_text = env.find_latest_content_by_cause(SimpleWriteTest.name) if env else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            elif isinstance(self.action, SimpleVerify):\n                env = getattr(self, \"env\", None)\n                code_text = env.find_latest_content_by_cause(SimpleWriteCode.name) if env else \"\"\n                tests_text = env.find_latest_content_by_cause(SimpleWriteTest.name) if env else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                # generic fallback\n                payload = message.content if message else \"\"\n                result = await self.action.run(payload)\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:300]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark as processed to prevent repeated failures\n            if msg_id:\n                self._processed_message_ids.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build outgoing message; include send_to empty set (environment will route to subscribers)\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(self.action, \"name\", \"\"),\n            sent_from=self.name,\n            send_to=set()\n        )\n\n        # mark input message as processed for idempotency\n        if msg_id:\n            self._processed_message_ids.add(msg_id)\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={response.id} cause_by={response.cause_by} preview={_preview(response.content,120)}\")\n        return response\n\n# Concrete role classes with explicit responsibilities\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        # coder responds to explicit user input or nudges\n        self.watch([type(\"UserInputDummy\", (), {\"name\": \"UserInput\"}), type(\"NudgeDummy\", (), {\"name\": \"Nudge\"})])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview])\n\n# Environment: message bus with deterministic routing, subscriptions and delivery tracking\n\nclass Environment:\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # map action_name -> set(role.name) who subscribe to that action\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)\n        # track delivered messages: message_id -> set(role.name)\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        # set environment reference on role\n        role.env = self\n        self.roles.append(role)\n        # register subscriptions\n        for action_name in getattr(role, \"watch_list\", set()):\n            self.subscriptions[action_name].add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile}) watching {sorted(list(getattr(role,'watch_list',[]))) }\")\n\n    def publish_message(self, message: Message):\n        # ensure id exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        # normalize send_to\n        if getattr(message, \"send_to\", None) is None:\n            message.send_to = set()\n        elif isinstance(message.send_to, (list, tuple)):\n            message.send_to = set(message.send_to)\n        self.history.append(message)\n        # initialize delivered tracking\n        self.delivered.setdefault(message.id, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published message {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content)} send_to={sorted(list(message.send_to))}\")\n\n    def find_latest_content_by_cause(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return msg.content\n        return None\n\n    def get_routable_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages that the role should process:\n        - Directly targeted via send_to or sent_to\n        - OR messages caused by actions the role watches\n        Exclude messages already delivered to the role.\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            if getattr(msg, \"send_to\", None):\n                # if message explicitly targets this role\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    targeted = True\n            # watch-based routing\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\n# Team orchestrator: deterministic pipeline, robust act calls, stable termination\n\nclass Team:\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        # termination stability: require same digest twice\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = 2\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {_preview(idea,200)}\")\n\n    async def _safe_act_call(self, role: Role, message: Optional[Message], timeout: float = 30.0, max_retries: int = 2) -> Optional[Message]:\n        \"\"\"\n        Invoke role.act with timeout and retries. Returns a Message even on error to keep pipeline robust.\n        \"\"\"\n        tracer = self.tracer\n        attempt = 0\n        last_exc = None\n        while attempt <= max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"ACT_ATTEMPT\", role.name, f\"Attempt {attempt} on message {getattr(message,'id',None)}\")\n                coro = role.act(message)\n                resp = await asyncio.wait_for(coro, timeout=timeout)\n                if resp:\n                    # mark as delivered/processed for this role\n                    if message:\n                        self.env.delivered.setdefault(message.id, set()).add(role.name)\n                    return resp\n                last_exc = \"empty_response\"\n                if tracer:\n                    tracer.log(\"ACT_EMPTY\", role.name, f\"Empty response attempt {attempt}\")\n            except asyncio.TimeoutError:\n                last_exc = \"timeout\"\n                if tracer:\n                    tracer.log(\"ACT_TIMEOUT\", role.name, f\"Timeout attempt {attempt}\")\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:300]}\"\n                if tracer:\n                    tracer.log(\"ACT_EXCEPTION\", role.name, f\"Exception attempt {attempt}: {last_exc}\")\n            await asyncio.sleep(0.2 * attempt)\n        # failed after retries\n        if tracer:\n            tracer.log(\"ACT_FAIL\", role.name, f\"Failed after {max_retries+1} attempts: {last_exc}\")\n        return Message(content=f\"ERROR: role {role.name} failed after retries: {last_exc}\", role=role.profile, cause_by=\"System\", sent_from=role.name)\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Kickoff message targeted at coders explicitly\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds_executed = 0\n\n        # deterministic order\n        order: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            for role_type in order:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    msgs = self.env.get_routable_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # avoid self-processing\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n                        response = await self._safe_act_call(role, msg)\n                        if not response:\n                            continue\n                        # ensure cause_by annotation\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.action, \"name\", \"\") if getattr(role, \"action\", None) else \"\"\n                        # routing: if send_to empty, route to subscribers of this action\n                        if not getattr(response, \"send_to\", None):\n                            subs = self.env.subscriptions.get(response.cause_by, set())\n                            response.send_to = set(subs)\n                        self.env.publish_message(response)\n                        any_activity = True\n\n                        # handle verification pass detection and stability\n                        if response.cause_by == SimpleVerify.name and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            # extract digest\n                            digest = None\n                            for part in response.content.split(\"|\"):\n                                p = part.strip()\n                                if p.startswith(\"digest=\"):\n                                    digest = p.split(\"=\", 1)[1].strip()\n                                    break\n                            if digest:\n                                if digest == self._last_digest:\n                                    self._streak += 1\n                                else:\n                                    self._last_digest = digest\n                                    self._streak = 1\n                                self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                if self._streak >= self._required_streak:\n                                    verified = True\n                            else:\n                                # no digest -> not stable\n                                self._streak = 0\n                                self._last_digest = None\n                                self.tracer.log(\"VERIFIER\", \"Team\", \"Verifier PASS without digest -> not considered stable\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} complete any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # no progress -> nudge coder(s) deterministically\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No activity this round; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: propose code for '{_preview(self.idea,120)}'\",\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.name}\n                        )\n                        self.env.publish_message(nudge)\n                # small sleep to allow potential async LLMs in other contexts\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds_executed} rounds verified={verified} messages={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds_executed} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 3.8304, Type: Migrant)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport random\nimport time\n\nclass Action(ABC):\n    \"\"\"\n    Base action class.\n    - Provides robust LLM call with exponential backoff, jitter, and clear error handling.\n    - Actions are pure units of work that take inputs and return outputs (strings).\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Call the LLM with retries, exponential backoff and jitter.\n        Returns either the LLM string response or a structured error string starting with \"LLM_ERROR:\".\n        \"\"\"\n        import asyncio\n\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if not self.llm:\n                    # Deterministic fallback for offline runs\n                    response = \"LLM_FALLBACK: no-llm-available\"\n                else:\n                    response = await self.llm.ask(messages)\n\n                # Detect common LLM error patterns\n                if not isinstance(response, str) or response.strip() == \"\":\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response from LLM\")\n                if response.strip().lower().startswith(\"error\") or \"http\" in response and \"error\" in response.lower():\n                    last_err = response\n                    raise RuntimeError(f\"LLM returned error-like text: {response[:200]}\")\n\n                # Log success\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} succeeded (len={len(response)})\")\n                return response\n\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"LLM_RETRY\", self.name, f\"Attempt {attempt} failed: {last_err[:200]}\")\n                # Backoff with jitter\n                if attempt < self.max_retries:\n                    backoff = self.base_backoff * (2 ** (attempt - 1))\n                    jitter = random.uniform(0, backoff * 0.1)\n                    await asyncio.sleep(backoff + jitter)\n                else:\n                    if self.context and getattr(self.context, \"tracer\", None):\n                        self.context.tracer.log(\"LLM_GIVEUP\", self.name, f\"Giving up after {self.max_retries} attempts: {last_err[:200]}\")\n        return f\"LLM_ERROR: {last_err}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result.\"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating code for idea (len={len(idea)})\")\n        prompt = (\n            \"You are an expert Python developer.\\n\"\n            \"Task:\\n\"\n            f\"{idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide production-ready Python code.\\n\"\n            \"- Include docstrings and input validation where appropriate.\\n\"\n            \"- Keep functions small and testable.\\n\"\n            \"- Return only the Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        # Basic sanity checks and fallback\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = f\"# ERROR: unable to generate code automatically. {result}\\n\\n# Placeholder function\\n\\ndef placeholder():\\n    \\\"\\\"\\\"Placeholder due to LLM failure.\\\"\\\"\\\"\\n    return None\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder code due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Generating tests for code (len={len(code)})\")\n        truncated = (code or \"\")[:4000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the provided Python code.\\n\\n\"\n            \"Code:\\n\"\n            f\"{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest test functions with clear assertions and docstrings.\\n\"\n            \"- Cover typical, boundary and error cases when applicable.\\n\"\n            \"- Return only pytest-compatible Python code.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            note = f\"# ERROR_GENERATING_TESTS: {result}\\n# Tests not generated due to LLM error.\\n\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Using placeholder test note due to LLM error\")\n            return note\n        return result\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code/tests (human={self.is_human})\")\n        if self.is_human:\n            return \"HUMAN_REVIEW: recommended manual review.\"\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review and a readiness verdict.\\n\\n\"\n            \"Code (truncated):\\n\"\n            f\"{(code or '')[:2000]}\\n\\n\"\n            \"Tests (truncated):\\n\"\n            f\"{(tests or '')[:2000]}\\n\\n\"\n            \"Return:\\n- A short list of issues (if any)\\n- Checklist of fixes\\n- VERDICT: READY or NOT_READY (single line at the end prefixed by VERDICT:)\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._llm_call(messages)\n        if result.startswith(\"LLM_ERROR\"):\n            fallback = \"REVIEW_ERROR: Review could not be completed due to LLM failure.\"\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Review fallback due to LLM error\")\n            return fallback\n        return result\n\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"\n        Deterministic verification using static analysis heuristics.\n        Returns a structured verification result string.\n        \"\"\"\n        import ast\n        issues: List[str] = []\n        code_ok = False\n        tests_ok = False\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Starting verification\")\n\n        # Code syntax check\n        if not code or not code.strip():\n            issues.append(\"code_missing_or_empty\")\n        else:\n            try:\n                parsed = ast.parse(code)\n                code_ok = True\n                fn_names = [n.name for n in parsed.body if isinstance(n, ast.FunctionDef)]\n            except Exception as e:\n                issues.append(f\"code_syntax_error: {e}\")\n                fn_names = []\n\n        # Tests syntax and heuristics\n        if not tests or not tests.strip():\n            issues.append(\"tests_missing_or_empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristics: tests must contain 'assert' and at least one function named test_\n                contains_assert = \"assert \" in tests or \"pytest\" in tests.lower()\n                test_fns = [n.name for n in parsed_tests.body if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\")]\n                tests_ok = bool(contains_assert and test_fns)\n                if not contains_assert:\n                    issues.append(\"tests_missing_asserts\")\n                if not test_fns:\n                    issues.append(\"tests_missing_test_functions\")\n            except Exception as e:\n                issues.append(f\"tests_syntax_error: {e}\")\n\n        # Ensure tests reference code functions when possible\n        references_code = False\n        if code_ok and tests_ok and fn_names:\n            for fn in fn_names:\n                if fn and fn in (tests or \"\"):\n                    references_code = True\n                    break\n            if not references_code:\n                issues.append(\"tests_do_not_reference_code\")\n\n        verified = code_ok and tests_ok and (references_code or not fn_names)\n        result = {\n            \"verified\": verified,\n            \"code_ok\": code_ok,\n            \"tests_ok\": tests_ok,\n            \"issues\": issues\n        }\n        summary = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | details: {result}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ACTION_END\", self.name, summary)\n        return summary\n\n\nclass Role(ABC):\n    \"\"\"\n    Clear role definition and responsibilities.\n    - Each role has a small set of actions.\n    - Each role maintains processed message ids to avoid duplicate work.\n    - Roles define watch_list (action names) and default recipients for produced messages.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # watch action names\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env = kwargs.get('env', None)\n        self._processed_message_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def watch_actions(self, actions: List[Type[Action]]):\n        self.watch_list = [a.name for a in actions]\n\n    def should_respond(self, message: Message) -> bool:\n        \"\"\"\n        Decide whether the role should respond:\n        - Not already processed\n        - Explicitly addressed via send_to or sent_to\n        - Message cause_by matches watched actions\n        - Human user instructions target coders by default\n        \"\"\"\n        if not message:\n            return False\n        if hasattr(message, \"id\") and message.id in self._processed_message_ids:\n            return False\n        # explicit addressing: either send_to set contains profile/name, or sent_to string matches\n        sent_to_set = getattr(message, \"send_to\", None)\n        if sent_to_set:\n            if isinstance(sent_to_set, (set, list)) and (self.profile in sent_to_set or self.name in sent_to_set or \"*\" in sent_to_set):\n                return True\n        sent_to_str = getattr(message, \"sent_to\", None)\n        if isinstance(sent_to_str, str) and (sent_to_str == self.profile or sent_to_str == self.name or sent_to_str == \"*\"):\n            return True\n        # watched action trigger\n        if getattr(message, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # default: user input goes to coders\n        if getattr(message, \"cause_by\", \"\") == \"UserInput\" and \"Coder\" in self.profile:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Core action executor:\n        - Picks first applicable action and runs it.\n        - Records processed message id.\n        - Returns a Message with content, cause_by and intended send_to recipients.\n        - Robust error handling with retries for transient failures.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Received message id={(getattr(message,'id',None))} cause_by={(getattr(message,'cause_by',None))}\")\n\n        # find message to act on (if provided)\n        if message is not None and not self.should_respond(message):\n            if self.context and getattr(self.context, \"tracer\", None):\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message id={(getattr(message,'id',None))}\")\n            return None\n\n        action = self.actions[0]  # single-responsibility per role; keep simple\n        attempts = 0\n        last_err = None\n        while attempts < 2:\n            attempts += 1\n            try:\n                # Build inputs based on action type\n                if isinstance(action, SimpleWriteCode):\n                    instruct = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                    result = await action.run(instruct)\n                    recipients = {\"SimpleTester\"}\n                elif isinstance(action, SimpleWriteTest):\n                    # Prefer code from message or find latest code in environment\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                    if not code_text and getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name:\n                                code_text = m.content\n                                break\n                    result = await action.run(code_text)\n                    recipients = {\"SimpleReviewer\", \"SimpleVerifier\"}\n                elif isinstance(action, SimpleWriteReview):\n                    # Acquire latest code and tests from env if not supplied\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"SimpleVerifier\", \"SimpleCoder\"}\n                elif isinstance(action, SimpleVerify):\n                    # collect latest code/tests\n                    code_text = \"\"\n                    tests_text = \"\"\n                    if getattr(self, \"env\", None):\n                        for m in reversed(self.env.history):\n                            if m.cause_by == SimpleWriteCode.name and not code_text:\n                                code_text = m.content\n                            if m.cause_by == SimpleWriteTest.name and not tests_text:\n                                tests_text = m.content\n                            if code_text and tests_text:\n                                break\n                    result = await action.run(code_text, tests_text)\n                    recipients = {\"Team\"}\n                else:\n                    result = await action.run()\n                    recipients = {\"Team\"}\n                # Mark message processed\n                if message and hasattr(message, \"id\"):\n                    self._processed_message_ids.add(message.id)\n                # Create response message with clear routing\n                response = Message(\n                    content=result,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=recipients\n                )\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message cause_by={response.cause_by} send_to={recipients}\")\n                return response\n            except Exception as exc:\n                last_err = str(exc)\n                if self.context and getattr(self.context, \"tracer\", None):\n                    self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {last_err[:200]}\")\n                # small backoff\n                time.sleep(0.1 * attempts)\n        # If here, role failed reliably\n        fail_msg = f\"ROLE_FAILED: {self.name} after retries. Error={last_err}\"\n        if self.context and getattr(self.context, \"tracer\", None):\n            self.context.tracer.log(\"ROLE_FAIL\", self.name, fail_msg)\n        response = Message(\n            content=fail_msg,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"Unknown\"),\n            sent_from=self.name,\n            send_to={\"Team\"}\n        )\n        return response\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self.watch_actions([])  # primarily triggered by UserInput or explicit addressing\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self.watch_actions([SimpleWriteCode])  # run when code is available\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self.watch_actions([SimpleWriteTest])\n\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self.watch_actions([SimpleWriteTest, SimpleWriteReview])\n\n\nclass Environment:\n    \"\"\"\n    Environment handles message publication and routing.\n    - Maintains history (ordered).\n    - Provides messages relevant to a role using explicit send_to and watch_list rules.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Ensure ID exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:160].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"From {message.sent_from} cause_by={message.cause_by} send_to={getattr(message,'send_to',None)} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages a role should consider:\n        - Explicitly addressed messages (send_to / sent_to)\n        - Messages whose cause_by matches role.watch_list\n        - Exclude messages already processed by the role\n        \"\"\"\n        relevant: List[Message] = []\n        for msg in self.history:\n            if hasattr(msg, \"id\") and msg.id in getattr(role, \"_processed_message_ids\", set()):\n                continue\n            # explicit addressing via send_to (preferred)\n            sent_to = getattr(msg, \"send_to\", None)\n            if sent_to:\n                if isinstance(sent_to, (set, list)) and (role.profile in sent_to or role.name in sent_to or \"*\" in sent_to):\n                    relevant.append(msg)\n                    continue\n            # explicit sent_to string field\n            sent_to_str = getattr(msg, \"sent_to\", None)\n            if isinstance(sent_to_str, str) and (sent_to_str == role.profile or sent_to_str == role.name or sent_to_str == \"*\"):\n                relevant.append(msg)\n                continue\n            # watch_list triggers\n            if getattr(msg, \"cause_by\", \"\") in role.watch_list:\n                relevant.append(msg)\n                continue\n        return relevant\n\n\nclass Team:\n    \"\"\"\n    Team orchestrates roles, sequencing, termination, and verification confirmation logic.\n    - Requires multiple independent verification confirmations to avoid premature termination.\n    - Tracks progress and stops on verification PASS or prolonged no-progress.\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # require confirmations from verifiers (could be same verifier across rounds)\n        self._verify_confirm_count = 0\n        self._verify_confirm_needed = 2\n        # track unique verifiers or rounds that produced PASS to reduce false positives\n        self._verify_pass_rounds: Set[int] = set()\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        import asyncio\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds; need {self._verify_confirm_needed} confirmations to stop early\")\n\n        # Initial User instruction directed to coder(s)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        no_progress_rounds = 0\n        last_history_len = len(self.env.history)\n\n        for round_idx in range(n_round):\n            round_num = round_idx + 1\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n            progress_made = False\n\n            # Evaluate each role; roles decide if they act based on environment messages\n            for role in list(self.env.roles):\n                # Gather messages relevant to this role\n                msgs = self.env.get_messages_for_role(role)\n                # On first round, ensure coder sees the initial instruction even if not in msgs\n                if isinstance(role, SimpleCoder) and round_idx == 0:\n                    msgs = [initial_msg] + msgs\n                # Process messages in order; roles may produce one message per input to keep steps atomic\n                for msg in msgs:\n                    try:\n                        resp = await role.act(msg)\n                        if resp:\n                            self.env.publish_message(resp)\n                            progress_made = True\n                            # If verifier response contains a PASS, count confirmation\n                            if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                                    self._verify_confirm_count += 1\n                                    self._verify_pass_rounds.add(round_idx)\n                                    self.tracer.log(\"VERIFY_CONFIRM\", \"Team\", f\"Verifier {role.name} PASS ({self._verify_confirm_count}/{self._verify_confirm_needed})\")\n                                    if self._verify_confirm_count >= self._verify_confirm_needed:\n                                        verified = True\n                                elif \"VERIFICATION_RESULT: FAIL\" in resp.content:\n                                    # reset confirmations on explicit fail\n                                    self._verify_confirm_count = 0\n                                    self.tracer.log(\"VERIFY_RESET\", \"Team\", f\"Verifier {role.name} reported FAIL; confirmations reset\")\n                            # Log role failures directed to team\n                            if isinstance(resp.content, str) and resp.content.startswith(\"ROLE_FAILED\"):\n                                self.tracer.log(\"TEAM_NOTE\", \"Team\", f\"Role failure: {resp.content[:200]}\")\n                    except Exception as e:\n                        self.tracer.log(\"ROUND_ERROR\", role.name, f\"Exception during role.act: {e}\")\n\n            # Determine progress/no-progress and update termination conditions\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} complete (progress={progress_made})\")\n\n            # Termination: require at least one full round and required confirmations\n            if verified and round_num >= 1:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification confirmed after {self._verify_confirm_count} confirmations; stopping\")\n                break\n\n            # Stop if no progress for multiple rounds to avoid wasting cycles\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 consecutive rounds; terminating early\")\n                break\n\n            # allow small async pause\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' finished after {round_num} rounds with {len(self.env.history)} messages. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Excellent avg_failures_per_task (2.167), Excellent total_failures (13.000)\n\n\n### Inspiration 2 (Score: 7.1111, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (5.000), Excellent total_failures (30.000)\n\n\n### Inspiration 3 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"LLM_FALLBACK: deterministic fallback response.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        # Defensive parsing\n                        try:\n                            return result[\"choices\"][0][\"message\"][\"content\"]\n                        except Exception:\n                            return \"Error: Malformed LLM response\"\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\n\n# Utility\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = str(text).replace(\"\\n\", \" \")\n    return (t[:n] + \"...\") if len(t) > n else t\n\n# ===================== Actions =====================\n\nclass Action(ABC):\n    \"\"\"Base action with robust LLM retry/backoff and clear contract.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries, backoff, and error detection. Deterministic fallback on failure.\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n            try:\n                if not self.llm:\n                    return \"LLM_UNAVAILABLE_FALLBACK\"\n                resp = await self.llm.ask(messages)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"empty LLM response\")\n                if resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"{_preview(last_err, 200)}\")\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # Exhausted\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err or 'unknown'}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAIL\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Coder: produce parseable Python module from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        if not idea or not idea.strip():\n            fallback = (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback when no idea is provided.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea; using fallback code\")\n            return fallback\n        prompt = (\n            \"You are an expert Python developer. Implement a single Python module for the task below.\\n\"\n            \"Return only valid Python code (no markdown/backticks). Include docstrings and basic input validation.\\n\\n\"\n            f\"Task:\\n{idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        code = await self._ask_with_retry(messages)\n        # Validate parseability; fallback if invalid\n        try:\n            ast.parse(code or \"\")\n        except Exception:\n            code = (\n                \"def main_task(data=None):\\n\"\n                \"    \\\"\\\"\\\"Fallback implementation when LLM output is invalid.\\\"\\\"\\\"\\n\"\n                \"    return data\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM code invalid; using fallback\")\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Code len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Tester: generate pytest-style tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        if not code or not code.strip():\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test when no code is available.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"No code; using fallback tests\")\n            return fallback\n        # Extract top-level function/class names to improve cross-reference\n        names: List[str] = []\n        try:\n            tree = ast.parse(code)\n            for n in tree.body:\n                if isinstance(n, (ast.FunctionDef, ast.ClassDef)) and not n.name.startswith(\"_\"):\n                    names.append(n.name)\n        except Exception:\n            names = []\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided module.\\n\"\n            \"- Include positive and negative cases\\n- Use assert statements\\n- Provide only test code\\n\\n\"\n            f\"Public API (hint): {', '.join(names[:6]) or '(none)'}\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:3000]}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        tests = await self._ask_with_retry(messages)\n        # Validate tests structure; fallback if invalid\n        try:\n            parsed = ast.parse(tests or \"\")\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in parsed.body)\n            has_assert = (\"assert \" in (tests or \"\")) or any(isinstance(n, ast.Assert) for n in ast.walk(parsed))\n            if not (has_test_fn or has_assert):\n                raise ValueError(\"no tests/asserts found\")\n        except Exception:\n            target = names[0] if names else \"main_task\"\n            tests = (\n                f\"def test_placeholder_positive():\\n\"\n                f\"    \\\"\\\"\\\"Basic positive touching {target}.\\\"\\\"\\\"\\n\"\n                f\"    assert True\\n\\n\"\n                f\"def test_placeholder_negative():\\n\"\n                f\"    \\\"\\\"\\\"Basic negative referencing {target}.\\\"\\\"\\\"\\n\"\n                f\"    assert not False\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM tests invalid; using fallback\")\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Reviewer: provide concise actionable review with decision token.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        # Static checks to seed review\n        issues: List[str] = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:140]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:140]}\")\n        if self.is_human:\n            review = (\"HUMAN_REVIEW: ok\" if not issues else \"HUMAN_REVIEW: \" + \"; \".join(issues)) + \"\\nREVIEW_DECISION: \" + (\"APPROVE\" if not issues else \"REQUEST_CHANGES\")\n            return review\n        prompt = (\n            \"You are a senior reviewer. Provide a concise review with 3 actionable points and end with:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGES\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\n\"\n            f\"Code (first 1200 chars):\\n{(code or '')[:1200]}\\n\\n\"\n            f\"Tests (first 1200 chars):\\n{(tests or '')[:1200]}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        resp = await self._ask_with_retry(messages)\n        review = resp if isinstance(resp, str) else \"REVIEW_DECISION: REQUEST_CHANGES\"\n        if \"REVIEW_DECISION:\" not in (review or \"\"):\n            # Heuristic decision\n            decision = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            review = (review or \"Automated review.\") + f\"\\nREVIEW_DECISION: {decision}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Verifier: deterministic static verification with digest for stability checks.\"\"\"\n    name = \"SimpleVerify\"\n\n    @staticmethod\n    def _digest(code: str, tests: str) -> str:\n        h = hashlib.sha256()\n        h.update((code or \"\").encode(\"utf-8\"))\n        h.update(b\"\\n--\\n\")\n        h.update((tests or \"\").encode(\"utf-8\"))\n        return h.hexdigest()[:12]\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying artifacts\")\n        details: List[str] = []\n        # Syntax checks\n        code_ok = False\n        tests_ok = False\n        try:\n            ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({str(e)[:120]})\")\n        try:\n            ttree = ast.parse(tests or \"\")\n            tests_ok = True\n            # check tests presence\n            has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ttree.body)\n            has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(ttree)) or (\"assert \" in (tests or \"\"))\n            details.append(\"tests_presence: ok\" if (has_test_fn or has_assert) else \"tests_presence: questionable\")\n            tests_presence_ok = (has_test_fn or has_assert)\n        except Exception as e:\n            tests_ok = False\n            tests_presence_ok = False\n            details.append(f\"tests_syntax: fail ({str(e)[:120]})\")\n        # Code entities and cross-reference\n        entities: Set[str] = set()\n        cross_ref = False\n        if code_ok:\n            try:\n                ctree = ast.parse(code or \"\")\n                for n in ctree.body:\n                    if isinstance(n, (ast.FunctionDef, ast.ClassDef)):\n                        entities.add(n.name)\n                details.append(f\"code_entities: {len(entities)}\")\n            except Exception:\n                details.append(\"code_entities: error\")\n        if entities and tests_ok:\n            try:\n                names_in_tests = set(n.id for n in ast.walk(ast.parse(tests or \"\")) if isinstance(n, ast.Name))\n                cross_ref = len(entities & names_in_tests) > 0\n                details.append(\"cross_reference: ok\" if cross_ref else \"cross_reference: fail\")\n            except Exception:\n                details.append(\"cross_reference: error\")\n        verified = bool(code_ok and tests_ok and tests_presence_ok and entities and cross_ref)\n        digest = self._digest(code or \"\", tests or \"\")\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# ===================== Roles =====================\n\nclass Role(ABC):\n    \"\"\"Base role with single responsibility, explicit watch-list, and idempotent handling.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n    _processed_ids: Set[str] = set()\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = None\n        self._processed_ids = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = {a.name for a in actions}\n\n    def _should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        # Explicit routing\n        targets = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n        if targets and (self.name in targets or self.profile in targets):\n            return True\n        # Watch-list by cause_by\n        if getattr(msg, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # Coder also listens to UserInput nudges\n        if isinstance(self, SimpleCoder) and getattr(msg, \"cause_by\", \"\") in {\"UserInput\", \"Nudge\"}:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.action:\n            return None\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Action={self.action.name} on msg={getattr(message,'id',None)}\")\n        try:\n            if isinstance(self.action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                out = await self.action.run(idea)\n                send_to = {\"SimpleTester\"}\n                cause_by = SimpleWriteCode.name\n            elif isinstance(self.action, SimpleWriteTest):\n                code_text = \"\"\n                if message and getattr(message, \"content\", None):\n                    code_text = message.content\n                elif self.env:\n                    latest_code = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = latest_code.content if latest_code else \"\"\n                out = await self.action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                cause_by = SimpleWriteTest.name\n            elif isinstance(self.action, SimpleWriteReview):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = {\"SimpleVerifier\"}\n                cause_by = SimpleWriteReview.name\n            elif isinstance(self.action, SimpleVerify):\n                code_msg = self.env.get_latest_by_cause(SimpleWriteCode.name) if self.env else None\n                tests_msg = self.env.get_latest_by_cause(SimpleWriteTest.name) if self.env else None\n                out = await self.action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n                send_to = {\"SimpleCoder\", \"SimpleTester\", \"SimpleReviewer\"}  # broadcast for traceability\n                cause_by = SimpleVerify.name\n            else:\n                out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                send_to = set()\n                cause_by = getattr(self.action, \"name\", \"Action\")\n            resp = Message(\n                content=out,\n                role=self.profile,\n                cause_by=cause_by,\n                sent_from=self.name,\n                send_to=set(send_to) if isinstance(send_to, (set, list)) else set()\n            )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION in {self.name}: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            resp = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n        # Mark processed\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={resp.id} to={getattr(resp,'send_to',set())}\")\n        return resp\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # acts on explicit routing or UserInput/Nudge\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\n# ===================== Environment =====================\n\nclass Environment:\n    \"\"\"Message bus with explicit routing, watch triggers, and idempotent processing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs to prevent duplicate handling\n        self.processed: Set[tuple] = set()\n        # index by cause_by for quick artifact retrieval\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # Normalize send_to as set\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if getattr(message, \"cause_by\", \"\"):\n            self._by_cause.setdefault(message.cause_by, []).append(message)\n        if self.tracer:\n            preview = _preview(getattr(message, \"content\", \"\"), 160)\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} to={list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        return (role.name, getattr(message, \"id\", None)) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages the role should handle (explicitly addressed or watched), excluding already processed.\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if self.has_processed(role, msg):\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            targets = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if targets and (role.name in targets or role.profile in targets):\n                out.append(msg)\n                continue\n            # watch-list by cause\n            if getattr(msg, \"cause_by\", \"\") in role.watch_list:\n                out.append(msg)\n                continue\n            # special: coder reacts to UserInput/Nudge\n            if isinstance(role, SimpleCoder) and getattr(msg, \"cause_by\", \"\") in {\"UserInput\", \"Nudge\"}:\n                out.append(msg)\n        return out\n\n    def get_latest_by_cause(self, cause_name: str) -> Optional[Message]:\n        lst = self._by_cause.get(cause_name, [])\n        return lst[-1] if lst else None\n\n# ===================== Team Orchestration =====================\n\nclass Team:\n    \"\"\"Orchestrates collaboration with deterministic ordering and stable termination.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Verification stability tracking\n        self._last_digest: Optional[str] = None\n        self._pass_streak: int = 0\n        self._required_streak: int = 2\n        self._last_verifier_index: int = -1\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_streak={self._required_streak})\")\n        # Kickoff message to coder (both by name and profile for robustness)\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"Alice\", \"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        role_order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_idx in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_idx}/{n_round}\")\n            progress = False\n\n            # Detect invalidation: if new code/tests were added after last verifier pass, reset streak\n            if self._last_verifier_index >= 0:\n                for i, m in enumerate(self.env.history[self._last_verifier_index + 1 :], start=self._last_verifier_index + 1):\n                    if getattr(m, \"cause_by\", \"\") in {SimpleWriteCode.name, SimpleWriteTest.name}:\n                        if self._pass_streak > 0:\n                            self.tracer.log(\"VERIFIER_INVALIDATE\", \"Team\", f\"New artifact after PASS; reset streak {self._pass_streak}->0\")\n                        self._pass_streak = 0\n                        self._last_digest = None\n                        break\n\n            for RoleType in role_order:\n                for role in [r for r in self.env.roles if isinstance(r, RoleType)]:\n                    msgs = self.env.get_messages_for_role(role)\n                    if not msgs and isinstance(role, SimpleCoder) and round_idx == 1:\n                        msgs = [initial_msg]  # ensure coder sees initial\n                    for msg in msgs:\n                        if self.env.has_processed(role, msg):\n                            continue\n                        try:\n                            resp = await role.act(msg)\n                            self.env.mark_processed(role, msg)\n                            if resp:\n                                self.env.publish_message(resp)\n                                progress = True\n                                # track verifier passes\n                                if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                                    self._last_verifier_index = len(self.env.history) - 1\n                                    content = resp.content\n                                    if \"VERIFICATION_RESULT: PASS\" in content:\n                                        # extract digest\n                                        digest = None\n                                        for part in content.split(\"|\"):\n                                            part = part.strip()\n                                            if part.startswith(\"digest=\"):\n                                                digest = part.split(\"=\", 1)[1]\n                                                break\n                                        if digest:\n                                            if digest == self._last_digest:\n                                                self._pass_streak += 1\n                                            else:\n                                                self._last_digest = digest\n                                                self._pass_streak = 1\n                                            self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"digest={digest} streak={self._pass_streak}\")\n                                        else:\n                                            self._pass_streak = 0\n                                            self._last_digest = None\n                                    else:\n                                        if self._pass_streak > 0:\n                                            self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._pass_streak}->0\")\n                                        self._pass_streak = 0\n                                        self._last_digest = None\n                        except Exception as e:\n                            self.tracer.log(\"ROLE_RUN_ERROR\", role.name, f\"{type(e).__name__}: {str(e)[:200]}\")\n                            err_msg = Message(\n                                content=f\"ERROR: {role.name} failed: {type(e).__name__}: {str(e)[:200]}\",\n                                role=role.profile,\n                                cause_by=\"RoleRunError\",\n                                sent_from=role.name,\n                                send_to={\"SimpleCoder\"}\n                            )\n                            self.env.publish_message(err_msg)\n                            progress = True\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_idx} done; progress={progress} pass_streak={self._pass_streak}\")\n\n            if self._pass_streak >= self._required_streak:\n                verified = True\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification stable; stopping\")\n                break\n\n            if not progress:\n                # Nudge coder to avoid stagnation\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"Alice\", \"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                for coder in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                    try:\n                        resp = await coder.act(nudge)\n                        if resp:\n                            self.env.publish_message(resp)\n                    except Exception as e:\n                        self.tracer.log(\"NUDGE_ERROR\", coder.name, f\"{type(e).__name__}: {str(e)[:120]}\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_idx} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach, Alternative combined_score approach, Excellent avg_failures_per_task (12.000)\n\n\n### Inspiration 4 (Score: 4.2143, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport time\nimport ast\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit routing (send_to) and watch/trigger logic\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with syntactic and structural checks\n# - Error handling and retry for LLM/API failures\n# - Stable termination: require consecutive verification passes before stopping early\n\nclass Action(ABC):\n    \"\"\"Base action class with LLM retry handling and standardized contract.\n\n    Responsibilities:\n    - Provide run(...) coroutine returning a text result.\n    - Manage LLM calls with retries/backoff and robust error detection.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 1.0  # seconds\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call the LLM with retries and exponential backoff. Returns a string (or clear error).\"\"\"\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    # deterministic fallback to avoid transient dependency failure\n                    fallback = \"LLM_UNAVAILABLE: fallback response\"\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                # treat responses beginning with \"Error\" as failure\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff before next attempt\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n        # exhausted retries\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_FINAL_FAILURE\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Produce an initial implementation from an idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Idea len={len(idea or '')}\")\n        prompt = (\n            \"You are a professional Python developer. Produce a compact, production-ready Python implementation \"\n            \"for the described task. Include docstrings, input validation, and error handling. \"\n            \"Return only the Python source code.\"\n            f\"\\n\\nTask: {idea}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated len={len(result)}\")\n        return result\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for a given code snippet.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Code len={len(code or '')}\")\n        snippet = (code or \"\")[:4000]\n        prompt = (\n            \"You are a QA engineer. Given the implementation below, produce pytest tests that cover normal behavior, \"\n            \"edge cases, and error conditions. Use clear test names and docstrings. Return only pytest code.\\n\\n\"\n            f\"Implementation:\\n{snippet}\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        result = await self._ask_with_retry(messages)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Tests len={len(result)}\")\n        return result\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and produce actionable items.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Human={self.is_human}\")\n        # Static checks\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = \"HUMAN_REVIEW: \" + (\"; \".join(issues) if issues else \"ok\")\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise, structured review (VERDICT: PASS/FAIL) and actionable items. \"\n                \"Include any static issues found.\\n\\n\"\n                f\"Code:\\n{(code or '')[:2000]}\\n\\nTests:\\n{(tests or '')[:2000]}\\n\\n\"\n                f\"STATIC_ISSUES: {issues}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code reviews.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            llm_resp = await self._ask_with_retry(messages)\n            # fall back to static-only if llm failed\n            if isinstance(llm_resp, str) and llm_resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n                review = \"REVIEW_FAIL: \" + \"; \".join(issues) if issues else \"REVIEW_PASS: minimal\"\n            else:\n                review = llm_resp\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Perform strong verification: syntax, tests presence, assertions, and references.\"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code/tests\")\n        status = []\n        code_ok = False\n        tests_ok = False\n        references_ok = False\n\n        # Check code syntax\n        if not code or not code.strip():\n            status.append(\"code: empty\")\n        else:\n            try:\n                parsed_code = ast.parse(code)\n                code_ok = True\n                status.append(\"code_syntax: ok\")\n            except Exception as e:\n                status.append(f\"code_syntax: fail ({str(e)[:160]})\")\n                parsed_code = None\n\n        # Check tests syntax and assertions\n        if not tests or not tests.strip():\n            status.append(\"tests: empty\")\n        else:\n            try:\n                parsed_tests = ast.parse(tests)\n                # heuristic: look for pytest functions or assert statements\n                has_test_fn = any(isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\") for n in ast.walk(parsed_tests))\n                has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n                if has_test_fn or has_assert:\n                    tests_ok = True\n                    status.append(\"tests_syntax_and_asserts: ok\")\n                else:\n                    status.append(\"tests_syntax: ok_but_no_tests_found\")\n                parsed_tests = parsed_tests\n            except Exception as e:\n                status.append(f\"tests_syntax: fail ({str(e)[:160]})\")\n                parsed_tests = None\n\n        # Check tests reference functions in code\n        if code_ok and tests_ok and parsed_code and parsed_tests:\n            func_names = {n.name for n in ast.walk(parsed_code) if isinstance(n, ast.FunctionDef)}\n            tests_text = tests or \"\"\n            if func_names:\n                for fn in func_names:\n                    if fn in tests_text:\n                        references_ok = True\n                        break\n                if references_ok:\n                    status.append(\"tests_reference_functions: ok\")\n                else:\n                    status.append(\"tests_reference_functions: fail (no references)\")\n            else:\n                status.append(\"tests_reference_functions: warn (no top-level functions in code)\")\n\n        verified = code_ok and tests_ok and references_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with clear responsibilities and processed-tracking to avoid duplicates.\n\n    Responsibilities:\n    - Decide whether to handle a message (match send_to or watch_list)\n    - Execute its single main action and produce a Message with routing metadata (send_to)\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed (message ids) per role to avoid reprocessing\n        self._processed_ids: Set[str] = set()\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions\n\n    def _watch(self, actions: List[Type[Action]]):\n        # store names for robust matching\n        self.watch_list = [a.name for a in actions]\n\n    def _should_handle(self, msg: Message) -> bool:\n        # never handle messages produced by self or already processed\n        if getattr(msg, \"sent_from\", None) == self.name:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # explicit routing\n        send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", None) or set())\n        if send_to:\n            if self.profile in send_to or self.name in send_to:\n                return True\n            return False\n        # watch-list matching by cause_by\n        if getattr(msg, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        # if message provided but not intended for this role, skip\n        if message and not self._should_handle(message):\n            return None\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Handling msg={getattr(message, 'id', 'none')} cause_by={getattr(message, 'cause_by', '')}\")\n        try:\n            # Dispatch by action name (explicit)\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or (message.content or \"\")\n                result_text = await action.run(idea)\n                # route to tester primarily, and reviewer optionally\n                send_to = {\"SimpleTester\"}\n                if \"ERROR\" in result_text or result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"LLM_UNAVAILABLE\"):\n                    # if generation failed, route back to coder (self) for retry later and to reviewer for context\n                    send_to = {self.profile}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteTest.name:\n                # expect code text in message.content, otherwise look up latest code in env\n                code_text = \"\"\n                if message and message.content:\n                    code_text = message.content\n                elif self.env:\n                    # find most recent code message\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name:\n                            code_text = m.content\n                            break\n                result_text = await action.run(code_text)\n                send_to = {\"SimpleReviewer\"}\n                if result_text.startswith(\"LLM_FAILED\") or result_text.startswith(\"ERROR\"):\n                    send_to = {\"SimpleTester\", \"SimpleCoder\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleWriteReview.name:\n                # collect latest code and tests from env\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # If review indicates issues, route back to coder/tester; else route to verifier\n                lowered = (result_text or \"\").lower()\n                if \"fail\" in lowered or \"error\" in lowered or \"syntax\" in lowered:\n                    send_to = {\"SimpleCoder\", \"SimpleTester\"}\n                else:\n                    send_to = {\"SimpleVerifier\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            elif action.name == SimpleVerify.name:\n                # collect latest code and tests\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    for m in reversed(self.env.history):\n                        if m.cause_by == SimpleWriteCode.name and not code_text:\n                            code_text = m.content\n                        if m.cause_by == SimpleWriteTest.name and not tests_text:\n                            tests_text = m.content\n                        if code_text and tests_text:\n                            break\n                result_text = await action.run(code_text, tests_text)\n                # verification is terminal but still broadcast to reviewer and coder for trace\n                send_to = {\"SimpleReviewer\", \"SimpleCoder\", \"SimpleTester\"}\n                response = Message(\n                    content=result_text,\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name,\n                    send_to=send_to\n                )\n            else:\n                response = Message(\n                    content=\"NO_OP\",\n                    role=self.profile,\n                    cause_by=action.name,\n                    sent_from=self.name\n                )\n        except Exception as e:\n            err = f\"ROLE_EXCEPTION: {str(e)}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_EXCEPTION\", self.name, err)\n            response = Message(\n                content=err,\n                role=self.profile,\n                cause_by=\"RoleException\",\n                sent_from=self.name,\n                send_to={\"SimpleCoder\"}\n            )\n\n        # mark input message as processed for this role to avoid duplicate processing\n        if message and getattr(message, \"id\", None):\n            self._processed_ids.add(message.id)\n        # also mark produced message id as processed locally to avoid reprocessing self-produced messages\n        if getattr(response, \"id\", None):\n            self._processed_ids.add(response.id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg={response.id} send_to={getattr(response, 'send_to', set())}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest, SimpleWriteReview, SimpleWriteCode])\n\nclass Environment:\n    \"\"\"Tracks roles, history and ensures idempotent processing via processed set.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # processed pairs of (role_name, msg_id)\n        self.processed: Set[Tuple[str, str]] = set()\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to exists as set for compatibility\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        self.history.append(message)\n        if self.tracer:\n            preview = (message.content or \"\")[:140].replace(\"\\n\", \" \")\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        if not getattr(message, \"id\", None):\n            return False\n        return (role.name, message.id) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return unprocessed messages relevant to the role (explicit routing or watch_list).\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if getattr(msg, \"id\", None) is None:\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.profile in send_to or role.name in send_to:\n                    out.append(msg)\n                    continue\n            # watch-list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n        # maintain chronological order\n        return out\n\nclass Team:\n    \"\"\"Orchestrates multi-agent collaboration with deterministic ordering, retries, and stable verification.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # verification stability tracking\n        self.verifier_streak: int = 0\n        self.required_stable_passes: int = 2\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def _process_role_messages(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            # allow role to act proactively (e.g., coder on initial round) if there is no directed message\n            # but guard against spamming by checking recent history\n            proactive_msg = None\n            # coder proactive behavior is controlled from the orchestrator\n            return\n        for m in msgs:\n            # call role\n            resp = await role.act(m)\n            # mark processed whether or not action succeeded to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                # if verifier produced PASS, update streak\n                if isinstance(role, SimpleVerifier) and \"VERIFICATION_RESULT: PASS\" in (resp.content or \"\"):\n                    self.verifier_streak += 1\n                    self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"streak={self.verifier_streak}\")\n                elif isinstance(role, SimpleVerifier):\n                    # reset on non-pass\n                    if self.verifier_streak > 0:\n                        self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self.verifier_streak}->0\")\n                    self.verifier_streak = 0\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (stable_passes={self.required_stable_passes})\")\n        # initial message targeted at coder\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\"}\n        )\n        self.env.publish_message(initial_msg)\n\n        # deterministic order\n        order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num+1}/{n_round}\")\n            # For each role in order, process relevant messages\n            for role_cls in order:\n                roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                for role in roles:\n                    # special-case: allow proactive coder run on first round if not yet produced code\n                    if isinstance(role, SimpleCoder) and round_num == 0:\n                        # check if coder has processed the initial user message\n                        user_msgs = [m for m in self.env.history if getattr(m, \"cause_by\", \"\") == \"UserInput\"]\n                        need_init = False\n                        for um in user_msgs:\n                            if not self.env.has_processed(role, um):\n                                need_init = True\n                                break\n                        if need_init:\n                            await self._process_role_messages(role)\n                            # continue to next role\n                            continue\n                    await self._process_role_messages(role)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num+1} completed; verifier_streak={self.verifier_streak}; history_len={len(self.env.history)}\")\n\n            # termination: require 'required_stable_passes' consecutive PASS results\n            if self.verifier_streak >= self.required_stable_passes:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self.verifier_streak} passes; stopping\")\n                break\n\n            # If no messages were produced in this round (no progress), nudge coder proactively once per stalled round\n            # Determine whether new messages were added this round by looking at history length changes is complex here;\n            # simpler heuristic: if the last messages are not tests/verifier/reviewer, nudge coder.\n            last_msgs = self.env.history[-4:] if len(self.env.history) >= 4 else self.env.history[:]\n            if not any((m.cause_by == SimpleWriteTest.name or m.cause_by == SimpleWriteCode.name or m.cause_by == SimpleWriteReview.name) for m in last_msgs):\n                # send a gentle nudge to coder to refine\n                nudge = Message(\n                    content=f\"Please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\"}\n                )\n                self.env.publish_message(nudge)\n                # process coder nudge immediately\n                coder_roles = [r for r in self.env.roles if isinstance(r, SimpleCoder)]\n                for coder in coder_roles:\n                    await self._process_role_messages(coder)\n\n        # finalization: log summary\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {round_num+1} rounds with {len(self.env.history)} messages. verifier_streak={self.verifier_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Alternative combined_score approach, Excellent avg_failures_per_task (2.500)\n\n\n### Inspiration 5 (Score: 4.6667, Type: High-Performer)\n```python\n# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n#\n# Goals:\n# - Clear role responsibilities\n# - Robust inter-agent communication with explicit send_to and subscriptions\n# - Strong verification/validation and stable termination\n# - Defensive error handling and LLM/API retry logic\n# - Deterministic orchestration to reduce nondeterministic failure modes\n\nimport asyncio\nimport ast\nimport hashlib\nimport time\nfrom collections import defaultdict\nfrom typing import List, Dict, Optional, Set, Tuple, Type\n\n# Utility for short previews in logs\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = text.strip()\n    return (t[:n] + \"...\") if len(t) > n else t\n\n# Base Action class: encapsulates LLM calls with retries, logging and deterministic fallback\nclass Action(ABC):\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper for LLM calls:\n        - Retries with exponential backoff\n        - Logs attempts and failures\n        - Returns deterministic fallback if LLM unavailable or exhausted\n        \"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.llm:\n            # Deterministic fallback string that downstream actions recognize\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if tracer:\n                tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        last_exc = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_exc = resp\n                    if tracer:\n                        tracer.log(\"LLM_ERROR\", self.name, _preview(resp, 200))\n                    # backoff and retry\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # treat empty responses as failure\n                if not resp or not isinstance(resp, str):\n                    last_exc = \"empty_response\"\n                    if tracer:\n                        tracer.log(\"LLM_EMPTY\", self.name, f\"Empty response on attempt {attempt}\")\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # success\n                return resp\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:300]}\"\n                if tracer:\n                    tracer.log(\"LLM_EXCEPTION\", self.name, last_exc)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                continue\n\n        # exhausted retries\n        failure_msg = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_exc}\"\n        if tracer:\n            tracer.log(\"LLM_ABORT\", self.name, failure_msg)\n        # stable, deterministic fallback\n        return f\"LLM_FAILURE_FALLBACK: {failure_msg}\"\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\n# Concrete Actions: Code, Tests, Review, Verify\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"idea_preview={_preview(idea)}\")\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module that implements the requested task.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no markdown).\\n\"\n            \"- Include docstrings and input validation where applicable.\\n\"\n            \"- Provide at least one function or class.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        code = await self.safe_ask(messages)\n        # quick heuristic validation; if invalid, return deterministic safe fallback\n        try:\n            ast.parse(code)\n            ok = True\n        except Exception as e:\n            ok = False\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, f\"Generated code failed parse: {e}\")\n        if not ok or \"LLM_FAILURE_FALLBACK\" in code or code.startswith(\"LLM_UNAVAILABLE_FALLBACK\"):\n            # deterministic safe minimal implementation\n            fallback = (\n                \"def placeholder(input_data=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback implementation.\\\"\\\"\\\"\\n\"\n                \"    return input_data\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using deterministic fallback code\")\n            code = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"code_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        snippet = (code or \"\")[:3000]\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the given Python module.\\n\\n\"\n            f\"Module (truncated):\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Include at least one positive and one negative test.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        tests = await self.safe_ask(messages)\n        # heuristic: ensure tests include 'assert' otherwise provide deterministic placeholder\n        if not tests or \"assert \" not in tests:\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback test\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Using deterministic fallback tests\")\n            tests = fallback\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"REVIEW_DECISION: APPROVE\\nHuman-simulated approval.\"\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, \"Human review simulated APPROVE\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a short review and an explicit decision line starting with REVIEW_DECISION: APPROVE or REVIEW_DECISION: REJECT.\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\nTests (truncated):\\n{(tests or '')[:1500]}\\n\\n\"\n            \"Be concise and actionable.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer performing code reviews.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        review = await self.safe_ask(messages)\n        # Ensure explicit decision\n        if not review or \"REVIEW_DECISION:\" not in review:\n            # conservative default\n            decision = \"REVIEW_DECISION: REJECT\"\n            review = (review or \"Automated review: missing explicit decision.\") + \"\\n\\n\" + decision\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"No explicit decision from LLM; defaulting to REJECT\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Starting deterministic verification\")\n\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            parsed_code = None\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Code parse failed: {e}\")\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            # check for assertions\n            tests_ok = bool(tests and (\"assert \" in tests or \"pytest\" in tests))\n            if tests_ok:\n                details.append(\"tests_syntax: ok\")\n            else:\n                details.append(\"tests_syntax: fail (no asserts found)\")\n        except Exception as e:\n            parsed_tests = None\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:160]})\")\n            if tracer:\n                tracer.log(\"VERIFY_ERROR\", self.name, f\"Tests parse failed: {e}\")\n\n        # Structural checks: code has functions/classes, tests reference them\n        referenced = False\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            details.append(f\"code_entities: {sorted(list(code_entities))[:6]}\")\n        else:\n            details.append(\"code_entities: none\")\n\n        if parsed_tests and code_entities:\n            names_in_tests = set()\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Name):\n                    names_in_tests.add(node.id)\n            inter = code_entities & names_in_tests\n            referenced = len(inter) > 0\n            details.append(f\"tests_reference_matches: {sorted(list(inter))[:6]}\")\n        else:\n            details.append(\"tests_reference_matches: none\")\n\n        passed = all([code_ok, tests_ok, bool(code_entities), referenced])\n\n        # compute digest for stability detection\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if passed else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\n# Roles: each role has a single responsibility and explicit watch list + idempotency\n\nclass Role(ABC):\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()  # action names\n    is_human: bool = False\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env: Optional[\"Environment\"] = kwargs.get(\"env\")\n        self._processed_message_ids: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: List[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", \"\") for a in actions}\n\n    def should_process(self, message: Optional[Message]) -> bool:\n        if message is None:\n            return False\n        # Direct addressing\n        targets = getattr(message, \"send_to\", None) or getattr(message, \"sent_to\", None)\n        if targets:\n            if isinstance(targets, (list, set)):\n                if self.name in targets or self.profile in targets:\n                    return True\n            else:\n                if targets == self.name or targets == self.profile:\n                    return True\n        # Watch list match\n        if getattr(message, \"cause_by\", None) in self.watch_list:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        # idempotency: skip processing if already done\n        if msg_id and msg_id in self._processed_message_ids:\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping already processed message {msg_id}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Processing message id={msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Decide inputs depending on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = getattr(message, \"instruct_content\", None) or (message.content if message else \"\")\n                result = await self.action.run(idea or \"\")\n            elif isinstance(self.action, SimpleWriteTest):\n                # prefer message content if it is code, else fetch latest code\n                code_src = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_src = message.content\n                elif getattr(self, \"env\", None):\n                    code_src = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code_src)\n            elif isinstance(self.action, SimpleWriteReview):\n                env = getattr(self, \"env\", None)\n                code_text = env.find_latest_content_by_cause(SimpleWriteCode.name) if env else \"\"\n                tests_text = env.find_latest_content_by_cause(SimpleWriteTest.name) if env else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            elif isinstance(self.action, SimpleVerify):\n                env = getattr(self, \"env\", None)\n                code_text = env.find_latest_content_by_cause(SimpleWriteCode.name) if env else \"\"\n                tests_text = env.find_latest_content_by_cause(SimpleWriteTest.name) if env else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                # generic fallback\n                payload = message.content if message else \"\"\n                result = await self.action.run(payload)\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:300]}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark as processed to prevent repeated failures\n            if msg_id:\n                self._processed_message_ids.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build outgoing message; include send_to empty set (environment will route to subscribers)\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(self.action, \"name\", \"\"),\n            sent_from=self.name,\n            send_to=set()\n        )\n\n        # mark input message as processed for idempotency\n        if msg_id:\n            self._processed_message_ids.add(msg_id)\n\n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message id={response.id} cause_by={response.cause_by} preview={_preview(response.content,120)}\")\n        return response\n\n# Concrete role classes with explicit responsibilities\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        # coder responds to explicit user input or nudges\n        self.watch([type(\"UserInputDummy\", (), {\"name\": \"UserInput\"}), type(\"NudgeDummy\", (), {\"name\": \"Nudge\"})])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview])\n\n# Environment: message bus with deterministic routing, subscriptions and delivery tracking\n\nclass Environment:\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # map action_name -> set(role.name) who subscribe to that action\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)\n        # track delivered messages: message_id -> set(role.name)\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        # set environment reference on role\n        role.env = self\n        self.roles.append(role)\n        # register subscriptions\n        for action_name in getattr(role, \"watch_list\", set()):\n            self.subscriptions[action_name].add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile}) watching {sorted(list(getattr(role,'watch_list',[]))) }\")\n\n    def publish_message(self, message: Message):\n        # ensure id exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        # normalize send_to\n        if getattr(message, \"send_to\", None) is None:\n            message.send_to = set()\n        elif isinstance(message.send_to, (list, tuple)):\n            message.send_to = set(message.send_to)\n        self.history.append(message)\n        # initialize delivered tracking\n        self.delivered.setdefault(message.id, set())\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published message {message.id} from {message.sent_from} cause_by={message.cause_by} preview={_preview(message.content)} send_to={sorted(list(message.send_to))}\")\n\n    def find_latest_content_by_cause(self, cause_by: str) -> Optional[str]:\n        for msg in reversed(self.history):\n            if getattr(msg, \"cause_by\", \"\") == cause_by:\n                return msg.content\n        return None\n\n    def get_routable_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Return messages that the role should process:\n        - Directly targeted via send_to or sent_to\n        - OR messages caused by actions the role watches\n        Exclude messages already delivered to the role.\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            if getattr(msg, \"send_to\", None):\n                # if message explicitly targets this role\n                if role.name in msg.send_to or role.profile in msg.send_to:\n                    targeted = True\n            # watch-based routing\n            watched = getattr(msg, \"cause_by\", None) in role.watch_list\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\n# Team orchestrator: deterministic pipeline, robust act calls, stable termination\n\nclass Team:\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        # termination stability: require same digest twice\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = 2\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {_preview(idea,200)}\")\n\n    async def _safe_act_call(self, role: Role, message: Optional[Message], timeout: float = 30.0, max_retries: int = 2) -> Optional[Message]:\n        \"\"\"\n        Invoke role.act with timeout and retries. Returns a Message even on error to keep pipeline robust.\n        \"\"\"\n        tracer = self.tracer\n        attempt = 0\n        last_exc = None\n        while attempt <= max_retries:\n            attempt += 1\n            try:\n                if tracer:\n                    tracer.log(\"ACT_ATTEMPT\", role.name, f\"Attempt {attempt} on message {getattr(message,'id',None)}\")\n                coro = role.act(message)\n                resp = await asyncio.wait_for(coro, timeout=timeout)\n                if resp:\n                    # mark as delivered/processed for this role\n                    if message:\n                        self.env.delivered.setdefault(message.id, set()).add(role.name)\n                    return resp\n                last_exc = \"empty_response\"\n                if tracer:\n                    tracer.log(\"ACT_EMPTY\", role.name, f\"Empty response attempt {attempt}\")\n            except asyncio.TimeoutError:\n                last_exc = \"timeout\"\n                if tracer:\n                    tracer.log(\"ACT_TIMEOUT\", role.name, f\"Timeout attempt {attempt}\")\n            except Exception as e:\n                last_exc = f\"{type(e).__name__}: {str(e)[:300]}\"\n                if tracer:\n                    tracer.log(\"ACT_EXCEPTION\", role.name, f\"Exception attempt {attempt}: {last_exc}\")\n            await asyncio.sleep(0.2 * attempt)\n        # failed after retries\n        if tracer:\n            tracer.log(\"ACT_FAIL\", role.name, f\"Failed after {max_retries+1} attempts: {last_exc}\")\n        return Message(content=f\"ERROR: role {role.name} failed after retries: {last_exc}\", role=role.profile, cause_by=\"System\", sent_from=role.name)\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # Kickoff message targeted at coders explicitly\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds_executed = 0\n\n        # deterministic order\n        order: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n        for rnd in range(1, n_round + 1):\n            rounds_executed = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            for role_type in order:\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    msgs = self.env.get_routable_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # avoid self-processing\n                        if getattr(msg, \"sent_from\", None) == role.name:\n                            continue\n                        response = await self._safe_act_call(role, msg)\n                        if not response:\n                            continue\n                        # ensure cause_by annotation\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.action, \"name\", \"\") if getattr(role, \"action\", None) else \"\"\n                        # routing: if send_to empty, route to subscribers of this action\n                        if not getattr(response, \"send_to\", None):\n                            subs = self.env.subscriptions.get(response.cause_by, set())\n                            response.send_to = set(subs)\n                        self.env.publish_message(response)\n                        any_activity = True\n\n                        # handle verification pass detection and stability\n                        if response.cause_by == SimpleVerify.name and isinstance(response.content, str) and \"VERIFICATION_RESULT: PASS\" in response.content:\n                            # extract digest\n                            digest = None\n                            for part in response.content.split(\"|\"):\n                                p = part.strip()\n                                if p.startswith(\"digest=\"):\n                                    digest = p.split(\"=\", 1)[1].strip()\n                                    break\n                            if digest:\n                                if digest == self._last_digest:\n                                    self._streak += 1\n                                else:\n                                    self._last_digest = digest\n                                    self._streak = 1\n                                self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                if self._streak >= self._required_streak:\n                                    verified = True\n                            else:\n                                # no digest -> not stable\n                                self._streak = 0\n                                self._last_digest = None\n                                self.tracer.log(\"VERIFIER\", \"Team\", \"Verifier PASS without digest -> not considered stable\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} complete any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # no progress -> nudge coder(s) deterministically\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No activity this round; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        nudge = Message(\n                            content=f\"Nudge: propose code for '{_preview(self.idea,120)}'\",\n                            role=\"System\",\n                            sent_from=\"Orchestrator\",\n                            cause_by=\"Nudge\",\n                            send_to={r.name}\n                        )\n                        self.env.publish_message(nudge)\n                # small sleep to allow potential async LLMs in other contexts\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds_executed} rounds verified={verified} messages={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds_executed} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach, Excellent avg_failures_per_task (14.000)\n\n\n\n# Current Program\n```python\n# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nfrom typing import Callable\n\nRETRY_ATTEMPTS = 3\nRETRY_BACKOFF_BASE = 0.5  # seconds\n\nclass Action(ABC):\n    \"\"\"Base action class with clear retry and error handling for LLM/API calls.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns response or raises.\"\"\"\n        if not self.llm:\n            return \"LLM_NOT_AVAILABLE\"\n        last_err = None\n        for attempt in range(1, RETRY_ATTEMPTS + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt} for LLM call\")\n                resp = await self.llm.ask(messages)\n                # Basic failure detection: LLMInterface returns string starting with \"Error\"\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff with jitter\n                await asyncio.sleep(RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) + random.random() * 0.1)\n        # All retries failed\n        raise RuntimeError(f\"LLM call failed after {RETRY_ATTEMPTS} attempts: {last_err}\")\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements. Responsible for producing a compilable code artifact.\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea with retries and validation.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:120]}\")\n\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module \"\n            \"that implements the described functionality. Keep functions reasonably small and documented. \"\n            \"Ensure code can be parsed by ast.parse. Do not include usage examples.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Clean, functional Python code\\n\"\n            \"2. Proper error handling\\n\"\n            \"3. Comments and docstrings\\n\"\n            \"4. Production-ready\\n\\n\"\n            \"Provide only the Python code (no backticks or explanation).\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        # Call LLM with retries\n        try:\n            code = await self._llm_call_with_retries(messages)\n        except Exception as e:\n            # Fallback minimal implementation when LLM unavailable\n            fallback = f\"# Fallback implementation for: {idea}\\n\\n\" \\\n                       \"def placeholder():\\n\" \\\n                       \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\" \\\n                       \"    return None\\n\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback due to error: {str(e)}\")\n            code = fallback\n\n        # Quick static validation: must parse\n        try:\n            import ast\n            ast.parse(code)\n            valid = True\n        except Exception as e:\n            valid = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} chars; parsed_ok={valid}\")\n\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for a code module. Responsible for producing pytest tests matching the code's API.\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests with validation that they parse and reference functions found in code.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code ({len(code)} chars)\")\n\n        # Extract possible function names for targeted testing (best-effort)\n        func_names = []\n        try:\n            import ast\n            mod = ast.parse(code or \"\")\n            for node in ast.walk(mod):\n                if isinstance(node, ast.FunctionDef):\n                    func_names.append(node.name)\n        except Exception:\n            func_names = []\n\n        prompt_parts = [\n            \"You are a QA engineer. Write pytest-style tests for the provided Python module.\",\n            \"Requirements:\",\n            \"1. Use pytest\",\n            \"2. Cover edge cases and error conditions if possible\",\n            \"3. Include docstrings for each test\",\n            \"4. If functions are present, write at least one positive and one negative test per function\"\n        ]\n        if func_names:\n            prompt_parts.append(\"Target functions: \" + \", \".join(func_names[:8]))\n        prompt_parts.append(\"\\nCode:\\n\" + (code[:2000] if code else \"(empty)\"))\n\n        prompt = \"\\n\".join(prompt_parts)\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer who writes pytest tests.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        try:\n            tests = await self._llm_call_with_retries(messages)\n        except Exception as e:\n            # Minimal fallback tests to ensure something exists\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder_exists():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback tests due to error: {str(e)}\")\n\n        # Validate tests parse\n        try:\n            import ast\n            ast.parse(tests)\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} chars; parsed_ok={tests_ok}\")\n\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests. Responsible for producing actionable, concise feedback.\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Provide a short review. If human, simulate; otherwise call LLM with retries.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: Basic sanity check passed. Suggest explicit edge-case tests and clearer error messages.\"\n        else:\n            prompt = (\n                \"You are a senior software engineer. Provide a concise, actionable review of the code and tests.\\n\\n\"\n                \"Focus on:\\n\"\n                \"1. Code quality and maintainability\\n\"\n                \"2. Completeness of tests\\n\"\n                \"3. Likely bugs or missing checks\\n\"\n                \"4. Priority suggestions\\n\\n\"\n                f\"Code:\\n{code[:1500]}\\n\\nTests:\\n{tests[:1500]}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior code reviewer.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            try:\n                review = await self._llm_call_with_retries(messages)\n            except Exception as e:\n                review = \"Automated review fallback: Unable to contact reviewer LLM. Please perform a manual review.\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback review due to error: {str(e)}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to reliably verify that code and tests are syntactically and semantically reasonable.\n    Responsibilities:\n    - Parse code and tests\n    - Ensure at least one function exists in code\n    - Ensure tests reference code entities where possible\n    - Report PASS/FAIL with diagnostics\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        diagnostics = []\n        code_ok = False\n        tests_ok = False\n\n        # Verify code parseability and presence of function/class definitions\n        try:\n            code_ast = ast.parse(code)\n            defs = [n for n in code_ast.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            if defs:\n                code_ok = True\n                diagnostics.append(f\"code_defs: {len(defs)}\")\n            else:\n                diagnostics.append(\"code_defs: none\")\n        except Exception as e:\n            diagnostics.append(f\"code_parse_error: {str(e)[:180]}\")\n\n        # Verify tests parseability and that they reference some names found in code\n        try:\n            tests_ast = ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n            if tests_ok and code_ok:\n                # gather names from tests to see if they reference code defs\n                test_names = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n                code_names = {n.name for n in ast.walk(code_ast) if isinstance(n, ast.FunctionDef)}\n                referenced = code_names & test_names\n                diagnostics.append(f\"tests_references: {len(referenced)}\")\n                if not referenced:\n                    diagnostics.append(\"tests_references: none of the functions referenced\")\n            else:\n                diagnostics.append(\"tests_parse: empty_or_invalid\")\n        except Exception as e:\n            diagnostics.append(f\"tests_parse_error: {str(e)[:180]}\")\n\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(diagnostics)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibility and inbox semantics.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # names of actions this role listens for\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # env is provided by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, action_types: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for; store their .name strings for robust matching.\"\"\"\n        self.watch_list = [t.name for t in action_types]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the role's primary action on the provided message (or default).\"\"\"\n        if not self.actions:\n            return None\n\n        action = self.actions[0]  # each role has a single primary action for simplicity\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message_id={(message.id if message else 'None')}\")\n\n        # Dispatch based on action type\n        try:\n            if isinstance(action, SimpleWriteCode):\n                # Use instruct_content when present\n                prompt = message.instruct_content if (message and getattr(message, \"instruct_content\", None)) else (message.content if message else \"\")\n                result = await action.run(prompt or \"\")\n            elif isinstance(action, SimpleWriteTest):\n                # Expect code to be in message.content\n                code_text = message.content if message else \"\"\n                result = await action.run(code_text)\n            elif isinstance(action, SimpleWriteReview):\n                # Need both code and tests: find latest unprocessed code/tests pair\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                result = \"Action completed\"\n        except Exception as e:\n            # Robust error handling: convert exception into a response message and log\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Exception during act: {str(e)[:200]}\")\n            result = f\"ERROR: {str(e)}\"\n\n        # Create response message with explicit metadata\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n\n        # Mark that this role processed the trigger message (if any)\n        if message and self.env:\n            self.env.mark_processed(message, self)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created; response_len={len(result)}\")\n\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code (responsible for producing code artifacts).\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests (responsible for producing tests for latest code).\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests (responsible for quality feedback).\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests (responsible for final PASS/FAIL decision).\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with robust messaging and processing tracking.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Tracking dictionaries to avoid mutating Message objects (compatible with pydantic)\n        self._processed: Dict[str, Set[str]] = {}  # message.id -> set of role.names processed\n        self._attempts: Dict[str, int] = {}       # message.id -> attempts count\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and initialize tracking\"\"\"\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        self._attempts.setdefault(message.id, 0)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                            f\"Message from {message.sent_from}: {message.content[:140]} | cause_by={message.cause_by}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        \"\"\"Mark that a role processed a message so it won't be processed again by that role.\"\"\"\n        self._processed.setdefault(message.id, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"Message {message.id} processed by {role.name}\")\n\n    def increment_attempt(self, message: Message):\n        \"\"\"Increment attempt count for a message\"\"\"\n        self._attempts[message.id] = self._attempts.get(message.id, 0) + 1\n        return self._attempts[message.id]\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that match the role's watch_list and haven't been processed by this role yet.\"\"\"\n        results = []\n        for msg in self.history:\n            if msg.cause_by in role.watch_list:\n                processed = self._processed.get(msg.id, set())\n                if role.name not in processed:\n                    results.append(msg)\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str):\n        \"\"\"Find the latest code and test messages in history (best-effort).\"\"\"\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and msg.cause_by == code_cause:\n                code_msg = msg\n            if not tests_msg and msg.cause_by == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Team of agents working together with explicit pipeline orchestration and robust termination logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Pipeline ordering ensures clear responsibilities\n        self.pipeline: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for up to n_rounds with robust coordination and termination.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        last_verified_round = -1\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n\n            # Pipeline orchestration: each stage processes relevant unprocessed messages\n            for role_type in self.pipeline:\n                # Find all roles of this type in env\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # If role listens to user input explicitly (e.g., coder on initial), allow processing of initial message\n                    inbox = []\n                    # Coder should respond to UserInput once per round 1 (or when explicit instruct_content)\n                    if isinstance(role, SimpleCoder):\n                        # Coder acts once with the initial instruction in the first round, otherwise only if triggered\n                        if round_num == 1:\n                            inbox = [initial_msg]\n                        else:\n                            inbox = self.env.get_unprocessed_messages_for_role(role)\n                    else:\n                        inbox = self.env.get_unprocessed_messages_for_role(role)\n\n                    # Process each message one-at-a-time to keep deterministic behavior\n                    for msg in inbox:\n                        # Prevent spamming: limit attempts per message\n                        attempts = self.env.increment_attempt(msg)\n                        if attempts > 5:\n                            # Too many attempts; log and skip further attempts for this message\n                            if self.tracer:\n                                self.tracer.log(\"ENV_SKIP\", \"Environment\", f\"Skipping message {msg.id} for {role.name} after {attempts} attempts\")\n                            self.env.mark_processed(msg, role)\n                            continue\n\n                        response = await role.act(msg if msg else None)\n                        if response:\n                            # Response should indicate which action caused it (already set in act)\n                            self.env.publish_message(response)\n\n                            # If the response is verification with PASS, set verified flag only after confirming\n                            if isinstance(role, SimpleVerifier):\n                                if \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                    # Confirm pass by running an explicit verification again to avoid transient success\n                                    # (run local verifier action directly for confirmation)\n                                    verifier_action = role.actions[0]\n                                    confirm = await verifier_action.run(\n                                        *self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                                    ) if hasattr(verifier_action, \"run\") else None\n                                    if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                        verified = True\n                                        last_verified_round = round_num\n                                        self.tracer.log(\"VERIFIED_CONFIRMED\", \"Team\", f\"Verification confirmed in round {round_num}\")\n                                    else:\n                                        # Not confirmed, leave verified False and continue\n                                        self.tracer.log(\"VERIFIED_REJECTED\", \"Team\", \"Verification attempted but not confirmed; continuing\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed\")\n\n            # Early stop: require at least one confirmed verification and some stability (no new messages since verification)\n            if verified:\n                # Wait one additional round to ensure stability before finalizing\n                if round_num >= last_verified_round + 1:\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification observed; stopping after round {round_num}\")\n                    break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport ast\nimport hashlib\nimport random\nimport time\nfrom typing import Tuple\n\n# Evolution goals:\n# - Clear roles & responsibilities\n# - Robust inter-agent communication with explicit routing and watch triggers\n# - Deterministic orchestration and processed-tracking to avoid duplicate processing\n# - Strong verification with deterministic digest and consecutive confirmation\n# - Retry and fallback for LLM/API failures\n# - Safe termination (require confirmed verification and stability)\n\n# Tunables\nLLM_MAX_RETRIES = 3\nLLM_BACKOFF_BASE = 0.6\nROLE_MAX_ATTEMPTS = 3\nVERIFICATION_STABLE_PASSES = 2\n\n# Utility\ndef _preview(text: Optional[str], n: int = 160) -> str:\n    if not text:\n        return \"\"\n    t = str(text).replace(\"\\n\", \" \")\n    return (t[:n] + \"...\") if len(t) > n else t\n\nclass Action(ABC):\n    \"\"\"Base action: encapsulates LLM retries, backoff and deterministic fallback.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = LLM_MAX_RETRIES\n    base_backoff: float = LLM_BACKOFF_BASE\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get(\"context\")\n        try:\n            if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    async def _ask_with_retry(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retry, backoff, jitter, and logging. Returns deterministic fallback on exhaustion.\"\"\"\n        tracer = getattr(self.context, \"tracer\", None)\n        last_err = None\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                if tracer:\n                    tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                if not self.llm:\n                    fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n                    if tracer:\n                        tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n                    return fallback\n                resp = await self.llm.ask(messages)\n                if isinstance(resp, str) and resp.strip().lower().startswith(\"error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                if not isinstance(resp, str) or not resp.strip():\n                    last_err = \"empty_response\"\n                    raise RuntimeError(\"Empty response from LLM\")\n                if tracer:\n                    tracer.log(\"LLM_OK\", self.name, f\"Attempt {attempt} succeeded len={len(resp)}\")\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if tracer:\n                    tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {_preview(last_err,200)}\")\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)) + random.uniform(0, 0.2))\n        final = f\"LLM_FAILED_AFTER_RETRIES: {last_err}\"\n        if tracer:\n            tracer.log(\"LLM_GIVEUP\", self.name, final)\n        return final\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        pass\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Idea preview={_preview(idea,200)}\")\n        if not idea or not idea.strip():\n            fallback = (\n                \"def placeholder(value=None):\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback when no idea provided.\\\"\\\"\\\"\\n\"\n                \"    return value\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"Empty idea; returning deterministic fallback\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python developer. Produce a single Python module implementing the described task.\\n\"\n            \"Return only valid Python source code (no markdown fences). Include docstrings and basic input validation.\\n\\n\"\n            f\"Task:\\n{idea}\\n\"\n        )\n        messages = [{\"role\":\"system\",\"content\":\"You are an expert Python programmer.\"},\n                    {\"role\":\"user\",\"content\":prompt}]\n        resp = await self._ask_with_retry(messages)\n        # If LLM returned failure sentinel, return deterministic fallback error content\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            fallback = f\"# CODE_GEN_ERROR: {resp}\\n# Please provide manual implementation.\"\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning error sentinel\")\n            return fallback\n        # strip common fences\n        code = resp.strip()\n        if code.startswith(\"```\"):\n            # remove fences\n            parts = code.split(\"```\")\n            if len(parts) >= 2:\n                code = parts[1].strip()\n        # Validate parseability\n        try:\n            ast.parse(code)\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, f\"Code parsed successfully len={len(code)}\")\n            return code\n        except Exception as e:\n            # attempt safe wrapper\n            try:\n                wrapper = \"def _generated_wrapper():\\n\"\n                for line in code.splitlines():\n                    wrapper += \"    \" + line + \"\\n\"\n                ast.parse(wrapper)\n                if tracer:\n                    tracer.log(\"ACTION_FIX\", self.name, \"Wrapped output in function to fix syntax\")\n                return wrapper\n            except Exception:\n                fallback = (\n                    \"def placeholder(value=None):\\n\"\n                    \"    \\\"\\\"\\\"Fallback due to parse errors in generated code.\\\"\\\"\\\"\\n\"\n                    \"    return value\\n\"\n                )\n                if tracer:\n                    tracer.log(\"ACTION_FALLBACK\", self.name, f\"Parsing failed: {str(e)[:200]}; returning fallback\")\n                return fallback\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Generating tests from code len={len(code or '')}\")\n        snippet = (code or \"\")[:3000]\n        # infer public API\n        public_names = []\n        try:\n            parsed = ast.parse(code or \"\")\n            for node in parsed.body:\n                if isinstance(node, ast.FunctionDef) and not node.name.startswith(\"_\"):\n                    public_names.append(node.name)\n                if isinstance(node, ast.ClassDef) and not node.name.startswith(\"_\"):\n                    public_names.append(node.name)\n        except Exception:\n            public_names = []\n        prompt = (\n            \"You are an expert QA engineer. Write pytest-style tests for the provided Python module.\\n\"\n            \"- Provide at least one positive and one edge-case test per public function (if any).\\n\"\n            \"- Use assert statements and include docstrings for tests.\\n\"\n            \"- Return only pytest-compatible Python code.\\n\\n\"\n            f\"Public API: {', '.join(public_names) if public_names else '(none)'}\\n\\n\"\n            f\"Module (truncated):\\n{snippet}\"\n        )\n        messages = [{\"role\":\"system\",\"content\":\"You are an expert QA engineer.\"},\n                    {\"role\":\"user\",\"content\":prompt}]\n        resp = await self._ask_with_retry(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Deterministic fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning fallback tests\")\n            return fallback\n        tests = resp.strip()\n        # simple validation\n        try:\n            ast.parse(tests)\n            if (\"assert \" not in tests) and (\"pytest\" not in tests):\n                raise ValueError(\"No asserts found\")\n            if tracer:\n                tracer.log(\"ACTION_END\", self.name, f\"Tests parsed OK len={len(tests)}\")\n            return tests\n        except Exception as e:\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if tracer:\n                tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests invalid: {str(e)[:200]}; using fallback\")\n            return fallback\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Reviewing artifacts; human={self.is_human}\")\n        # static seed\n        issues = []\n        try:\n            ast.parse(code or \"\")\n        except Exception as e:\n            issues.append(f\"code_syntax_error: {str(e)[:160]}\")\n        try:\n            ast.parse(tests or \"\")\n        except Exception as e:\n            issues.append(f\"tests_syntax_error: {str(e)[:160]}\")\n        if self.is_human:\n            review = (\"HUMAN_REVIEW: OK\" if not issues else \"HUMAN_REVIEW: \" + \"; \".join(issues))\n            review += \"\\nREVIEW_DECISION: APPROVE\" if not issues else \"\\nREVIEW_DECISION: REQUEST_CHANGES\"\n            return review\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review and end with a single line:\\n\"\n            \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REQUEST_CHANGES\\n\\n\"\n            f\"STATIC_ISSUES: {issues}\\n\\n\"\n            f\"Code (truncated):\\n{(code or '')[:1500]}\\n\\n\"\n            f\"Tests (truncated):\\n{(tests or '')[:1500]}\"\n        )\n        messages = [{\"role\":\"system\",\"content\":\"You are a senior software engineer doing code review.\"},\n                    {\"role\":\"user\",\"content\":prompt}]\n        resp = await self._ask_with_retry(messages)\n        if isinstance(resp, str) and resp.startswith(\"LLM_FAILED_AFTER_RETRIES\"):\n            fallback = (\"REVIEW_DECISION: REQUEST_CHANGES\\nAutomated review fallback: LLM unavailable; manual review suggested.\")\n            if tracer:\n                tracer.log(\"ACTION_FALLBACK\", self.name, \"LLM failed; returning fallback review\")\n            return fallback\n        review = resp.strip()\n        if \"REVIEW_DECISION:\" not in review:\n            decision = \"APPROVE\" if not issues else \"REQUEST_CHANGES\"\n            review += f\"\\nREVIEW_DECISION: {decision}\"\n            if tracer:\n                tracer.log(\"ACTION_WARN\", self.name, \"Appended heuristic REVIEW_DECISION\")\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    name = \"SimpleVerify\"\n\n    @staticmethod\n    def _digest(code: str, tests: str) -> str:\n        h = hashlib.sha256()\n        h.update((code or \"\").encode(\"utf-8\"))\n        h.update(b\"\\n--\\n\")\n        h.update((tests or \"\").encode(\"utf-8\"))\n        return h.hexdigest()[:12]\n\n    async def run(self, code: str, tests: str) -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Deterministic verification starting\")\n        details = []\n        code_ok = False\n        tests_ok = False\n        entities: Set[str] = set()\n\n        # code syntax & entities\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = bool(code and code.strip())\n            for n in parsed_code.body:\n                if isinstance(n, (ast.FunctionDef, ast.ClassDef)):\n                    entities.add(n.name)\n            details.append(f\"code_entities:{len(entities)}\")\n            details.append(\"code_syntax:ok\")\n        except Exception as e:\n            details.append(f\"code_syntax:fail({type(e).__name__}:{str(e)[:120]})\")\n\n        # tests parse & asserts\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            has_assert = \"assert \" in (tests or \"\") or any(isinstance(n, ast.Assert) for n in ast.walk(parsed_tests))\n            tests_ok = bool(tests and has_assert)\n            details.append(\"tests_asserts:ok\" if has_assert else \"tests_asserts:none\")\n        except Exception as e:\n            details.append(f\"tests_syntax:fail({type(e).__name__}:{str(e)[:120]})\")\n\n        # cross reference\n        referenced = False\n        if entities and tests_ok:\n            try:\n                names_in_tests = {n.id for n in ast.walk(ast.parse(tests or \"\")) if isinstance(n, ast.Name)}\n                inter = entities & names_in_tests\n                referenced = len(inter) > 0\n                details.append(f\"tests_reference_matches:{len(inter)}\")\n            except Exception:\n                details.append(\"tests_reference_matches:error\")\n        else:\n            details.append(\"tests_reference_matches:0\")\n\n        verified = bool(code_ok and tests_ok and entities and referenced)\n        digest = self._digest(code or \"\", tests or \"\")\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | digest={digest} | \" + \"; \".join(details)\n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role with single responsibility, watch list, idempotent handling and retry.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: Set[str] = set()\n    env: Optional[\"Environment\"] = None\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = kwargs.get(\"context\")\n        self.is_human = kwargs.get(\"is_human\", False)\n        self.action = None\n        self.watch_list = set()\n        self.env = kwargs.get(\"env\", None)\n        self._processed_ids: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def watch(self, actions: List[Type[Action]]):\n        self.watch_list = {getattr(a, \"name\", \"\") for a in actions}\n\n    def _should_handle(self, msg: Message) -> bool:\n        if msg is None:\n            return False\n        if getattr(msg, \"id\", None) in self._processed_ids:\n            return False\n        # direct addressing via send_to\n        targets = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n        if targets:\n            if (self.name in targets) or (self.profile in targets) or (\"*\" in targets):\n                return True\n            return False\n        # watch-list trigger\n        if getattr(msg, \"cause_by\", \"\") in self.watch_list:\n            return True\n        # coder listens to user input/nudge implicitly\n        if isinstance(self, SimpleCoder) and getattr(msg, \"cause_by\", \"\") in {\"UserInput\", \"Nudge\", \"REQUEST_CHANGE\"}:\n            return True\n        return False\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        tracer = getattr(self.context, \"tracer\", None)\n        if not self.action:\n            if tracer:\n                tracer.log(\"ROLE_NO_ACTION\", self.name, \"No action assigned\")\n            return None\n        if message and not self._should_handle(message):\n            if tracer:\n                tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping message {getattr(message,'id',None)}\")\n            return None\n\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Processing message id={getattr(message,'id',None)} cause_by={getattr(message,'cause_by',None)}\")\n\n        attempts = 0\n        last_exc = None\n        while attempts < ROLE_MAX_ATTEMPTS:\n            attempts += 1\n            try:\n                if isinstance(self.action, SimpleWriteCode):\n                    idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\")\n                    out = await self.action.run(idea)\n                    send_to = {\"SimpleTester\"}\n                elif isinstance(self.action, SimpleWriteTest):\n                    code_text = \"\"\n                    if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                        code_text = message.content\n                    elif self.env:\n                        code_text = self.env.find_latest_content_by_cause(SimpleWriteCode.name) or \"\"\n                    out = await self.action.run(code_text)\n                    send_to = {\"SimpleReviewer\"}\n                elif isinstance(self.action, SimpleWriteReview):\n                    code_text = self.env.find_latest_content_by_cause(SimpleWriteCode.name) if self.env else \"\"\n                    tests_text = self.env.find_latest_content_by_cause(SimpleWriteTest.name) if self.env else \"\"\n                    out = await self.action.run(code_text or \"\", tests_text or \"\")\n                    # route based on decision if present\n                    lowered = (out or \"\").lower()\n                    if \"request_changes\" in lowered or \"request change\" in lowered or \"reject\" in lowered:\n                        send_to = {\"SimpleCoder\"}\n                    else:\n                        send_to = {\"SimpleVerifier\"}\n                elif isinstance(self.action, SimpleVerify):\n                    code_text = self.env.find_latest_content_by_cause(SimpleWriteCode.name) if self.env else \"\"\n                    tests_text = self.env.find_latest_content_by_cause(SimpleWriteTest.name) if self.env else \"\"\n                    out = await self.action.run(code_text or \"\", tests_text or \"\")\n                    # broadcast verification for traceability\n                    send_to = {r.profile for r in (self.env.roles if self.env else [])}\n                else:\n                    out = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n                    send_to = set()\n                # create response message\n                response = Message(\n                    content=out,\n                    role=self.profile,\n                    cause_by=getattr(self.action, \"name\", \"\"),\n                    sent_from=self.name,\n                    send_to=set(send_to) if isinstance(send_to, (set, list)) else set()\n                )\n                # mark processed\n                if message and getattr(message, \"id\", None):\n                    self._processed_ids.add(message.id)\n                    if self.env:\n                        self.env.mark_processed(role=self, message=message)\n                if tracer:\n                    tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced msg id={getattr(response,'id',None)} cause_by={response.cause_by} send_to={list(response.send_to)}\")\n                return response\n            except Exception as e:\n                last_exc = str(e)\n                if tracer:\n                    tracer.log(\"ROLE_ERROR\", self.name, f\"Attempt {attempts} failed: {_preview(last_exc,200)}\")\n                await asyncio.sleep(0.1 * attempts)\n        # Failed after retries\n        err = f\"ROLE_FAILED: {self.name} after {attempts} attempts: {last_exc}\"\n        if tracer:\n            tracer.log(\"ROLE_FAIL\", self.name, err)\n        response = Message(\n            content=err,\n            role=self.profile,\n            cause_by=\"RoleFailure\",\n            sent_from=self.name,\n            send_to={\"SimpleCoder\"}\n        )\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self.watch([])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self.watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self.watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self.watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"Message bus with explicit routing, watch triggers, idempotent processing and artifact lookup.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # track processed pairs (role_name, message_id)\n        self.processed: Set[Tuple[str, str]] = set()\n        # index messages by cause_by for quick artifact retrieval\n        self._by_cause: Dict[str, List[Message]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        # ensure send_to normalized\n        if getattr(message, \"send_to\", None) is None:\n            try:\n                message.send_to = set(getattr(message, \"sent_to\", set()) or set())\n            except Exception:\n                message.send_to = set()\n        # ensure id exists\n        if not getattr(message, \"id\", None):\n            try:\n                message.id = str(uuid.uuid4())\n            except Exception:\n                pass\n        self.history.append(message)\n        self._by_cause.setdefault(getattr(message, \"cause_by\", \"\"), []).append(message)\n        if self.tracer:\n            preview = _preview(getattr(message, \"content\", \"\"), 140)\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Msg {message.id} from {message.sent_from} cause_by={message.cause_by} -> {list(message.send_to)} preview={preview}\")\n\n    def mark_processed(self, role: Role, message: Message):\n        if getattr(message, \"id\", None):\n            self.processed.add((role.name, message.id))\n            if self.tracer:\n                self.tracer.log(\"ENV_MARK_PROCESSED\", \"Environment\", f\"{role.name} processed {message.id}\")\n\n    def has_processed(self, role: Role, message: Message) -> bool:\n        return (role.name, getattr(message, \"id\", None)) in self.processed\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages relevant to role (explicit or watch) and not yet processed by that role.\"\"\"\n        out: List[Message] = []\n        for msg in self.history:\n            if not getattr(msg, \"id\", None):\n                continue\n            if (role.name, msg.id) in self.processed:\n                continue\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n            # explicit routing preferred\n            send_to = getattr(msg, \"send_to\", None) or set(getattr(msg, \"sent_to\", set()) or set())\n            if send_to:\n                if role.name in send_to or role.profile in send_to or \"*\" in send_to:\n                    out.append(msg)\n                    continue\n            # watch list\n            if getattr(msg, \"cause_by\", None) in role.watch_list:\n                out.append(msg)\n                continue\n            # coder special-case: user input\n            if isinstance(role, SimpleCoder) and getattr(msg, \"cause_by\", \"\") in {\"UserInput\", \"Nudge\", \"REQUEST_CHANGE\"}:\n                out.append(msg)\n        return out\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[Message]:\n        lst = self._by_cause.get(cause_by, [])\n        return lst[-1] if lst else None\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str) -> Tuple[Optional[Message], Optional[Message]]:\n        code_msg = self.find_latest_by_cause(code_cause)\n        tests_msg = self.find_latest_by_cause(tests_cause)\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Orchestrates roles in deterministic pipeline with verification stability checks and retries.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # verification stability\n        self._last_digest: Optional[str] = None\n        self._streak: int = 0\n        self._required_streak: int = VERIFICATION_STABLE_PASSES\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {_preview(idea,200)}\")\n\n    async def _process_role(self, role: Role):\n        msgs = self.env.get_messages_for_role(role)\n        if not msgs:\n            return False\n        activity = False\n        for m in msgs:\n            # avoid duplicate processing\n            if self.env.has_processed(role, m):\n                continue\n            try:\n                resp = await role.act(m)\n            except Exception as e:\n                resp = Message(content=f\"ERROR: role {role.name} exception {type(e).__name__}: {str(e)[:200]}\", role=role.profile, sent_from=role.name, cause_by=\"RoleException\")\n                if self.tracer:\n                    self.tracer.log(\"ROLE_RUN_EXCEPTION\", role.name, f\"{type(e).__name__}: {_preview(str(e),200)}\")\n            # mark processed regardless to avoid infinite loops\n            self.env.mark_processed(role, m)\n            if resp:\n                self.env.publish_message(resp)\n                activity = True\n                # verification handling\n                if isinstance(role, SimpleVerifier) and isinstance(resp.content, str):\n                    if \"VERIFICATION_RESULT: PASS\" in resp.content:\n                        # extract digest\n                        digest = None\n                        for part in resp.content.split(\"|\"):\n                            p = part.strip()\n                            if p.startswith(\"digest=\"):\n                                digest = p.split(\"=\",1)[1].strip()\n                                break\n                        if digest:\n                            if digest == self._last_digest:\n                                self._streak += 1\n                            else:\n                                self._last_digest = digest\n                                self._streak = 1\n                            self.tracer.log(\"VERIFIER_PASS\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                        else:\n                            # no digest -> reset\n                            self._streak = 0\n                            self._last_digest = None\n                    else:\n                        if self._streak > 0:\n                            self.tracer.log(\"VERIFIER_RESET\", \"Team\", f\"resetting streak {self._streak}->0\")\n                        self._streak = 0\n                        self._last_digest = None\n            # small pause to allow cooperative multitasking\n            await asyncio.sleep(0)\n        return activity\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds (require_streak={self._required_streak})\")\n        # initial message targeted to coder\n        initial = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to={\"SimpleCoder\", \"Alice\"}\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        last_history_len = len(self.env.history)\n        no_progress_rounds = 0\n\n        for round_idx in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_idx}/{n_round}\")\n            progress = False\n            # deterministic ordering\n            for role_cls in self.order:\n                for role in [r for r in self.env.roles if isinstance(r, role_cls)]:\n                    # ensure coder sees initial message on first round even if not matching watch list\n                    if isinstance(role, SimpleCoder) and round_idx == 1:\n                        # process initial directly if not yet processed\n                        if not any((role.name, initial.id) == x for x in self.env.processed):\n                            resp = await role.act(initial)\n                            self.env.mark_processed(role, initial)\n                            if resp:\n                                self.env.publish_message(resp)\n                                progress = True\n                                # if coder created code immediately, downstream will pick up next roles in this round\n                    # process role's message queue\n                    activity = await self._process_role(role)\n                    if activity:\n                        progress = True\n            # detect progress\n            if len(self.env.history) == last_history_len:\n                no_progress_rounds += 1\n            else:\n                no_progress_rounds = 0\n            last_history_len = len(self.env.history)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_idx} complete progress={progress} history_len={len(self.env.history)} verifier_streak={self._streak}\")\n\n            # termination: stable verification achieved\n            if self._streak >= self._required_streak:\n                # optionally allow one more round for stability\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable with streak={self._streak}; stopping\")\n                verified = True\n                break\n\n            # if no progress for several rounds, nudge coder and break to avoid wasted cycles\n            if no_progress_rounds >= 2:\n                self.tracer.log(\"TEAM_NO_PROGRESS\", \"Team\", \"No progress for 2 rounds; nudging coder and terminating\")\n                # send nudge\n                nudge = Message(\n                    content=f\"Nudge: please refine and re-run implementation for: {self.idea}\",\n                    instruct_content=self.idea,\n                    role=\"System\",\n                    sent_from=\"Orchestrator\",\n                    cause_by=\"Nudge\",\n                    send_to={\"SimpleCoder\", \"Alice\"}\n                )\n                self.env.publish_message(nudge)\n                # give one opportunity to act on nudge\n                for role in [r for r in self.env.roles if isinstance(r, SimpleCoder)]:\n                    await self._process_role(role)\n                break\n\n            await asyncio.sleep(0.01)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project run finished\")\n        summary = f\"Project '{self.idea}' finished after {round_idx} rounds with {len(self.env.history)} messages. Verified={self._streak >= self._required_streak}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}