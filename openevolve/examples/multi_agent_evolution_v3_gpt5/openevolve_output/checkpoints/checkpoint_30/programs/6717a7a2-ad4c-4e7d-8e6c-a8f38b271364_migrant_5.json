{"id": "6717a7a2-ad4c-4e7d-8e6c-a8f38b271364_migrant_5", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport hashlib\nimport ast\nfrom collections import defaultdict\n\ndef artifact_preview(text: Optional[str], length: int = 80) -> str:\n    if not text:\n        return \"\"\n    return (text[:length] + \"...\") if len(text) > length else text\n\nclass Action(ABC):\n    \"\"\"\n    Base action class.\n    Responsibilities:\n    - Provide run(...) coroutine performing the action.\n    - Encapsulate robust LLM calls with retries, backoff and logging.\n    \"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    max_retries: int = 3\n    base_backoff: float = 0.5\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and getattr(self.context, \"config\", None) and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def safe_ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"\n        Robust wrapper for LLM calls:\n        - Retries on exceptions or error markers.\n        - Exponential backoff.\n        - Logs each attempt and final outcome.\n        - Returns explicit failure marker on exhaustion.\n        \"\"\"\n        if not self.llm:\n            # Deterministic fallback for testing without LLM\n            fallback = \"LLM_UNAVAILABLE_FALLBACK\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"LLM_FALLBACK\", self.name, fallback)\n            return fallback\n\n        attempt = 0\n        last_err = None\n        while attempt < self.max_retries:\n            attempt += 1\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt}/{self.max_retries}\")\n                resp = await self.llm.ask(messages)\n                # LLMInterface uses \"Error:\" prefix for non-200 responses or exceptions returned as strings\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"LLM_ERROR\", self.name, f\"LLM returned error: {resp[:200]}\")\n                    await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                    continue\n                # Accept string responses (successful)\n                return resp\n            except Exception as e:\n                last_err = f\"{type(e).__name__}: {str(e)[:200]}\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_EXCEPTION\", self.name, last_err)\n                await asyncio.sleep(self.base_backoff * (2 ** (attempt - 1)))\n                continue\n\n        failure_msg = f\"LLM_CALL_FAILED after {self.max_retries} attempts: {last_err}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"LLM_ABORT\", self.name, failure_msg)\n        return failure_msg\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate Python module code from idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"idea={artifact_preview(idea, 200)}\")\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module implementing the requested functionality.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Constraints:\\n\"\n            \"- Return only valid Python source code (no surrounding markdown).\\n\"\n            \"- Include docstrings, input validation and basic error handling.\\n            \"\n            \"- Ensure at least one function or class is defined.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        code = await self.safe_ask(messages)\n        if not code or not any(token in code for token in (\"def \", \"class \")):\n            # deterministic fallback if LLM failed or produced non-code\n            fallback = (\n                \"def placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback placeholder implementation.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"LLM produced no valid code; using fallback\")\n            code = fallback\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"generated_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"code_len={len(code or '')}\")\n        truncated = (code or \"\")[:3000]\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following Python module.\\n\\n\"\n            f\"Module (truncated):\\n{truncated}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Provide pytest-compatible tests only.\\n\"\n            \"- Cover typical cases and at least one edge case.\\n\"\n            \"- Use assert statements and include docstrings for tests.\\n\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        tests = await self.safe_ask(messages)\n        # Fallback if the LLM response doesn't look like tests\n        if not tests or (\"assert\" not in tests and \"pytest\" not in tests):\n            fallback = (\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Fallback test\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_WARN\", self.name, \"LLM produced no valid tests; using fallback\")\n            tests = fallback\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"tests_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Produce a concise review; include explicit REVIEW_DECISION.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: APPROVE\\nREVIEW_DECISION: APPROVE\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Provide a concise review and an explicit decision line:\\n\"\n                \"REVIEW_DECISION: APPROVE or REVIEW_DECISION: REJECT\\n\\n\"\n                \"Code (truncated):\\n\"\n                f\"{(code or '')[:2000]}\\n\\nTests (truncated):\\n\"\n                f\"{(tests or '')[:2000]}\\n\\n\"\n                \"Focus on bugs, missing tests and actionable improvements.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            review = await self.safe_ask(messages)\n            if not review or \"REVIEW_DECISION:\" not in review:\n                # derive decision heuristically\n                decision = \"APPROVE\" if (\"assert\" in (tests or \"\")) and (\"def \" in (code or \"\") or \"class \" in (code or \"\")) else \"REJECT\"\n                review = (review or \"Automated review\") + f\"\\n\\nREVIEW_DECISION: {decision}\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"review_len={len(review)}\")\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"\n    Verify code and tests using deterministic checks:\n    - Syntax parsing\n    - At least one function/class in code\n    - Tests include asserts and reference code entities\n    - Produces VERIFICATION_RESULT: PASS/FAIL and digest\n    \"\"\"\n    name = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"verifying artifacts\")\n        details: List[str] = []\n        code_ok = False\n        tests_ok = False\n        code_entities: Set[str] = set()\n\n        # Syntax checks\n        try:\n            parsed_code = ast.parse(code or \"\")\n            code_ok = True\n            details.append(\"code_syntax: ok\")\n        except Exception as e:\n            details.append(f\"code_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_code = None\n\n        try:\n            parsed_tests = ast.parse(tests or \"\")\n            tests_ok = True\n            details.append(\"tests_syntax: ok\")\n        except Exception as e:\n            details.append(f\"tests_syntax: fail ({type(e).__name__}: {str(e)[:120]})\")\n            parsed_tests = None\n\n        # Semantic checks\n        if parsed_code:\n            for node in parsed_code.body:\n                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n                    code_entities.add(node.name)\n            if code_entities:\n                details.append(f\"code_entities: {sorted(list(code_entities))[:6]}\")\n            else:\n                details.append(\"code_entities: none\")\n\n        tests_has_assert = False\n        tests_references = set()\n        if parsed_tests:\n            for node in ast.walk(parsed_tests):\n                if isinstance(node, ast.Assert):\n                    tests_has_assert = True\n                if isinstance(node, ast.Name):\n                    tests_references.add(node.id)\n            details.append(f\"tests_asserts: {tests_has_assert}\")\n            inter = code_entities & tests_references\n            details.append(f\"tests_references_code_entities: {sorted(list(inter))[:6]}\")\n\n        # Determine pass/fail\n        passed = all([code_ok, tests_ok, bool(code_entities), tests_has_assert, len(code_entities & tests_references) > 0])\n        # Compute digest of current artifacts for stability detection\n        digest_src = (code or \"\").encode(\"utf-8\") + b\"\\n--\\n\" + (tests or \"\").encode(\"utf-8\")\n        digest = hashlib.sha256(digest_src).hexdigest()[:12]\n\n        status = \"PASS\" if passed else \"FAIL\"\n        result = f\"VERIFICATION_RESULT: {status} | digest={digest} | \" + \"; \".join(details)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"\n    Base Role:\n    - Single primary responsibility (one action).\n    - Maintains processed message ids to ensure idempotency.\n    - Uses environment subscriptions for explicit routing.\n    \"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    action: Optional[Action] = None\n    watch_list: List[Type[Action]] = []\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.action = None\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None\n        # track processed messages\n        self._processed: Set[str] = set()\n\n    def set_action(self, action: Action):\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = actions\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"\n        Execute the role's primary action in response to a message.\n        Ensures idempotency by skipping already processed messages.\n        Returns a Message or None.\n        \"\"\"\n        if not self.action:\n            return None\n\n        msg_id = getattr(message, \"id\", None)\n        if msg_id and msg_id in self._processed:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_SKIP\", self.name, f\"Skipping already processed message {msg_id}\")\n            return None\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Acting on message {msg_id} cause_by={getattr(message,'cause_by',None)}\")\n\n        try:\n            # Extract inputs depending on action type\n            if isinstance(self.action, SimpleWriteCode):\n                idea = (getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\")) if message else \"\"\n                result = await self.action.run(idea)\n            elif isinstance(self.action, SimpleWriteTest):\n                # Expect code in message.content, or fetch last code from env\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and self.env:\n                    code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                result = await self.action.run(code)\n            elif isinstance(self.action, SimpleWriteReview):\n                # Need both code and tests\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            elif isinstance(self.action, SimpleVerify):\n                code = self.env.find_latest_by_cause(SimpleWriteCode.name) or \"\"\n                tests = self.env.find_latest_by_cause(SimpleWriteTest.name) or \"\"\n                result = await self.action.run(code, tests)\n            else:\n                # Generic action fallback\n                result = await self.action.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            err = f\"ROLE_ACTION_ERROR: {type(e).__name__}: {str(e)[:200]}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err)\n            # mark message as processed to avoid repeated failing attempts\n            if msg_id:\n                self._processed.add(msg_id)\n            return Message(content=err, role=self.profile, cause_by=\"Error\", sent_from=self.name)\n\n        # Build response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=self.action.name if self.action else \"\",\n            sent_from=self.name,\n            send_to=set()  # environment will fill routing based on subscriptions if left empty\n        )\n\n        # Mark processed\n        if msg_id:\n            self._processed.add(msg_id)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Produced message {response.id} cause_by={response.cause_by}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # coder is typically triggered by UserInput (explicit send_to)\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteCode])\n\nclass SimpleVerifier(Role):\n    name = \"Dana\"\n    profile = \"SimpleVerifier\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_action(SimpleVerify(context=self.context))\n        self._watch([SimpleWriteTest, SimpleWriteReview])\n\nclass Environment:\n    \"\"\"\n    Environment:\n    - Holds history of Messages.\n    - Maintains action_name -> roles subscriptions.\n    - Provides helpers to route messages deterministically and fetch latest artifacts.\n    \"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # subscriptions mapping: action_name -> set(role.name)\n        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)\n        # track delivery: message_id -> set(role.name) delivered\n        self.delivered: Dict[str, Set[str]] = defaultdict(set)\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role {role.name}({role.profile})\")\n        for watched in role.watch_list:\n            self.subscriptions[watched.name].add(role.name)\n\n    def publish_message(self, message: Message):\n        # normalize send_to\n        if getattr(message, \"send_to\", None) is None:\n            message.send_to = set()\n        self.history.append(message)\n        # initialize delivered set\n        self.delivered[message.id] = set()\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Published msg {message.id} from {message.sent_from} cause_by={message.cause_by} preview={artifact_preview(message.content,200)} send_to={sorted(list(message.send_to)[:10])}\")\n\n    def find_latest_by_cause(self, cause_by: str) -> Optional[str]:\n        \"\"\"Return content of the latest message with cause_by.\"\"\"\n        for msg in reversed(self.history):\n            if msg.cause_by == cause_by:\n                return msg.content\n        return None\n\n    def get_routable_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"\n        Determine messages a role should process:\n        - Explicitly targeted via send_to (role.name or role.profile)\n        - OR messages caused by an action the role watches\n        - Excludes messages already delivered to that role\n        \"\"\"\n        out: List[Message] = []\n        seen = self.delivered.get(role.name, set())\n        for msg in self.history:\n            if msg.id in seen:\n                continue\n            targeted = False\n            targets = getattr(msg, \"send_to\", None) or set()\n            if role.name in targets or role.profile in targets:\n                targeted = True\n            watched = False\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    watched = True\n                    break\n            if targeted or watched:\n                out.append(msg)\n                seen.add(msg.id)\n        if out:\n            self.delivered[role.name] = seen\n        return out\n\nclass Team:\n    \"\"\"\n    Team orchestrator:\n    - Deterministic order of role processing.\n    - Explicit routing via Environment.subscriptions and message.send_to.\n    - Termination requires stable verification: same digest consecutively.\n    - Robust handling of role/LLM failures and retries at action level.\n    \"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment = 20.0\n        self.idea = \"\"\n        self.order = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n        # verification stability\n        self._last_digest: Optional[str] = None\n        self._streak = 0\n        self._required_streak = 2\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project started: {artifact_preview(idea,200)}\")\n\n    async def run(self, n_round: int = 4):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n        # initial kickoff: targeted to coders explicitly\n        coder_names = {r.name for r in self.env.roles if isinstance(r, SimpleCoder)}\n        initial = Message(\n            content=f\"Project kickoff: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            send_to=coder_names\n        )\n        self.env.publish_message(initial)\n\n        verified = False\n        rounds = 0\n\n        for rnd in range(1, n_round + 1):\n            rounds = rnd\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnd}/{n_round}\")\n            any_activity = False\n\n            # deterministic role order\n            for role_type in self.order:\n                roles_of_type = [r for r in self.env.roles if isinstance(r, role_type)]\n                for role in roles_of_type:\n                    msgs = self.env.get_routable_messages_for_role(role)\n                    if not msgs:\n                        continue\n                    for msg in msgs:\n                        # guard redundant processing at role level\n                        try:\n                            response = await role.act(msg)\n                            # mark delivery/processing\n                            # Environment.delivery was updated in get_routable_messages_for_role\n                            any_activity = True\n                            if response:\n                                # route response: if send_to empty, fill subscribers watching this action\n                                if not getattr(response, \"send_to\", None):\n                                    # find roles who watch this action\n                                    subscribers = self.env.subscriptions.get(response.cause_by, set())\n                                    response.send_to = set(subscribers)\n                                self.env.publish_message(response)\n                                # If verifier directly produced PASS, parse it\n                                if response.cause_by == SimpleVerify.name and \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                    # parse digest\n                                    digest = None\n                                    for part in (response.content or \"\").split(\"|\"):\n                                        part = part.strip()\n                                        if part.startswith(\"digest=\"):\n                                            digest = part.split(\"=\",1)[1]\n                                            break\n                                    if digest:\n                                        if digest == self._last_digest:\n                                            self._streak += 1\n                                        else:\n                                            self._last_digest = digest\n                                            self._streak = 1\n                                        self.tracer.log(\"VERIFIER_STREAK\", \"Team\", f\"digest={digest} streak={self._streak}\")\n                                        if self._streak >= self._required_streak:\n                                            verified = True\n                                    else:\n                                        # no digest, treat as non-stable pass\n                                        self._streak = 0\n                                        self._last_digest = None\n                                        self.tracer.log(\"VERIFIER\", \"Team\", \"Pass without digest - not considered stable\")\n                            # record that role processed msg to ensure idempotency\n                            self.env.delivered[msg.id].add(role.name)\n                        except Exception as e:\n                            self.tracer.log(\"TEAM_ROLE_ERROR\", \"Team\", f\"Role {role.name} raised {type(e).__name__}: {str(e)[:200]}\")\n                            continue\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnd} completed; any_activity={any_activity} verified={verified}\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Verification stable for {self._required_streak} rounds; stopping early\")\n                break\n            if not any_activity:\n                # deadlock: allow coders to re-attempt once by targeting them explicitly\n                self.tracer.log(\"TEAM_DEADLOCK\", \"Team\", \"No activity this round; nudging coders\")\n                for r in self.env.roles:\n                    if isinstance(r, SimpleCoder):\n                        # create a nudge message targeting that coder only if they haven't processed the initial\n                        if not self.env.has_been_processed_by if False else True:\n                            nudge = Message(content=f\"Nudge: please propose initial code for '{artifact_preview(self.idea,120)}'\", role=\"System\", sent_from=\"Orchestrator\", cause_by=\"Nudge\", send_to={r.name})\n                            self.env.publish_message(nudge)\n                # short pause to allow asynchronous LLM processing in environments where real LLM calls might be queued\n                await asyncio.sleep(0.05)\n\n        self.tracer.log(\"TEAM_END\", \"Team\", f\"Completed after {rounds} rounds; verified={verified} history_len={len(self.env.history)}\")\n        self.tracer.log(\"SUMMARY\", \"Team\", f\"Project '{self.idea}' ended rounds={rounds} verified={verified} messages={len(self.env.history)}\")\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "6717a7a2-ad4c-4e7d-8e6c-a8f38b271364", "generation": 2, "timestamp": 1754655498.84315, "iteration_found": 0, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 5, "migrant": true}, "artifacts_json": null, "artifact_dir": null}