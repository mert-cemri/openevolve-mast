{"id": "e205f29d-a04d-4139-8571-726a074f6e0f", "code": "# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nfrom typing import Callable\n\nRETRY_ATTEMPTS = 3\nRETRY_BACKOFF_BASE = 0.5  # seconds\n\nclass Action(ABC):\n    \"\"\"Base action class with clear retry and error handling for LLM/API calls.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns response or raises.\"\"\"\n        if not self.llm:\n            return \"LLM_NOT_AVAILABLE\"\n        last_err = None\n        for attempt in range(1, RETRY_ATTEMPTS + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt} for LLM call\")\n                resp = await self.llm.ask(messages)\n                # Basic failure detection: LLMInterface returns string starting with \"Error\"\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff with jitter\n                await asyncio.sleep(RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) + random.random() * 0.1)\n        # All retries failed\n        raise RuntimeError(f\"LLM call failed after {RETRY_ATTEMPTS} attempts: {last_err}\")\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements. Responsible for producing a compilable code artifact.\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea with retries and validation.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:120]}\")\n\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module \"\n            \"that implements the described functionality. Keep functions reasonably small and documented. \"\n            \"Ensure code can be parsed by ast.parse. Do not include usage examples.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Clean, functional Python code\\n\"\n            \"2. Proper error handling\\n\"\n            \"3. Comments and docstrings\\n\"\n            \"4. Production-ready\\n\\n\"\n            \"Provide only the Python code (no backticks or explanation).\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        # Call LLM with retries\n        try:\n            code = await self._llm_call_with_retries(messages)\n        except Exception as e:\n            # Fallback minimal implementation when LLM unavailable\n            fallback = f\"# Fallback implementation for: {idea}\\n\\n\" \\\n                       \"def placeholder():\\n\" \\\n                       \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\" \\\n                       \"    return None\\n\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback due to error: {str(e)}\")\n            code = fallback\n\n        # Quick static validation: must parse\n        try:\n            import ast\n            ast.parse(code)\n            valid = True\n        except Exception as e:\n            valid = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} chars; parsed_ok={valid}\")\n\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for a code module. Responsible for producing pytest tests matching the code's API.\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests with validation that they parse and reference functions found in code.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code ({len(code)} chars)\")\n\n        # Extract possible function names for targeted testing (best-effort)\n        func_names = []\n        try:\n            import ast\n            mod = ast.parse(code or \"\")\n            for node in ast.walk(mod):\n                if isinstance(node, ast.FunctionDef):\n                    func_names.append(node.name)\n        except Exception:\n            func_names = []\n\n        prompt_parts = [\n            \"You are a QA engineer. Write pytest-style tests for the provided Python module.\",\n            \"Requirements:\",\n            \"1. Use pytest\",\n            \"2. Cover edge cases and error conditions if possible\",\n            \"3. Include docstrings for each test\",\n            \"4. If functions are present, write at least one positive and one negative test per function\"\n        ]\n        if func_names:\n            prompt_parts.append(\"Target functions: \" + \", \".join(func_names[:8]))\n        prompt_parts.append(\"\\nCode:\\n\" + (code[:2000] if code else \"(empty)\"))\n\n        prompt = \"\\n\".join(prompt_parts)\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer who writes pytest tests.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        try:\n            tests = await self._llm_call_with_retries(messages)\n        except Exception as e:\n            # Minimal fallback tests to ensure something exists\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder_exists():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback tests due to error: {str(e)}\")\n\n        # Validate tests parse\n        try:\n            import ast\n            ast.parse(tests)\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} chars; parsed_ok={tests_ok}\")\n\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests. Responsible for producing actionable, concise feedback.\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Provide a short review. If human, simulate; otherwise call LLM with retries.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: Basic sanity check passed. Suggest explicit edge-case tests and clearer error messages.\"\n        else:\n            prompt = (\n                \"You are a senior software engineer. Provide a concise, actionable review of the code and tests.\\n\\n\"\n                \"Focus on:\\n\"\n                \"1. Code quality and maintainability\\n\"\n                \"2. Completeness of tests\\n\"\n                \"3. Likely bugs or missing checks\\n\"\n                \"4. Priority suggestions\\n\\n\"\n                f\"Code:\\n{code[:1500]}\\n\\nTests:\\n{tests[:1500]}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior code reviewer.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            try:\n                review = await self._llm_call_with_retries(messages)\n            except Exception as e:\n                review = \"Automated review fallback: Unable to contact reviewer LLM. Please perform a manual review.\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback review due to error: {str(e)}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to reliably verify that code and tests are syntactically and semantically reasonable.\n    Responsibilities:\n    - Parse code and tests\n    - Ensure at least one function exists in code\n    - Ensure tests reference code entities where possible\n    - Report PASS/FAIL with diagnostics\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        diagnostics = []\n        code_ok = False\n        tests_ok = False\n\n        # Verify code parseability and presence of function/class definitions\n        try:\n            code_ast = ast.parse(code)\n            defs = [n for n in code_ast.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            if defs:\n                code_ok = True\n                diagnostics.append(f\"code_defs: {len(defs)}\")\n            else:\n                diagnostics.append(\"code_defs: none\")\n        except Exception as e:\n            diagnostics.append(f\"code_parse_error: {str(e)[:180]}\")\n\n        # Verify tests parseability and that they reference some names found in code\n        try:\n            tests_ast = ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n            if tests_ok and code_ok:\n                # gather names from tests to see if they reference code defs\n                test_names = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n                code_names = {n.name for n in ast.walk(code_ast) if isinstance(n, ast.FunctionDef)}\n                referenced = code_names & test_names\n                diagnostics.append(f\"tests_references: {len(referenced)}\")\n                if not referenced:\n                    diagnostics.append(\"tests_references: none of the functions referenced\")\n            else:\n                diagnostics.append(\"tests_parse: empty_or_invalid\")\n        except Exception as e:\n            diagnostics.append(f\"tests_parse_error: {str(e)[:180]}\")\n\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(diagnostics)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibility and inbox semantics.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # names of actions this role listens for\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # env is provided by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, action_types: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for; store their .name strings for robust matching.\"\"\"\n        self.watch_list = [t.name for t in action_types]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the role's primary action on the provided message (or default).\"\"\"\n        if not self.actions:\n            return None\n\n        action = self.actions[0]  # each role has a single primary action for simplicity\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message_id={(message.id if message else 'None')}\")\n\n        # Dispatch based on action type\n        try:\n            if isinstance(action, SimpleWriteCode):\n                # Use instruct_content when present\n                prompt = message.instruct_content if (message and getattr(message, \"instruct_content\", None)) else (message.content if message else \"\")\n                result = await action.run(prompt or \"\")\n            elif isinstance(action, SimpleWriteTest):\n                # Expect code to be in message.content\n                code_text = message.content if message else \"\"\n                result = await action.run(code_text)\n            elif isinstance(action, SimpleWriteReview):\n                # Need both code and tests: find latest unprocessed code/tests pair\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                result = \"Action completed\"\n        except Exception as e:\n            # Robust error handling: convert exception into a response message and log\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Exception during act: {str(e)[:200]}\")\n            result = f\"ERROR: {str(e)}\"\n\n        # Create response message with explicit metadata\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n\n        # Mark that this role processed the trigger message (if any)\n        if message and self.env:\n            self.env.mark_processed(message, self)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created; response_len={len(result)}\")\n\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code (responsible for producing code artifacts).\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests (responsible for producing tests for latest code).\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests (responsible for quality feedback).\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests (responsible for final PASS/FAIL decision).\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with robust messaging and processing tracking.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Tracking dictionaries to avoid mutating Message objects (compatible with pydantic)\n        self._processed: Dict[str, Set[str]] = {}  # message.id -> set of role.names processed\n        self._attempts: Dict[str, int] = {}       # message.id -> attempts count\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and initialize tracking\"\"\"\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        self._attempts.setdefault(message.id, 0)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                            f\"Message from {message.sent_from}: {message.content[:140]} | cause_by={message.cause_by}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        \"\"\"Mark that a role processed a message so it won't be processed again by that role.\"\"\"\n        self._processed.setdefault(message.id, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"Message {message.id} processed by {role.name}\")\n\n    def increment_attempt(self, message: Message):\n        \"\"\"Increment attempt count for a message\"\"\"\n        self._attempts[message.id] = self._attempts.get(message.id, 0) + 1\n        return self._attempts[message.id]\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that match the role's watch_list and haven't been processed by this role yet.\"\"\"\n        results = []\n        for msg in self.history:\n            if msg.cause_by in role.watch_list:\n                processed = self._processed.get(msg.id, set())\n                if role.name not in processed:\n                    results.append(msg)\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str):\n        \"\"\"Find the latest code and test messages in history (best-effort).\"\"\"\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and msg.cause_by == code_cause:\n                code_msg = msg\n            if not tests_msg and msg.cause_by == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Team of agents working together with explicit pipeline orchestration and robust termination logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Pipeline ordering ensures clear responsibilities\n        self.pipeline: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for up to n_rounds with robust coordination and termination.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        last_verified_round = -1\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n\n            # Pipeline orchestration: each stage processes relevant unprocessed messages\n            for role_type in self.pipeline:\n                # Find all roles of this type in env\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # If role listens to user input explicitly (e.g., coder on initial), allow processing of initial message\n                    inbox = []\n                    # Coder should respond to UserInput once per round 1 (or when explicit instruct_content)\n                    if isinstance(role, SimpleCoder):\n                        # Coder acts once with the initial instruction in the first round, otherwise only if triggered\n                        if round_num == 1:\n                            inbox = [initial_msg]\n                        else:\n                            inbox = self.env.get_unprocessed_messages_for_role(role)\n                    else:\n                        inbox = self.env.get_unprocessed_messages_for_role(role)\n\n                    # Process each message one-at-a-time to keep deterministic behavior\n                    for msg in inbox:\n                        # Prevent spamming: limit attempts per message\n                        attempts = self.env.increment_attempt(msg)\n                        if attempts > 5:\n                            # Too many attempts; log and skip further attempts for this message\n                            if self.tracer:\n                                self.tracer.log(\"ENV_SKIP\", \"Environment\", f\"Skipping message {msg.id} for {role.name} after {attempts} attempts\")\n                            self.env.mark_processed(msg, role)\n                            continue\n\n                        response = await role.act(msg if msg else None)\n                        if response:\n                            # Response should indicate which action caused it (already set in act)\n                            self.env.publish_message(response)\n\n                            # If the response is verification with PASS, set verified flag only after confirming\n                            if isinstance(role, SimpleVerifier):\n                                if \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                    # Confirm pass by running an explicit verification again to avoid transient success\n                                    # (run local verifier action directly for confirmation)\n                                    verifier_action = role.actions[0]\n                                    confirm = await verifier_action.run(\n                                        *self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                                    ) if hasattr(verifier_action, \"run\") else None\n                                    if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                        verified = True\n                                        last_verified_round = round_num\n                                        self.tracer.log(\"VERIFIED_CONFIRMED\", \"Team\", f\"Verification confirmed in round {round_num}\")\n                                    else:\n                                        # Not confirmed, leave verified False and continue\n                                        self.tracer.log(\"VERIFIED_REJECTED\", \"Team\", \"Verification attempted but not confirmed; continuing\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed\")\n\n            # Early stop: require at least one confirmed verification and some stability (no new messages since verification)\n            if verified:\n                # Wait one additional round to ensure stability before finalizing\n                if round_num >= last_verified_round + 1:\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification observed; stopping after round {round_num}\")\n                    break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END", "language": "python", "parent_id": "3d91acaf-bcc7-43c5-88af-7196dafaee82", "generation": 1, "timestamp": 1754655172.0391295, "iteration_found": 4, "metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "avg_failures_per_task": 14.0, "error": "name 'ABC' is not defined"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.16666666666666666, "avg_failures_per_task": 5.0, "total_failures": 30.0, "successful_runs": 6.0}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes per the MAST taxonomy.\n\nFocus on:\n- Clear role definitions and responsibilities\n- Robust inter-agent communication patterns and explicit watch/trigger logic\n- Termination conditions (avoid premature termination; stop once verified)\n- Strong verification and validation steps\n- Error handling and retry on LLM/API failures\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 1.0000\n- overall_score: 0.5000\n- combined_score: 0.1667\n- avg_failures_per_task: 5.0000\n- total_failures: 30.0000\n- successful_runs: 6.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, overall_score: 0.5000, combined_score: 0.1667, avg_failures_per_task: 5.0000, total_failures: 30.0000, successful_runs: 6.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 7.1111)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on overall_score (0.5000), Performs well on combined_score (0.1667), Performs well on avg_failures_per_task (5.0000), Performs well on total_failures (30.0000), Performs well on successful_runs (6.0000)\n\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-5\"\n        self.api_key = None\n        self.base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n        self.proxy = \"\"\n        self.temperature = 0.35\n        self.max_token = 8192\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token\n        }\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nProvide only the Python code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nProvide only the Python test code with no surrounding backticks or explanations.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to verify code and tests and decide readiness\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n        try:\n            ast.parse(code)\n            code_ok = True\n        except Exception as e:\n            code_ok = False\n            code_err = str(e)\n        try:\n            ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            tests_err = str(e)\n        status = []\n        if code_ok:\n            status.append(\"code_syntax: ok\")\n        else:\n            status.append(f\"code_syntax: fail ({code_err[:120]})\")\n        if tests_ok:\n            status.append(\"tests_syntax: ok\")\n        else:\n            status.append(f\"tests_syntax: fail ({(tests_err if 'tests_err' in locals() else 'empty')[:120]})\")\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(status)\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        elif isinstance(action, SimpleVerify):\n            # For verification, try to find latest code and tests from history\n            env = getattr(self, 'env', None)\n            code_msg = None\n            tests_msg = None\n            if env:\n                for msg in reversed(env.history):\n                    if msg.cause_by == SimpleWriteCode.name and code_msg is None:\n                        code_msg = msg\n                    if msg.cause_by == SimpleWriteTest.name and tests_msg is None:\n                        tests_msg = msg\n                    if code_msg and tests_msg:\n                        break\n            result = await action.run(code_msg.content if code_msg else \"\", tests_msg.content if tests_msg else \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Provide env reference for roles that need to look back at history\n            setattr(role, 'env', self.env)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        verified = False\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Orchestrated sequence: Coder -> Tester -> Reviewer -> Verifier\n            for role in self.env.roles:\n                if isinstance(role, SimpleCoder):\n                    response = await role.act(initial_msg if round_num == 0 else None)\n                    if response:\n                        self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleTester):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleReviewer):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n            for role in self.env.roles:\n                if isinstance(role, SimpleVerifier):\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])\n                        if response:\n                            self.env.publish_message(response)\n                            if \"VERIFICATION_RESULT: PASS\" in response.content:\n                                verified = True\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            if verified:\n                self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", \"Verification passed, stopping early\")\n                break\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num + 1} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 4, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context),\n        SimpleVerifier(context=context)\n    ])\n    \n    team.invest(investment=15.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n# python\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nimport asyncio\nimport random\nfrom typing import Callable\n\nRETRY_ATTEMPTS = 3\nRETRY_BACKOFF_BASE = 0.5  # seconds\n\nclass Action(ABC):\n    \"\"\"Base action class with clear retry and error handling for LLM/API calls.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n\n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n\n    async def _llm_call_with_retries(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call LLM with retries and exponential backoff. Returns response or raises.\"\"\"\n        if not self.llm:\n            return \"LLM_NOT_AVAILABLE\"\n        last_err = None\n        for attempt in range(1, RETRY_ATTEMPTS + 1):\n            try:\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_CALL\", self.name, f\"Attempt {attempt} for LLM call\")\n                resp = await self.llm.ask(messages)\n                # Basic failure detection: LLMInterface returns string starting with \"Error\"\n                if isinstance(resp, str) and resp.startswith(\"Error\"):\n                    last_err = resp\n                    raise RuntimeError(resp)\n                return resp\n            except Exception as e:\n                last_err = str(e)\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"LLM_ERROR\", self.name, f\"Attempt {attempt} failed: {last_err}\")\n                # backoff with jitter\n                await asyncio.sleep(RETRY_BACKOFF_BASE * (2 ** (attempt - 1)) + random.random() * 0.1)\n        # All retries failed\n        raise RuntimeError(f\"LLM call failed after {RETRY_ATTEMPTS} attempts: {last_err}\")\n\n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements. Responsible for producing a compilable code artifact.\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea with retries and validation.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:120]}\")\n\n        prompt = (\n            \"You are a professional Python programmer. Produce a single Python module \"\n            \"that implements the described functionality. Keep functions reasonably small and documented. \"\n            \"Ensure code can be parsed by ast.parse. Do not include usage examples.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Clean, functional Python code\\n\"\n            \"2. Proper error handling\\n\"\n            \"3. Comments and docstrings\\n\"\n            \"4. Production-ready\\n\\n\"\n            \"Provide only the Python code (no backticks or explanation).\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        # Call LLM with retries\n        try:\n            code = await self._llm_call_with_retries(messages)\n        except Exception as e:\n            # Fallback minimal implementation when LLM unavailable\n            fallback = f\"# Fallback implementation for: {idea}\\n\\n\" \\\n                       \"def placeholder():\\n\" \\\n                       \"    \\\"\\\"\\\"Fallback placeholder function.\\\"\\\"\\\"\\n\" \\\n                       \"    return None\\n\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback due to error: {str(e)}\")\n            code = fallback\n\n        # Quick static validation: must parse\n        try:\n            import ast\n            ast.parse(code)\n            valid = True\n        except Exception as e:\n            valid = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} chars; parsed_ok={valid}\")\n\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for a code module. Responsible for producing pytest tests matching the code's API.\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests with validation that they parse and reference functions found in code.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing tests for code ({len(code)} chars)\")\n\n        # Extract possible function names for targeted testing (best-effort)\n        func_names = []\n        try:\n            import ast\n            mod = ast.parse(code or \"\")\n            for node in ast.walk(mod):\n                if isinstance(node, ast.FunctionDef):\n                    func_names.append(node.name)\n        except Exception:\n            func_names = []\n\n        prompt_parts = [\n            \"You are a QA engineer. Write pytest-style tests for the provided Python module.\",\n            \"Requirements:\",\n            \"1. Use pytest\",\n            \"2. Cover edge cases and error conditions if possible\",\n            \"3. Include docstrings for each test\",\n            \"4. If functions are present, write at least one positive and one negative test per function\"\n        ]\n        if func_names:\n            prompt_parts.append(\"Target functions: \" + \", \".join(func_names[:8]))\n        prompt_parts.append(\"\\nCode:\\n\" + (code[:2000] if code else \"(empty)\"))\n\n        prompt = \"\\n\".join(prompt_parts)\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer who writes pytest tests.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        try:\n            tests = await self._llm_call_with_retries(messages)\n        except Exception as e:\n            # Minimal fallback tests to ensure something exists\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder_exists():\\n\"\n                \"    \\\"\\\"\\\"Fallback test that always passes.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback tests due to error: {str(e)}\")\n\n        # Validate tests parse\n        try:\n            import ast\n            ast.parse(tests)\n            tests_ok = bool(tests and tests.strip())\n        except Exception as e:\n            tests_ok = False\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_VALIDATION_FAIL\", self.name, f\"Tests AST parse failed: {str(e)[:200]}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} chars; parsed_ok={tests_ok}\")\n\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests. Responsible for producing actionable, concise feedback.\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Provide a short review. If human, simulate; otherwise call LLM with retries.\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing (human={self.is_human})\")\n\n        if self.is_human:\n            review = \"Human review: Basic sanity check passed. Suggest explicit edge-case tests and clearer error messages.\"\n        else:\n            prompt = (\n                \"You are a senior software engineer. Provide a concise, actionable review of the code and tests.\\n\\n\"\n                \"Focus on:\\n\"\n                \"1. Code quality and maintainability\\n\"\n                \"2. Completeness of tests\\n\"\n                \"3. Likely bugs or missing checks\\n\"\n                \"4. Priority suggestions\\n\\n\"\n                f\"Code:\\n{code[:1500]}\\n\\nTests:\\n{tests[:1500]}\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior code reviewer.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            try:\n                review = await self._llm_call_with_retries(messages)\n            except Exception as e:\n                review = \"Automated review fallback: Unable to contact reviewer LLM. Please perform a manual review.\"\n                if self.context and self.context.tracer:\n                    self.context.tracer.log(\"ACTION_FALLBACK\", self.name, f\"Using fallback review due to error: {str(e)}\")\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review length={len(review)}\")\n\n        return review\n\nclass SimpleVerify(Action):\n    \"\"\"Action to reliably verify that code and tests are syntactically and semantically reasonable.\n    Responsibilities:\n    - Parse code and tests\n    - Ensure at least one function exists in code\n    - Ensure tests reference code entities where possible\n    - Report PASS/FAIL with diagnostics\"\"\"\n    name: str = \"SimpleVerify\"\n\n    async def run(self, code: str, tests: str) -> str:\n        import ast\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Verifying code and tests\")\n\n        diagnostics = []\n        code_ok = False\n        tests_ok = False\n\n        # Verify code parseability and presence of function/class definitions\n        try:\n            code_ast = ast.parse(code)\n            defs = [n for n in code_ast.body if isinstance(n, (ast.FunctionDef, ast.ClassDef))]\n            if defs:\n                code_ok = True\n                diagnostics.append(f\"code_defs: {len(defs)}\")\n            else:\n                diagnostics.append(\"code_defs: none\")\n        except Exception as e:\n            diagnostics.append(f\"code_parse_error: {str(e)[:180]}\")\n\n        # Verify tests parseability and that they reference some names found in code\n        try:\n            tests_ast = ast.parse(tests or \"\")\n            tests_ok = bool(tests and tests.strip())\n            if tests_ok and code_ok:\n                # gather names from tests to see if they reference code defs\n                test_names = {n.id for n in ast.walk(tests_ast) if isinstance(n, ast.Name)}\n                code_names = {n.name for n in ast.walk(code_ast) if isinstance(n, ast.FunctionDef)}\n                referenced = code_names & test_names\n                diagnostics.append(f\"tests_references: {len(referenced)}\")\n                if not referenced:\n                    diagnostics.append(\"tests_references: none of the functions referenced\")\n            else:\n                diagnostics.append(\"tests_parse: empty_or_invalid\")\n        except Exception as e:\n            diagnostics.append(f\"tests_parse_error: {str(e)[:180]}\")\n\n        verified = code_ok and tests_ok\n        result = f\"VERIFICATION_RESULT: {'PASS' if verified else 'FAIL'} | \" + \"; \".join(diagnostics)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, result)\n\n        return result\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with explicit responsibility and inbox semantics.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[str] = []  # names of actions this role listens for\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        # env is provided by Team.hire\n        self.env = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n\n    def _watch(self, action_types: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for; store their .name strings for robust matching.\"\"\"\n        self.watch_list = [t.name for t in action_types]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the role's primary action on the provided message (or default).\"\"\"\n        if not self.actions:\n            return None\n\n        action = self.actions[0]  # each role has a single primary action for simplicity\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name} on message_id={(message.id if message else 'None')}\")\n\n        # Dispatch based on action type\n        try:\n            if isinstance(action, SimpleWriteCode):\n                # Use instruct_content when present\n                prompt = message.instruct_content if (message and getattr(message, \"instruct_content\", None)) else (message.content if message else \"\")\n                result = await action.run(prompt or \"\")\n            elif isinstance(action, SimpleWriteTest):\n                # Expect code to be in message.content\n                code_text = message.content if message else \"\"\n                result = await action.run(code_text)\n            elif isinstance(action, SimpleWriteReview):\n                # Need both code and tests: find latest unprocessed code/tests pair\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            elif isinstance(action, SimpleVerify):\n                code_msg, tests_msg = self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                code_text = code_msg.content if code_msg else \"\"\n                tests_text = tests_msg.content if tests_msg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                result = \"Action completed\"\n        except Exception as e:\n            # Robust error handling: convert exception into a response message and log\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, f\"Exception during act: {str(e)[:200]}\")\n            result = f\"ERROR: {str(e)}\"\n\n        # Create response message with explicit metadata\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n\n        # Mark that this role processed the trigger message (if any)\n        if message and self.env:\n            self.env.mark_processed(message, self)\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created; response_len={len(result)}\")\n\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code (responsible for producing code artifacts).\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests (responsible for producing tests for latest code).\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests (responsible for quality feedback).\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass SimpleVerifier(Role):\n    \"\"\"Role that verifies code and tests (responsible for final PASS/FAIL decision).\"\"\"\n    name: str = \"Dana\"\n    profile: str = \"SimpleVerifier\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleVerify(context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with robust messaging and processing tracking.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Tracking dictionaries to avoid mutating Message objects (compatible with pydantic)\n        self._processed: Dict[str, Set[str]] = {}  # message.id -> set of role.names processed\n        self._attempts: Dict[str, int] = {}       # message.id -> attempts count\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment and initialize tracking\"\"\"\n        self.history.append(message)\n        self._processed.setdefault(message.id, set())\n        self._attempts.setdefault(message.id, 0)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                            f\"Message from {message.sent_from}: {message.content[:140]} | cause_by={message.cause_by}\")\n\n    def mark_processed(self, message: Message, role: Role):\n        \"\"\"Mark that a role processed a message so it won't be processed again by that role.\"\"\"\n        self._processed.setdefault(message.id, set()).add(role.name)\n        if self.tracer:\n            self.tracer.log(\"ENV_PROCESSED\", \"Environment\", f\"Message {message.id} processed by {role.name}\")\n\n    def increment_attempt(self, message: Message):\n        \"\"\"Increment attempt count for a message\"\"\"\n        self._attempts[message.id] = self._attempts.get(message.id, 0) + 1\n        return self._attempts[message.id]\n\n    def get_unprocessed_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that match the role's watch_list and haven't been processed by this role yet.\"\"\"\n        results = []\n        for msg in self.history:\n            if msg.cause_by in role.watch_list:\n                processed = self._processed.get(msg.id, set())\n                if role.name not in processed:\n                    results.append(msg)\n        return results\n\n    def find_latest_pair(self, code_cause: str, tests_cause: str):\n        \"\"\"Find the latest code and test messages in history (best-effort).\"\"\"\n        code_msg = None\n        tests_msg = None\n        for msg in reversed(self.history):\n            if not code_msg and msg.cause_by == code_cause:\n                code_msg = msg\n            if not tests_msg and msg.cause_by == tests_cause:\n                tests_msg = msg\n            if code_msg and tests_msg:\n                break\n        return code_msg, tests_msg\n\nclass Team:\n    \"\"\"Team of agents working together with explicit pipeline orchestration and robust termination logic.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 20.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n        # Pipeline ordering ensures clear responsibilities\n        self.pipeline: List[Type[Role]] = [SimpleCoder, SimpleTester, SimpleReviewer, SimpleVerifier]\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire environment references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 4):\n        \"\"\"Run the team collaboration for up to n_rounds with robust coordination and termination.\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running up to {n_round} rounds\")\n\n        # Initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        verified = False\n        last_verified_round = -1\n\n        for round_num in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num}/{n_round}\")\n\n            # Pipeline orchestration: each stage processes relevant unprocessed messages\n            for role_type in self.pipeline:\n                # Find all roles of this type in env\n                for role in [r for r in self.env.roles if isinstance(r, role_type)]:\n                    # If role listens to user input explicitly (e.g., coder on initial), allow processing of initial message\n                    inbox = []\n                    # Coder should respond to UserInput once per round 1 (or when explicit instruct_content)\n                    if isinstance(role, SimpleCoder):\n                        # Coder acts once with the initial instruction in the first round, otherwise only if triggered\n                        if round_num == 1:\n                            inbox = [initial_msg]\n                        else:\n                            inbox = self.env.get_unprocessed_messages_for_role(role)\n                    else:\n                        inbox = self.env.get_unprocessed_messages_for_role(role)\n\n                    # Process each message one-at-a-time to keep deterministic behavior\n                    for msg in inbox:\n                        # Prevent spamming: limit attempts per message\n                        attempts = self.env.increment_attempt(msg)\n                        if attempts > 5:\n                            # Too many attempts; log and skip further attempts for this message\n                            if self.tracer:\n                                self.tracer.log(\"ENV_SKIP\", \"Environment\", f\"Skipping message {msg.id} for {role.name} after {attempts} attempts\")\n                            self.env.mark_processed(msg, role)\n                            continue\n\n                        response = await role.act(msg if msg else None)\n                        if response:\n                            # Response should indicate which action caused it (already set in act)\n                            self.env.publish_message(response)\n\n                            # If the response is verification with PASS, set verified flag only after confirming\n                            if isinstance(role, SimpleVerifier):\n                                if \"VERIFICATION_RESULT: PASS\" in (response.content or \"\"):\n                                    # Confirm pass by running an explicit verification again to avoid transient success\n                                    # (run local verifier action directly for confirmation)\n                                    verifier_action = role.actions[0]\n                                    confirm = await verifier_action.run(\n                                        *self.env.find_latest_pair(SimpleWriteCode.name, SimpleWriteTest.name)\n                                    ) if hasattr(verifier_action, \"run\") else None\n                                    if isinstance(confirm, str) and \"VERIFICATION_RESULT: PASS\" in confirm:\n                                        verified = True\n                                        last_verified_round = round_num\n                                        self.tracer.log(\"VERIFIED_CONFIRMED\", \"Team\", f\"Verification confirmed in round {round_num}\")\n                                    else:\n                                        # Not confirmed, leave verified False and continue\n                                        self.tracer.log(\"VERIFIED_REJECTED\", \"Team\", \"Verification attempted but not confirmed; continuing\")\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num} completed\")\n\n            # Early stop: require at least one confirmed verification and some stability (no new messages since verification)\n            if verified:\n                # Wait one additional round to ensure stability before finalizing\n                if round_num >= last_verified_round + 1:\n                    self.tracer.log(\"TEAM_EARLY_STOP\", \"Team\", f\"Stable verification observed; stopping after round {round_num}\")\n                    break\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {round_num} rounds with {len(self.env.history)} messages exchanged. Verified={verified}\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n```"]}}}