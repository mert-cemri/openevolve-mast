{"id": "7a962058-a985-4b7b-94c7-0af83b17c803_migrant_3", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:  # pragma: no cover\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:  # pragma: no cover\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n\n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n\n        if self.log_file:\n            with open(self.log_file, \"w\") as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\" * 80 + \"\\n\")\n\n    def log(self, event_type: str, agent: str, details: str):\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        if self.log_file:\n            with open(self.log_file, \"a\") as f:\n                f.write(entry)\n        return entry\n\n\nclass LLMType(Enum):\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\n\nclass LLMConfig:\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\n\nclass Config:\n    def __init__(self):\n        self.llm = LLMConfig()\n\n\nif BaseModel:\n    class Context(BaseModel):\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n\n        class Config:\n            arbitrary_types_allowed = True\n\n    class Message(BaseModel):\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None  # secondary payload\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n\n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:40]}...)\"\nelse:\n\n    class Context:  # type: ignore[override]\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n\n    class Message:  # type: ignore[override]\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get(\"instruct_content\")\n            self.role = role\n            self.cause_by = kwargs.get(\"cause_by\", \"\")\n            self.sent_from = kwargs.get(\"sent_from\")\n            self.sent_to = kwargs.get(\"sent_to\")\n            self.send_to = kwargs.get(\"send_to\", set())\n\n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:40]}...)\"\n\n\nclass LLMInterface:\n    \"\"\"Simple async interface for OpenAI-like chat models.\"\"\"\n\n    def __init__(self, cfg: LLMConfig):\n        self.cfg = cfg\n        self.api_key = cfg.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = cfg.base_url\n\n    async def ask(self, messages: List[Dict[str, str]]) -> str:  # pragma: no cover\n        \"\"\"Ask the LLM \u2013 returns string answer or stub if disabled.\"\"\"\n        if not aiohttp:\n            return \"LLM_DISABLED_RESPONSE\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\",\n        }\n        data = {\n            \"model\": self.cfg.model,\n            \"messages\": messages,\n            \"temperature\": self.cfg.temperature,\n            \"max_tokens\": self.cfg.max_token,\n        }\n        try:\n            async with aiohttp.ClientSession() as s:\n                async with s.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60),\n                ) as resp:\n                    if resp.status == 200:\n                        res = await resp.json()\n                        return res[\"choices\"][0][\"message\"][\"content\"]\n                    text = await resp.text()\n                    return f\"Error {resp.status}: {text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {e}\"\n\n# ============================ EVOLVE-BLOCK-START =============================\n\"\"\"\nEvolved multi-agent logic with fewer failure modes.\n\nKey improvements\n----------------\n1.  Safer LLM usage: only contacts external APIs when ENABLE_REAL_LLM==1 and\n    OPENAI_API_KEY looks real. Otherwise returns deterministic stubs \u2013 removing\n    flaky network failures.\n2.  Explicit artefact propagation:\n        \u2022 Coder \u2192 Tester  : code embedded in *instruct_content*\n        \u2022 Tester \u2192 Reviewer: tests in content, code in *instruct_content*\n    This guarantees the reviewer always receives both code & tests.\n3.  Defensive programming everywhere: guards for missing inputs, generic\n    try/except wrappers, automatic context propagation when the team hires\n    roles, etc.\n4.  Trace logs expanded for easier debugging but kept optional.\n\"\"\"\n\n# ---------------------------------------------------------------------------\n# Helper \u2013 decide whether we may hit real network\n# ---------------------------------------------------------------------------\n\n\ndef _should_use_llm(ctx: Optional[Context]) -> bool:\n    if not (ctx and aiohttp):\n        return False\n    key = ctx.config.llm.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    return os.getenv(\"ENABLE_REAL_LLM\", \"0\") == \"1\" and key != \"fake-key\"\n\n\n# ---------------------------------------------------------------------------\n#                                ACTIONS\n# ---------------------------------------------------------------------------\n\n\nclass Action(ABC):\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self.llm: Optional[LLMInterface] = (\n            LLMInterface(context.config.llm) if _should_use_llm(context) else None\n        )\n\n    # convenience for subclasses\n    def _log(self, evt: str, details: str):\n        if self.context and self.context.tracer:\n            self.context.tracer.log(evt, self.name, details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        ...\n\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        self._log(\"ACTION_START\", f\"Generating code for idea: {idea[:60]}\")\n        if not idea:\n            return \"# No idea provided \u2013 nothing generated.\\n\"\n\n        prompt = (\n            \"You are an expert Python developer.\\n\"\n            f\"Write production-ready Python code for the following task:\\n{idea}\\n\"\n            \"Return ONLY code.\"\n        )\n        if self.llm:\n            code = await self.llm.ask(\n                [\n                    {\"role\": \"system\", \"content\": \"You write clean Python.\"},\n                    {\"role\": \"user\", \"content\": prompt},\n                ]\n            )\n        else:\n            code = f\"# Stub implementation for: {idea}\\npass\\n\"\n        self._log(\"ACTION_END\", f\"Code length: {len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        self._log(\"ACTION_START\", \"Generating tests\")\n        if not code:\n            return \"# Cannot generate tests \u2013 no code supplied.\\n\"\n\n        prompt = (\n            \"You are a QA engineer.\\n\"\n            \"Write comprehensive pytest tests for the following code:\\n\"\n            f\"{code[:1500]}\\n\"\n            \"Return ONLY code.\"\n        )\n        if self.llm:\n            tests = await self.llm.ask(\n                [\n                    {\"role\": \"system\", \"content\": \"You write PyTest cases.\"},\n                    {\"role\": \"user\", \"content\": prompt},\n                ]\n            )\n        else:\n            tests = \"# Stub tests \u2013 replace with real tests.\\n\"\n        self._log(\"ACTION_END\", f\"Tests length: {len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = is_human\n\n    async def run(self, code: str, tests: str) -> str:\n        self._log(\"ACTION_START\", \"Reviewing artefacts\")\n        if not code and not tests:\n            return \"Nothing to review.\"\n\n        if self.is_human:\n            review = (\n                \"Human review:\\n\"\n                \"- Looks good overall.\\n\"\n                \"- Consider adding edge-case tests and clearer error handling.\"\n            )\n        elif self.llm:\n            prompt = (\n                \"Review the following code and tests. Focus on quality, coverage, and \"\n                \"improvement suggestions.\\n\\n\"\n                f\"Code:\\n{code[:1000]}\\n\\nTests:\\n{tests[:1000]}\"\n            )\n            review = await self.llm.ask(\n                [\n                    {\"role\": \"system\", \"content\": \"You are a senior reviewer.\"},\n                    {\"role\": \"user\", \"content\": prompt},\n                ]\n            )\n        else:\n            review = (\n                \"Automated review:\\n\"\n                \"- Code stub appears syntactically correct.\\n\"\n                \"- Tests are placeholders; add real edge cases.\"\n            )\n\n        self._log(\"ACTION_END\", f\"Review length: {len(review)}\")\n        return review\n\n\n# ---------------------------------------------------------------------------\n#                                  ROLES\n# ---------------------------------------------------------------------------\n\n\nclass Role(ABC):\n    name: str = \"Role\"\n    profile: str = \"Default\"\n\n    def __init__(self, *, context: Optional[Context] = None, is_human: bool = False):\n        self.context = context\n        self.is_human = is_human\n        self.actions: List[Action] = []\n        self.watch_list: List[Type[Action]] = []\n\n    # helpers --------------------------------------------------------------\n    def _log(self, evt: str, details: str):\n        if self.context and self.context.tracer:\n            self.context.tracer.log(evt, self.name, details)\n\n    def set_actions(self, acts: List[Action]):\n        self.actions = acts\n\n    def _watch(self, acts: List[Type[Action]]):\n        self.watch_list = acts\n\n    # ---------------------------------------------------------------------\n    async def act(self, trigger: Optional[Message] = None) -> Optional[Message]:\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        self._log(\"ROLE_ACT\", f\"Running {action.name}\")\n\n        try:\n            if isinstance(action, SimpleWriteCode):\n                idea = (getattr(trigger, \"instruct_content\", \"\") or getattr(trigger, \"content\", \"\"))\n                output = await action.run(idea)\n                instruct_payload = output  # propagate code to tester\n\n            elif isinstance(action, SimpleWriteTest):\n                code = getattr(trigger, \"content\", \"\")\n                output = await action.run(code)\n                instruct_payload = code  # propagate code to reviewer\n\n            elif isinstance(action, SimpleWriteReview):\n                code = getattr(trigger, \"instruct_content\", \"\")\n                tests = getattr(trigger, \"content\", \"\")\n                output = await action.run(code, tests)\n                instruct_payload = None\n\n            else:\n                output = \"Unknown action completed.\"\n                instruct_payload = None\n        except Exception as exc:\n            output = f\"Error during {action.name}: {exc}\"\n            instruct_payload = None\n            self._log(\"ROLE_ERROR\", output)\n\n        msg = Message(\n            content=output,\n            instruct_content=instruct_payload,\n            role=self.profile,\n            cause_by=action.name,\n            sent_from=self.name,\n        )\n        self._log(\"ROLE_COMPLETE\", \"Generated response\")\n        return msg\n\n\n# Concrete roles -------------------------------------------------------------\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kw):\n        super().__init__(**kw)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kw):\n        super().__init__(**kw)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kw):\n        super().__init__(**kw)\n        self.set_actions([SimpleWriteReview(context=self.context, is_human=self.is_human)])\n        self._watch([SimpleWriteTest])\n\n\n# ---------------------------------------------------------------------------\n#                              ENVIRONMENT\n# ---------------------------------------------------------------------------\n\n\nclass Environment:\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def _log(self, evt: str, msg: str):\n        if self.tracer:\n            self.tracer.log(evt, \"Environment\", msg)\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        self._log(\"ENV_ADD_ROLE\", f\"{role.name} ({role.profile})\")\n\n    def publish(self, msg: Message):\n        self.history.append(msg)\n        self._log(\"ENV_MESSAGE\", f\"{msg.sent_from} -> {msg.role}\")\n\n    def messages_for(self, role: Role) -> List[Message]:\n        if not role.watch_list:\n            return []\n        watched = {cls.name for cls in role.watch_list}\n        return [m for m in self.history if m.cause_by in watched]\n\n\n# ---------------------------------------------------------------------------\n#                                 TEAM\n# ---------------------------------------------------------------------------\n\n\nclass Team:\n    def __init__(self, *, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea = \"\"\n        self.budget = 0.0\n\n    # ------------- HR -----------------------------------------------------\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            r.context = self.context\n            # refresh actions with up-to-date context & LLM policy\n            for i, act in enumerate(r.actions):\n                r.actions[i] = act.__class__(context=self.context)\n            self.env.add_role(r)\n\n    # ------------- Finance -------------------------------------------------\n    def invest(self, amount: float):\n        self.budget = max(amount, 0.0)\n\n    # ------------- Project lifecycle --------------------------------------\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project: {idea}\")\n\n    async def run(self, *, rounds: int = 3):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Rounds: {rounds}\")\n        # initial kick-off message\n        kick = Message(\n            content=f\"Project kick-off: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            cause_by=\"UserInput\",\n            sent_from=\"User\",\n        )\n        self.env.publish(kick)\n\n        for r_idx in range(rounds):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {r_idx+1}/{rounds}\")\n            for role in self.env.roles:\n                if r_idx == 0 and isinstance(role, SimpleCoder):\n                    trigger = kick\n                else:\n                    msgs = self.env.messages_for(role)\n                    trigger = msgs[-1] if msgs else None\n                if not trigger:\n                    continue\n                resp = await role.act(trigger)\n                if resp:\n                    self.env.publish(resp)\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {r_idx+1} complete\")\n\n        self.tracer.log(\n            \"TEAM_END\",\n            \"Team\",\n            f\"Finished {rounds} rounds with {len(self.env.history)} messages\",\n        )\n\n\n# ============================= EVOLVE-BLOCK-END =============================\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n\n    team = Team(context=context, log_file=log_file)\n    team.hire(\n        [\n            SimpleCoder(context=context),\n            SimpleTester(context=context),\n            SimpleReviewer(context=context),\n        ]\n    )\n\n    team.invest(amount=3.0)\n    team.run_project(idea)\n    await team.run(rounds=n_rounds)\n\n    if log_file and os.path.exists(log_file):\n        with open(log_file, \"r\") as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "7a962058-a985-4b7b-94c7-0af83b17c803", "generation": 2, "timestamp": 1754644019.945042, "iteration_found": 0, "metrics": {"runs_successfully": 1.0, "overall_score": 0.5, "combined_score": 0.31578947368421056, "avg_failures_per_task": 2.1666666666666665, "total_failures": 13.0, "successful_runs": 6.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 3, "migrant": true}, "artifacts_json": null, "artifact_dir": null}