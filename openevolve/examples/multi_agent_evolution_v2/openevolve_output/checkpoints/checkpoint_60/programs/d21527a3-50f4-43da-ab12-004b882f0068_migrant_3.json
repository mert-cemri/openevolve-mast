{"id": "d21527a3-50f4-43da-ab12-004b882f0068_migrant_3", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n\n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n\n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\" * 80 + \"\\n\")\n\n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n\n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n\n        return log_entry\n\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n\n    def __init__(self):\n        self.llm = LLMConfig()\n\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n\n        # A simple shared dict that agents can use to exchange artefacts safely\n        shared: Dict[str, Any] = Field(default_factory=dict)\n\n        class Config:\n            arbitrary_types_allowed = True\n\n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n\n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\n\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n            self.shared: Dict[str, Any] = {}\n\n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get(\"instruct_content\")\n            self.role = role\n            self.cause_by = kwargs.get(\"cause_by\", \"\")\n            self.sent_from = kwargs.get(\"sent_from\")\n            self.sent_to = kwargs.get(\"sent_to\")\n            self.send_to = kwargs.get(\"send_to\", set())\n\n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\n\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n\n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback when aiohttp (or Internet) is unavailable\n            return \"LLM_PLACEHOLDER_RESPONSE\"\n\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature,\n            \"max_tokens\": self.config.max_token,\n        }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60),\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    error_text = await response.text()\n                    return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n# The main goals are:\n#   1) Reduce runtime failures (guard-rails & sensible defaults)\n#   2) Keep message exchange coherent by sharing artefacts explicitly\n#   3) Minimise code-duplication for easier maintainability\n\n\n# ---------- Action Layer ----------\nclass Action(ABC):\n    \"\"\"Abstract base class for any action an agent can perform.\"\"\"\n\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None, **kwargs):\n        self.context = context\n        # lazily instantiate LLM interface only if required\n        self._llm: Optional[LLMInterface] = None\n\n    # Property avoids constructing the interface during unittests where\n    # network is disabled.\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context:\n            self._llm = LLMInterface(self.context.config.llm)\n        return self._llm\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:  # pragma: no cover\n        ...\n\n    # Utility for safe tracer logging\n    def _log(self, event: str, details: str):\n        if self.context and self.context.tracer:\n            self.context.tracer.log(event, self.name, details)\n\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code for a given idea.\"\"\"\n\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str) -> str:\n        idea = idea or \"Generic Python utility\"\n        self._log(\"ACTION_START\", f\"Code generation for '{idea[:60]}'\")\n\n        prompt = (\n            \"You are a senior Python engineer.\\n\"\n            f\"Write production-ready, well-documented Python code to fulfil the following task:\\n{idea}\\n\"\n            \"Return ONLY valid Python code.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You write clean, idiomatic Python.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n\n        code = (\n            await self.llm.ask(messages)\n            if self.llm\n            else f\"# Stub implementation for: {idea}\\n\"\n        )\n\n        # Persist artefact for other agents\n        if self.context:\n            self.context.shared[\"code\"] = code\n\n        self._log(\"ACTION_END\", f\"Generated code length: {len(code)}\")\n        return code\n\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest tests for provided implementation.\"\"\"\n\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str) -> str:\n        # If no code provided explicitly, fetch from shared store.\n        if not code and self.context:\n            code = self.context.shared.get(\"code\", \"\")\n\n        self._log(\"ACTION_START\", \"Generating tests\")\n        prompt = (\n            \"You are a QA engineer specialised in pytest.\\n\"\n            \"Write comprehensive pytest tests for the following code:\\n\"\n            f\"{code[:1500]}\\n\"\n            \"The tests must include edge cases and negative paths. \"\n            \"Return ONLY valid Python test code.\"\n        )\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n\n        tests = (\n            await self.llm.ask(messages)\n            if self.llm\n            else \"# Stub tests \u2013 real tests would be generated here\\n\"\n        )\n\n        if self.context:\n            self.context.shared[\"tests\"] = tests\n\n        self._log(\"ACTION_END\", f\"Generated tests length: {len(tests)}\")\n        return tests\n\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code & tests artefacts.\"\"\"\n\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        # Pull latest artefacts if missing\n        if self.context:\n            code = code or self.context.shared.get(\"code\", \"\")\n            tests = tests or self.context.shared.get(\"tests\", \"\")\n\n        self._log(\"ACTION_START\", \"Starting review\")\n\n        if self.is_human:\n            review = (\n                \"Human review: Looks solid overall. \"\n                \"Consider stricter error handling and additional logging.\"\n            )\n        else:\n            prompt = (\n                \"You are a senior reviewer. Provide an actionable short review of the following artefacts.\\n\"\n                f\"Code:\\n{code[:1000]}\\n\\nTests:\\n{tests[:1000]}\\n\"\n                \"Focus on: code quality, correctness, test coverage, improvements.\\n\"\n                \"Respond concisely.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are an experienced software reviewer.\"},\n                {\"role\": \"user\", \"content\": prompt},\n            ]\n            review = (\n                await self.llm.ask(messages)\n                if self.llm\n                else \"Stub review \u2013 code quality acceptable, improve test edge cases.\"\n            )\n\n        self.context.shared[\"review\"] = review if self.context else review\n        self._log(\"ACTION_END\", f\"Review length: {len(review)}\")\n        return review\n\n\n# ---------- Role Layer ----------\nclass Role(ABC):\n    \"\"\"Generic role holding a repertoire of actions.\"\"\"\n\n    name: str = \"Role\"\n    profile: str = \"Default\"\n\n    def __init__(\n        self,\n        context: Optional[Context] = None,\n        is_human: bool = False,\n        **kwargs,\n    ):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context = context\n        self.is_human = is_human\n        self.actions: List[Action] = []\n        self.watch_list: List[Type[Action]] = []\n\n    # Helper for tracer\n    def _log(self, event: str, details: str):\n        if self.context and self.context.tracer:\n            self.context.tracer.log(event, self.name, details)\n\n    def set_actions(self, actions: List[Action]):\n        self.actions = actions or []\n\n    def _watch(self, actions: List[Type[Action]]):\n        self.watch_list = actions or []\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform first available action with appropriate inputs.\"\"\"\n        if not self.actions:\n            return None\n\n        action = self.actions[0]\n        self._log(\"ROLE_ACT\", f\"Executing {action.name}\")\n\n        # Execute with guarded exception handling\n        try:\n            if isinstance(action, SimpleWriteCode):\n                idea = (\n                    message.instruct_content\n                    if message and getattr(message, \"instruct_content\", None)\n                    else (message.content if message else \"\")\n                )\n                output = await action.run(idea)\n\n            elif isinstance(action, SimpleWriteTest):\n                code_input = message.content if message else \"\"\n                output = await action.run(code_input)\n\n            elif isinstance(action, SimpleWriteReview):\n                # Provide latest artefacts if message not containing both parts\n                output = await action.run()\n\n            else:\n                output = await action.run()  # type: ignore[arg-type]\n\n        except Exception as exc:  # Capture errors to prevent whole run crashing\n            err_msg = f\"Error in action {action.name}: {exc}\"\n            self._log(\"ROLE_ERROR\", err_msg)\n            output = err_msg\n\n        response = Message(\n            content=output,\n            role=self.profile,\n            cause_by=action.name,\n            sent_from=self.name,\n        )\n\n        self._log(\"ROLE_COMPLETE\", \"Action executed & message created\")\n        return response\n\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(context=self.context, is_human=self.is_human)])\n        self._watch([SimpleWriteTest])\n\n\n# ---------- Environment Layer ----------\nclass Environment:\n    \"\"\"Manages roles and message exchange.\"\"\"\n\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    # Tracer helper\n    def _log(self, event: str, details: str):\n        if self.tracer:\n            self.tracer.log(event, \"Environment\", details)\n\n    def add_role(self, role: Role):\n        self.roles.append(role)\n        self._log(\"ENV_ADD_ROLE\", f\"{role.name} ({role.profile}) added\")\n\n    def publish_message(self, message: Message):\n        self.history.append(message)\n        self._log(\"ENV_MESSAGE\", f\"{message.sent_from} -> {message.role}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return history messages this role cares about.\"\"\"\n        relevant: List[Message] = []\n        if not role.watch_list:\n            return relevant\n        for msg in self.history:\n            if any(msg.cause_by == wat.name for wat in role.watch_list):\n                relevant.append(msg)\n        return relevant\n\n\n# ---------- Team Layer ----------\nclass Team:\n    \"\"\"Coordinates the collaborative workflow of agents.\"\"\"\n\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        # Ensure shared store exists even if fallback Context\n        if not hasattr(self.context, \"shared\"):\n            self.context.shared = {}\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.idea: str = \"\"\n        self.investment: float = 5.0\n\n    def hire(self, roles: List[Role]):\n        for role in roles:\n            role.context = self.context\n            # Re-initialise actions with updated context\n            for idx, act in enumerate(role.actions):\n                role.actions[idx] = act.__class__(context=self.context)  # type: ignore[call-arg]\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = max(0.0, investment)\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Project idea: {idea}\")\n\n    async def run(self, n_round: int = 3):\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Rounds: {n_round}\")\n\n        # Kick-off message\n        initial_msg = Message(\n            content=f\"Project kick-off: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n        )\n        self.env.publish_message(initial_msg)\n\n        for current_round in range(1, n_round + 1):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {current_round}\")\n            for role in self.env.roles:\n                # Decide which message triggers the role\n                trigger_msg: Optional[Message] = None\n                if current_round == 1 and isinstance(role, SimpleCoder):\n                    trigger_msg = initial_msg\n                else:\n                    msgs = self.env.get_messages_for_role(role)\n                    if msgs:\n                        trigger_msg = msgs[-1]\n\n                if not trigger_msg:\n                    continue  # Nothing to do this round\n\n                response = await role.act(trigger_msg)\n                if response:\n                    self.env.publish_message(response)\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {current_round} finished\")\n\n        self.tracer.log(\n            \"TEAM_END\",\n            \"Team\",\n            f\"Completed {n_round} rounds, {len(self.env.history)} messages exchanged\",\n        )\n\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n\n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire(\n        [\n            SimpleCoder(context=context),\n            SimpleTester(context=context),\n            SimpleReviewer(context=context),\n        ]\n    )\n\n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n\n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, \"r\") as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "d21527a3-50f4-43da-ab12-004b882f0068", "generation": 3, "timestamp": 1754643289.9601872, "iteration_found": 0, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 3, "migrant": true}, "artifacts_json": null, "artifact_dir": null}