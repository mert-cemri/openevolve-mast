{"id": "60c38775-4ea0-41ec-bf49-4b5c6d7ef965", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            # Basic identifiers and payload\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            # sent_to can be a single name or iterable of recipients\n            self.sent_to = kwargs.get('sent_to')\n            # send_to is normalized to a set for broadcast-style addressing\n            send_to_raw = kwargs.get('send_to', set())\n            self.send_to = set(send_to_raw) if send_to_raw is not None else set()\n            # Additional metadata to support verification and routing\n            self.timestamp = datetime.now()\n            self.content_type = kwargs.get('content_type', 'text')  # e.g. 'code', 'tests', 'review'\n            self.status = kwargs.get('status', 'ok')  # 'ok', 'error', 'invalid'\n    \n        def is_valid(self) -> bool:\n            \"\"\"Lightweight validation used by environment/roles to decide if a message is actionable.\"\"\"\n            if self.content is None:\n                return False\n            if isinstance(self.content, str) and not self.content.strip():\n                return False\n            # Could add more checks (e.g. content_type-specific checks) later\n            return True\n    \n        def __str__(self):\n            ct = getattr(self, 'content_type', 'text')\n            short = (self.content[:80] + '...') if isinstance(self.content, str) and len(self.content) > 80 else self.content\n            return f\"Message(id={self.id}, role={self.role}, type={ct}, from={self.sent_from}, content={short})\"\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    env: Optional[Any] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.env = kwargs.get('env')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message.\n\n        Enhancements:\n        - Robust try/except around action execution to catch errors and report them.\n        - Basic validation of action output; if invalid, produce a failure message.\n        - Clearer logging for action start, errors, and completion.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        # Execute the first action (simplified policy)\n        action = self.actions[0]\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n\n        try:\n            # Execute action based on concrete type with clear inputs\n            if isinstance(action, SimpleWriteCode):\n                input_text = \"\"\n                if message and hasattr(message, \"instruct_content\") and message.instruct_content:\n                    input_text = message.instruct_content\n                elif message and getattr(message, \"content\", None):\n                    input_text = message.content\n                result = await action.run(input_text)\n\n            elif isinstance(action, SimpleWriteTest):\n                input_text = message.content if message and getattr(message, \"content\", None) else \"\"\n                result = await action.run(input_text)\n\n            elif isinstance(action, SimpleWriteReview):\n                # For review, gather the latest code from environment history and tests from message\n                tests_text = message.content if message and getattr(message, \"content\", None) else \"\"\n                code_text = \"\"\n                if getattr(self, \"env\", None) and getattr(self.env, \"history\", None):\n                    try:\n                        for msg in reversed(self.env.history):\n                            if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name:\n                                code_text = getattr(msg, \"content\", \"\") or \"\"\n                                break\n                    except Exception as e:\n                        # Log history lookup failure but continue\n                        if self.context and self.context.tracer:\n                            self.context.tracer.log(\"ROLE_WARN\", self.name, f\"Failed to lookup history: {e}\")\n                        code_text = code_text\n                result = await action.run(code_text, tests_text)\n\n            else:\n                # Generic action; attempt to call run if available\n                if hasattr(action, \"run\"):\n                    result = await action.run()\n                else:\n                    result = \"Action completed\"\n\n        except Exception as e:\n            # Catch action-level exceptions and return a well-formed error message\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"{action.name} raised exception: {e}\")\n            error_text = f\"ActionError: {action.name} failed with exception: {e}\"\n            response = Message(\n                content=error_text,\n                role=self.profile,\n                cause_by=f\"{action.name}:Exception\",\n                sent_from=self.name\n            )\n            return response\n\n        # Basic validation of result to detect obvious failure modes\n        invalid_result = False\n        if result is None:\n            invalid_result = True\n        elif isinstance(result, str):\n            stripped = result.strip()\n            if stripped == \"\" or stripped.lower().startswith(\"error\") or stripped.lower().startswith(\"actionerror\") or stripped.lower().startswith(\"failure\"):\n                invalid_result = True\n\n        if invalid_result:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_INVALID\", self.name, f\"Invalid or empty result from {action.name}\")\n            response = Message(\n                content=f\"Failure: invalid result from {action.name}\",\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name\n            )\n        else:\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name if action else \"\",\n                sent_from=self.name\n            )\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created, cause_by={response.cause_by}\")\n\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        role.env = self  # provide environment reference for inter-agent context lookup\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment.\n\n        Improvements:\n        - Log explicit routing when message.send_to is used.\n        - Keep behaviour backward-compatible (messages are still appended to history),\n          but include additional tracing to make message flow and routing explicit.\n        \"\"\"\n        # Append message to history to preserve audit trail\n        self.history.append(message)\n\n        # Log recipient routing if specified\n        recipients = None\n        try:\n            # message.send_to may be a set or list of role names/profiles\n            send_to = getattr(message, \"send_to\", None)\n            if send_to:\n                # Normalize to a comma separated string for logs\n                if isinstance(send_to, (set, list, tuple)):\n                    recipients = \", \".join(sorted(map(str, send_to)))\n                else:\n                    recipients = str(send_to)\n        except Exception:\n            recipients = None\n\n        if self.tracer:\n            if recipients:\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                                f\"Message from {message.sent_from} to [{recipients}]: {message.content[:100]}\")\n            else:\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                                f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to.\n\n        Improvements:\n        - Support explicit addressing via message.send_to / message.sent_to (so messages can target specific roles).\n        - Respect watch_list (cause_by) as before.\n        - Avoid returning messages produced by the same role (prevents self-loops).\n        - Deduplicate and prioritize recent messages.\n        \"\"\"\n        relevant_messages = []\n        seen_ids = set()\n        # Iterate in history order (oldest -> newest); we'll reverse at the end to prioritize newest\n        for msg in self.history:\n            # Avoid self-processing loops\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n\n            matched = False\n\n            # Explicit addressing (send_to may be a set of role names/profiles)\n            if getattr(msg, \"send_to\", None):\n                try:\n                    if role.name in msg.send_to or role.profile in msg.send_to:\n                        matched = True\n                except Exception:\n                    # send_to may not be iterable; ignore safely\n                    pass\n\n            # Also check sent_to (single or collection)\n            if not matched and getattr(msg, \"sent_to\", None):\n                sent_to = msg.sent_to\n                try:\n                    if role.name == sent_to or role.profile == sent_to or (isinstance(sent_to, (list, set, tuple)) and (role.name in sent_to or role.profile in sent_to)):\n                        matched = True\n                except Exception:\n                    pass\n\n            # Watch list: match by cause_by (backward-compatibility)\n            if not matched:\n                for watched_action in role.watch_list:\n                    if getattr(msg, \"cause_by\", \"\") == getattr(watched_action, \"name\", \"\"):\n                        matched = True\n                        break\n\n            if matched and getattr(msg, \"id\", None) not in seen_ids:\n                relevant_messages.append(msg)\n                seen_ids.add(getattr(msg, \"id\", None))\n\n        # Return newest-first so roles see the most recent context first\n        return list(reversed(relevant_messages))\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds.\n\n        Improvements:\n        - Deterministic role ordering (Coder -> Tester -> Reviewer) to reduce race conditions.\n        - Retry logic for transient failures with a bounded retry limit.\n        - Validation of role responses and explicit failure messages when retry limit is reached.\n        - More explicit tracing for round start/end and retries.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n\n            # Deterministic ordering to avoid role confusion: coder -> tester -> reviewer\n            ordered_roles = sorted(\n                self.env.roles,\n                key=lambda r: 0 if isinstance(r, SimpleCoder) else (1 if isinstance(r, SimpleTester) else 2)\n            )\n\n            for role in ordered_roles:\n                # Determine input messages this role should respond to\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    candidate_msg = initial_msg\n                else:\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    candidate_msg = relevant_msgs[-1] if relevant_msgs else None\n\n                if not candidate_msg:\n                    # Nothing to do for this role this round\n                    continue\n\n                # Attempt action with retries for transient/LLM-like failures\n                max_retries = 2\n                attempt = 0\n                while attempt <= max_retries:\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"ROLE_ATTEMPT\", role.name, f\"Attempt {attempt + 1} for input caused by {getattr(candidate_msg, 'cause_by', '')}\")\n\n                    response = await role.act(candidate_msg)\n\n                    if response:\n                        self.env.publish_message(response)\n\n                        # Simple post-action validation: ensure response is not an explicit failure/error\n                        content = getattr(response, \"content\", \"\")\n                        if isinstance(content, str):\n                            normalized = content.strip().lower()\n                            if normalized == \"\" or normalized.startswith(\"failure\") or normalized.startswith(\"actionerror\") or \"error\" in normalized:\n                                # Treated as failed attempt; retry if attempts remain\n                                if attempt < max_retries:\n                                    if self.context and self.context.tracer:\n                                        self.context.tracer.log(\"RETRY\", role.name, f\"Invalid response detected; will retry (attempt {attempt + 1})\")\n                                    attempt += 1\n                                    continue\n                                else:\n                                    # Retries exhausted -> publish permanent failure notice and break\n                                    permanent = Message(\n                                        content=f\"PermanentFailure: {role.name} failed after {max_retries} retries\",\n                                        role=role.profile,\n                                        cause_by=\"RetryLimit\",\n                                        sent_from=role.name\n                                    )\n                                    self.env.publish_message(permanent)\n                                    if self.context and self.context.tracer:\n                                        self.context.tracer.log(\"ROLE_FAIL\", role.name, f\"Exceeded retries; published permanent failure\")\n                                    break\n                            else:\n                                # Success: break retry loop and proceed to next role\n                                break\n                        else:\n                            # Non-string result considered success; proceed\n                            break\n                    else:\n                        # No response produced; treat as failure and retry if possible\n                        if attempt < max_retries:\n                            attempt += 1\n                            if self.context and self.context.tracer:\n                                self.context.tracer.log(\"RETRY\", role.name, f\"No response; retrying (attempt {attempt + 1})\")\n                            continue\n                        else:\n                            permanent = Message(\n                                content=f\"PermanentFailure: {role.name} produced no response after {max_retries} retries\",\n                                role=role.profile,\n                                cause_by=\"RetryLimit\",\n                                sent_from=role.name\n                            )\n                            self.env.publish_message(permanent)\n                            if self.context and self.context.tracer:\n                                self.context.tracer.log(\"ROLE_FAIL\", role.name, f\"No response after retries; published permanent failure\")\n                            break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        # After rounds, perform an explicit verification: reviewers synthesize final review\n        try:\n            self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed - running verification pass\")\n            # Find most recent code and test artifacts\n            code_msg = None\n            test_msg = None\n            for msg in reversed(self.env.history):\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteCode\" and code_msg is None:\n                    code_msg = msg\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteTest\" and test_msg is None:\n                    test_msg = msg\n                if code_msg and test_msg:\n                    break\n\n            if code_msg and test_msg:\n                for role in self.env.roles:\n                    if isinstance(role, SimpleReviewer):\n                        try:\n                            review_action = role.actions[0] if role.actions else None\n                            if review_action:\n                                # call the review action directly so we can pass both artifacts\n                                review_text = await review_action.run(code_msg.content, test_msg.content)\n                                review_msg = Message(\n                                    content=review_text,\n                                    role=role.profile,\n                                    sent_from=role.name,\n                                    cause_by=review_action.name,\n                                    content_type=\"review\",\n                                    send_to=set([r.name for r in self.env.roles])  # broadcast review\n                                )\n                                self.env.publish_message(review_msg)\n                        except Exception as e:\n                            if self.tracer:\n                                self.tracer.log(\"REVIEW_ERROR\", role.name, f\"Reviewer failed: {e}\")\n        except Exception as e:\n            if self.tracer:\n                self.tracer.log(\"VERIFICATION_ERROR\", \"Team\", f\"Verification pass failed: {e}\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "e657e526-a518-4231-9faf-b9cabe38aef4", "generation": 3, "timestamp": 1754640404.0076616, "iteration_found": 28, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 10 lines with 32 lines\nChange 2: Replace 10 lines with 50 lines\nChange 3: Replace 5 lines with 41 lines", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 3}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software architect specializing in multi-agent systems. \nYour goal is to evolve the multi-agent collaboration patterns to minimize \nfailure modes and improve task completion rates.\n\nFocus on:\n1. Clear role definitions and responsibilities\n2. Robust inter-agent communication patterns\n3. Better error handling and failure recovery\n4. Improved task coordination and sequencing\n5. More effective verification and validation steps\n\nThe system is evaluated based on failure mode detection by an LLM judge, \nso prioritize solutions that reduce coordination failures, role confusion, \nand task derailment.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.5000\n- overall_score: 0.2500\n- combined_score: 0.1000\n- avg_failures_per_task: 12.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            # Basic identifiers and payload\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            # sent_to can be a single name or iterable of recipients\n            self.sent_to = kwargs.get('sent_to')\n            # send_to is normalized to a set for broadcast-style addressing\n            send_to_raw = kwargs.get('send_to', set())\n            self.send_to = set(send_to_raw) if send_to_raw is not None else set()\n            # Additional metadata to support verification and routing\n            self.timestamp = datetime.now()\n            self.content_type = kwargs.get('content_type', 'text')  # e.g. 'code', 'tests', 'review'\n            self.status = kwargs.get('status', 'ok')  # 'ok', 'error', 'invalid'\n    \n        def is_valid(self) -> bool:\n            \"\"\"Lightweight validation used by environment/roles to decide if a message is actionable.\"\"\"\n            if self.content is None:\n                return False\n            if isinstance(self.content, str) and not self.content.strip():\n                return False\n            # Could add more checks (e.g. content_type-specific checks) later\n            return True\n    \n        def __str__(self):\n            ct = getattr(self, 'content_type', 'text')\n            short = (self.content[:80] + '...') if isinstance(self.content, str) and len(self.content) > 80 else self.content\n            return f\"Message(id={self.id}, role={self.role}, type={ct}, from={self.sent_from}, content={short})\"\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to.\n        Improved routing:\n        - Prefer messages explicitly addressed to the role (sent_to/send_to).\n        - Otherwise, fall back to matching the role's watch_list by cause_by.\n        - Only return messages that pass basic validation.\n        \"\"\"\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            # Skip invalid messages early\n            if hasattr(msg, \"is_valid\") and not msg.is_valid():\n                continue\n    \n            # 1) Explicit addressing: sent_to (single) or send_to (set/list)\n            if getattr(msg, \"sent_to\", None) is not None:\n                # match by exact name/profile\n                if msg.sent_to == role.name or msg.sent_to == role.profile:\n                    relevant_messages.append(msg)\n                    continue\n                # allow sent_to to be an iterable (string handled above)\n                try:\n                    if hasattr(msg.sent_to, '__iter__') and role.name in msg.sent_to:\n                        relevant_messages.append(msg)\n                        continue\n                except Exception:\n                    pass\n    \n            if getattr(msg, \"send_to\", None):\n                try:\n                    if role.name in msg.send_to or role.profile in msg.send_to:\n                        relevant_messages.append(msg)\n                        continue\n                except Exception:\n                    pass\n    \n            # 2) Fallback: check watch_list association by cause_by\n            for watched_action in role.watch_list:\n                # watch_list stores Action types; compare by the class name to action.name\n                watched_name = getattr(watched_action, \"__name__\", getattr(watched_action, \"name\", None))\n                if watched_name and getattr(msg, \"cause_by\", \"\") == watched_name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds with improved coordination, retries,\n        validation and a final verification pass by reviewers.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n    \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            content_type=\"idea\"\n        )\n        self.env.publish_message(initial_msg)\n    \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n    \n            # Each role acts in sequence with basic retry/error handling\n            for role in self.env.roles:\n                response = None\n                # Determine what messages this role should respond to\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        candidate_msg = initial_msg\n                    else:\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        candidate_msg = relevant_msgs[-1]  # Act on most recent relevant message\n    \n                    # Basic retry loop for transient failures\n                    max_attempts = 2\n                    last_exc = None\n                    for attempt in range(max_attempts):\n                        try:\n                            if self.tracer:\n                                self.tracer.log(\"ROLE_ATTEMPT\", role.name,\n                                                f\"Attempt {attempt+1}/{max_attempts} to act on message {getattr(candidate_msg,'id', '')}\")\n                            response = await role.act(candidate_msg)\n                            # Validate response if possible\n                            if response is None:\n                                # Nothing to publish, treat as successful no-op\n                                break\n                            if hasattr(response, \"is_valid\") and not response.is_valid():\n                                # mark invalid and try again if attempts remain\n                                response.status = \"invalid\"\n                                if self.tracer:\n                                    self.tracer.log(\"ROLE_INVALID\", role.name, f\"Invalid response content; attempt {attempt+1}\")\n                                response = None\n                                continue\n                            # Enrich response metadata: who it's from and routing hints\n                            response.sent_from = role.name\n                            # Route to roles that watch this action (if any), otherwise broadcast\n                            try:\n                                action_instance = role.actions[0] if role.actions else None\n                                recipients = set()\n                                if action_instance:\n                                    action_name = getattr(action_instance, \"name\", None)\n                                    for r in self.env.roles:\n                                        for watched in getattr(r, \"watch_list\", []):\n                                            watched_name = getattr(watched, \"__name__\", getattr(watched, \"name\", None))\n                                            if watched_name and watched_name == action_name:\n                                                recipients.add(r.name)\n                                if recipients:\n                                    response.send_to = recipients\n                                else:\n                                    # default broadcast to other agents\n                                    response.send_to = set([r.name for r in self.env.roles if r.name != role.name])\n                            except Exception:\n                                # best-effort: leave send_to as-is\n                                pass\n                            break  # successful response\n                        except Exception as e:\n                            last_exc = e\n                            if self.tracer:\n                                self.tracer.log(\"ROLE_ERROR\", role.name, f\"Error on attempt {attempt+1}: {e}\")\n                    if last_exc and response is None:\n                        # role permanently failed; publish an error message so system can see failure mode\n                        err_msg = Message(\n                            content=f\"Role {role.name} failed to act: {last_exc}\",\n                            role=\"System\",\n                            sent_from=\"Team\",\n                            cause_by=\"RoleFailure\",\n                            content_type=\"error\"\n                        )\n                        if self.tracer:\n                            self.tracer.log(\"ROLE_FAIL\", role.name, f\"Publishing failure message\")\n                        self.env.publish_message(err_msg)\n                        continue\n                except Exception as e:\n                    # Unexpected failure while orchestrating this role\n                    if self.tracer:\n                        self.tracer.log(\"ORCHESTRATION_ERROR\", \"Team\", f\"Error orchestrating {role.name}: {e}\")\n                    continue\n    \n                # Publish successful response\n                if response:\n                    self.env.publish_message(response)\n    \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n    \n        # After rounds, perform an explicit verification: reviewers synthesize final review\n        try:\n            # Find most recent code and test artifacts\n            code_msg = None\n            test_msg = None\n            for msg in reversed(self.env.history):\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteCode\" and code_msg is None:\n                    code_msg = msg\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteTest\" and test_msg is None:\n                    test_msg = msg\n                if code_msg and test_msg:\n                    break\n    \n            if code_msg and test_msg:\n                for role in self.env.roles:\n                    if isinstance(role, SimpleReviewer):\n                        try:\n                            review_action = role.actions[0] if role.actions else None\n                            if review_action:\n                                # call the review action directly so we can pass both artifacts\n                                review_text = await review_action.run(code_msg.content, test_msg.content)\n                                review_msg = Message(\n                                    content=review_text,\n                                    role=role.profile,\n                                    sent_from=role.name,\n                                    cause_by=review_action.name,\n                                    content_type=\"review\",\n                                    send_to=set([r.name for r in self.env.roles])  # broadcast review\n                                )\n                                self.env.publish_message(review_msg)\n                        except Exception as e:\n                            if self.tracer:\n                                self.tracer.log(\"REVIEW_ERROR\", role.name, f\"Reviewer failed: {e}\")\n        except Exception as e:\n            if self.tracer:\n                self.tracer.log(\"VERIFICATION_ERROR\", \"Team\", f\"Verification pass failed: {e}\")\n    \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n    \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n### Program 2 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    env: Optional[Any] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.env = kwargs.get('env')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message.\n\n        Enhancements:\n        - Robust try/except around action execution to catch errors and report them.\n        - Basic validation of action output; if invalid, produce a failure message.\n        - Clearer logging for action start, errors, and completion.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        # Execute the first action (simplified policy)\n        action = self.actions[0]\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n\n        try:\n            # Execute action based on concrete type with clear inputs\n            if isinstance(action, SimpleWriteCode):\n                input_text = \"\"\n                if message and hasattr(message, \"instruct_content\") and message.instruct_content:\n                    input_text = message.instruct_content\n                elif message and getattr(message, \"content\", None):\n                    input_text = message.content\n                result = await action.run(input_text)\n\n            elif isinstance(action, SimpleWriteTest):\n                input_text = message.content if message and getattr(message, \"content\", None) else \"\"\n                result = await action.run(input_text)\n\n            elif isinstance(action, SimpleWriteReview):\n                # For review, gather the latest code from environment history and tests from message\n                tests_text = message.content if message and getattr(message, \"content\", None) else \"\"\n                code_text = \"\"\n                if getattr(self, \"env\", None) and getattr(self.env, \"history\", None):\n                    try:\n                        for msg in reversed(self.env.history):\n                            if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name:\n                                code_text = getattr(msg, \"content\", \"\") or \"\"\n                                break\n                    except Exception as e:\n                        # Log history lookup failure but continue\n                        if self.context and self.context.tracer:\n                            self.context.tracer.log(\"ROLE_WARN\", self.name, f\"Failed to lookup history: {e}\")\n                        code_text = code_text\n                result = await action.run(code_text, tests_text)\n\n            else:\n                # Generic action; attempt to call run if available\n                if hasattr(action, \"run\"):\n                    result = await action.run()\n                else:\n                    result = \"Action completed\"\n\n        except Exception as e:\n            # Catch action-level exceptions and return a well-formed error message\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"{action.name} raised exception: {e}\")\n            error_text = f\"ActionError: {action.name} failed with exception: {e}\"\n            response = Message(\n                content=error_text,\n                role=self.profile,\n                cause_by=f\"{action.name}:Exception\",\n                sent_from=self.name\n            )\n            return response\n\n        # Basic validation of result to detect obvious failure modes\n        invalid_result = False\n        if result is None:\n            invalid_result = True\n        elif isinstance(result, str):\n            stripped = result.strip()\n            if stripped == \"\" or stripped.lower().startswith(\"error\") or stripped.lower().startswith(\"actionerror\") or stripped.lower().startswith(\"failure\"):\n                invalid_result = True\n\n        if invalid_result:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_INVALID\", self.name, f\"Invalid or empty result from {action.name}\")\n            response = Message(\n                content=f\"Failure: invalid result from {action.name}\",\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name\n            )\n        else:\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name if action else \"\",\n                sent_from=self.name\n            )\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created, cause_by={response.cause_by}\")\n\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        role.env = self  # provide environment reference for inter-agent context lookup\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment.\n\n        Improvements:\n        - Log explicit routing when message.send_to is used.\n        - Keep behaviour backward-compatible (messages are still appended to history),\n          but include additional tracing to make message flow and routing explicit.\n        \"\"\"\n        # Append message to history to preserve audit trail\n        self.history.append(message)\n\n        # Log recipient routing if specified\n        recipients = None\n        try:\n            # message.send_to may be a set or list of role names/profiles\n            send_to = getattr(message, \"send_to\", None)\n            if send_to:\n                # Normalize to a comma separated string for logs\n                if isinstance(send_to, (set, list, tuple)):\n                    recipients = \", \".join(sorted(map(str, send_to)))\n                else:\n                    recipients = str(send_to)\n        except Exception:\n            recipients = None\n\n        if self.tracer:\n            if recipients:\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                                f\"Message from {message.sent_from} to [{recipients}]: {message.content[:100]}\")\n            else:\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                                f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds.\n\n        Improvements:\n        - Deterministic role ordering (Coder -> Tester -> Reviewer) to reduce race conditions.\n        - Retry logic for transient failures with a bounded retry limit.\n        - Validation of role responses and explicit failure messages when retry limit is reached.\n        - More explicit tracing for round start/end and retries.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n\n            # Deterministic ordering to avoid role confusion: coder -> tester -> reviewer\n            ordered_roles = sorted(\n                self.env.roles,\n                key=lambda r: 0 if isinstance(r, SimpleCoder) else (1 if isinstance(r, SimpleTester) else 2)\n            )\n\n            for role in ordered_roles:\n                # Determine input messages this role should respond to\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    candidate_msg = initial_msg\n                else:\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    candidate_msg = relevant_msgs[-1] if relevant_msgs else None\n\n                if not candidate_msg:\n                    # Nothing to do for this role this round\n                    continue\n\n                # Attempt action with retries for transient/LLM-like failures\n                max_retries = 2\n                attempt = 0\n                while attempt <= max_retries:\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"ROLE_ATTEMPT\", role.name, f\"Attempt {attempt + 1} for input caused by {getattr(candidate_msg, 'cause_by', '')}\")\n\n                    response = await role.act(candidate_msg)\n\n                    if response:\n                        self.env.publish_message(response)\n\n                        # Simple post-action validation: ensure response is not an explicit failure/error\n                        content = getattr(response, \"content\", \"\")\n                        if isinstance(content, str):\n                            normalized = content.strip().lower()\n                            if normalized == \"\" or normalized.startswith(\"failure\") or normalized.startswith(\"actionerror\") or \"error\" in normalized:\n                                # Treated as failed attempt; retry if attempts remain\n                                if attempt < max_retries:\n                                    if self.context and self.context.tracer:\n                                        self.context.tracer.log(\"RETRY\", role.name, f\"Invalid response detected; will retry (attempt {attempt + 1})\")\n                                    attempt += 1\n                                    continue\n                                else:\n                                    # Retries exhausted -> publish permanent failure notice and break\n                                    permanent = Message(\n                                        content=f\"PermanentFailure: {role.name} failed after {max_retries} retries\",\n                                        role=role.profile,\n                                        cause_by=\"RetryLimit\",\n                                        sent_from=role.name\n                                    )\n                                    self.env.publish_message(permanent)\n                                    if self.context and self.context.tracer:\n                                        self.context.tracer.log(\"ROLE_FAIL\", role.name, f\"Exceeded retries; published permanent failure\")\n                                    break\n                            else:\n                                # Success: break retry loop and proceed to next role\n                                break\n                        else:\n                            # Non-string result considered success; proceed\n                            break\n                    else:\n                        # No response produced; treat as failure and retry if possible\n                        if attempt < max_retries:\n                            attempt += 1\n                            if self.context and self.context.tracer:\n                                self.context.tracer.log(\"RETRY\", role.name, f\"No response; retrying (attempt {attempt + 1})\")\n                            continue\n                        else:\n                            permanent = Message(\n                                content=f\"PermanentFailure: {role.name} produced no response after {max_retries} retries\",\n                                role=role.profile,\n                                cause_by=\"RetryLimit\",\n                                sent_from=role.name\n                            )\n                            self.env.publish_message(permanent)\n                            if self.context and self.context.tracer:\n                                self.context.tracer.log(\"ROLE_FAIL\", role.name, f\"No response after retries; published permanent failure\")\n                            break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        try:\n            # Execute action based on type and perform lightweight validation so downstream phases\n            # don't get garbage and to allow Team.run to retry early.\n            if isinstance(action, SimpleWriteCode):\n                if message and getattr(message, \"instruct_content\", None):\n                    result = await action.run(message.instruct_content or message.content)\n                else:\n                    result = await action.run(\"\")\n                # Simple sanity checks for generated code\n                if not result or (len(result.strip()) < 30 and not any(tok in result for tok in (\"def \", \"class \", \"import \", \"return \"))):\n                    raise ValueError(\"Validation failed: generated code appears incomplete or too short\")\n            elif isinstance(action, SimpleWriteTest):\n                if message:\n                    result = await action.run(message.content)\n                else:\n                    result = await action.run(\"\")\n                # Validate that tests contain at least one pytest-style test function\n                if not result or \"def test_\" not in result:\n                    raise ValueError(\"Validation failed: generated tests appear incomplete or missing test functions\")\n            elif isinstance(action, SimpleWriteReview):\n                # For review, the environment (Team.run) should pass a composite message\n                # where message.content contains both code and tests concatenated.\n                if message:\n                    # Expect \"code\\n\\n---TESTS---\\n\\ntests\" style, but fall back gracefully.\n                    content = message.content or \"\"\n                    # Try split marker first\n                    if \"\\n\\n---TESTS---\\n\\n\" in content:\n                        code_part, tests_part = content.split(\"\\n\\n---TESTS---\\n\\n\", 1)\n                    else:\n                        # If no marker, give entire content to both parameters as a fallback\n                        code_part, tests_part = content, \"\"\n                    result = await action.run(code_part, tests_part)\n                else:\n                    result = await action.run(\"\", \"\")\n                # Validate review length to avoid empty/meaningless reviews\n                if not result or len(result.strip()) < 10:\n                    raise ValueError(\"Validation failed: review appears too short\")\n            else:\n                result = \"Action completed\"\n        except Exception as e:\n            # Robust error handling: log, create an error response so environment can react\n            err_text = str(e)\n            err_msg = f\"ERROR during {getattr(action, 'name', 'Action')} by {self.name}: {err_text}\"\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ROLE_ERROR\", self.name, err_msg)\n            # Classify validation errors separately so coordinator can decide to retry vs fail fast\n            cause = \"VALIDATION_FAIL\" if \"Validation failed\" in err_text else \"ERROR\"\n            response = Message(\n                content=err_msg,\n                role=self.profile,\n                cause_by=cause,\n                sent_from=self.name\n            )\n            return response\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to.\n\n        Improvements:\n        - Support explicit addressing via message.send_to / message.sent_to (so messages can target specific roles).\n        - Respect watch_list (cause_by) as before.\n        - Avoid returning messages produced by the same role (prevents self-loops).\n        - Deduplicate and prioritize recent messages.\n        \"\"\"\n        relevant_messages = []\n        seen_ids = set()\n        # Iterate in history order (oldest -> newest); we'll reverse at the end to prioritize newest\n        for msg in self.history:\n            # Avoid self-processing loops\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n\n            matched = False\n\n            # Explicit addressing (send_to may be a set of role names/profiles)\n            if getattr(msg, \"send_to\", None):\n                try:\n                    if role.name in msg.send_to or role.profile in msg.send_to:\n                        matched = True\n                except Exception:\n                    # send_to may not be iterable; ignore safely\n                    pass\n\n            # Also check sent_to (single or collection)\n            if not matched and getattr(msg, \"sent_to\", None):\n                sent_to = msg.sent_to\n                try:\n                    if role.name == sent_to or role.profile == sent_to or (isinstance(sent_to, (list, set, tuple)) and (role.name in sent_to or role.profile in sent_to)):\n                        matched = True\n                except Exception:\n                    pass\n\n            # Watch list: match by cause_by (backward-compatibility)\n            if not matched:\n                for watched_action in role.watch_list:\n                    if getattr(msg, \"cause_by\", \"\") == getattr(watched_action, \"name\", \"\"):\n                        matched = True\n                        break\n\n            if matched and getattr(msg, \"id\", None) not in seen_ids:\n                relevant_messages.append(msg)\n                seen_ids.add(getattr(msg, \"id\", None))\n\n        # Return newest-first so roles see the most recent context first\n        return list(reversed(relevant_messages))\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds with phased coordination and retries\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        # Define strict phased sequence to reduce coordination failures\n        phases = [\n            (\"CoderPhase\", SimpleCoder, SimpleWriteCode),\n            (\"TesterPhase\", SimpleTester, SimpleWriteTest),\n            (\"ReviewerPhase\", SimpleReviewer, SimpleWriteReview)\n        ]\n        \n        # For each round, execute phases in order. This reduces race conditions and role confusion.\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            for phase_name, role_cls, expected_action in phases:\n                self.tracer.log(\"PHASE_START\", phase_name, f\"Starting phase in round {round_num + 1}\")\n                \n                # Find roles of the phase\n                phase_roles = [r for r in self.env.roles if isinstance(r, role_cls)]\n                if not phase_roles:\n                    self.tracer.log(\"PHASE_SKIP\", phase_name, f\"No roles for {phase_name}, skipping\")\n                    continue\n                \n                # Determine input message for this phase\n                input_msg = None\n                if expected_action is SimpleWriteCode:\n                    # Coder consumes the initial user idea on first round otherwise last code request\n                    if round_num == 0:\n                        input_msg = initial_msg\n                    else:\n                        # find latest message produced by code action\n                        msgs = [m for m in self.env.history if m.cause_by == SimpleWriteCode.name]\n                        input_msg = msgs[-1] if msgs else initial_msg\n                elif expected_action is SimpleWriteTest:\n                    # Tester must consume latest code output\n                    msgs = [m for m in self.env.history if m.cause_by == SimpleWriteCode.name]\n                    input_msg = msgs[-1] if msgs else None\n                elif expected_action is SimpleWriteReview:\n                    # Reviewer needs both code and tests; build composite message\n                    code_msgs = [m for m in self.env.history if m.cause_by == SimpleWriteCode.name]\n                    test_msgs = [m for m in self.env.history if m.cause_by == SimpleWriteTest.name]\n                    if code_msgs:\n                        code_part = code_msgs[-1].content\n                    else:\n                        code_part = \"\"\n                    if test_msgs:\n                        tests_part = test_msgs[-1].content\n                    else:\n                        tests_part = \"\"\n                    # Use a clear separator so Role.act can split reliably\n                    composite_content = f\"{code_part}\\n\\n---TESTS---\\n\\n{tests_part}\"\n                    input_msg = Message(\n                        content=composite_content,\n                        role=\"System\",\n                        sent_from=\"TeamCoordinator\",\n                        cause_by=\"CompositeForReview\"\n                    )\n                \n                # If there's no input to work from, log and continue\n                if expected_action is SimpleWriteTest and input_msg is None:\n                    self.tracer.log(\"PHASE_WAIT\", phase_name, \"No code available for testing yet; skipping this phase\")\n                    continue\n                \n                # Each role in the phase attempts action with retry logic\n                for role in phase_roles:\n                    attempt = 0\n                    max_attempts = 2\n                    while attempt < max_attempts:\n                        attempt += 1\n                        try:\n                            if input_msg:\n                                response = await role.act(input_msg)\n                            else:\n                                response = await role.act(None)\n                        except Exception as e:\n                            # Defensive catch in case Role.act raises unexpectedly\n                            self.tracer.log(\"PHASE_ERROR\", phase_name, f\"Unexpected error from {role.name}: {e}\")\n                            response = Message(\n                                content=f\"ERROR: Unexpected failure in {role.name}: {e}\",\n                                role=role.profile,\n                                cause_by=\"ERROR\",\n                                sent_from=role.name\n                            )\n                        \n                        if response:\n                            self.env.publish_message(response)\n                            # If action produced an error or validation failure, log and decide whether to retry\n                            if response.cause_by in (\"ERROR\", \"VALIDATION_FAIL\") or (response.content and (response.content.startswith(\"ERROR\") or response.content.startswith(\"Validation failed\") or response.content.startswith(\"ERROR during\"))):\n                                self.tracer.log(\"PHASE_RETRY\", phase_name, f\"{role.name} produced error/validation failure on attempt {attempt} (cause={response.cause_by})\")\n                                if attempt < max_attempts:\n                                    continue\n                                else:\n                                    self.tracer.log(\"PHASE_FAIL\", phase_name, f\"{role.name} failed after {attempt} attempts\")\n                            # Successful publish or non-error response; break retry loop\n                            break\n                        else:\n                            # No response; retry once\n                            self.tracer.log(\"PHASE_NO_RESP\", phase_name, f\"{role.name} returned no response on attempt {attempt}\")\n                            if attempt >= max_attempts:\n                                self.tracer.log(\"PHASE_FAIL\", phase_name, f\"{role.name} gave no response after {attempt} attempts\")\n                \n                self.tracer.log(\"PHASE_END\", phase_name, f\"Completed phase in round {round_num + 1}\")\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            # Basic identifiers and payload\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            # sent_to can be a single name or iterable of recipients\n            self.sent_to = kwargs.get('sent_to')\n            # send_to is normalized to a set for broadcast-style addressing\n            send_to_raw = kwargs.get('send_to', set())\n            self.send_to = set(send_to_raw) if send_to_raw is not None else set()\n            # Additional metadata to support verification and routing\n            self.timestamp = datetime.now()\n            self.content_type = kwargs.get('content_type', 'text')  # e.g. 'code', 'tests', 'review'\n            self.status = kwargs.get('status', 'ok')  # 'ok', 'error', 'invalid'\n    \n        def is_valid(self) -> bool:\n            \"\"\"Lightweight validation used by environment/roles to decide if a message is actionable.\"\"\"\n            if self.content is None:\n                return False\n            if isinstance(self.content, str) and not self.content.strip():\n                return False\n            # Could add more checks (e.g. content_type-specific checks) later\n            return True\n    \n        def __str__(self):\n            ct = getattr(self, 'content_type', 'text')\n            short = (self.content[:80] + '...') if isinstance(self.content, str) and len(self.content) > 80 else self.content\n            return f\"Message(id={self.id}, role={self.role}, type={ct}, from={self.sent_from}, content={short})\"\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to.\n        Improved routing:\n        - Prefer messages explicitly addressed to the role (sent_to/send_to).\n        - Otherwise, fall back to matching the role's watch_list by cause_by.\n        - Only return messages that pass basic validation.\n        \"\"\"\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            # Skip invalid messages early\n            if hasattr(msg, \"is_valid\") and not msg.is_valid():\n                continue\n    \n            # 1) Explicit addressing: sent_to (single) or send_to (set/list)\n            if getattr(msg, \"sent_to\", None) is not None:\n                # match by exact name/profile\n                if msg.sent_to == role.name or msg.sent_to == role.profile:\n                    relevant_messages.append(msg)\n                    continue\n                # allow sent_to to be an iterable (string handled above)\n                try:\n                    if hasattr(msg.sent_to, '__iter__') and role.name in msg.sent_to:\n                        relevant_messages.append(msg)\n                        continue\n                except Exception:\n                    pass\n    \n            if getattr(msg, \"send_to\", None):\n                try:\n                    if role.name in msg.send_to or role.profile in msg.send_to:\n                        relevant_messages.append(msg)\n                        continue\n                except Exception:\n                    pass\n    \n            # 2) Fallback: check watch_list association by cause_by\n            for watched_action in role.watch_list:\n                # watch_list stores Action types; compare by the class name to action.name\n                watched_name = getattr(watched_action, \"__name__\", getattr(watched_action, \"name\", None))\n                if watched_name and getattr(msg, \"cause_by\", \"\") == watched_name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds with improved coordination, retries,\n        validation and a final verification pass by reviewers.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n    \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\",\n            content_type=\"idea\"\n        )\n        self.env.publish_message(initial_msg)\n    \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n    \n            # Each role acts in sequence with basic retry/error handling\n            for role in self.env.roles:\n                response = None\n                # Determine what messages this role should respond to\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        candidate_msg = initial_msg\n                    else:\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        candidate_msg = relevant_msgs[-1]  # Act on most recent relevant message\n    \n                    # Basic retry loop for transient failures\n                    max_attempts = 2\n                    last_exc = None\n                    for attempt in range(max_attempts):\n                        try:\n                            if self.tracer:\n                                self.tracer.log(\"ROLE_ATTEMPT\", role.name,\n                                                f\"Attempt {attempt+1}/{max_attempts} to act on message {getattr(candidate_msg,'id', '')}\")\n                            response = await role.act(candidate_msg)\n                            # Validate response if possible\n                            if response is None:\n                                # Nothing to publish, treat as successful no-op\n                                break\n                            if hasattr(response, \"is_valid\") and not response.is_valid():\n                                # mark invalid and try again if attempts remain\n                                response.status = \"invalid\"\n                                if self.tracer:\n                                    self.tracer.log(\"ROLE_INVALID\", role.name, f\"Invalid response content; attempt {attempt+1}\")\n                                response = None\n                                continue\n                            # Enrich response metadata: who it's from and routing hints\n                            response.sent_from = role.name\n                            # Route to roles that watch this action (if any), otherwise broadcast\n                            try:\n                                action_instance = role.actions[0] if role.actions else None\n                                recipients = set()\n                                if action_instance:\n                                    action_name = getattr(action_instance, \"name\", None)\n                                    for r in self.env.roles:\n                                        for watched in getattr(r, \"watch_list\", []):\n                                            watched_name = getattr(watched, \"__name__\", getattr(watched, \"name\", None))\n                                            if watched_name and watched_name == action_name:\n                                                recipients.add(r.name)\n                                if recipients:\n                                    response.send_to = recipients\n                                else:\n                                    # default broadcast to other agents\n                                    response.send_to = set([r.name for r in self.env.roles if r.name != role.name])\n                            except Exception:\n                                # best-effort: leave send_to as-is\n                                pass\n                            break  # successful response\n                        except Exception as e:\n                            last_exc = e\n                            if self.tracer:\n                                self.tracer.log(\"ROLE_ERROR\", role.name, f\"Error on attempt {attempt+1}: {e}\")\n                    if last_exc and response is None:\n                        # role permanently failed; publish an error message so system can see failure mode\n                        err_msg = Message(\n                            content=f\"Role {role.name} failed to act: {last_exc}\",\n                            role=\"System\",\n                            sent_from=\"Team\",\n                            cause_by=\"RoleFailure\",\n                            content_type=\"error\"\n                        )\n                        if self.tracer:\n                            self.tracer.log(\"ROLE_FAIL\", role.name, f\"Publishing failure message\")\n                        self.env.publish_message(err_msg)\n                        continue\n                except Exception as e:\n                    # Unexpected failure while orchestrating this role\n                    if self.tracer:\n                        self.tracer.log(\"ORCHESTRATION_ERROR\", \"Team\", f\"Error orchestrating {role.name}: {e}\")\n                    continue\n    \n                # Publish successful response\n                if response:\n                    self.env.publish_message(response)\n    \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n    \n        # After rounds, perform an explicit verification: reviewers synthesize final review\n        try:\n            # Find most recent code and test artifacts\n            code_msg = None\n            test_msg = None\n            for msg in reversed(self.env.history):\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteCode\" and code_msg is None:\n                    code_msg = msg\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteTest\" and test_msg is None:\n                    test_msg = msg\n                if code_msg and test_msg:\n                    break\n    \n            if code_msg and test_msg:\n                for role in self.env.roles:\n                    if isinstance(role, SimpleReviewer):\n                        try:\n                            review_action = role.actions[0] if role.actions else None\n                            if review_action:\n                                # call the review action directly so we can pass both artifacts\n                                review_text = await review_action.run(code_msg.content, test_msg.content)\n                                review_msg = Message(\n                                    content=review_text,\n                                    role=role.profile,\n                                    sent_from=role.name,\n                                    cause_by=review_action.name,\n                                    content_type=\"review\",\n                                    send_to=set([r.name for r in self.env.roles])  # broadcast review\n                                )\n                                self.env.publish_message(review_msg)\n                        except Exception as e:\n                            if self.tracer:\n                                self.tracer.log(\"REVIEW_ERROR\", role.name, f\"Reviewer failed: {e}\")\n        except Exception as e:\n            if self.tracer:\n                self.tracer.log(\"VERIFICATION_ERROR\", \"Team\", f\"Verification pass failed: {e}\")\n    \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n    \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Change 1: Replace 10 lines with 32 lines\nChange 2: Replace 10 lines with 43 lines\nChange 3: Replace 41 lines with 147 lines, Alternative overall_score approach\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    env: Optional[Any] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.env = kwargs.get('env')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message.\n\n        Enhancements:\n        - Robust try/except around action execution to catch errors and report them.\n        - Basic validation of action output; if invalid, produce a failure message.\n        - Clearer logging for action start, errors, and completion.\n        \"\"\"\n        if not self.actions:\n            return None\n\n        # Execute the first action (simplified policy)\n        action = self.actions[0]\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n\n        try:\n            # Execute action based on concrete type with clear inputs\n            if isinstance(action, SimpleWriteCode):\n                input_text = \"\"\n                if message and hasattr(message, \"instruct_content\") and message.instruct_content:\n                    input_text = message.instruct_content\n                elif message and getattr(message, \"content\", None):\n                    input_text = message.content\n                result = await action.run(input_text)\n\n            elif isinstance(action, SimpleWriteTest):\n                input_text = message.content if message and getattr(message, \"content\", None) else \"\"\n                result = await action.run(input_text)\n\n            elif isinstance(action, SimpleWriteReview):\n                # For review, gather the latest code from environment history and tests from message\n                tests_text = message.content if message and getattr(message, \"content\", None) else \"\"\n                code_text = \"\"\n                if getattr(self, \"env\", None) and getattr(self.env, \"history\", None):\n                    try:\n                        for msg in reversed(self.env.history):\n                            if getattr(msg, \"cause_by\", \"\") == SimpleWriteCode.name:\n                                code_text = getattr(msg, \"content\", \"\") or \"\"\n                                break\n                    except Exception as e:\n                        # Log history lookup failure but continue\n                        if self.context and self.context.tracer:\n                            self.context.tracer.log(\"ROLE_WARN\", self.name, f\"Failed to lookup history: {e}\")\n                        code_text = code_text\n                result = await action.run(code_text, tests_text)\n\n            else:\n                # Generic action; attempt to call run if available\n                if hasattr(action, \"run\"):\n                    result = await action.run()\n                else:\n                    result = \"Action completed\"\n\n        except Exception as e:\n            # Catch action-level exceptions and return a well-formed error message\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_ERROR\", self.name, f\"{action.name} raised exception: {e}\")\n            error_text = f\"ActionError: {action.name} failed with exception: {e}\"\n            response = Message(\n                content=error_text,\n                role=self.profile,\n                cause_by=f\"{action.name}:Exception\",\n                sent_from=self.name\n            )\n            return response\n\n        # Basic validation of result to detect obvious failure modes\n        invalid_result = False\n        if result is None:\n            invalid_result = True\n        elif isinstance(result, str):\n            stripped = result.strip()\n            if stripped == \"\" or stripped.lower().startswith(\"error\") or stripped.lower().startswith(\"actionerror\") or stripped.lower().startswith(\"failure\"):\n                invalid_result = True\n\n        if invalid_result:\n            if self.context and self.context.tracer:\n                self.context.tracer.log(\"ACTION_INVALID\", self.name, f\"Invalid or empty result from {action.name}\")\n            response = Message(\n                content=f\"Failure: invalid result from {action.name}\",\n                role=self.profile,\n                cause_by=action.name,\n                sent_from=self.name\n            )\n        else:\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=action.name if action else \"\",\n                sent_from=self.name\n            )\n\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created, cause_by={response.cause_by}\")\n\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        role.env = self  # provide environment reference for inter-agent context lookup\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment.\n\n        Improvements:\n        - Log explicit routing when message.send_to is used.\n        - Keep behaviour backward-compatible (messages are still appended to history),\n          but include additional tracing to make message flow and routing explicit.\n        \"\"\"\n        # Append message to history to preserve audit trail\n        self.history.append(message)\n\n        # Log recipient routing if specified\n        recipients = None\n        try:\n            # message.send_to may be a set or list of role names/profiles\n            send_to = getattr(message, \"send_to\", None)\n            if send_to:\n                # Normalize to a comma separated string for logs\n                if isinstance(send_to, (set, list, tuple)):\n                    recipients = \", \".join(sorted(map(str, send_to)))\n                else:\n                    recipients = str(send_to)\n        except Exception:\n            recipients = None\n\n        if self.tracer:\n            if recipients:\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                                f\"Message from {message.sent_from} to [{recipients}]: {message.content[:100]}\")\n            else:\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\",\n                                f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds.\n\n        Improvements:\n        - Deterministic role ordering (Coder -> Tester -> Reviewer) to reduce race conditions.\n        - Retry logic for transient failures with a bounded retry limit.\n        - Validation of role responses and explicit failure messages when retry limit is reached.\n        - More explicit tracing for round start/end and retries.\n        \"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n\n            # Deterministic ordering to avoid role confusion: coder -> tester -> reviewer\n            ordered_roles = sorted(\n                self.env.roles,\n                key=lambda r: 0 if isinstance(r, SimpleCoder) else (1 if isinstance(r, SimpleTester) else 2)\n            )\n\n            for role in ordered_roles:\n                # Determine input messages this role should respond to\n                if isinstance(role, SimpleCoder) and round_num == 0:\n                    candidate_msg = initial_msg\n                else:\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    candidate_msg = relevant_msgs[-1] if relevant_msgs else None\n\n                if not candidate_msg:\n                    # Nothing to do for this role this round\n                    continue\n\n                # Attempt action with retries for transient/LLM-like failures\n                max_retries = 2\n                attempt = 0\n                while attempt <= max_retries:\n                    if self.context and self.context.tracer:\n                        self.context.tracer.log(\"ROLE_ATTEMPT\", role.name, f\"Attempt {attempt + 1} for input caused by {getattr(candidate_msg, 'cause_by', '')}\")\n\n                    response = await role.act(candidate_msg)\n\n                    if response:\n                        self.env.publish_message(response)\n\n                        # Simple post-action validation: ensure response is not an explicit failure/error\n                        content = getattr(response, \"content\", \"\")\n                        if isinstance(content, str):\n                            normalized = content.strip().lower()\n                            if normalized == \"\" or normalized.startswith(\"failure\") or normalized.startswith(\"actionerror\") or \"error\" in normalized:\n                                # Treated as failed attempt; retry if attempts remain\n                                if attempt < max_retries:\n                                    if self.context and self.context.tracer:\n                                        self.context.tracer.log(\"RETRY\", role.name, f\"Invalid response detected; will retry (attempt {attempt + 1})\")\n                                    attempt += 1\n                                    continue\n                                else:\n                                    # Retries exhausted -> publish permanent failure notice and break\n                                    permanent = Message(\n                                        content=f\"PermanentFailure: {role.name} failed after {max_retries} retries\",\n                                        role=role.profile,\n                                        cause_by=\"RetryLimit\",\n                                        sent_from=role.name\n                                    )\n                                    self.env.publish_message(permanent)\n                                    if self.context and self.context.tracer:\n                                        self.context.tracer.log(\"ROLE_FAIL\", role.name, f\"Exceeded retries; published permanent failure\")\n                                    break\n                            else:\n                                # Success: break retry loop and proceed to next role\n                                break\n                        else:\n                            # Non-string result considered success; proceed\n                            break\n                    else:\n                        # No response produced; treat as failure and retry if possible\n                        if attempt < max_retries:\n                            attempt += 1\n                            if self.context and self.context.tracer:\n                                self.context.tracer.log(\"RETRY\", role.name, f\"No response; retrying (attempt {attempt + 1})\")\n                            continue\n                        else:\n                            permanent = Message(\n                                content=f\"PermanentFailure: {role.name} produced no response after {max_retries} retries\",\n                                role=role.profile,\n                                cause_by=\"RetryLimit\",\n                                sent_from=role.name\n                            )\n                            self.env.publish_message(permanent)\n                            if self.context and self.context.tracer:\n                                self.context.tracer.log(\"ROLE_FAIL\", role.name, f\"No response after retries; published permanent failure\")\n                            break\n\n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["<<<<<<< SEARCH\n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n=======\n    class Message:\n        def __init__(self, content, role, **kwargs):\n            # Basic identifiers and payload\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            # sent_to can be a single name or iterable of recipients\n            self.sent_to = kwargs.get('sent_to')\n            # send_to is normalized to a set for broadcast-style addressing\n            send_to_raw = kwargs.get('send_to', set())\n            self.send_to = set(send_to_raw) if send_to_raw is not None else set()\n            # Additional metadata to support verification and routing\n            self.timestamp = datetime.now()\n            self.content_type = kwargs.get('content_type', 'text')  # e.g. 'code', 'tests', 'review'\n            self.status = kwargs.get('status', 'ok')  # 'ok', 'error', 'invalid'\n    \n        def is_valid(self) -> bool:\n            \"\"\"Lightweight validation used by environment/roles to decide if a message is actionable.\"\"\"\n            if self.content is None:\n                return False\n            if isinstance(self.content, str) and not self.content.strip():\n                return False\n            # Could add more checks (e.g. content_type-specific checks) later\n            return True\n    \n        def __str__(self):\n            ct = getattr(self, 'content_type', 'text')\n            short = (self.content[:80] + '...') if isinstance(self.content, str) and len(self.content) > 80 else self.content\n            return f\"Message(id={self.id}, role={self.role}, type={ct}, from={self.sent_from}, content={short})\"\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n=======\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to.\n\n        Improvements:\n        - Support explicit addressing via message.send_to / message.sent_to (so messages can target specific roles).\n        - Respect watch_list (cause_by) as before.\n        - Avoid returning messages produced by the same role (prevents self-loops).\n        - Deduplicate and prioritize recent messages.\n        \"\"\"\n        relevant_messages = []\n        seen_ids = set()\n        # Iterate in history order (oldest -> newest); we'll reverse at the end to prioritize newest\n        for msg in self.history:\n            # Avoid self-processing loops\n            if getattr(msg, \"sent_from\", None) == role.name:\n                continue\n\n            matched = False\n\n            # Explicit addressing (send_to may be a set of role names/profiles)\n            if getattr(msg, \"send_to\", None):\n                try:\n                    if role.name in msg.send_to or role.profile in msg.send_to:\n                        matched = True\n                except Exception:\n                    # send_to may not be iterable; ignore safely\n                    pass\n\n            # Also check sent_to (single or collection)\n            if not matched and getattr(msg, \"sent_to\", None):\n                sent_to = msg.sent_to\n                try:\n                    if role.name == sent_to or role.profile == sent_to or (isinstance(sent_to, (list, set, tuple)) and (role.name in sent_to or role.profile in sent_to)):\n                        matched = True\n                except Exception:\n                    pass\n\n            # Watch list: match by cause_by (backward-compatibility)\n            if not matched:\n                for watched_action in role.watch_list:\n                    if getattr(msg, \"cause_by\", \"\") == getattr(watched_action, \"name\", \"\"):\n                        matched = True\n                        break\n\n            if matched and getattr(msg, \"id\", None) not in seen_ids:\n                relevant_messages.append(msg)\n                seen_ids.add(getattr(msg, \"id\", None))\n\n        # Return newest-first so roles see the most recent context first\n        return list(reversed(relevant_messages))\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n=======\n        # After rounds, perform an explicit verification: reviewers synthesize final review\n        try:\n            self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed - running verification pass\")\n            # Find most recent code and test artifacts\n            code_msg = None\n            test_msg = None\n            for msg in reversed(self.env.history):\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteCode\" and code_msg is None:\n                    code_msg = msg\n                if getattr(msg, \"cause_by\", \"\") == \"SimpleWriteTest\" and test_msg is None:\n                    test_msg = msg\n                if code_msg and test_msg:\n                    break\n\n            if code_msg and test_msg:\n                for role in self.env.roles:\n                    if isinstance(role, SimpleReviewer):\n                        try:\n                            review_action = role.actions[0] if role.actions else None\n                            if review_action:\n                                # call the review action directly so we can pass both artifacts\n                                review_text = await review_action.run(code_msg.content, test_msg.content)\n                                review_msg = Message(\n                                    content=review_text,\n                                    role=role.profile,\n                                    sent_from=role.name,\n                                    cause_by=review_action.name,\n                                    content_type=\"review\",\n                                    send_to=set([r.name for r in self.env.roles])  # broadcast review\n                                )\n                                self.env.publish_message(review_msg)\n                        except Exception as e:\n                            if self.tracer:\n                                self.tracer.log(\"REVIEW_ERROR\", role.name, f\"Reviewer failed: {e}\")\n        except Exception as e:\n            if self.tracer:\n                self.tracer.log(\"VERIFICATION_ERROR\", \"Team\", f\"Verification pass failed: {e}\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n>>>>>>> REPLACE\n\nExplanation of changes and rationale:\n\n1) Message fallback: normalize and enrich message metadata; add is_valid and __str__\n- What changed: the lightweight fallback Message (used when pydantic is unavailable) now normalizes send_to to a set, records timestamp, content_type and status, and exposes an is_valid() helper and improved __str__.\n- Why: better message metadata makes routing and validation more robust without depending on pydantic. The is_valid() helper prevents agents from acting on empty/blank messages and reduces failure modes caused by malformed messages. Normalizing send_to avoids surprising types (list vs set vs single value), reducing routing errors.\n\n2) Environment.get_messages_for_role: robust routing, deduplication, avoid self-processing, explicit addressing\n- What changed: the routing logic now:\n  - honors explicit targeting via send_to and sent_to,\n  - falls back to watch_list by cause_by,\n  - skips messages emitted by the same role (prevent self-loops),\n  - deduplicates messages and returns newest-first so agents act on the latest context.\n- Why: coordination failures often stem from ambiguous routing and race conditions. Explicit addressing and newest-first prioritization reduce role confusion and stale processing. Avoiding self-processing prevents loops that inflate failures_per_task.\n\n3) Team.run: add explicit verification pass by reviewers at the end\n- What changed: after the rounds complete, the team now attempts a verification step: it locates the most recent code and test artifacts and asks reviewer(s) to synthesize a final review message (broadcast). Errors in verification are logged but don't crash the run.\n- Why: an explicit verification/validation stage catches cross-artifact inconsistencies (code vs tests) and provides a single final artifact for downstream judging. This improves overall task completion reliability and helps the LLM judge detect and penalize fewer coordination failures.\n\nOverall effect on metrics:\n- runs_successfully: reducing malformed messages, avoiding self-loops, and adding final verification increases the chance of completing meaningful runs.\n- overall_score / combined_score: clearer routing and validation reduce noisy artifacts and increase meaningful message exchanges, improving scores.\n- avg_failures_per_task: better validation and deduplication will lower failure counts per run by preventing retries caused by malformed/stale messages.\n\nThese changes are targeted and minimal; they focus on inter-agent communication, validation, coordination, and a final verification step \u2014 aligning with the prioritized goals: clear roles/responsibilities, robust communication, improved error handling and verification."]}}}