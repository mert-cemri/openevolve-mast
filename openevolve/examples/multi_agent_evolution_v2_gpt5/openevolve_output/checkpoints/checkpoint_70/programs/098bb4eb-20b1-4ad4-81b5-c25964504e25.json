{"id": "098bb4eb-20b1-4ad4-81b5-c25964504e25", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Safe logging helper that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str,\n                 role: str,\n                 cause_by: str = \"\",\n                 sent_from: Optional[str] = None,\n                 instruct_content: Optional[str] = None) -> Message:\n    \"\"\"\n    Robust factory to create Message objects compatible with both pydantic and fallback classes.\n    Accepts defaults for optional fields to reduce failure modes.\n    \"\"\"\n    kwargs = {\n        \"content\": content if content is not None else \"\",\n        \"role\": role if role is not None else \"\",\n        \"cause_by\": cause_by if cause_by is not None else \"\",\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        # Preferred construction for pydantic-based Message\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional/fallback Message constructor\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Final minimal fallback: simple object with expected attributes\n            class _M:\n                pass\n            m = _M()\n            m.id = str(uuid.uuid4())\n            m.content = kwargs[\"content\"]\n            m.instruct_content = kwargs.get(\"instruct_content\")\n            m.role = kwargs[\"role\"]\n            m.cause_by = kwargs[\"cause_by\"]\n            m.sent_from = kwargs[\"sent_from\"]\n            m.sent_to = None\n            m.send_to = set()\n            return m\n\nclass Action(ABC):\n    \"\"\"Minimal, robust action base with lazy LLM binding and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily instantiate LLMInterface if configuration exists.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code from a human idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Generating code for idea (len={len(idea_text)})\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Provide only the code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic safe fallback that is valid Python\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until an LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_snippet = (code or \"\")[:2000]\n        self._log(\"ACTION_START\", f\"Generating tests (code_len={len(code_snippet)})\")\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following code:\\n\\n\"\n            f\"Code:\\n{code_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain each test\\n\\n\"\n            \"Provide only the test code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide a concise review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\")[:1500]\n        tests_text = (tests or \"\")[:1500]\n        self._log(\"ACTION_START\", f\"Reviewing (human={self.is_human}) code_len={len(code_text)} tests_len={len(tests_text)}\")\n        try:\n            if self.is_human:\n                review = \"Human review: Looks generally good. Consider additional error handling and edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_text}\\n\\n\"\n                    f\"Tests:\\n{tests_text}\\n\\n\"\n                    \"Give a concise review focusing on code quality, test coverage, potential bugs and suggestions.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable. Add more edge-case coverage and clearer exceptions.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        self._log(\"ACTION_END\", f\"Review length={len(review)}\")\n        return review\n\nclass Role:\n    \"\"\"Lightweight role holding a single primary action and a watch list of cause_by tokens.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains strings matching Message.cause_by\n        self.watch_list: Set[str] = set()\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Bind provided action instances and ensure context alignment.\"\"\"\n        bound: List[Action] = []\n        for a in (actions or []):\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: Set[str] = set()\n        for a in (actions or []):\n            if isinstance(a, str):\n                names.add(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Run the primary action and return a Message result or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        try:\n            # Routing: map messages/environment to action inputs deterministically and simply\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code from the triggering message (if any); else fetch latest code from env\n                code = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code = getattr(message, \"content\", \"\") or \"\"\n                if not code and self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Gather best-effort code and tests from env or message\n                code = \"\"\n                tests = \"\"\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    tests = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                if message:\n                    tests = tests or getattr(message, \"content\", \"\") or \"\"\n                    code = code or getattr(message, \"instruct_content\", \"\") or \"\"\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, f\"Created message id={getattr(response, 'id', None)}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration: holds roles and messages and provides simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        try:\n            role.env = self\n        except Exception:\n            role.env = None\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        \"\"\"Append a message to history and log a short preview. Be resilient to message shape.\"\"\"\n        try:\n            # Ensure id exists where possible\n            if not getattr(message, \"id\", None):\n                try:\n                    message.id = str(uuid.uuid4())\n                except Exception:\n                    pass\n            self.history.append(message)\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n            sender = getattr(message, \"sent_from\", \"unknown\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n        except Exception:\n            # Try to normalize and store minimal message\n            try:\n                minimal = make_message(\n                    content=str(getattr(message, \"content\", \"\") or \"\"),\n                    role=getattr(message, \"role\", \"Unknown\"),\n                    cause_by=getattr(message, \"cause_by\", \"\"),\n                    sent_from=getattr(message, \"sent_from\", \"unknown\")\n                )\n                self.history.append(minimal)\n            except Exception:\n                # give up silently to avoid propagation\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches anything in the role's watch_list, preserving order.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        relevant: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant.append(msg)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by, or None.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates a group of roles to collaborate for n rounds with robust handling.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure tracer accessible via context, but don't fail if not allowed\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Add roles to the team and align contexts and environments.\"\"\"\n        for role in roles:\n            try:\n                role.context = role.context or self.context\n                role.env = self.env\n                # Ensure action instances are context-aware\n                for a in getattr(role, \"actions\", []) or []:\n                    a.context = a.context or self.context\n            except Exception:\n                pass\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea or \"\"\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message (user instruction)\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_idx in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_idx + 1}/{n_round}\")\n            # Deterministic iteration order of roles\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    # First round: let coder(s) respond to initial input\n                    if round_idx == 0 and any(a.name == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        latest = relevant[-1]\n                        response = await role.act(latest)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_idx + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "7e205c81-734c-42d8-be65-ca76f68acd2b", "generation": 3, "timestamp": 1754648285.335232, "iteration_found": 64, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes.\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.5000\n- overall_score: 0.2500\n- combined_score: 0.1000\n- avg_failures_per_task: 12.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never throws.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": content,\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        return Message(kwargs[\"content\"], kwargs[\"role\"],\n                       instruct_content=kwargs.get(\"instruct_content\"),\n                       cause_by=kwargs[\"cause_by\"],\n                       sent_from=kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Base action class with unified execution wrapper.\"\"\"\n    name: str = \"Action\"\n    \n    def __init__(self, **kwargs):\n        self.context: Optional[Context] = kwargs.get('context')\n        self.llm: Optional[LLMInterface] = None\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            try:\n                self.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self.llm = None\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result\"\"\"\n        raise NotImplementedError\n    \n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Unified execution wrapper for mapping message/environment to concrete action inputs.\n        Keeps logic central to reduce branching and failure surface.\n        \"\"\"\n        try:\n            if isinstance(self, SimpleWriteCode):\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            if isinstance(self, SimpleWriteTest):\n                # Prefer explicit code from message; otherwise grab latest code from env.\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                return await self.run(code)\n            if isinstance(self, SimpleWriteReview):\n                # Needs both code and tests; search env for latest items if missing.\n                tests = getattr(message, \"content\", \"\") if message else \"\"\n                code = getattr(message, \"instruct_content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                if not tests and env:\n                    latest_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    if latest_tests:\n                        tests = getattr(latest_tests, \"content\", \"\") or \"\"\n                return await self.run(code, tests)\n            # Fallback for unknown actions\n            return await self.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_EXCEPTION\", getattr(self, \"name\", \"Action\"), str(e))\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str = \"\") -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        idea_text = (idea or \"\").strip()\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Writing code for: {idea_text[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea_text}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception as exc:\\n\"\n                    \"        raise exc\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str = \"\") -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        \"\"\"Review the code and tests\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n                \n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n                \n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks reasonable. Tests cover main functionality; add more edge cases.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with simplified action handling\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context: Optional[Context] = kwargs.get('context')\n        self.is_human: bool = kwargs.get('is_human', False)\n        self.actions: List[Action] = []\n        # watch_list stores action names (strings) for simpler comparisons\n        self.watch_list: List[str] = []\n        # environment reference set by Team.hire\n        self.env: Optional[\"Environment\"] = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform (ensure action contexts are aligned)\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n            try:\n                if self.context:\n                    a.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                a.llm = None\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for. Accept types or names.\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = names\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action based on a message.\"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        \n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n        \n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # create action instances lazily with given context\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watch by action name to avoid fragile type checks\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        preview = \"\"\n        try:\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n        except Exception:\n            preview = \"\"\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {getattr(message, 'sent_from', 'unknown')}: {preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        watched = set(role.watch_list or [])\n        if not watched:\n            return relevant_messages\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n    \n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and ensure contexts for role actions are aligned\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env  # allow roles to inspect environment history\n            if hasattr(role, \"actions\"):\n                for a in role.actions:\n                    a.context = self.context\n                    try:\n                        a.llm = LLMInterface(self.context.config.llm)\n                    except Exception:\n                        a.llm = None\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        response = await role.act(initial_msg)\n                    else:\n                        # Other roles respond to relevant messages\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        response = await role.act(relevant_msgs[-1])\n                except Exception as e:\n                    self.tracer.log(\"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    response = None\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n### Program 2 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never throws.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": content,\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # Try positional where pydantic is not present\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Minimal fallback object\n            class _M:\n                def __init__(self, content, role, cause_by, sent_from, instruct_content=None):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = instruct_content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n                def __str__(self):\n                    return f\"Message(role={self.role}, content={self.content[:50]}...)\"\n            return _M(kwargs[\"content\"], kwargs[\"role\"], kwargs[\"cause_by\"], kwargs[\"sent_from\"], kwargs.get(\"instruct_content\"))\n\nclass Action(ABC):\n    \"\"\"Base action class with lazy LLM and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        _safe_log(tracer, event, self.name, details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Writing code for: {idea_text[:120]}\")\n        prompt = (\n            f\"You are a professional programmer. Write Python code for the following task:\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Please provide only the code without any explanation.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic, safe fallback\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder_function():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'placeholder'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_text = (code or \"\").strip()\n        self._log(\"ACTION_START\", f\"Writing tests for code (len={len(code_text)})\")\n        snippet = code_text[:2000] if code_text else \"# No code provided\"\n        prompt = (\n            \"You are a QA engineer. Write comprehensive tests for the following code:\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain what each test does\\n\\n\"\n            \"Please provide only the test code without any explanation.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\").strip()\n        tests_text = (tests or \"\").strip()\n        self._log(\"ACTION_START\", f\"Reviewing code (human={self.is_human})\")\n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_text[:1500]}\\n\\n\"\n                    f\"Tests:\\n{tests_text[:1500]}\\n\\n\"\n                    \"Provide a brief review focusing on:\\n\"\n                    \"1. Code quality and best practices\\n\"\n                    \"2. Test coverage\\n\"\n                    \"3. Potential bugs or issues\\n\"\n                    \"4. Suggestions for improvement\\n\\n\"\n                    \"Keep your review concise and actionable.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks reasonable. Tests cover main functionality; add more edge cases.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        self._log(\"ACTION_END\", f\"Review completed ({len(review)} chars)\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents (simplified).\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list stores cause_by names (strings) to react to\n        self.watch_list: List[str] = []\n        # environment reference set by Team.hire\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        # Bind context into action instances and keep them per-instance (no shared mutable)\n        bound: List[Action] = []\n        for a in actions or []:\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif isinstance(a, type) and hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform primary action based on a message; returns a Message or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        try:\n            # Map inputs according to action type\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code from message (if coder produced it), else search environment history\n                code = \"\"\n                if message and getattr(message, \"content\", None):\n                    code = message.content\n                elif self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Gather code and tests from message or environment\n                code = \"\"\n                tests = \"\"\n                if message:\n                    tests = getattr(message, \"content\", \"\") or \"\"\n                    code = getattr(message, \"instruct_content\", \"\") or \"\"\n                if self.env:\n                    if not code:\n                        latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                        code = getattr(latest_code, \"content\", \"\") if latest_code else code\n                    if not tests:\n                        latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests = getattr(latest_tests, \"content\", \"\") if latest_tests else tests\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self._watch([])  # coder responds to user input explicitly\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        # append and log safely\n        try:\n            self.history.append(message)\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n            sender = getattr(message, \"sent_from\", \"unknown\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n        except Exception:\n            # best-effort attempt to normalize and store minimal info\n            try:\n                minimal = make_message(str(getattr(message, \"content\", \"\")), role=getattr(message, \"role\", \"Unknown\"), cause_by=getattr(message, \"cause_by\", \"\"), sent_from=getattr(message, \"sent_from\", \"unknown\"))\n                self.history.append(minimal)\n            except Exception:\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        relevant: List[Message] = []\n        watched = set(role.watch_list or [])\n        if not watched:\n            return relevant\n        for m in self.history:\n            try:\n                if getattr(m, \"cause_by\", \"\") in watched:\n                    relevant.append(m)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for m in reversed(self.history):\n            try:\n                if getattr(m, \"cause_by\", \"\") == cause_name:\n                    return m\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure tracer in context\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team; ensure contexts for role actions are aligned\"\"\"\n        for role in roles:\n            role.context = role.context or self.context\n            role.env = self.env\n            # ensure actions know the team's context\n            for a in role.actions:\n                a.context = a.context or self.context\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 3):\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        # initial message (user instruction)\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_num in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            # roles act in deterministic order\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        response = await role.act(relevant[-1])\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    response = None\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never throws.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": content,\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        return Message(kwargs[\"content\"], kwargs[\"role\"],\n                       instruct_content=kwargs.get(\"instruct_content\"),\n                       cause_by=kwargs[\"cause_by\"],\n                       sent_from=kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Base action class with unified execution wrapper.\"\"\"\n    name: str = \"Action\"\n    \n    def __init__(self, **kwargs):\n        self.context: Optional[Context] = kwargs.get('context')\n        self.llm: Optional[LLMInterface] = None\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            try:\n                self.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self.llm = None\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result\"\"\"\n        raise NotImplementedError\n    \n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Unified execution wrapper for mapping message/environment to concrete action inputs.\n        Keeps logic central to reduce branching and failure surface.\n        \"\"\"\n        try:\n            aname = getattr(self, \"name\", \"\") or self.__class__.__name__\n            if aname == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            if aname == SimpleWriteTest.name:\n                # Prefer explicit code from message; otherwise grab latest code from env.\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                return await self.run(code)\n            if aname == SimpleWriteReview.name:\n                # Needs both code and tests; search env for latest items if missing.\n                tests = getattr(message, \"content\", \"\") if message else \"\"\n                code = getattr(message, \"instruct_content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                if not tests and env:\n                    latest_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    if latest_tests:\n                        tests = getattr(latest_tests, \"content\", \"\") or \"\"\n                return await self.run(code, tests)\n            # Fallback for unknown actions\n            return await self.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_EXCEPTION\", getattr(self, \"name\", \"Action\"), str(e))\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str = \"\") -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        idea_text = (idea or \"\").strip()\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Writing code for: {idea_text[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea_text}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception as exc:\\n\"\n                    \"        raise exc\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str = \"\") -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        \"\"\"Review the code and tests\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n                \n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n                \n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks reasonable. Tests cover main functionality; add more edge cases.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with simplified action handling\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context: Optional[Context] = kwargs.get('context')\n        self.is_human: bool = kwargs.get('is_human', False)\n        self.actions: List[Action] = []\n        # watch_list stores action names (strings) for simpler comparisons\n        self.watch_list: List[str] = []\n        # environment reference set by Team.hire\n        self.env: Optional[\"Environment\"] = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform (ensure action contexts are aligned)\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n            try:\n                if self.context:\n                    a.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                a.llm = None\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for. Accept types or names.\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = names\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action based on a message.\"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        \n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n        \n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # create action instances lazily with given context\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watch by action name to avoid fragile type checks\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        preview = \"\"\n        try:\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n        except Exception:\n            preview = \"\"\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {getattr(message, 'sent_from', 'unknown')}: {preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        watched = set(role.watch_list or [])\n        if not watched:\n            return relevant_messages\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n    \n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and ensure contexts for role actions are aligned\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env  # allow roles to inspect environment history\n            if hasattr(role, \"actions\"):\n                for a in role.actions:\n                    a.context = self.context\n                    try:\n                        a.llm = LLMInterface(self.context.config.llm)\n                    except Exception:\n                        a.llm = None\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        response = await role.act(initial_msg)\n                    else:\n                        # Other roles respond to relevant messages\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        response = await role.act(relevant_msgs[-1])\n                except Exception as e:\n                    self.tracer.log(\"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    response = None\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D2 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    try:\n        if x is None:\n            return \"\"\n        if isinstance(x, str):\n            return x\n        return str(x)\n    except Exception:\n        return \"\"\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n            else:\n                self.llm = None\n        except Exception:\n            self.llm = None\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        idea_text = _safe_str(idea).strip()\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea_text[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea_text}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'placeholder'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        \n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated {len(_safe_str(code))} characters of code\")\n        \n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        code_text = _safe_str(code).strip()\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        snippet = code_text[:2000] if code_text else \"# No code provided\"\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        \n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Generated {len(_safe_str(tests))} characters of tests\")\n        \n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        code_text = _safe_str(code).strip()\n        tests_text = _safe_str(tests).strip()\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code_text[:1500]}\n\nTests:\n{tests_text[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n                \n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n                \n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        \n        if tracer:\n            tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(_safe_str(review))} characters\")\n        \n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        # Per-instance action instances and watch list names\n        self.actions: List[Action] = []\n        self.watch_list: List[str] = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform and align contexts\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n            try:\n                if self.context and getattr(self.context, \"config\", None):\n                    a.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                a.llm = None\n    \n    def _watch(self, actions: List[Any]):\n        \"\"\"Set the actions this role watches for (accepts classes or names)\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = names\n    \n    async def act(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        \n        # Dispatch by action type/name with safe fallbacks\n        try:\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code in triggering message, else search environment\n                code = \"\"\n                if message and getattr(message, \"content\", None):\n                    code = message.content or \"\"\n                elif env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Assemble code and tests from message or environment\n                code = \"\"\n                tests = \"\"\n                if message:\n                    # If a composite message is provided, content=tests and instruct_content=code\n                    code = getattr(message, \"instruct_content\", \"\") or \"\"\n                    tests = getattr(message, \"content\", \"\") or \"\"\n                if (not code or not tests) and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    latest_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code = code or (getattr(latest_code, \"content\", \"\") if latest_code else \"\")\n                    tests = tests or (getattr(latest_tests, \"content\", \"\") if latest_tests else \"\")\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            result = f\"Action {getattr(action, 'name', 'Unknown')} failed: {e}\"\n            if tracer:\n                tracer.log(\"ROLE_ERROR\", self.name, result)\n        \n        # Create response message\n        try:\n            response = Message(\n                content=_safe_str(result),\n                role=self.profile,\n                cause_by=getattr(action, \"name\", \"\"),\n                sent_from=self.name\n            )\n        except Exception:\n            # Fallback lightweight message\n            class _SimpleMsg:\n                def __init__(self, content, role, cause_by, sent_from):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n            response = _SimpleMsg(_safe_str(result), self.profile, getattr(action, \"name\", \"\"), self.name)\n        \n        if tracer:\n            tracer.log(\"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            try:\n                self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n            except Exception:\n                pass\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            try:\n                preview = (_safe_str(getattr(message, \"content\", \"\")))[:100]\n                sender = getattr(message, \"sent_from\", \"Unknown\")\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n            except Exception:\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \"Message published\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to (by cause_by name)\"\"\"\n        if not getattr(role, \"watch_list\", None):\n            return []\n        relevant_messages: List[Message] = []\n        watched = set(role.watch_list or [])\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Get the most recent message whose cause_by matches cause_name\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and align action contexts\"\"\"\n        for role in roles:\n            role.context = self.context\n            # Align existing action instances with the team's context and LLM\n            if hasattr(role, \"actions\"):\n                for a in role.actions:\n                    a.context = self.context\n                    try:\n                        a.llm = LLMInterface(self.context.config.llm)\n                    except Exception:\n                        a.llm = None\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        response = await role.act(initial_msg, env=self.env)\n                    else:\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        last_msg = relevant_msgs[-1]\n                        if isinstance(role, SimpleReviewer):\n                            # Build a composite message: tests in content, code in instruct_content\n                            code_msg = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                            test_msg = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                            composite = Message(\n                                content=(getattr(test_msg, \"content\", \"\") if test_msg else getattr(last_msg, \"content\", \"\")),\n                                instruct_content=(getattr(code_msg, \"content\", \"\") if code_msg else \"\"),\n                                role=\"System\",\n                                sent_from=\"Environment\",\n                                cause_by=\"Composite\"\n                            )\n                            response = await role.act(composite, env=self.env)\n                        else:\n                            response = await role.act(last_msg, env=self.env)\n                except Exception as e:\n                    self.tracer.log(\"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    response = None\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D3 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Return a safe string for any input.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        return x if isinstance(x, str) else str(x)\n    except Exception:\n        return \"\"\n\ndef _log_safe(tracer: Optional[ExecutionTracer], event: str, agent: str, details: str):\n    \"\"\"Best-effort logging helper to avoid raising inside logging.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Construct a Message instance in a stable way for both pydantic and fallback Message.\"\"\"\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": _safe_str(role),\n        \"cause_by\": _safe_str(cause_by),\n        \"sent_from\": _safe_str(sent_from) if sent_from is not None else None\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = _safe_str(instruct_content)\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional constructor if pydantic variant failed\n        return Message(kwargs[\"content\"], kwargs[\"role\"], instruct_content=kwargs.get(\"instruct_content\"), cause_by=kwargs[\"cause_by\"], sent_from=kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Simple, single-responsibility Action base.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            try:\n                self._llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self._llm = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        return self._llm\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Perform the action and return textual result.\"\"\"\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code from requirements.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea = _safe_str(idea).strip()\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"idea={idea[:120]}\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Please provide only the code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = f\"# Implementation for: {idea}\\n# [LLM unavailable - placeholder implementation]\\n\"\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"len={len(_safe_str(code))}\")\n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate tests for a piece of code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code = _safe_str(code)\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"code_len={len(code)}\")\n        snippet = code[:2000] if code else \"# No code provided\"\n        prompt = (\n            \"You are a QA engineer. Write comprehensive tests for the following code:\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain what each test does\\n\\n\"\n            \"Please provide only the test code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = \"import pytest\\n\\n# Placeholder tests\\n\\ndef test_placeholder():\\n    assert True\\n\"\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"len={len(_safe_str(tests))}\")\n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and provide concise feedback.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code = _safe_str(code)\n        tests = _safe_str(tests)\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"is_human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Looks generally good. Consider more error handling and edge-case tests.\"\n        else:\n            prompt = (\n                \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                f\"Code:\\n{code[:1500]}\\n\\n\"\n                f\"Tests:\\n{tests[:1500]}\\n\\n\"\n                \"Provide a brief review focusing on:\\n\"\n                \"1. Code quality and best practices\\n\"\n                \"2. Test coverage\\n\"\n                \"3. Potential bugs or issues\\n\"\n                \"4. Suggestions for improvement\\n\\n\"\n                \"Keep your review concise and actionable.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt},\n            ]\n            try:\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable; add more edge-case handling and clearer errors.\"\n            except Exception as e:\n                review = f\"Error during review: {e}\"\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"len={len(_safe_str(review))}\")\n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Minimal, deterministic Role implementation.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n\n    def __init__(self, name: Optional[str] = None, profile: Optional[str] = None, context: Optional[Context] = None, is_human: bool = False):\n        if name:\n            self.name = name\n        if profile:\n            self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains cause_by string tokens indicating which messages to handle\n        self.watch_list: Set[str] = set()\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Assign action instances; ensure their context is aligned.\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        \"\"\"Normalize a watch list to names (strings).\"\"\"\n        names: Set[str] = set()\n        for a in actions or []:\n            if isinstance(a, str):\n                names.add(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute primary action with clear routing rules.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        _log_safe(tracer, \"ROLE_ACT\", self.name, f\"action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        try:\n            # Routing by action name keeps behavior explicit and simple\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n\n            elif action.name == SimpleWriteTest.name:\n                # Prefer code from triggering message (if caused by code action),\n                # else get latest code from environment if available.\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest:\n                        code_text = getattr(latest, \"content\", \"\") or \"\"\n                result = await action.run(code_text)\n\n            elif action.name == SimpleWriteReview.name:\n                # Compose code and tests from environment for review\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    code_msg = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    test_msg = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code_text = getattr(code_msg, \"content\", \"\") if code_msg else \"\"\n                    tests_text = getattr(test_msg, \"content\", \"\") if test_msg else \"\"\n                # If message explicitly contains something, prefer its fields\n                if message:\n                    tests_text = tests_text or getattr(message, \"content\", \"\") or \"\"\n                    code_text = code_text or getattr(message, \"instruct_content\", \"\") or \"\"\n                result = await action.run(code_text, tests_text)\n\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _log_safe(tracer, \"ROLE_ERROR\", self.name, _safe_str(e))\n            result = f\"Error executing {getattr(action, 'name', 'Action')}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _log_safe(tracer, \"ROLE_COMPLETE\", self.name, f\"created_msg_id={getattr(response, 'id', None)}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(name=self.name, profile=self.profile, context=kwargs.get('context'), is_human=kwargs.get('is_human', False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(name=self.name, profile=self.profile, context=kwargs.get('context'), is_human=kwargs.get('is_human', False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(name=self.name, profile=self.profile, context=kwargs.get('context'), is_human=kwargs.get('is_human', False))\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Lightweight environment to hold messages and provide simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _log_safe(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def publish_message(self, message: Message):\n        \"\"\"Append a message and log a concise preview.\"\"\"\n        # Ensure message has an id attribute where possible\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        preview = _safe_str(getattr(message, \"content\", \"\"))[:100]\n        _log_safe(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={getattr(message, 'sent_from', 'unknown')} cause={getattr(message, 'cause_by', '')} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by is in the role's watch list (preserve order).\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        return [m for m in self.history if getattr(m, \"cause_by\", \"\") in watched]\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the latest message with matching cause_by, or None.\"\"\"\n        for m in reversed(self.history):\n            if getattr(m, \"cause_by\", \"\") == cause_name:\n                return m\n        return None\n\nclass Team:\n    \"\"\"Orchestrates the roles and runs the collaboration rounds.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # propagate tracer into context\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Attach roles to the team and align contexts.\"\"\"\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            # Ensure actions point to the shared context\n            if hasattr(r, \"actions\"):\n                for a in r.actions:\n                    a.context = self.context\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        _log_safe(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 3):\n        _log_safe(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        # initial message\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        for round_num in range(n_round):\n            _log_safe(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            # iterate roles deterministically\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    if round_num == 0 and getattr(role, \"profile\", \"\") == \"SimpleCoder\":\n                        response = await role.act(initial_msg)\n                    else:\n                        msgs = self.env.get_messages_for_role(role)\n                        if not msgs:\n                            continue\n                        response = await role.act(msgs[-1])\n                except Exception as e:\n                    _log_safe(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _safe_str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n            _log_safe(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        _log_safe(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _log_safe(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 3.2125, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    try:\n        if x is None:\n            return \"\"\n        return x if isinstance(x, str) else str(x)\n    except Exception:\n        return \"\"\n\ndef _make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"\n    Robust helper to construct Message objects across pydantic/fallback implementations.\n    \"\"\"\n    try:\n        return Message(\n            content=_safe_str(content),\n            role=role,\n            cause_by=cause_by or \"\",\n            sent_from=sent_from,\n            instruct_content=instruct_content\n        )\n    except Exception:\n        # Fallback to minimal object compatible with Environment expectations\n        class _M:\n            pass\n        m = _M()\n        m.id = str(uuid.uuid4())\n        m.content = _safe_str(content)\n        m.instruct_content = instruct_content\n        m.role = role\n        m.cause_by = cause_by or \"\"\n        m.sent_from = sent_from\n        m.sent_to = None\n        m.send_to = set()\n        return m\n\nclass Action(ABC):\n    \"\"\"Base action with safe logging and lazy LLM access\"\"\"\n    name: str = \"Action\"\n    \n    def __init__(self, **kwargs):\n        self.context: Optional[Context] = kwargs.get('context')\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, etype: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(etype, self.name, details)\n            except Exception:\n                pass\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        idea = _safe_str(idea).strip()\n        self._log(\"ACTION_START\", f\"Writing code for: {idea[:120]}\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Please provide only the code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea}\\n\"\n                    \"def solution():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder solution.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return None\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(_safe_str(code))} characters of code\")\n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        code = _safe_str(code)\n        self._log(\"ACTION_START\", \"Writing tests for code\")\n        prompt = (\n            \"You are a QA engineer. Write comprehensive tests for the following code:\\n\\n\"\n            f\"Code:\\n{code[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain what each test does\\n\\n\"\n            \"Please provide only the test code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(_safe_str(tests))} characters of tests\")\n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = bool(is_human)\n    \n    async def run(self, code: str, tests: str) -> str:\n        code = _safe_str(code)\n        tests = _safe_str(tests)\n        self._log(\"ACTION_START\", f\"Reviewing code (human={self.is_human})\")\n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling and more edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code[:1500]}\\n\\n\"\n                    f\"Tests:\\n{tests[:1500]}\\n\\n\"\n                    \"Provide a brief review focusing on:\\n\"\n                    \"1. Code quality and best practices\\n\"\n                    \"2. Test coverage\\n\"\n                    \"3. Potential bugs or issues\\n\"\n                    \"4. Suggestions for improvement\\n\\n\"\n                    \"Keep your review concise and actionable.\"\n                )\n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt},\n                ]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable; add more edge-case handling and clearer error messages.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        self._log(\"ACTION_END\", f\"Review completed: {len(_safe_str(review))} characters\")\n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with simplified routing\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context: Optional[Context] = kwargs.get('context')\n        self.is_human: bool = bool(kwargs.get('is_human', False))\n        self.actions: List[Action] = []\n        # watch_list stores cause_by names (strings)\n        self.watch_list: Set[str] = set()\n        # reference to the environment (set when hired)\n        self.env: Optional[\"Environment\"] = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform and ensure context alignment\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            try:\n                a.context = self.context\n            except Exception:\n                pass\n    \n    def _watch(self, actions: List[Type[Action] or str]):\n        \"\"\"Set the actions this role watches for. Accepts types or names.\"\"\"\n        names: Set[str] = set()\n        for a in (actions or []):\n            try:\n                if isinstance(a, str):\n                    names.add(a)\n                elif hasattr(a, 'name'):\n                    names.add(getattr(a, 'name'))\n                elif isinstance(a, type) and hasattr(a, 'name'):\n                    names.add(getattr(a, 'name'))\n                else:\n                    names.add(str(a))\n            except Exception:\n                continue\n        self.watch_list = names\n    \n    def _log(self, etype: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(etype, self.name, details)\n            except Exception:\n                pass\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message.\"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        action_name = getattr(action, \"name\", \"Action\")\n        self._log(\"ROLE_ACT\", f\"Executing action: {action_name}\")\n        \n        result = \"\"\n        try:\n            if action_name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n\n            elif action_name == SimpleWriteTest.name:\n                code_text = \"\"\n                # Prefer code from triggering message if it was produced by coder\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                # Else use the latest code from environment\n                if not code_text and self.env:\n                    try:\n                        code_msg = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                        if code_msg:\n                            code_text = getattr(code_msg, \"content\", \"\") or code_text\n                    except Exception:\n                        pass\n                # Fallback: use message content if present\n                if not code_text and message:\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(code_text)\n\n            elif action_name == SimpleWriteReview.name:\n                tests_text = \"\"\n                code_text = \"\"\n                # Prefer tests from triggering message if it was produced by tester\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                    tests_text = getattr(message, \"content\", \"\") or \"\"\n                # Get latest code/tests from environment as needed\n                if self.env:\n                    try:\n                        if not code_text:\n                            code_msg = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                            if code_msg:\n                                code_text = getattr(code_msg, \"content\", \"\") or code_text\n                        if not tests_text:\n                            test_msg = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                            if test_msg:\n                                tests_text = getattr(test_msg, \"content\", \"\") or tests_text\n                    except Exception:\n                        pass\n                result = await action.run(code_text or \"\", tests_text or \"\")\n\n            else:\n                # Generic action: pass message content\n                content = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(content)\n        except Exception as e:\n            err = f\"Error executing action {action_name}: {e}\"\n            self._log(\"ROLE_ERROR\", err)\n            result = err\n        \n        response = _make_message(\n            content=result,\n            role=self.profile,\n            cause_by=action_name,\n            sent_from=self.name\n        )\n        self._log(\"ROLE_COMPLETE\", f\"Action completed, message created (cause_by={action_name})\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        # Ensure back-references\n        try:\n            role.env = self\n        except Exception:\n            pass\n        self.roles.append(role)\n        if self.tracer:\n            try:\n                self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n            except Exception:\n                pass\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        try:\n            self.history.append(message)\n        except Exception:\n            # Attempt to normalize and append\n            try:\n                m = _make_message(\n                    content=_safe_str(getattr(message, \"content\", message)),\n                    role=_safe_str(getattr(message, \"role\", \"Unknown\")),\n                    cause_by=_safe_str(getattr(message, \"cause_by\", \"\")),\n                    sent_from=_safe_str(getattr(message, \"sent_from\", \"Unknown\"))\n                )\n                self.history.append(m)\n                message = m\n            except Exception:\n                # Give up silently to prevent crashing\n                return\n        if self.tracer:\n            try:\n                sender = getattr(message, \"sent_from\", \"Unknown\")\n                content_preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {content_preview}\")\n            except Exception:\n                pass\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        watch_names = set(getattr(role, \"watch_list\", []) or [])\n        if not watch_names:\n            return relevant_messages\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watch_names:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message whose cause_by matches cause_name.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            try:\n                role.context = self.context\n                # Ensure all existing actions carry updated context\n                for a in getattr(role, \"actions\", []) or []:\n                    try:\n                        a.context = self.context\n                    except Exception:\n                        pass\n            except Exception:\n                pass\n            # Provide environment reference so roles can inspect history\n            role.env = self.env\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = _make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in self.env.roles:\n                response = None\n                # First round: let the coder respond to the user input explicitly\n                if round_num == 0 and isinstance(role, SimpleCoder):\n                    try:\n                        response = await role.act(initial_msg)\n                    except Exception as e:\n                        if self.tracer:\n                            self.tracer.log(\"ROLE_RUN_ERROR\", role.name, f\"Error during act: {e}\")\n                        response = None\n                else:\n                    # Other roles respond to relevant messages\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        try:\n                            response = await role.act(relevant_msgs[-1])  # Act on most recent relevant message\n                        except Exception as e:\n                            if self.tracer:\n                                self.tracer.log(\"ROLE_RUN_ERROR\", role.name, f\"Error during act: {e}\")\n                            response = None\n                    else:\n                        # No relevant messages; skip\n                        continue\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n### Inspiration 2 (Score: 3.2125, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Base action class\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        self.context = kwargs.get('context')\n        if self.context and self.context.config.llm:\n            self.llm = LLMInterface(self.context.config.llm)\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs):\n        \"\"\"Run the action\"\"\"\n        pass\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Writing code for: {idea[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            code = await self.llm.ask(messages)\n        else:\n            code = f\"# Implementation for: {idea}\\n# [Code would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        \n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code[:2000]}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        if self.llm:\n            tests = await self.llm.ask(messages)\n        else:\n            tests = f\"# Tests for the implementation\\n# [Tests would be generated here]\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        \n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str, tests: str) -> str:\n        \"\"\"Review the code and tests\"\"\"\n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        if self.is_human:\n            # Simulate human review\n            review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n        else:\n            prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code[:1500]}\n\nTests:\n{tests[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n            \n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        \n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action] = []\n    watch_list: List[Type[Action]] = []\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = actions\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for\"\"\"\n        self.watch_list = actions\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform an action based on the message\"\"\"\n        if not self.actions:\n            return None\n        \n        # Execute the first action (simplified)\n        action = self.actions[0]\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_ACT\", self.name, f\"Executing action: {action.name}\")\n        \n        # Execute action based on type\n        if isinstance(action, SimpleWriteCode):\n            if message and hasattr(message, 'instruct_content'):\n                result = await action.run(message.instruct_content or message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteTest):\n            if message:\n                result = await action.run(message.content)\n            else:\n                result = await action.run(\"\")\n        elif isinstance(action, SimpleWriteReview):\n            # For review, we need both code and tests\n            if message:\n                # Extract code and tests from previous messages (simplified)\n                result = await action.run(message.content, \"\")\n            else:\n                result = await action.run(\"\", \"\")\n        else:\n            result = \"Action completed\"\n        \n        # Create response message\n        response = Message(\n            content=result,\n            role=self.profile,\n            cause_by=action.name if action else \"\",\n            sent_from=self.name\n        )\n        \n        if self.context and self.context.tracer:\n            self.context.tracer.log(\"ROLE_COMPLETE\", self.name, f\"Action completed, message created\")\n        \n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        if self.tracer:\n            self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        if self.tracer:\n            self.tracer.log(\"ENV_MESSAGE\", \"Environment\", \n                          f\"Message from {message.sent_from}: {message.content[:100]}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages = []\n        for msg in self.history:\n            # Check if this message is from an action the role watches\n            for watched_action in role.watch_list:\n                if msg.cause_by == watched_action.name:\n                    relevant_messages.append(msg)\n                    break\n        return relevant_messages\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in self.env.roles:\n                # Determine what messages this role should respond to\n                if round_num == 0 and isinstance(role, SimpleCoder):\n                    # Coder responds to initial message\n                    response = await role.act(initial_msg)\n                else:\n                    # Other roles respond to relevant messages\n                    relevant_msgs = self.env.get_messages_for_role(role)\n                    if relevant_msgs:\n                        response = await role.act(relevant_msgs[-1])  # Act on most recent relevant message\n                    else:\n                        continue\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Alternative overall_score approach, Alternative combined_score approach\n\n\n### Inspiration 3 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Return a safe string representation for any object.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        if isinstance(x, str):\n            return x\n        return str(x)\n    except Exception:\n        return \"\"\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message that works with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        return Message(\n            kwargs[\"content\"],\n            kwargs[\"role\"],\n            instruct_content=kwargs.get(\"instruct_content\"),\n            cause_by=kwargs[\"cause_by\"],\n            sent_from=kwargs[\"sent_from\"]\n        )\n\nclass Action(ABC):\n    \"\"\"Base action class with unified execution wrapper.\"\"\"\n    name: str = \"Action\"\n    context: Optional[Context] = None\n    llm: Optional[LLMInterface] = None\n    \n    def __init__(self, **kwargs):\n        # Per-instance state only\n        self.context = kwargs.get('context')\n        self.llm = None\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError(\"Action.run must be implemented by subclasses\")\n    \n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Map a message/environment to concrete run(...) parameters.\n        Centralized routing reduces duplication and failure surface.\n        \"\"\"\n        try:\n            if isinstance(self, SimpleWriteCode):\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            \n            if isinstance(self, SimpleWriteTest):\n                code = \"\"\n                # Prefer explicit code in triggering message if it came from coder\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code = getattr(message, \"content\", \"\") or \"\"\n                # Otherwise, locate the latest code in the environment\n                if not code and env:\n                    m = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(m, \"content\", \"\") if m else \"\"\n                return await self.run(code)\n            \n            if isinstance(self, SimpleWriteReview):\n                # Reviewer uses the latest code and tests available in the environment\n                code = \"\"\n                tests = \"\"\n                if env:\n                    m_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    m_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code = getattr(m_code, \"content\", \"\") if m_code else \"\"\n                    tests = getattr(m_tests, \"content\", \"\") if m_tests else \"\"\n                # Fallback to message content if env search failed\n                if not tests and message:\n                    tests = getattr(message, \"content\", \"\") or tests\n                return await self.run(code, tests)\n            \n            # Generic fallback\n            payload = getattr(message, \"content\", \"\") if message else \"\"\n            return await self.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_EXCEPTION\", self.name, _safe_str(e))\n            return f\"Error executing {self.name}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        idea_text = _safe_str(idea).strip()\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Writing code for: {idea_text[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea_text}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception as exc:\\n\"\n                    \"        raise exc\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(_safe_str(code))} characters of code\")\n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        code_text = _safe_str(code)\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        code_snippet = (code_text[:2000] + (\"...\" if len(code_text) > 2000 else \"\"))\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{code_snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(_safe_str(tests))} characters of tests\")\n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = bool(is_human)\n    \n    async def run(self, code: str, tests: str) -> str:\n        code_text = _safe_str(code)\n        tests_text = _safe_str(tests)\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code_text[:1500]}\n\nTests:\n{tests_text[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n                \n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n                \n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Review completed: {len(_safe_str(review))} characters\")\n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Base role class for agents (simplified and robust)\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    context: Optional[Context] = None\n    actions: List[Action]\n    watch_list: List[str]\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context = kwargs.get('context')\n        self.is_human = kwargs.get('is_human', False)\n        self.actions = []\n        self.watch_list = []\n        self.env: Optional[\"Environment\"] = None  # Set when added to Environment\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform and align contexts\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n            try:\n                if self.context:\n                    a.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                a.llm = None\n    \n    def _watch(self, actions: List[Type[Action] or str]):\n        \"\"\"Set the actions this role watches for (accepts classes or names)\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = names\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action using a unified execution wrapper\"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        _safe_log(tracer, \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        \n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(tracer, \"ROLE_ERROR\", self.name, f\"Execution failed: {_safe_str(e)}\")\n            result = f\"Error in role {self.name}: {e}\"\n        \n        response = make_message(\n            content=_safe_str(result),\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(tracer, \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        role.env = self  # provide back-reference for context lookups\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        try:\n            preview = _safe_str(getattr(message, \"content\", \"\"))[:100]\n            sender = _safe_str(getattr(message, \"sent_from\", \"Unknown\"))\n        except Exception:\n            preview, sender = \"\", \"Unknown\"\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        watched = set(role.watch_list or [])\n        if not watched:\n            return relevant_messages\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n    \n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message created by a specific action\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            # Ensure any pre-created actions align with team context\n            if hasattr(role, \"actions\"):\n                for a in role.actions:\n                    a.context = self.context\n                    try:\n                        a.llm = LLMInterface(self.context.config.llm)\n                    except Exception:\n                        a.llm = None\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        response = await role.act(initial_msg)\n                    else:\n                        # Other roles respond to relevant messages\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        last_msg = relevant_msgs[-1]\n                        response = await role.act(last_msg)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _safe_str(e))\n                    response = None\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n### Inspiration 4 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    try:\n        if x is None:\n            return \"\"\n        return x if isinstance(x, str) else str(x)\n    except Exception:\n        return \"\"\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef _make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from,\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        return Message(kwargs[\"content\"], kwargs[\"role\"],\n                       instruct_content=kwargs.get(\"instruct_content\"),\n                       cause_by=kwargs[\"cause_by\"], sent_from=kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Minimal, robust base action with a unified execution wrapper.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, **kwargs):\n        self.context: Optional[Context] = kwargs.get(\"context\")\n        self.llm: Optional[LLMInterface] = None\n        try:\n            if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"Map message/env to concrete action inputs with safe fallbacks.\"\"\"\n        try:\n            if isinstance(self, SimpleWriteCode):\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n\n            if isinstance(self, SimpleWriteTest):\n                # Prefer explicit code in triggering message; otherwise search env history.\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and env:\n                    last_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if last_code:\n                        code = getattr(last_code, \"content\", \"\") or \"\"\n                return await self.run(code)\n\n            if isinstance(self, SimpleWriteReview):\n                # Needs both code and tests; derive best-effort from message and env.\n                tests = getattr(message, \"content\", \"\") if message else \"\"\n                code = \"\"\n                if env:\n                    last_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if last_code:\n                        code = getattr(last_code, \"content\", \"\") or \"\"\n                return await self.run(code, tests)\n\n            # Fallback: single string argument from message content\n            return await self.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_EXCEPTION\", self.name, _safe_str(e))\n            return f\"Error executing {self.name}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        idea_txt = _safe_str(idea)\n        _safe_log(tracer, \"ACTION_START\", self.name, f\"Writing code for: {idea_txt[:100]}\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\"\n            f\"Task: {idea_txt}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Please provide only the code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_txt}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception as exc:\\n\"\n                    \"        raise exc\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        _safe_log(tracer, \"ACTION_END\", self.name, f\"Generated {len(_safe_str(code))} characters of code\")\n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        code_txt = _safe_str(code)\n        _safe_log(tracer, \"ACTION_START\", self.name, \"Writing tests for code\")\n        snippet = code_txt[:2000]\n        prompt = (\n            \"You are a QA engineer. Write comprehensive tests for the following code:\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain what each test does\\n\\n\"\n            \"Please provide only the test code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        _safe_log(tracer, \"ACTION_END\", self.name, f\"Generated {len(_safe_str(tests))} characters of tests\")\n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        tracer = getattr(self.context, \"tracer\", None)\n        code_txt = _safe_str(code)\n        tests_txt = _safe_str(tests)\n        _safe_log(tracer, \"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_txt[:1500]}\\n\\n\"\n                    f\"Tests:\\n{tests_txt[:1500]}\\n\\n\"\n                    \"Provide a brief review focusing on:\\n\"\n                    \"1. Code quality and best practices\\n\"\n                    \"2. Test coverage\\n\"\n                    \"3. Potential bugs or issues\\n\"\n                    \"4. Suggestions for improvement\\n\\n\"\n                    \"Keep your review concise and actionable.\"\n                )\n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt},\n                ]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks reasonable. Tests cover main functionality; add more edge cases.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        _safe_log(tracer, \"ACTION_END\", self.name, f\"Review completed: {len(_safe_str(review))} characters\")\n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Simplified role abstraction with late-bound action instantiation.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get(\"name\", self.name)\n        self.profile = kwargs.get(\"profile\", self.profile)\n        self.context: Optional[Context] = kwargs.get(\"context\")\n        self.is_human: bool = bool(kwargs.get(\"is_human\", False))\n        self.env: Optional[\"Environment\"] = None\n        # single primary action class (late instantiation with current context)\n        self._action_cls: Optional[Type[Action]] = None\n        # watch list stores action names (strings)\n        self.watch_list: List[str] = []\n\n    def set_actions(self, actions: List[Type[Action]]):\n        self._action_cls = actions[0] if actions else None\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = [n for n in names if n]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        if not self._action_cls:\n            return None\n        tracer = getattr(self.context, \"tracer\", None)\n\n        # Instantiate action with current context (and is_human for reviewer)\n        try:\n            if self._action_cls is SimpleWriteReview:\n                action = self._action_cls(context=self.context, is_human=self.is_human)  # type: ignore\n            else:\n                action = self._action_cls(context=self.context)  # type: ignore\n        except Exception as e:\n            _safe_log(tracer, \"ROLE_ERROR\", self.name, f\"Failed to instantiate action: {_safe_str(e)}\")\n            return None\n\n        _safe_log(tracer, \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', self._action_cls.__name__)}\")\n\n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(tracer, \"ROLE_EXCEPTION\", self.name, _safe_str(e))\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = _make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(tracer, \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        self.history.append(message)\n        preview = \"\"\n        try:\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n        except Exception:\n            preview = \"\"\n        sender = getattr(message, \"sent_from\", \"Unknown\")\n        cause = getattr(message, \"cause_by\", \"\")\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={sender} cause={cause} preview={preview}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches the role's watch list.\"\"\"\n        if not role.watch_list:\n            return []\n        watched = set(role.watch_list)\n        relevant: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant.append(msg)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and wire their context/env references.\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 3):\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        initial_msg = _make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        for round_num in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        response = await role.act(initial_msg)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        response = await role.act(relevant[-1])\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _safe_str(e))\n                    response = None\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n### Inspiration 5 (Score: 3.2125, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\nclass Action(ABC):\n    \"\"\"Lightweight base action with safe LLM access and logging helpers.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily construct LLMInterface if configuration is present.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg is not None and getattr(cfg, \"llm\", None) is not None:\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(event, self.name, details)\n            except Exception:\n                # never allow tracing issues to propagate\n                pass\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n    def __init__(self, *, context: Optional[Context] = None):\n        super().__init__(context=context)\n\n    async def run(self, idea: str) -> str:\n        idea = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Preparing code generation (len={len(idea)})\")\n        if not idea:\n            # explicit deterministic fallback: small template that is valid Python\n            fallback = (\n                \"# No idea provided. Placeholder implementation\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", \"Used deterministic fallback for code\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python programmer. Produce clear, correct Python code for the task below.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Clean, testable code\\n\"\n            \"- Basic error handling when applicable\\n\"\n            \"- Short comments explaining non-obvious parts\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                result = await self.llm.ask(messages)\n            else:\n                result = f\"# Implementation for: {idea}\\n# [LLM not available - deterministic stub]\\n\"\n        except Exception as e:\n            result = f\"# Error generating code: {e}\\n\"\n        self._log(\"ACTION_END\", f\"Generated code (len={len(result)})\")\n        return result\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n    def __init__(self, *, context: Optional[Context] = None):\n        super().__init__(context=context)\n\n    async def run(self, code: str) -> str:\n        code = (code or \"\").strip()\n        self._log(\"ACTION_START\", f\"Preparing tests generation (code_len={len(code)})\")\n        if not code:\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", \"Used deterministic fallback for tests\")\n            return fallback\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided implementation.\\n\\n\"\n            f\"Code (first 2000 chars):\\n{code[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover typical and edge cases\\n\"\n            \"- Return only test code\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                result = await self.llm.ask(messages)\n            else:\n                result = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            result = f\"# Error generating tests: {e}\\n\"\n        self._log(\"ACTION_END\", f\"Generated tests (len={len(result)})\")\n        return result\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str, tests: str) -> str:\n        code = (code or \"\").strip()\n        tests = (tests or \"\").strip()\n        self._log(\"ACTION_START\", f\"Preparing review (code_len={len(code)}, tests_len={len(tests)}, human={self.is_human})\")\n        if self.is_human:\n            review = \"Human review: Looks good; consider adding more edge-case tests and clearer docstrings.\"\n            self._log(\"ACTION_END\", \"Produced human-like review\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review of the code and tests.\\n\\n\"\n            f\"Code (first 1500 chars):\\n{code[:1500]}\\n\\n\"\n            f\"Tests (first 1500 chars):\\n{tests[:1500]}\\n\\n\"\n            \"Focus on readability, possible bugs, test coverage, and simple suggestions. Keep it short.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                result = await self.llm.ask(messages)\n            else:\n                result = \"Automated review: Code structure acceptable. Consider more boundary tests.\"\n        except Exception as e:\n            result = f\"Review error: {e}\"\n        self._log(\"ACTION_END\", f\"Review generated (len={len(result)})\")\n        return result\n\nclass Role(ABC):\n    \"\"\"Simple role that holds one primary action and optional watch list.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = is_human\n        self.actions: List[Action] = []\n        # watch_list contains strings of cause_by values to react to\n        self.watch_list: List[str] = []\n        # env will be set by Team.hire\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        # Bind context into actions for safety\n        bound: List[Action] = []\n        for a in actions or []:\n            a.context = a.context or self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(event, self.name, details)\n            except Exception:\n                pass\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action deterministically and return a Message.\"\"\"\n        if not self.actions:\n            self._log(\"ROLE_SKIP\", \"No actions assigned\")\n            return None\n\n        action = self.actions[0]\n        self._log(\"ROLE_ACT\", f\"Action={action.name} MessageID={getattr(message, 'id', None)}\")\n\n        try:\n            if action.name == SimpleWriteCode.name:\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif action.name == SimpleWriteTest.name:\n                # prefer code from the provided message; otherwise look up last code in environment\n                code_text = getattr(message, \"content\", \"\") if message else \"\"\n                if not code_text and self.env:\n                    last_code = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(last_code, \"content\", \"\") if last_code else \"\"\n                result = await action.run(code_text)\n            elif action.name == SimpleWriteReview.name:\n                # assemble code and tests from environment history when possible\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    last_code = self.env.get_latest_by_cause(SimpleWriteCode.name)\n                    last_tests = self.env.get_latest_by_cause(SimpleWriteTest.name)\n                    code_text = getattr(last_code, \"content\", \"\") if last_code else \"\"\n                    tests_text = getattr(last_tests, \"content\", \"\") if last_tests else \"\"\n                # message may contain part of this too (use to fill gaps)\n                if message:\n                    if getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name and not code_text:\n                        code_text = getattr(message, \"content\", \"\")\n                    if getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name and not tests_text:\n                        tests_text = getattr(message, \"content\", \"\")\n                result = await action.run(code_text, tests_text)\n            else:\n                # generic fallback, pass content if available\n                arg = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(arg)\n        except Exception as e:\n            err = f\"Action {action.name} failed: {e}\"\n            self._log(\"ROLE_ERROR\", err)\n            result = err\n\n        # Construct response message safely for both pydantic and plain implementations\n        try:\n            response = Message(content=result, role=self.profile, cause_by=action.name, sent_from=self.name)\n        except Exception:\n            # fallback minimal object\n            class Mini:\n                pass\n            response = Mini()\n            response.content = result\n            response.role = self.profile\n            response.cause_by = action.name\n            response.sent_from = self.name\n\n        self._log(\"ROLE_COMPLETE\", f\"Produced message (len={len(result)})\")\n        return response\n\nclass SimpleCoder(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # coder listens to user input only (handled by Team)\n        self._watch([])\n\nclass SimpleTester(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Tracks roles and message history; provides helper queries used by roles.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            try:\n                self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n            except Exception:\n                pass\n\n    def publish_message(self, message: Message):\n        try:\n            self.history.append(message)\n        except Exception:\n            # safe append: wrap into simple message if necessary\n            try:\n                m = Message(content=str(getattr(message, \"content\", \"\")), role=getattr(message, \"role\", \"Unknown\"), cause_by=getattr(message, \"cause_by\", \"\"))\n                self.history.append(m)\n                message = m\n            except Exception:\n                return\n        if self.tracer:\n            try:\n                sender = getattr(message, \"sent_from\", \"Unknown\")\n                snippet = (getattr(message, \"content\", \"\") or \"\")[:100]\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"From {sender}: {snippet}\")\n            except Exception:\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches any entry in role.watch_list.\"\"\"\n        if not role.watch_list:\n            return []\n        watched = set(role.watch_list)\n        relevant: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant.append(msg)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_by_cause(self, cause: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with the given cause_by.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates roles, environment, and rounds in a deterministic and robust way.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure context tracer reference exists\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            try:\n                r.context = r.context or self.context\n                r.env = self.env\n                # ensure actions have context\n                for a in getattr(r, \"actions\", []):\n                    a.context = a.context or self.context\n            except Exception:\n                pass\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea or \"\"\n        try:\n            self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n        except Exception:\n            pass\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        try:\n            self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        except Exception:\n            pass\n\n        # Initial user message with instruct_content\n        initial = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for rnum in range(n_round):\n            try:\n                self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {rnum+1}/{n_round}\")\n            except Exception:\n                pass\n\n            # deterministic order: coder(s) first, then tester(s), then reviewer(s)\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    # coder responds to initial instruction on first round\n                    if rnum == 0 and any(getattr(a, \"name\", \"\") == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial)\n                    else:\n                        candidates = self.env.get_messages_for_role(role)\n                        if not candidates:\n                            continue\n                        response = await role.act(candidates[-1])\n\n                    if response:\n                        # ensure cause_by set\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.actions[0], \"name\", \"UnknownAction\")\n                        self.env.publish_message(response)\n                except Exception as e:\n                    try:\n                        self.tracer.log(\"ROLE_EXCEPTION\", role.name, f\"Exception while acting: {e}\")\n                    except Exception:\n                        pass\n                    continue\n\n            try:\n                self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {rnum+1} completed\")\n            except Exception:\n                pass\n\n        try:\n            self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n            summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n            self.tracer.log(\"SUMMARY\", \"Team\", summary)\n        except Exception:\n            pass\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n\n# Current Program\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never throws.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": content,\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        return Message(kwargs[\"content\"], kwargs[\"role\"],\n                       instruct_content=kwargs.get(\"instruct_content\"),\n                       cause_by=kwargs[\"cause_by\"],\n                       sent_from=kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Base action class with unified execution wrapper.\"\"\"\n    name: str = \"Action\"\n    \n    def __init__(self, **kwargs):\n        self.context: Optional[Context] = kwargs.get('context')\n        self.llm: Optional[LLMInterface] = None\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            try:\n                self.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self.llm = None\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result\"\"\"\n        raise NotImplementedError\n    \n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Unified execution wrapper for mapping message/environment to concrete action inputs.\n        Keeps logic central to reduce branching and failure surface.\n        \"\"\"\n        try:\n            if isinstance(self, SimpleWriteCode):\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            if isinstance(self, SimpleWriteTest):\n                # Prefer explicit code from message; otherwise grab latest code from env.\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                return await self.run(code)\n            if isinstance(self, SimpleWriteReview):\n                # Needs both code and tests; search env for latest items if missing.\n                tests = getattr(message, \"content\", \"\") if message else \"\"\n                code = getattr(message, \"instruct_content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                if not tests and env:\n                    latest_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    if latest_tests:\n                        tests = getattr(latest_tests, \"content\", \"\") or \"\"\n                return await self.run(code, tests)\n            # Fallback for unknown actions\n            return await self.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_EXCEPTION\", getattr(self, \"name\", \"Action\"), str(e))\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str = \"\") -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        idea_text = (idea or \"\").strip()\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Writing code for: {idea_text[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea_text}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception as exc:\\n\"\n                    \"        raise exc\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str = \"\") -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        \"\"\"Review the code and tests\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n                \n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n                \n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks reasonable. Tests cover main functionality; add more edge cases.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with simplified action handling\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context: Optional[Context] = kwargs.get('context')\n        self.is_human: bool = kwargs.get('is_human', False)\n        self.actions: List[Action] = []\n        # watch_list stores action names (strings) for simpler comparisons\n        self.watch_list: List[str] = []\n        # environment reference set by Team.hire\n        self.env: Optional[\"Environment\"] = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform (ensure action contexts are aligned)\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n            try:\n                if self.context:\n                    a.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                a.llm = None\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for. Accept types or names.\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = names\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action based on a message.\"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        \n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n        \n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # create action instances lazily with given context\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watch by action name to avoid fragile type checks\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        preview = \"\"\n        try:\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n        except Exception:\n            preview = \"\"\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {getattr(message, 'sent_from', 'unknown')}: {preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        watched = set(role.watch_list or [])\n        if not watched:\n            return relevant_messages\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n    \n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and ensure contexts for role actions are aligned\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env  # allow roles to inspect environment history\n            if hasattr(role, \"actions\"):\n                for a in role.actions:\n                    a.context = self.context\n                    try:\n                        a.llm = LLMInterface(self.context.config.llm)\n                    except Exception:\n                        a.llm = None\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        response = await role.act(initial_msg)\n                    else:\n                        # Other roles respond to relevant messages\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        response = await role.act(relevant_msgs[-1])\n                except Exception as e:\n                    self.tracer.log(\"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    response = None\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Safe logging helper that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str,\n                 role: str,\n                 cause_by: str = \"\",\n                 sent_from: Optional[str] = None,\n                 instruct_content: Optional[str] = None) -> Message:\n    \"\"\"\n    Robust factory to create Message objects compatible with both pydantic and fallback classes.\n    Accepts defaults for optional fields to reduce failure modes.\n    \"\"\"\n    kwargs = {\n        \"content\": content if content is not None else \"\",\n        \"role\": role if role is not None else \"\",\n        \"cause_by\": cause_by if cause_by is not None else \"\",\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        # Preferred construction for pydantic-based Message\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional/fallback Message constructor\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Final minimal fallback: simple object with expected attributes\n            class _M:\n                pass\n            m = _M()\n            m.id = str(uuid.uuid4())\n            m.content = kwargs[\"content\"]\n            m.instruct_content = kwargs.get(\"instruct_content\")\n            m.role = kwargs[\"role\"]\n            m.cause_by = kwargs[\"cause_by\"]\n            m.sent_from = kwargs[\"sent_from\"]\n            m.sent_to = None\n            m.send_to = set()\n            return m\n\nclass Action(ABC):\n    \"\"\"Minimal, robust action base with lazy LLM binding and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily instantiate LLMInterface if configuration exists.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code from a human idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Generating code for idea (len={len(idea_text)})\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Provide only the code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic safe fallback that is valid Python\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until an LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_snippet = (code or \"\")[:2000]\n        self._log(\"ACTION_START\", f\"Generating tests (code_len={len(code_snippet)})\")\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following code:\\n\\n\"\n            f\"Code:\\n{code_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain each test\\n\\n\"\n            \"Provide only the test code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide a concise review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\")[:1500]\n        tests_text = (tests or \"\")[:1500]\n        self._log(\"ACTION_START\", f\"Reviewing (human={self.is_human}) code_len={len(code_text)} tests_len={len(tests_text)}\")\n        try:\n            if self.is_human:\n                review = \"Human review: Looks generally good. Consider additional error handling and edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_text}\\n\\n\"\n                    f\"Tests:\\n{tests_text}\\n\\n\"\n                    \"Give a concise review focusing on code quality, test coverage, potential bugs and suggestions.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable. Add more edge-case coverage and clearer exceptions.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        self._log(\"ACTION_END\", f\"Review length={len(review)}\")\n        return review\n\nclass Role:\n    \"\"\"Lightweight role holding a single primary action and a watch list of cause_by tokens.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains strings matching Message.cause_by\n        self.watch_list: Set[str] = set()\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Bind provided action instances and ensure context alignment.\"\"\"\n        bound: List[Action] = []\n        for a in (actions or []):\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: Set[str] = set()\n        for a in (actions or []):\n            if isinstance(a, str):\n                names.add(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Run the primary action and return a Message result or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        try:\n            # Routing: map messages/environment to action inputs deterministically and simply\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code from the triggering message (if any); else fetch latest code from env\n                code = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code = getattr(message, \"content\", \"\") or \"\"\n                if not code and self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Gather best-effort code and tests from env or message\n                code = \"\"\n                tests = \"\"\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    tests = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                if message:\n                    tests = tests or getattr(message, \"content\", \"\") or \"\"\n                    code = code or getattr(message, \"instruct_content\", \"\") or \"\"\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, f\"Created message id={getattr(response, 'id', None)}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration: holds roles and messages and provides simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        try:\n            role.env = self\n        except Exception:\n            role.env = None\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        \"\"\"Append a message to history and log a short preview. Be resilient to message shape.\"\"\"\n        try:\n            # Ensure id exists where possible\n            if not getattr(message, \"id\", None):\n                try:\n                    message.id = str(uuid.uuid4())\n                except Exception:\n                    pass\n            self.history.append(message)\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n            sender = getattr(message, \"sent_from\", \"unknown\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n        except Exception:\n            # Try to normalize and store minimal message\n            try:\n                minimal = make_message(\n                    content=str(getattr(message, \"content\", \"\") or \"\"),\n                    role=getattr(message, \"role\", \"Unknown\"),\n                    cause_by=getattr(message, \"cause_by\", \"\"),\n                    sent_from=getattr(message, \"sent_from\", \"unknown\")\n                )\n                self.history.append(minimal)\n            except Exception:\n                # give up silently to avoid propagation\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches anything in the role's watch_list, preserving order.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        relevant: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant.append(msg)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by, or None.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates a group of roles to collaborate for n rounds with robust handling.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure tracer accessible via context, but don't fail if not allowed\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Add roles to the team and align contexts and environments.\"\"\"\n        for role in roles:\n            try:\n                role.context = role.context or self.context\n                role.env = self.env\n                # Ensure action instances are context-aware\n                for a in getattr(role, \"actions\", []) or []:\n                    a.context = a.context or self.context\n            except Exception:\n                pass\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea or \"\"\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message (user instruction)\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_idx in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_idx + 1}/{n_round}\")\n            # Deterministic iteration order of roles\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    # First round: let coder(s) respond to initial input\n                    if round_idx == 0 and any(a.name == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        latest = relevant[-1]\n                        response = await role.act(latest)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_idx + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}