{"id": "7e205c81-734c-42d8-be65-ca76f68acd2b_migrant_0", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never throws.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": content,\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        return Message(kwargs[\"content\"], kwargs[\"role\"],\n                       instruct_content=kwargs.get(\"instruct_content\"),\n                       cause_by=kwargs[\"cause_by\"],\n                       sent_from=kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Base action class with unified execution wrapper.\"\"\"\n    name: str = \"Action\"\n    \n    def __init__(self, **kwargs):\n        self.context: Optional[Context] = kwargs.get('context')\n        self.llm: Optional[LLMInterface] = None\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            try:\n                self.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self.llm = None\n    \n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Run the action and return a string result\"\"\"\n        raise NotImplementedError\n    \n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Unified execution wrapper for mapping message/environment to concrete action inputs.\n        Keeps logic central to reduce branching and failure surface.\n        \"\"\"\n        try:\n            if isinstance(self, SimpleWriteCode):\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            if isinstance(self, SimpleWriteTest):\n                # Prefer explicit code from message; otherwise grab latest code from env.\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                return await self.run(code)\n            if isinstance(self, SimpleWriteReview):\n                # Needs both code and tests; search env for latest items if missing.\n                tests = getattr(message, \"content\", \"\") if message else \"\"\n                code = getattr(message, \"instruct_content\", \"\") if message else \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                if not tests and env:\n                    latest_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    if latest_tests:\n                        tests = getattr(latest_tests, \"content\", \"\") or \"\"\n                return await self.run(code, tests)\n            # Fallback for unknown actions\n            return await self.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_EXCEPTION\", getattr(self, \"name\", \"Action\"), str(e))\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str = \"\") -> str:\n        \"\"\"Generate code based on the idea\"\"\"\n        idea_text = (idea or \"\").strip()\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Writing code for: {idea_text[:100]}\")\n        \n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea_text}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception as exc:\\n\"\n                    \"        raise exc\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str = \"\") -> str:\n        \"\"\"Generate tests for the given code\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, \"Writing tests for code\")\n        \n        snippet = (code or \"\")[:2000]\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}  # Truncate if too long\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = is_human\n    \n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        \"\"\"Review the code and tests\"\"\"\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n        \n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{(code or '')[:1500]}\n\nTests:\n{(tests or '')[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n                \n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n                \n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks reasonable. Tests cover main functionality; add more edge cases.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Review completed: {len(review)} characters\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with simplified action handling\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    \n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context: Optional[Context] = kwargs.get('context')\n        self.is_human: bool = kwargs.get('is_human', False)\n        self.actions: List[Action] = []\n        # watch_list stores action names (strings) for simpler comparisons\n        self.watch_list: List[str] = []\n        # environment reference set by Team.hire\n        self.env: Optional[\"Environment\"] = None\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform (ensure action contexts are aligned)\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n            try:\n                if self.context:\n                    a.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                a.llm = None\n    \n    def _watch(self, actions: List[Type[Action]]):\n        \"\"\"Set the actions this role watches for. Accept types or names.\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = names\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action based on a message.\"\"\"\n        if not self.actions:\n            return None\n        \n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        \n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n        \n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        \n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # create action instances lazily with given context\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watch by action name to avoid fragile type checks\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return self.roles\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        self.history.append(message)\n        preview = \"\"\n        try:\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n        except Exception:\n            preview = \"\"\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {getattr(message, 'sent_from', 'unknown')}: {preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to\"\"\"\n        relevant_messages: List[Message] = []\n        watched = set(role.watch_list or [])\n        if not watched:\n            return relevant_messages\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n    \n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team and ensure contexts for role actions are aligned\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env  # allow roles to inspect environment history\n            if hasattr(role, \"actions\"):\n                for a in role.actions:\n                    a.context = self.context\n                    try:\n                        a.llm = LLMInterface(self.context.config.llm)\n                    except Exception:\n                        a.llm = None\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Each role acts in sequence\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        # Coder responds to initial message\n                        response = await role.act(initial_msg)\n                    else:\n                        # Other roles respond to relevant messages\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        response = await role.act(relevant_msgs[-1])\n                except Exception as e:\n                    self.tracer.log(\"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    response = None\n                \n                if response:\n                    self.env.publish_message(response)\n            \n            self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        self.tracer.log(\"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "7e205c81-734c-42d8-be65-ca76f68acd2b", "generation": 2, "timestamp": 1754647500.2914164, "iteration_found": 0, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 0, "migrant": true}, "artifacts_json": null, "artifact_dir": null}