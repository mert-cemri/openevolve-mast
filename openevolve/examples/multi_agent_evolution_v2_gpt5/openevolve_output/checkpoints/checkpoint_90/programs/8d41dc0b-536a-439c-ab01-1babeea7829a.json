{"id": "8d41dc0b-536a-439c-ab01-1babeea7829a", "code": "# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event: str, agent: str, details: str):\n    \"\"\"Best-effort logging helper that never raises.\"\"\"\n    if not tracer:\n        return\n    try:\n        tracer.log(event, agent, details)\n    except Exception:\n        pass\n\ndef _ensure_str(s: Optional[str]) -> str:\n    \"\"\"Convert possibly None or non-string to a safe string.\"\"\"\n    if s is None:\n        return \"\"\n    try:\n        return str(s)\n    except Exception:\n        return \"\"\n\nclass Action(ABC):\n    \"\"\"Simplified base Action with safe llm access and logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg is not None and getattr(cfg, \"llm\", None) is not None:\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate code for the provided idea/requirements.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea = _ensure_str(idea).strip()\n        self._log(\"ACTION_START\", f\"len_idea={len(idea)}\")\n        if not idea:\n            # Deterministic fallback to reduce variability/failure\n            fallback = (\n                \"# No idea provided. Placeholder implementation\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder solution.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python programmer. Write clean, testable Python code for the task below.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Clean, testable code\\n\"\n            \"- Basic error handling\\n\"\n            \"- Short comments for non-obvious parts\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = f\"# Implementation for: {idea}\\n# [LLM unavailable - fallback placeholder]\\n\"\n        except Exception as e:\n            code = f\"# Error generating code: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for given code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code = _ensure_str(code)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}\")\n        if not code.strip():\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the implementation below.\\n\\n\"\n            f\"Code (first 2000 chars):\\n{code[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover normal and edge cases\\n\"\n            \"- Include docstrings\\n\\n\"\n            \"Return only the test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide concise human-like or automated review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code = _ensure_str(code)\n        tests = _ensure_str(tests)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}, tests_len={len(tests)}, human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Looks good overall. Consider adding more edge-case tests and clearer docstrings.\"\n            self._log(\"ACTION_END\", \"human_review\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review of the code and tests.\\n\\n\"\n            f\"Code (first 1500 chars):\\n{code[:1500]}\\n\\n\"\n            f\"Tests (first 1500 chars):\\n{tests[:1500]}\\n\\n\"\n            \"Focus on readability, potential bugs, and test coverage. Be concise.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Automated review: Code structure acceptable. Add more boundary and negative-case tests.\"\n        except Exception as e:\n            review = f\"Review error: {e}\"\n        self._log(\"ACTION_END\", f\"generated_len={len(review)}\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Simple role abstraction with deterministic action selection.\"\"\"\n    def __init__(self, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = is_human\n        # single primary action instance per role\n        self.action: Optional[Action] = None\n        # watch_list: cause_by strings this role should respond to\n        self.watch_list: List[str] = []\n        # environment reference set when hired\n        self.env: Optional[\"Environment\"] = None\n\n    def set_action(self, action: Action):\n        # ensure action knows context\n        if getattr(action, \"context\", None) is None:\n            action.context = self.context\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, self.name, details)\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action using a small set of explicit, deterministic rules.\"\"\"\n        if not self.action:\n            self._log(\"ROLE_SKIP\", \"no_action\")\n            return None\n\n        self._log(\"ROLE_ACT\", f\"action={getattr(self.action, 'name', 'unknown')}, msg_id={getattr(message, 'id', None)}\")\n\n        try:\n            # Determine inputs in priority: explicit message -> env latest -> fallback\n            if getattr(self.action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await self.action.run(idea or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteTest.name:\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\")\n                elif self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await self.action.run(code_text or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteReview.name:\n                # prefer tests from triggering message and code from latest code message\n                tests_text = \"\"\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                    tests_text = getattr(message, \"content\", \"\")\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    if not tests_text:\n                        latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests_text = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                # Generic fallback: pass message content or empty string\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await self.action.run(payload)\n        except Exception as e:\n            err = f\"Action failed: {e}\"\n            self._log(\"ROLE_ERROR\", err)\n            result = err\n\n        # Construct a Message for response; keep compatible with both pydantic and fallback Message\n        try:\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=getattr(self.action, \"name\", \"\"),\n                sent_from=self.name\n            )\n        except Exception:\n            class _Mini:\n                pass\n            response = _Mini()\n            response.id = str(uuid.uuid4())\n            response.content = result\n            response.instruct_content = None\n            response.role = self.profile\n            response.cause_by = getattr(self.action, \"name\", \"\")\n            response.sent_from = self.name\n\n        self._log(\"ROLE_COMPLETE\", f\"produced_len={len(_ensure_str(result))}\")\n        return response\n\nclass SimpleCoder(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Alice\"), profile=kwargs.get(\"profile\", \"SimpleCoder\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # responds to initial user instruction\n\nclass SimpleTester(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Bob\"), profile=kwargs.get(\"profile\", \"SimpleTester\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Charlie\"), profile=kwargs.get(\"profile\", \"SimpleReviewer\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Lightweight environment for storing messages and providing simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role={role.name}\")\n\n    def publish_message(self, message: Message):\n        # Ensure message has id where possible and append; log safely\n        try:\n            if not hasattr(message, \"id\") or getattr(message, \"id\", None) is None:\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={getattr(message, 'sent_from', 'Unknown')} cause={getattr(message, 'cause_by', '')} preview={_ensure_str(getattr(message, 'content', ''))[:100]}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by is in role.watch_list (in chronological order).\"\"\"\n        if not role.watch_list:\n            return []\n        watched = set(role.watch_list)\n        result: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    result.append(msg)\n            except Exception:\n                continue\n        return result\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates roles to collaborate on an idea. Simple, deterministic and robust.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # Ensure context has tracer reference\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            # Bind team context and environment to roles and their actions\n            r.context = r.context or self.context\n            r.env = self.env\n            if getattr(r, \"action\", None):\n                try:\n                    r.action.context = r.action.context or self.context\n                except Exception:\n                    pass\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = float(investment)\n\n    def run_project(self, idea: str):\n        self.idea = _ensure_str(idea)\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running rounds={n_round}\")\n\n        # Initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        # Deterministic order: as added\n        for rnum in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"round={rnum+1}/{n_round}\")\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    # Give coder the initial message on first round\n                    if rnum == 0 and getattr(role.action, \"name\", \"\") == SimpleWriteCode.name:\n                        response = await role.act(initial_msg)\n                    else:\n                        candidates = self.env.get_messages_for_role(role)\n                        if not candidates:\n                            continue\n                        # Act on the most recent relevant message\n                        response = await role.act(candidates[-1])\n\n                    if response:\n                        # ensure cause_by present\n                        try:\n                            if not getattr(response, \"cause_by\", None):\n                                response.cause_by = getattr(role.action, \"name\", \"\") or \"\"\n                        except Exception:\n                            pass\n                        self.env.publish_message(response)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    # continue with next role despite errors\n                    continue\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"round={rnum+1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "9e8d9a3a-6d6c-4cdd-a268-9295694b06e2_migrant_2", "generation": 4, "timestamp": 1754649024.158546, "iteration_found": 85, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are an expert software architect specializing in multi-agent systems.\nRewrite the program inside the EVOLVE-BLOCK to reduce failure modes.\n\nCRITICAL OUTPUT RULES:\n- Output ONLY a single fenced code block labeled \"python\".\n- The block must contain the ENTIRE rewritten file (not just the block).\n- Preserve all imports and non-evolved infrastructure.\n- Keep the EVOLVE-BLOCK-START and EVOLVE-BLOCK-END markers.\n- Do NOT include any text outside the code block.\n", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 0.5000\n- overall_score: 0.2500\n- combined_score: 0.1000\n- avg_failures_per_task: 12.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 0.5000, overall_score: 0.2500, combined_score: 0.1000, avg_failures_per_task: 12.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Safe logging helper that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str,\n                 role: str,\n                 cause_by: str = \"\",\n                 sent_from: Optional[str] = None,\n                 instruct_content: Optional[str] = None) -> Message:\n    \"\"\"\n    Robust factory to create Message objects compatible with both pydantic and fallback classes.\n    Accepts defaults for optional fields to reduce failure modes.\n    \"\"\"\n    kwargs = {\n        \"content\": content if content is not None else \"\",\n        \"role\": role if role is not None else \"\",\n        \"cause_by\": cause_by if cause_by is not None else \"\",\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        # Preferred construction for pydantic-based Message\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional/fallback Message constructor\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Final minimal fallback: simple object with expected attributes\n            class _M:\n                pass\n            m = _M()\n            m.id = str(uuid.uuid4())\n            m.content = kwargs[\"content\"]\n            m.instruct_content = kwargs.get(\"instruct_content\")\n            m.role = kwargs[\"role\"]\n            m.cause_by = kwargs[\"cause_by\"]\n            m.sent_from = kwargs[\"sent_from\"]\n            m.sent_to = None\n            m.send_to = set()\n            return m\n\nclass Action(ABC):\n    \"\"\"Minimal, robust action base with lazy LLM binding and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily instantiate LLMInterface if configuration exists.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code from a human idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Generating code for idea (len={len(idea_text)})\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Provide only the code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic safe fallback that is valid Python\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until an LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_snippet = (code or \"\")[:2000]\n        self._log(\"ACTION_START\", f\"Generating tests (code_len={len(code_snippet)})\")\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following code:\\n\\n\"\n            f\"Code:\\n{code_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain each test\\n\\n\"\n            \"Provide only the test code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide a concise review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\")[:1500]\n        tests_text = (tests or \"\")[:1500]\n        self._log(\"ACTION_START\", f\"Reviewing (human={self.is_human}) code_len={len(code_text)} tests_len={len(tests_text)}\")\n        try:\n            if self.is_human:\n                review = \"Human review: Looks generally good. Consider additional error handling and edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_text}\\n\\n\"\n                    f\"Tests:\\n{tests_text}\\n\\n\"\n                    \"Give a concise review focusing on code quality, test coverage, potential bugs and suggestions.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable. Add more edge-case coverage and clearer exceptions.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        self._log(\"ACTION_END\", f\"Review length={len(review)}\")\n        return review\n\nclass Role:\n    \"\"\"Lightweight role holding a single primary action and a watch list of cause_by tokens.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains strings matching Message.cause_by\n        self.watch_list: Set[str] = set()\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Bind provided action instances and ensure context alignment.\"\"\"\n        bound: List[Action] = []\n        for a in (actions or []):\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: Set[str] = set()\n        for a in (actions or []):\n            if isinstance(a, str):\n                names.add(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Run the primary action and return a Message result or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        try:\n            # Routing: map messages/environment to action inputs deterministically and simply\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code from the triggering message (if any); else fetch latest code from env\n                code = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code = getattr(message, \"content\", \"\") or \"\"\n                if not code and self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Gather best-effort code and tests from env or message\n                code = \"\"\n                tests = \"\"\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    tests = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                if message:\n                    tests = tests or getattr(message, \"content\", \"\") or \"\"\n                    code = code or getattr(message, \"instruct_content\", \"\") or \"\"\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, f\"Created message id={getattr(response, 'id', None)}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration: holds roles and messages and provides simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        try:\n            role.env = self\n        except Exception:\n            role.env = None\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        \"\"\"Append a message to history and log a short preview. Be resilient to message shape.\"\"\"\n        try:\n            # Ensure id exists where possible\n            if not getattr(message, \"id\", None):\n                try:\n                    message.id = str(uuid.uuid4())\n                except Exception:\n                    pass\n            self.history.append(message)\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n            sender = getattr(message, \"sent_from\", \"unknown\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n        except Exception:\n            # Try to normalize and store minimal message\n            try:\n                minimal = make_message(\n                    content=str(getattr(message, \"content\", \"\") or \"\"),\n                    role=getattr(message, \"role\", \"Unknown\"),\n                    cause_by=getattr(message, \"cause_by\", \"\"),\n                    sent_from=getattr(message, \"sent_from\", \"unknown\")\n                )\n                self.history.append(minimal)\n            except Exception:\n                # give up silently to avoid propagation\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches anything in the role's watch_list, preserving order.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        relevant: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant.append(msg)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by, or None.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates a group of roles to collaborate for n rounds with robust handling.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure tracer accessible via context, but don't fail if not allowed\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Add roles to the team and align contexts and environments.\"\"\"\n        for role in roles:\n            try:\n                role.context = role.context or self.context\n                role.env = self.env\n                # Ensure action instances are context-aware\n                for a in getattr(role, \"actions\", []) or []:\n                    a.context = a.context or self.context\n            except Exception:\n                pass\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea or \"\"\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message (user instruction)\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_idx in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_idx + 1}/{n_round}\")\n            # Deterministic iteration order of roles\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    # First round: let coder(s) respond to initial input\n                    if round_idx == 0 and any(a.name == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        latest = relevant[-1]\n                        response = await role.act(latest)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_idx + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n### Program 2 (Score: 3.2125)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event: str, agent: str, details: str):\n    \"\"\"Best-effort logging helper that never raises.\"\"\"\n    if not tracer:\n        return\n    try:\n        tracer.log(event, agent, details)\n    except Exception:\n        pass\n\ndef _ensure_str(s: Optional[str]) -> str:\n    \"\"\"Convert possibly None or non-string to a safe string.\"\"\"\n    if s is None:\n        return \"\"\n    try:\n        return str(s)\n    except Exception:\n        return \"\"\n\nclass Action(ABC):\n    \"\"\"Simplified base Action with safe llm access and logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg is not None and getattr(cfg, \"llm\", None) is not None:\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate code for the provided idea/requirements.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea = _ensure_str(idea).strip()\n        self._log(\"ACTION_START\", f\"len_idea={len(idea)}\")\n        if not idea:\n            # Deterministic fallback to reduce variability/failure\n            fallback = (\n                \"# No idea provided. Placeholder implementation\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder solution.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python programmer. Write clean, testable Python code for the task below.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Clean, testable code\\n\"\n            \"- Basic error handling\\n\"\n            \"- Short comments for non-obvious parts\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = f\"# Implementation for: {idea}\\n# [LLM unavailable - fallback placeholder]\\n\"\n        except Exception as e:\n            code = f\"# Error generating code: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for given code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code = _ensure_str(code)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}\")\n        if not code.strip():\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the implementation below.\\n\\n\"\n            f\"Code (first 2000 chars):\\n{code[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover normal and edge cases\\n\"\n            \"- Include docstrings\\n\\n\"\n            \"Return only the test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide concise human-like or automated review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code = _ensure_str(code)\n        tests = _ensure_str(tests)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}, tests_len={len(tests)}, human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Looks good overall. Consider adding more edge-case tests and clearer docstrings.\"\n            self._log(\"ACTION_END\", \"human_review\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review of the code and tests.\\n\\n\"\n            f\"Code (first 1500 chars):\\n{code[:1500]}\\n\\n\"\n            f\"Tests (first 1500 chars):\\n{tests[:1500]}\\n\\n\"\n            \"Focus on readability, potential bugs, and test coverage. Be concise.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Automated review: Code structure acceptable. Add more boundary and negative-case tests.\"\n        except Exception as e:\n            review = f\"Review error: {e}\"\n        self._log(\"ACTION_END\", f\"generated_len={len(review)}\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Simple role abstraction with deterministic action selection.\"\"\"\n    def __init__(self, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = is_human\n        # single primary action instance per role\n        self.action: Optional[Action] = None\n        # watch_list: cause_by strings this role should respond to\n        self.watch_list: List[str] = []\n        # environment reference set when hired\n        self.env: Optional[\"Environment\"] = None\n\n    def set_action(self, action: Action):\n        # ensure action knows context\n        if getattr(action, \"context\", None) is None:\n            action.context = self.context\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, self.name, details)\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action using a small set of explicit, deterministic rules.\"\"\"\n        if not self.action:\n            self._log(\"ROLE_SKIP\", \"no_action\")\n            return None\n\n        self._log(\"ROLE_ACT\", f\"action={getattr(self.action, 'name', 'unknown')}, msg_id={getattr(message, 'id', None)}\")\n\n        try:\n            # Determine inputs in priority: explicit message -> env latest -> fallback\n            if getattr(self.action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await self.action.run(idea or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteTest.name:\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\")\n                elif self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await self.action.run(code_text or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteReview.name:\n                # prefer tests from triggering message and code from latest code message\n                tests_text = \"\"\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                    tests_text = getattr(message, \"content\", \"\")\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    if not tests_text:\n                        latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests_text = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                # Generic fallback: pass message content or empty string\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await self.action.run(payload)\n        except Exception as e:\n            err = f\"Action failed: {e}\"\n            self._log(\"ROLE_ERROR\", err)\n            result = err\n\n        # Construct a Message for response; keep compatible with both pydantic and fallback Message\n        try:\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=getattr(self.action, \"name\", \"\"),\n                sent_from=self.name\n            )\n        except Exception:\n            class _Mini:\n                pass\n            response = _Mini()\n            response.id = str(uuid.uuid4())\n            response.content = result\n            response.instruct_content = None\n            response.role = self.profile\n            response.cause_by = getattr(self.action, \"name\", \"\")\n            response.sent_from = self.name\n\n        self._log(\"ROLE_COMPLETE\", f\"produced_len={len(_ensure_str(result))}\")\n        return response\n\nclass SimpleCoder(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Alice\"), profile=kwargs.get(\"profile\", \"SimpleCoder\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # responds to initial user instruction\n\nclass SimpleTester(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Bob\"), profile=kwargs.get(\"profile\", \"SimpleTester\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Charlie\"), profile=kwargs.get(\"profile\", \"SimpleReviewer\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Lightweight environment for storing messages and providing simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role={role.name}\")\n\n    def publish_message(self, message: Message):\n        # Ensure message has id where possible and append; log safely\n        try:\n            if not hasattr(message, \"id\") or getattr(message, \"id\", None) is None:\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={getattr(message, 'sent_from', 'Unknown')} cause={getattr(message, 'cause_by', '')} preview={_ensure_str(getattr(message, 'content', ''))[:100]}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by is in role.watch_list (in chronological order).\"\"\"\n        if not role.watch_list:\n            return []\n        watched = set(role.watch_list)\n        result: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    result.append(msg)\n            except Exception:\n                continue\n        return result\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates roles to collaborate on an idea. Simple, deterministic and robust.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # Ensure context has tracer reference\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            # Bind team context and environment to roles and their actions\n            r.context = r.context or self.context\n            r.env = self.env\n            if getattr(r, \"action\", None):\n                try:\n                    r.action.context = r.action.context or self.context\n                except Exception:\n                    pass\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = float(investment)\n\n    def run_project(self, idea: str):\n        self.idea = _ensure_str(idea)\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running rounds={n_round}\")\n\n        # Initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        # Deterministic order: as added\n        for rnum in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"round={rnum+1}/{n_round}\")\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    # Give coder the initial message on first round\n                    if rnum == 0 and getattr(role.action, \"name\", \"\") == SimpleWriteCode.name:\n                        response = await role.act(initial_msg)\n                    else:\n                        candidates = self.env.get_messages_for_role(role)\n                        if not candidates:\n                            continue\n                        # Act on the most recent relevant message\n                        response = await role.act(candidates[-1])\n\n                    if response:\n                        # ensure cause_by present\n                        try:\n                            if not getattr(response, \"cause_by\", None):\n                                response.cause_by = getattr(role.action, \"name\", \"\") or \"\"\n                        except Exception:\n                            pass\n                        self.env.publish_message(response)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    # continue with next role despite errors\n                    continue\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"round={rnum+1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Performs well on runs_successfully (0.5000), Performs well on overall_score (0.2500), Performs well on combined_score (0.1000), Performs well on avg_failures_per_task (12.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type, Union\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Robust string conversion that never raises.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        if isinstance(x, str):\n            return x\n        return str(x)\n    except Exception:\n        return \"\"\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef _make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback Message.\"\"\"\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": role,\n        \"cause_by\": _safe_str(cause_by),\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = _safe_str(instruct_content)\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional for non-pydantic Message\n        return Message(kwargs[\"content\"], kwargs[\"role\"],\n                       instruct_content=kwargs.get(\"instruct_content\"),\n                       cause_by=kwargs[\"cause_by\"],\n                       sent_from=kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Minimal robust base action with safe logging and a unified execute mapping.\"\"\"\n    name: str = \"Action\"\n    \n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily initialize LLM, swallow any errors.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg is not None and getattr(cfg, \"llm\", None) is not None:\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Perform the concrete action and return a textual result.\"\"\"\n        raise NotImplementedError\n\n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Central mapping from environment/message to action inputs.\n        Keeps logic small and explicit to reduce failure modes.\n        \"\"\"\n        try:\n            if isinstance(self, SimpleWriteCode):\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            if isinstance(self, SimpleWriteTest):\n                code = \"\"\n                if message:\n                    # if directly triggered by coder output, use its content\n                    if getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                        code = getattr(message, \"content\", \"\") or \"\"\n                    else:\n                        code = getattr(message, \"content\", \"\") or \"\"\n                if not code and env:\n                    latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest_code:\n                        code = getattr(latest_code, \"content\", \"\") or \"\"\n                return await self.run(code)\n            if isinstance(self, SimpleWriteReview):\n                code = \"\"\n                tests = \"\"\n                # Prefer tests from triggering message if it is from tester\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                    tests = getattr(message, \"content\", \"\") or \"\"\n                # Look up latest code and tests in the environment as needed\n                if env:\n                    if not code:\n                        last_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                        if last_code:\n                            code = getattr(last_code, \"content\", \"\") or code\n                    if not tests:\n                        last_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        if last_tests:\n                            tests = getattr(last_tests, \"content\", \"\") or tests\n                return await self.run(code, tests)\n            # Generic fallback\n            return await self.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            self._log(\"ACTION_EXCEPTION\", f\"{e}\")\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n    \n    async def run(self, idea: str) -> str:\n        idea = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"idea_len={len(idea)}\")\n        # Deterministic fallback when idea missing\n        if not idea:\n            fallback = (\n                \"# No task provided. Placeholder implementation.\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder solution.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback_code\")\n            return fallback\n\n        prompt = (\n            \"You are a professional Python programmer. \"\n            \"Write robust, well-documented Python code for the following task.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Clean, functional Python code\\n\"\n            \"- Proper error handling\\n\"\n            \"- Comments for non-obvious logic\\n\"\n            \"- Focus on correctness and clarity\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = f\"# Implementation for: {idea}\\n# [LLM not available - stub]\\n\"\n        except Exception as e:\n            code = f\"# Error generating code: {e}\\n\"\n        self._log(\"ACTION_END\", f\"code_len={len(code)}\")\n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n    \n    async def run(self, code: str) -> str:\n        code = (code or \"\").strip()\n        self._log(\"ACTION_START\", f\"code_len={len(code)}\")\n        if not code:\n            # Deterministic fallback tests\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Always true placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback_tests\")\n            return fallback\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided Python code.\\n\\n\"\n            f\"Code (first 2000 chars):\\n{code[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover normal and edge cases\\n\"\n            \"- Include brief docstrings for each test\\n\\n\"\n            \"Return only the test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\\n\"\n        self._log(\"ACTION_END\", f\"tests_len={len(tests)}\")\n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n    \n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n    \n    async def run(self, code: str, tests: str) -> str:\n        code = (code or \"\").strip()\n        tests = (tests or \"\").strip()\n        self._log(\"ACTION_START\", f\"code_len={len(code)} tests_len={len(tests)} human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Looks reasonable. Add edge-case tests and clarify error messages.\"\n            self._log(\"ACTION_END\", f\"review_len={len(review)}\")\n            return review\n\n        prompt = (\n            \"You are a senior software engineer. Provide a concise, actionable review of the code and its tests.\\n\\n\"\n            f\"Code (first 1500 chars):\\n{code[:1500]}\\n\\n\"\n            f\"Tests (first 1500 chars):\\n{tests[:1500]}\\n\\n\"\n            \"Focus on readability, potential bugs, test coverage, and simple improvements.\\n\"\n            \"Return only the review text.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Automated review: Structure OK. Consider more boundary tests and clearer error handling.\"\n        except Exception as e:\n            review = f\"Review generation error: {e}\"\n        self._log(\"ACTION_END\", f\"review_len={len(review)}\")\n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Base role class for agents with simplified mapping and robust logging.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n    \n    def __init__(self, *, name: Optional[str] = None, profile: Optional[str] = None, context: Optional[Context] = None, env: Optional[\"Environment\"] = None, is_human: bool = False):\n        self.name = name or self.name\n        self.profile = profile or self.profile\n        self.context = context\n        self.env = env  # environment reference (set by Team.hire)\n        self.is_human = is_human\n        self.actions: List[Action] = []\n        # watch_list stores action names (strings) that this role reacts to\n        self.watch_list: List[str] = []\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, self.name, details)\n    \n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform\"\"\"\n        self.actions = list(actions or [])\n    \n    def _watch(self, actions: List[Union[Type[Action], str]]):\n        \"\"\"Set the actions (by class or name) this role watches for\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"__name__\"):\n                names.append(a.__name__)\n        self.watch_list = [n for n in names if n]\n    \n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the first available action based on the message.\"\"\"\n        if not self.actions:\n            self._log(\"ROLE_NOP\", \"No actions assigned\")\n            return None\n        \n        action = self.actions[0]\n        self._log(\"ROLE_ACT\", f\"action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        \n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            self._log(\"ROLE_ERROR\", f\"{e}\")\n            result = f\"Error in role {self.name}: {e}\"\n        \n        # Build response message robustly\n        response = _make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"Action\"),\n            sent_from=self.name\n        )\n        self._log(\"ROLE_COMPLETE\", f\"produced_len={len(_safe_str(result))}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder is triggered by user input; not watching other actions\n        self._watch([])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n    \n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment\"\"\"\n        self.roles.append(role)\n        # Provide environment reference to role\n        role.env = self\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n    \n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n    \n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        try:\n            self.history.append(message)\n        except Exception:\n            # last-resort: wrap into a minimal Message\n            try:\n                minimal = _make_message(\n                    content=_safe_str(getattr(message, \"content\", \"\")),\n                    role=_safe_str(getattr(message, \"role\", \"Unknown\")),\n                    cause_by=_safe_str(getattr(message, \"cause_by\", \"\")),\n                    sent_from=_safe_str(getattr(message, \"sent_from\", \"Unknown\"))\n                )\n                self.history.append(minimal)\n                message = minimal\n            except Exception:\n                return\n        preview = (_safe_str(getattr(message, \"content\", \"\")) or \"\")[:100]\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={getattr(message, 'sent_from', 'Unknown')} preview={preview}\")\n    \n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to based on its watch_list.\"\"\"\n        if not role.watch_list:\n            return []\n        relevant_messages: List[Message] = []\n        watched = set(role.watch_list)\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n    \n    def get_latest_message_by_cause(self, cause_by: str) -> Optional[Message]:\n        \"\"\"Return the most recent message whose cause_by equals the provided string.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_by:\n                    return msg\n            except Exception:\n                continue\n        return None\n\n    # Convenience alias used by some role logic variants\n    def get_latest_by_cause(self, cause_by: str) -> Optional[Message]:\n        return self.get_latest_message_by_cause(cause_by)\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        self.context.tracer = self.tracer\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n    \n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team\"\"\"\n        for role in roles:\n            # Ensure role has shared context and environment\n            role.context = self.context\n            role.env = self.env\n            # Refresh actions to ensure bound context and fresh LLM handles\n            refreshed: List[Action] = []\n            for a in getattr(role, \"actions\", []) or []:\n                try:\n                    refreshed.append(a.__class__(context=self.context, is_human=getattr(a, \"is_human\", False)))\n                except Exception:\n                    try:\n                        a.context = self.context\n                        refreshed.append(a)\n                    except Exception:\n                        continue\n            if refreshed:\n                role.set_actions(refreshed)\n            self.env.add_role(role)\n    \n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n    \n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n    \n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        \n        # Initial message with the idea (from user)\n        initial_msg = _make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n        \n        for round_num in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            \n            # Snapshot roles to avoid issues if list changes during iteration\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    # First round: coder responds to the initial user input\n                    if round_num == 0 and any(getattr(a, \"name\", \"\") == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial_msg)\n                    else:\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        # Act on the most recent relevant message\n                        response = await role.act(relevant_msgs[-1])\n                except Exception as e:\n                    _safe_log(self.tracer, \"TEAM_ROLE_ERROR\", role.name, f\"{e}\")\n                    response = None\n                \n                if response:\n                    # Ensure cause_by is present\n                    try:\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.actions[0], \"name\", \"UnknownAction\")\n                    except Exception:\n                        pass\n                    self.env.publish_message(response)\n            \n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n        \n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        \n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D2 (Score: 3.2125)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Safe string conversion that never raises.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        if isinstance(x, str):\n            return x\n        return str(x)\n    except Exception:\n        return \"\"\n\ndef _make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Construct a Message instance compatible with pydantic and fallback Message.\"\"\"\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": role,\n        \"cause_by\": _safe_str(cause_by),\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = _safe_str(instruct_content)\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # fallback to positional-compatible constructor or ad-hoc object\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"], instruct_content=kwargs.get(\"instruct_content\"), cause_by=kwargs[\"cause_by\"], sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            class _M:\n                def __init__(self, content, role, cause_by, sent_from, instruct_content=None):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = instruct_content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n            return _M(kwargs[\"content\"], kwargs[\"role\"], kwargs[\"cause_by\"], kwargs[\"sent_from\"], kwargs.get(\"instruct_content\"))\n\nclass Action(ABC):\n    \"\"\"Simple, robust base Action with lazy LLM access and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily initialize LLMInterface; swallow any errors to reduce failure modes.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg is not None and getattr(cfg, \"llm\", None) is not None:\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(event, self.name, details)\n            except Exception:\n                pass\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        super().__init__(context=context)\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = _safe_str(idea).strip()\n        self._log(\"ACTION_START\", f\"Code generation (len={len(idea_text)})\")\n        if not idea_text:\n            # deterministic minimal stub to avoid empty outputs\n            stub = (\n                \"# No idea provided. Placeholder implementation\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder solution.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", \"Used fallback stub for code\")\n            return stub\n\n        prompt = (\n            \"You are an expert Python programmer. Produce clear, correct Python code for the task below.\\n\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Clean, testable code\\n\"\n            \"- Basic error handling where applicable\\n\"\n            \"- Short comments for non-obvious logic\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                out = await self.llm.ask(messages)\n                result = _safe_str(out)\n            else:\n                result = f\"# Implementation for: {idea_text}\\n# [LLM not available - deterministic stub]\\n\"\n        except Exception as e:\n            result = f\"# Error generating code: {_safe_str(e)}\\n\"\n            self._log(\"ACTION_ERROR\", result)\n        self._log(\"ACTION_END\", f\"Generated {len(result)} chars\")\n        return result\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        super().__init__(context=context)\n\n    async def run(self, code: str = \"\") -> str:\n        code_text = _safe_str(code)\n        self._log(\"ACTION_START\", f\"Test generation (code_len={len(code_text[:2000])})\")\n        if not code_text:\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Placeholder test until code is provided.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", \"Used fallback tests\")\n            return fallback\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the provided implementation.\\n\\n\"\n            f\"Code (first 2000 chars):\\n{code_text[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover typical and edge cases\\n\"\n            \"- Return only test code\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                out = await self.llm.ask(messages)\n                result = _safe_str(out)\n            else:\n                result = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            result = f\"# Error generating tests: {_safe_str(e)}\\n\"\n            self._log(\"ACTION_ERROR\", result)\n        self._log(\"ACTION_END\", f\"Generated {len(result)} chars\")\n        return result\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = _safe_str(code)[:1500]\n        tests_text = _safe_str(tests)[:1500]\n        self._log(\"ACTION_START\", f\"Review (human={self.is_human})\")\n        if self.is_human:\n            review = \"Human review: Looks reasonable. Consider adding more edge-case tests and clearer docstrings.\"\n            self._log(\"ACTION_END\", \"Produced human-like review\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review of the code and tests.\\n\\n\"\n            f\"Code (first 1500 chars):\\n{code_text}\\n\\n\"\n            f\"Tests (first 1500 chars):\\n{tests_text}\\n\\n\"\n            \"Focus on readability, possible bugs, test coverage, and simple suggestions. Keep it short.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                out = await self.llm.ask(messages)\n                result = _safe_str(out)\n            else:\n                result = \"Automated review: Structure acceptable. Add more edge-case tests.\"\n        except Exception as e:\n            result = f\"Review error: {_safe_str(e)}\"\n            self._log(\"ACTION_ERROR\", result)\n        self._log(\"ACTION_END\", f\"Review generated len={len(result)}\")\n        return result\n\nclass Role(ABC):\n    \"\"\"Minimal robust role: holds a primary action and responds deterministically.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains cause_by strings\n        self.watch_list: List[str] = []\n        # environment will be injected by Team.hire\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        # bind contexts safely\n        bound: List[Action] = []\n        for a in actions or []:\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                pass\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Any]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                try:\n                    names.append(getattr(a, \"name\"))\n                except Exception:\n                    pass\n            elif hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(event, self.name, details)\n            except Exception:\n                pass\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the first action deterministically using message and env to build inputs.\"\"\"\n        if not self.actions:\n            self._log(\"ROLE_SKIP\", \"No actions\")\n            return None\n\n        action = self.actions[0]\n        self._log(\"ROLE_ACT\", f\"Action={action.name} MessageID={getattr(message, 'id', None)}\")\n\n        try:\n            if action.name == SimpleWriteCode.name:\n                idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(idea)\n            elif action.name == SimpleWriteTest.name:\n                # Prefer explicit code message, otherwise search env history\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                elif self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code_text)\n            elif action.name == SimpleWriteReview.name:\n                # assemble code + tests from message/env\n                code_text = \"\"\n                tests_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                    tests_text = getattr(message, \"content\", \"\") or \"\"\n                if self.env:\n                    if not code_text:\n                        cmsg = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                        code_text = getattr(cmsg, \"content\", \"\") if cmsg else \"\"\n                    if not tests_text:\n                        tmsg = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests_text = getattr(tmsg, \"content\", \"\") if tmsg else \"\"\n                result = await action.run(code_text, tests_text)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            err_text = f\"Action {action.name} failed: {_safe_str(e)}\"\n            self._log(\"ROLE_ERROR\", err_text)\n            result = err_text\n\n        # Construct response message robustly\n        response = _make_message(content=result, role=self.profile, cause_by=getattr(action, \"name\", \"\"), sent_from=self.name)\n        self._log(\"ROLE_COMPLETE\", f\"Produced message (len={len(_safe_str(result))})\")\n        return response\n\nclass SimpleCoder(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self._watch([])\n\nclass SimpleTester(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with small, well-tested API.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        if self.tracer:\n            try:\n                self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n            except Exception:\n                pass\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        # safe append and log\n        try:\n            self.history.append(message)\n        except Exception:\n            try:\n                m = _make_message(content=_safe_str(getattr(message, \"content\", \"\")), role=getattr(message, \"role\", \"Unknown\"), cause_by=getattr(message, \"cause_by\", \"\"), sent_from=getattr(message, \"sent_from\", None))\n                self.history.append(m)\n                message = m\n            except Exception:\n                return\n        if self.tracer:\n            try:\n                sender = getattr(message, \"sent_from\", getattr(message, \"role\", \"Unknown\"))\n                preview = (_safe_str(getattr(message, \"content\", \"\")) or \"\")[:120]\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"From {sender} cause={getattr(message, 'cause_by', '')} preview={preview}\")\n            except Exception:\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches the role's watch_list.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        results: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    results.append(msg)\n            except Exception:\n                continue\n        return results\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates roles, environment, and rounds in a deterministic and robust way.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        try:\n            self.context.env = self.env\n        except Exception:\n            pass\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles and ensure contexts/actions are aligned.\"\"\"\n        for role in roles or []:\n            try:\n                role.context = role.context or self.context\n                role.env = self.env\n                # refresh action contexts\n                for a in getattr(role, \"actions\", []) or []:\n                    a.context = a.context or self.context\n            except Exception:\n                pass\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea or \"\"\n        try:\n            self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n        except Exception:\n            pass\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        try:\n            self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        except Exception:\n            pass\n\n        initial = _make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_num in range(n_round):\n            try:\n                self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            except Exception:\n                pass\n\n            # Snapshot roles to avoid mutation during iteration\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    # Round 0: coder(s) respond to initial instruction explicitly\n                    if round_num == 0 and any(getattr(a, \"name\", \"\") == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        response = await role.act(relevant[-1])\n\n                    if response:\n                        # ensure cause_by is set\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(role.actions[0], \"name\", \"UnknownAction\")\n                        self.env.publish_message(response)\n                except Exception as e:\n                    try:\n                        self.tracer.log(\"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _safe_str(e))\n                    except Exception:\n                        pass\n                    continue\n\n            try:\n                self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            except Exception:\n                pass\n\n        try:\n            self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n            summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n            self.tracer.log(\"SUMMARY\", \"Team\", summary)\n        except Exception:\n            pass\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n\n### Program D3 (Score: 3.2125)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _s(x: Any) -> str:\n    \"\"\"Safe string conversion.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        return x if isinstance(x, str) else str(x)\n    except Exception:\n        return \"\"\n\ndef _log(tracer: Optional[ExecutionTracer], event: str, agent: str, details: str):\n    \"\"\"Never-throw logger.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Robust message constructor that works for both pydantic and fallback Message.\"\"\"\n    kwargs = {\n        \"content\": _s(content),\n        \"role\": _s(role),\n        \"cause_by\": _s(cause_by),\n        \"sent_from\": _s(sent_from) if sent_from is not None else None,\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = _s(instruct_content)\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # Try positional form (fallback Message)\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"], instruct_content=kwargs.get(\"instruct_content\"), cause_by=kwargs[\"cause_by\"], sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Minimal object with required attributes\n            class _M:\n                def __init__(self, content, role, cause_by, sent_from, instruct_content=None):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = instruct_content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n                def __str__(self):\n                    return f\"Message(role={self.role}, content={self.content[:50]}...)\"\n            return _M(kwargs[\"content\"], kwargs[\"role\"], kwargs[\"cause_by\"], kwargs[\"sent_from\"], kwargs.get(\"instruct_content\"))\n\nclass Action(ABC):\n    \"\"\"Base action with lazy LLM, safe logging, and unified execute wrapper.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"Map (message, env) into concrete run() args in one centralized place.\"\"\"\n        try:\n            aname = getattr(self, \"name\", \"\") or self.__class__.__name__\n            if aname == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(_s(idea))\n            if aname == SimpleWriteTest.name:\n                code = getattr(message, \"content\", \"\") if message else \"\"\n                if not code and env:\n                    latest = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest:\n                        code = getattr(latest, \"content\", \"\") or \"\"\n                return await self.run(_s(code))\n            if aname == SimpleWriteReview.name:\n                # Prefer tests in triggering message; pull latest code/tests from env if missing\n                tests = getattr(message, \"content\", \"\") if message else \"\"\n                code = getattr(message, \"instruct_content\", \"\") if message else \"\"\n                if env:\n                    if not code:\n                        cmsg = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                        code = getattr(cmsg, \"content\", \"\") if cmsg else code\n                    if not tests:\n                        tmsg = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests = getattr(tmsg, \"content\", \"\") if tmsg else tests\n                return await self.run(_s(code), _s(tests))\n            # Fallback\n            return await self.run(_s(getattr(message, \"content\", \"\")) if message else \"\")\n        except Exception as e:\n            self._log(\"ACTION_EXCEPTION\", _s(e))\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Writing code for: {idea_text[:120]}\")\n        if not idea_text:\n            code = (\n                \"# No task provided. Placeholder implementation.\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder function.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", f\"Generated {len(code)} chars (fallback)\")\n            return code\n\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Clean, functional Python\\n\"\n            \"2. Basic error handling\\n\"\n            \"3. Comments explaining non-obvious logic\\n\"\n            \"4. Production-ready where reasonable\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder_function():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception as exc:\\n\"\n                    \"        raise exc\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(_s(code))} characters of code\")\n        return _s(code)\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_text = (code or \"\").strip()\n        self._log(\"ACTION_START\", f\"Writing tests (code_len={len(code_text)})\")\n        if not code_text:\n            tests = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Placeholder test until code is available.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", f\"Generated {len(tests)} chars (fallback)\")\n            return tests\n\n        prompt = (\n            \"You are a QA engineer. Write comprehensive pytest tests for the following code:\\n\\n\"\n            f\"{code_text[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Cover typical and edge cases\\n\"\n            \"- Include negative tests where applicable\\n\"\n            \"- Use clear test names and minimal mocking\\n\"\n            \"Return only the test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(_s(tests))} characters of tests\")\n        return _s(tests)\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\").strip()\n        tests_text = (tests or \"\").strip()\n        self._log(\"ACTION_START\", f\"Reviewing (human={self.is_human})\")\n        try:\n            if self.is_human:\n                review = \"Human review: Looks good overall; consider more defensive checks and additional edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests.\\n\\n\"\n                    f\"Code (first 1500 chars):\\n{code_text[:1500]}\\n\\n\"\n                    f\"Tests (first 1500 chars):\\n{tests_text[:1500]}\\n\\n\"\n                    \"Provide a brief, actionable review focusing on:\\n\"\n                    \"- Code quality and best practices\\n\"\n                    \"- Test coverage and gaps\\n\"\n                    \"- Potential bugs or edge cases\\n\"\n                    \"- Clear suggestions for improvement\\n\"\n                    \"Keep it concise.\"\n                )\n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt},\n                ]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable; add input validation and more boundary tests.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        self._log(\"ACTION_END\", f\"Review completed ({len(_s(review))} chars)\")\n        return _s(review)\n\nclass Role(ABC):\n    \"\"\"Minimal role abstraction that executes a single primary action.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list stores cause_by values this role responds to\n        self.watch_list: List[str] = []\n        # environment reference (set by Team.hire)\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Bind actions to this role and align contexts.\"\"\"\n        bound: List[Action] = []\n        for a in actions or []:\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        \"\"\"Accept action classes or names.\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = [n for n in names if n]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action and return a response message.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        _log(tracer, \"ROLE_ACT\", self.name, f\"Executing: {getattr(action, 'name', 'Action')}\")\n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _log(tracer, \"ROLE_ERROR\", self.name, _s(e))\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=_s(result),\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _log(tracer, \"ROLE_COMPLETE\", self.name, \"Action completed, message emitted\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        # Coder responds to the initial user input (handled by Team), not to other messages\n        self._watch([])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = bool(kwargs.get(\"is_human\", False))\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment that stores messages, roles, and prevents reprocessing.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Track last processed message id per role to avoid duplicate processing\n        self._last_processed: Dict[str, Optional[str]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._last_processed.setdefault(role.name, None)\n        _log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        \"\"\"Append message safely and log a short preview.\"\"\"\n        try:\n            # Normalize minimal fields\n            content = _s(getattr(message, \"content\", \"\"))\n            setattr(message, \"content\", content)\n            cause = _s(getattr(message, \"cause_by\", \"\"))\n            setattr(message, \"cause_by\", cause)\n            self.history.append(message)\n            preview = content[:120]\n            sender = _s(getattr(message, \"sent_from\", getattr(message, \"role\", \"Unknown\")))\n            _log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={sender} cause={cause} preview={preview}\")\n        except Exception as e:\n            _log(self.tracer, \"ENV_ERROR\", \"Environment\", f\"publish failed: {_s(e)}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return at most one unprocessed latest message whose cause_by matches role.watch_list.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        candidates: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    candidates.append(msg)\n            except Exception:\n                continue\n        if not candidates:\n            return []\n        latest = candidates[-1]\n        last_id = self._last_processed.get(role.name)\n        if last_id and getattr(latest, \"id\", None) == last_id:\n            return []\n        return [latest]\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\n    def mark_processed(self, role: Role, message: Message):\n        try:\n            self._last_processed[role.name] = getattr(message, \"id\", None)\n            _log(self.tracer, \"ENV_MARKED\", \"Environment\", f\"{role.name} processed {getattr(message, 'id', '')}\")\n        except Exception:\n            pass\n\nclass Team:\n    \"\"\"Team orchestrator running deterministic rounds.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Attach shared context/env and align actions' context.\"\"\"\n        for role in roles:\n            role.context = role.context or self.context\n            role.env = self.env\n            for a in getattr(role, \"actions\", []) or []:\n                try:\n                    a.context = a.context or self.context\n                except Exception:\n                    a.context = self.context\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        _log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        _log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial user instruction\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_num in range(n_round):\n            _log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                used_message: Optional[Message] = None\n                try:\n                    # Round 0: coder responds directly to user input\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        used_message = initial\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        used_message = relevant[-1]\n                        response = await role.act(used_message)\n                except Exception as e:\n                    _log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _s(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n                    if used_message:\n                        self.env.mark_processed(role, used_message)\n\n            _log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        _log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to overall_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Safe logging helper that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str,\n                 role: str,\n                 cause_by: str = \"\",\n                 sent_from: Optional[str] = None,\n                 instruct_content: Optional[str] = None) -> Message:\n    \"\"\"\n    Robust factory to create Message objects compatible with both pydantic and fallback classes.\n    Accepts defaults for optional fields to reduce failure modes.\n    \"\"\"\n    kwargs = {\n        \"content\": content if content is not None else \"\",\n        \"role\": role if role is not None else \"\",\n        \"cause_by\": cause_by if cause_by is not None else \"\",\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        # Preferred construction for pydantic-based Message\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional/fallback Message constructor\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Final minimal fallback: simple object with expected attributes\n            class _M:\n                pass\n            m = _M()\n            m.id = str(uuid.uuid4())\n            m.content = kwargs[\"content\"]\n            m.instruct_content = kwargs.get(\"instruct_content\")\n            m.role = kwargs[\"role\"]\n            m.cause_by = kwargs[\"cause_by\"]\n            m.sent_from = kwargs[\"sent_from\"]\n            m.sent_to = None\n            m.send_to = set()\n            return m\n\nclass Action(ABC):\n    \"\"\"Minimal, robust action base with lazy LLM binding and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily instantiate LLMInterface if configuration exists.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code from a human idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Generating code for idea (len={len(idea_text)})\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Provide only the code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic safe fallback that is valid Python\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until an LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_snippet = (code or \"\")[:2000]\n        self._log(\"ACTION_START\", f\"Generating tests (code_len={len(code_snippet)})\")\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following code:\\n\\n\"\n            f\"Code:\\n{code_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain each test\\n\\n\"\n            \"Provide only the test code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide a concise review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\")[:1500]\n        tests_text = (tests or \"\")[:1500]\n        self._log(\"ACTION_START\", f\"Reviewing (human={self.is_human}) code_len={len(code_text)} tests_len={len(tests_text)}\")\n        try:\n            if self.is_human:\n                review = \"Human review: Looks generally good. Consider additional error handling and edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_text}\\n\\n\"\n                    f\"Tests:\\n{tests_text}\\n\\n\"\n                    \"Give a concise review focusing on code quality, test coverage, potential bugs and suggestions.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable. Add more edge-case coverage and clearer exceptions.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        self._log(\"ACTION_END\", f\"Review length={len(review)}\")\n        return review\n\nclass Role:\n    \"\"\"Lightweight role holding a single primary action and a watch list of cause_by tokens.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains strings matching Message.cause_by\n        self.watch_list: Set[str] = set()\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Bind provided action instances and ensure context alignment.\"\"\"\n        bound: List[Action] = []\n        for a in (actions or []):\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: Set[str] = set()\n        for a in (actions or []):\n            if isinstance(a, str):\n                names.add(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Run the primary action and return a Message result or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        try:\n            # Routing: map messages/environment to action inputs deterministically and simply\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code from the triggering message (if any); else fetch latest code from env\n                code = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code = getattr(message, \"content\", \"\") or \"\"\n                if not code and self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Gather best-effort code and tests from env or message\n                code = \"\"\n                tests = \"\"\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    tests = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                if message:\n                    tests = tests or getattr(message, \"content\", \"\") or \"\"\n                    code = code or getattr(message, \"instruct_content\", \"\") or \"\"\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, f\"Created message id={getattr(response, 'id', None)}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration: holds roles and messages and provides simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        try:\n            role.env = self\n        except Exception:\n            role.env = None\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        \"\"\"Append a message to history and log a short preview. Be resilient to message shape.\"\"\"\n        try:\n            # Ensure id exists where possible\n            if not getattr(message, \"id\", None):\n                try:\n                    message.id = str(uuid.uuid4())\n                except Exception:\n                    pass\n            self.history.append(message)\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n            sender = getattr(message, \"sent_from\", \"unknown\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n        except Exception:\n            # Try to normalize and store minimal message\n            try:\n                minimal = make_message(\n                    content=str(getattr(message, \"content\", \"\") or \"\"),\n                    role=getattr(message, \"role\", \"Unknown\"),\n                    cause_by=getattr(message, \"cause_by\", \"\"),\n                    sent_from=getattr(message, \"sent_from\", \"unknown\")\n                )\n                self.history.append(minimal)\n            except Exception:\n                # give up silently to avoid propagation\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches anything in the role's watch_list, preserving order.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        relevant: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant.append(msg)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by, or None.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates a group of roles to collaborate for n rounds with robust handling.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure tracer accessible via context, but don't fail if not allowed\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Add roles to the team and align contexts and environments.\"\"\"\n        for role in roles:\n            try:\n                role.context = role.context or self.context\n                role.env = self.env\n                # Ensure action instances are context-aware\n                for a in getattr(role, \"actions\", []) or []:\n                    a.context = a.context or self.context\n            except Exception:\n                pass\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea or \"\"\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message (user instruction)\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_idx in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_idx + 1}/{n_round}\")\n            # Deterministic iteration order of roles\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    # First round: let coder(s) respond to initial input\n                    if round_idx == 0 and any(a.name == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        latest = relevant[-1]\n                        response = await role.act(latest)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_idx + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n### Inspiration 2 (Score: 3.2125, Type: Migrant)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never throws.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": content,\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # Try positional where pydantic is not present\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Minimal fallback object\n            class _M:\n                def __init__(self, content, role, cause_by, sent_from, instruct_content=None):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = instruct_content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n                def __str__(self):\n                    return f\"Message(role={self.role}, content={self.content[:50]}...)\"\n            return _M(kwargs[\"content\"], kwargs[\"role\"], kwargs[\"cause_by\"], kwargs[\"sent_from\"], kwargs.get(\"instruct_content\"))\n\nclass Action(ABC):\n    \"\"\"Base action class with lazy LLM and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        _safe_log(tracer, event, self.name, details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Writing code for: {idea_text[:120]}\")\n        prompt = (\n            f\"You are a professional programmer. Write Python code for the following task:\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Please provide only the code without any explanation.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic, safe fallback\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder_function():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'placeholder'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(code)} characters of code\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_text = (code or \"\").strip()\n        self._log(\"ACTION_START\", f\"Writing tests for code (len={len(code_text)})\")\n        snippet = code_text[:2000] if code_text else \"# No code provided\"\n        prompt = (\n            \"You are a QA engineer. Write comprehensive tests for the following code:\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain what each test does\\n\\n\"\n            \"Please provide only the test code without any explanation.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated {len(tests)} characters of tests\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\").strip()\n        tests_text = (tests or \"\").strip()\n        self._log(\"ACTION_START\", f\"Reviewing code (human={self.is_human})\")\n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_text[:1500]}\\n\\n\"\n                    f\"Tests:\\n{tests_text[:1500]}\\n\\n\"\n                    \"Provide a brief review focusing on:\\n\"\n                    \"1. Code quality and best practices\\n\"\n                    \"2. Test coverage\\n\"\n                    \"3. Potential bugs or issues\\n\"\n                    \"4. Suggestions for improvement\\n\\n\"\n                    \"Keep your review concise and actionable.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks reasonable. Tests cover main functionality; add more edge cases.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n        self._log(\"ACTION_END\", f\"Review completed ({len(review)} chars)\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Base role class for agents (simplified).\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list stores cause_by names (strings) to react to\n        self.watch_list: List[str] = []\n        # environment reference set by Team.hire\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        # Bind context into action instances and keep them per-instance (no shared mutable)\n        bound: List[Action] = []\n        for a in actions or []:\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif isinstance(a, type) and hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform primary action based on a message; returns a Message or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n        try:\n            # Map inputs according to action type\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code from message (if coder produced it), else search environment history\n                code = \"\"\n                if message and getattr(message, \"content\", None):\n                    code = message.content\n                elif self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Gather code and tests from message or environment\n                code = \"\"\n                tests = \"\"\n                if message:\n                    tests = getattr(message, \"content\", \"\") or \"\"\n                    code = getattr(message, \"instruct_content\", \"\") or \"\"\n                if self.env:\n                    if not code:\n                        latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                        code = getattr(latest_code, \"content\", \"\") if latest_code else code\n                    if not tests:\n                        latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests = getattr(latest_tests, \"content\", \"\") if latest_tests else tests\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self._watch([])  # coder responds to user input explicitly\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        # append and log safely\n        try:\n            self.history.append(message)\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n            sender = getattr(message, \"sent_from\", \"unknown\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n        except Exception:\n            # best-effort attempt to normalize and store minimal info\n            try:\n                minimal = make_message(str(getattr(message, \"content\", \"\")), role=getattr(message, \"role\", \"Unknown\"), cause_by=getattr(message, \"cause_by\", \"\"), sent_from=getattr(message, \"sent_from\", \"unknown\"))\n                self.history.append(minimal)\n            except Exception:\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        relevant: List[Message] = []\n        watched = set(role.watch_list or [])\n        if not watched:\n            return relevant\n        for m in self.history:\n            try:\n                if getattr(m, \"cause_by\", \"\") in watched:\n                    relevant.append(m)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for m in reversed(self.history):\n            try:\n                if getattr(m, \"cause_by\", \"\") == cause_name:\n                    return m\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure tracer in context\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team; ensure contexts for role actions are aligned\"\"\"\n        for role in roles:\n            role.context = role.context or self.context\n            role.env = self.env\n            # ensure actions know the team's context\n            for a in role.actions:\n                a.context = a.context or self.context\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 3):\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        # initial message (user instruction)\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_num in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            # roles act in deterministic order\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and isinstance(role, SimpleCoder):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        response = await role.act(relevant[-1])\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    response = None\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n### Inspiration 3 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Return a safe string representation for any object.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        if isinstance(x, str):\n            return x\n        return str(x)\n    except Exception:\n        return \"\"\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str, sent_from: str, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Create a Message instance compatible with both pydantic and fallback implementations.\"\"\"\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": role,\n        \"cause_by\": cause_by,\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # fallback to positional constructor used in older Message fallback\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # last-resort lightweight object\n            class _SimpleMsg:\n                def __init__(self, content, role, cause_by, sent_from):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = kwargs.get(\"instruct_content\")\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n                def __str__(self):\n                    return f\"Message(role={self.role}, content={self.content[:50]}...)\"\n            return _SimpleMsg(kwargs[\"content\"], kwargs[\"role\"], kwargs[\"cause_by\"], kwargs[\"sent_from\"])\n\nclass Action(ABC):\n    \"\"\"Minimal, robust base action with unified execute mapping.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, **kwargs):\n        self.context: Optional[Context] = kwargs.get(\"context\")\n        self.llm: Optional[LLMInterface] = None\n        try:\n            if self.context and getattr(self.context, \"config\", None):\n                self.llm = LLMInterface(self.context.config.llm)\n        except Exception:\n            self.llm = None\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError()\n\n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Map incoming message + environment into the appropriate arguments for run().\n        Keep this mapping small and explicit to reduce failure surface.\n        \"\"\"\n        try:\n            aname = getattr(self, \"name\", \"\") or self.__class__.__name__\n            if aname == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            if aname == SimpleWriteTest.name:\n                # Prefer code coming in the message; otherwise fetch latest code from env\n                code = \"\"\n                if message and getattr(message, \"content\", \"\"):\n                    code = message.content\n                elif env:\n                    latest = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                return await self.run(code)\n            if aname == SimpleWriteReview.name:\n                # Assemble code and tests from env, prefer composite message if provided\n                code = \"\"\n                tests = \"\"\n                if message:\n                    tests = getattr(message, \"content\", \"\") or \"\"\n                    code = getattr(message, \"instruct_content\", \"\") or \"\"\n                if env:\n                    if not code:\n                        latest_code = env.get_latest_message_by_cause(SimpleWriteCode.name)\n                        code = getattr(latest_code, \"content\", \"\") if latest_code else code\n                    if not tests:\n                        latest_tests = env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests = getattr(latest_tests, \"content\", \"\") if latest_tests else tests\n                return await self.run(code, tests)\n            # Generic fallback\n            payload = getattr(message, \"content\", \"\") if message else \"\"\n            return await self.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_EXCEPTION\", getattr(self, \"name\", \"Action\"), _safe_str(e))\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Action to write code based on requirements\"\"\"\n    name: str = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = _safe_str(idea).strip()\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Writing code for: {idea_text[:100]}\")\n\n        prompt = f\"\"\"You are a professional programmer. Write Python code for the following task:\nTask: {idea_text}\n\nRequirements:\n1. Write clean, functional Python code\n2. Include proper error handling\n3. Add comments explaining the logic\n4. Make it production-ready\n\nPlease provide only the code without any explanation.\"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'placeholder'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(_safe_str(code))} characters of code\")\n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Action to write tests for code\"\"\"\n    name: str = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_text = _safe_str(code)\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, \"Writing tests for code\")\n\n        snippet = code_text[:2000] if code_text else \"# No code provided\"\n        prompt = f\"\"\"You are a QA engineer. Write comprehensive tests for the following code:\n\nCode:\n{snippet}\n\nRequirements:\n1. Write pytest-style test cases\n2. Cover edge cases and error conditions\n3. Include both positive and negative tests\n4. Add docstrings to explain what each test does\n\nPlease provide only the test code without any explanation.\"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Generated {len(_safe_str(tests))} characters of tests\")\n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Action to review code and tests\"\"\"\n    name: str = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, **kwargs):\n        super().__init__(**kwargs)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = _safe_str(code)\n        tests_text = _safe_str(tests)\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"Reviewing code (human={self.is_human})\")\n\n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more error handling.\"\n            else:\n                prompt = f\"\"\"You are a senior code reviewer. Review the following code and tests:\n\nCode:\n{code_text[:1500]}\n\nTests:\n{tests_text[:1500]}\n\nProvide a brief review focusing on:\n1. Code quality and best practices\n2. Test coverage\n3. Potential bugs or issues\n4. Suggestions for improvement\n\nKeep your review concise and actionable.\"\"\"\n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Review: Code structure looks good. Tests cover main functionality.\"\n        except Exception as e:\n            review = f\"Error during review generation: {e}\"\n\n        _safe_log(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"Review completed: {len(_safe_str(review))} characters\")\n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Base role class for agents (simple and robust)\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n\n    def __init__(self, **kwargs):\n        self.name = kwargs.get('name', self.name)\n        self.profile = kwargs.get('profile', self.profile)\n        self.context: Optional[Context] = kwargs.get('context')\n        self.is_human: bool = kwargs.get('is_human', False)\n        # actions are instances to keep things simple\n        self.actions: List[Action] = []\n        # watch_list stores action names (strings)\n        self.watch_list: List[str] = []\n        # environment reference (set by Team.hire)\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Set the actions this role can perform and align contexts\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n            try:\n                if self.context:\n                    a.llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                a.llm = None\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        \"\"\"Set the actions this role watches for. Accept types or names.\"\"\"\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Perform the primary action using the unified Action.execute()\"\"\"\n        if not self.actions:\n            return None\n\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        _safe_log(tracer, \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', 'Action')}\")\n\n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(tracer, \"ROLE_ERROR\", self.name, f\"Execution failed: {_safe_str(e)}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=_safe_str(result),\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n\n        _safe_log(tracer, \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    name: str = \"Alice\"\n    profile: str = \"SimpleCoder\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # create action instance with the role's context\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    name: str = \"Bob\"\n    profile: str = \"SimpleTester\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        # Watch coder's output by name\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    name: str = \"Charlie\"\n    profile: str = \"SimpleReviewer\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        # Watch tester's output by name\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        \"\"\"Add a role to the environment and attach backrefs\"\"\"\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        \"\"\"Get roles by profile\"\"\"\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        \"\"\"Publish a message to the environment\"\"\"\n        # Ensure message has an id\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        try:\n            preview = _safe_str(getattr(message, \"content\", \"\"))[:100]\n            sender = _safe_str(getattr(message, \"sent_from\", \"Unknown\"))\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview} (cause: {getattr(message, 'cause_by', '')})\")\n        except Exception:\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", \"Message published\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Get messages that a role should respond to (by cause_by name)\"\"\"\n        if not getattr(role, \"watch_list\", None):\n            return []\n        watched = set(role.watch_list or [])\n        relevant_messages: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant_messages.append(msg)\n            except Exception:\n                continue\n        return relevant_messages\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Get the most recent message whose cause_by matches cause_name\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team of agents working together\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure context has tracer set\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Hire roles into the team; align action contexts and env references\"\"\"\n        for role in roles:\n            role.context = self.context\n            role.env = self.env\n            # Align any pre-instantiated actions with the team's context\n            if hasattr(role, \"actions\"):\n                for a in role.actions:\n                    a.context = self.context\n                    try:\n                        a.llm = LLMInterface(self.context.config.llm)\n                    except Exception:\n                        a.llm = None\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        \"\"\"Set investment/budget\"\"\"\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        \"\"\"Set the project idea\"\"\"\n        self.idea = idea\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 3):\n        \"\"\"Run the team collaboration for n rounds\"\"\"\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message with the idea\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        for round_num in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n\n            # Each role acts in deterministic order (snapshot to avoid modification during iteration)\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if round_num == 0 and getattr(role, \"profile\", \"\") == \"SimpleCoder\":\n                        # Coder responds to initial message\n                        response = await role.act(initial_msg)\n                    else:\n                        relevant_msgs = self.env.get_messages_for_role(role)\n                        if not relevant_msgs:\n                            continue\n                        last_msg = relevant_msgs[-1]\n                        # If reviewer, provide a composite message containing latest code (in instruct_content) and tests (in content)\n                        if getattr(role, \"profile\", \"\") == \"SimpleReviewer\":\n                            code_msg = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                            test_msg = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                            composite = make_message(\n                                content=(getattr(test_msg, \"content\", \"\") if test_msg else getattr(last_msg, \"content\", \"\")),\n                                instruct_content=(getattr(code_msg, \"content\", \"\") if code_msg else \"\"),\n                                role=\"System\",\n                                sent_from=\"Environment\",\n                                cause_by=\"Composite\"\n                            )\n                            response = await role.act(composite)\n                        else:\n                            response = await role.act(last_msg)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _safe_str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n\n        # Final summary\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n### Inspiration 4 (Score: 3.2125, Type: High-Performer)\n```python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Convert value to string safely.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        if isinstance(x, str):\n            return x\n        return str(x)\n    except Exception:\n        return \"\"\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Best-effort logging that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"\n    Construct a Message compatible with both Pydantic and fallback implementations.\n    Provides robust fallbacks to avoid crashes when Message signature differs.\n    \"\"\"\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": role,\n        \"cause_by\": cause_by or \"\",\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    # Try keyword constructor first\n    try:\n        return Message(**kwargs)  # type: ignore\n    except Exception:\n        # Try positional fallback\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])  # type: ignore\n        except Exception:\n            # Minimal dynamic fallback object\n            class _Msg:\n                def __init__(self, content, role, cause_by, sent_from, instruct_content=None):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = instruct_content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n                def __str__(self):\n                    return f\"Message(role={self.role}, content={self.content[:50]}...)\"\n            return _Msg(kwargs[\"content\"], kwargs[\"role\"], kwargs[\"cause_by\"], kwargs[\"sent_from\"], kwargs.get(\"instruct_content\"))\n\nclass Action(ABC):\n    \"\"\"Minimal, robust base action with lazy LLM initialization and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily create LLM interface if configuration is available.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        _safe_log(tracer, event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\n    async def execute(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> str:\n        \"\"\"\n        Simple, deterministic mapping from incoming message + environment to action inputs.\n        Reduces branching and failure surface by providing clear fallbacks.\n        \"\"\"\n        try:\n            aname = getattr(self, \"name\", \"\") or self.__class__.__name__\n            if aname == \"SimpleWriteCode\":\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                return await self.run(idea)\n            if aname == \"SimpleWriteTest\":\n                code = \"\"\n                if message and getattr(message, \"content\", None):\n                    code = message.content\n                elif env:\n                    latest = env.get_latest_message_by_cause(\"SimpleWriteCode\")\n                    if latest:\n                        code = getattr(latest, \"content\", \"\") or \"\"\n                return await self.run(code)\n            if aname == \"SimpleWriteReview\":\n                # Prefer explicit code/tests in message; otherwise search environment.\n                tests = getattr(message, \"content\", \"\") if message else \"\"\n                code = getattr(message, \"instruct_content\", \"\") if message else \"\"\n                if env:\n                    if not code:\n                        latest_code = env.get_latest_message_by_cause(\"SimpleWriteCode\")\n                        code = getattr(latest_code, \"content\", \"\") if latest_code else code\n                    if not tests:\n                        latest_tests = env.get_latest_message_by_cause(\"SimpleWriteTest\")\n                        tests = getattr(latest_tests, \"content\", \"\") if latest_tests else tests\n                return await self.run(code, tests)\n            # Generic fallback: pass message content\n            return await self.run(getattr(message, \"content\", \"\") if message else \"\")\n        except Exception as e:\n            self._log(\"ACTION_EXCEPTION\", _safe_str(e))\n            return f\"Error executing {getattr(self, 'name', 'Action')}: {e}\"\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate Python code from a short description.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_txt = _safe_str(idea).strip()\n        self._log(\"ACTION_START\", f\"Writing code for: {idea_txt[:120]}\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\\n\"\n            f\"Task: {idea_txt}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Please provide only the code without any explanation.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Stable, deterministic fallback\n                code = (\n                    f\"# Implementation for: {idea_txt}\\n\"\n                    \"def placeholder_function():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'placeholder'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {_safe_str(e)}\"\n        self._log(\"ACTION_END\", f\"Generated {len(_safe_str(code))} chars\")\n        return _safe_str(code)\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest tests for given code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_txt = _safe_str(code)\n        self._log(\"ACTION_START\", f\"Writing tests (code_len={len(code_txt)})\")\n        snippet = code_txt[:2000] if code_txt else \"# No code provided\"\n        prompt = (\n            \"You are a QA engineer. Write comprehensive tests for the following code:\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain what each test does\\n\\n\"\n            \"Please provide only the test code without any explanation.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {_safe_str(e)}\"\n        self._log(\"ACTION_END\", f\"Generated {len(_safe_str(tests))} chars\")\n        return _safe_str(tests)\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests, optionally simulating a human reviewer.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_txt = _safe_str(code)\n        tests_txt = _safe_str(tests)\n        self._log(\"ACTION_START\", f\"Reviewing code (human={self.is_human})\")\n        try:\n            if self.is_human:\n                review = \"Human review: The code looks good overall. Consider adding more explicit error handling and additional edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_txt[:1500]}\\n\\n\"\n                    f\"Tests:\\n{tests_txt[:1500]}\\n\\n\"\n                    \"Provide a brief review focusing on:\\n\"\n                    \"1. Code quality and best practices\\n\"\n                    \"2. Test coverage\\n\"\n                    \"3. Potential bugs or issues\\n\"\n                    \"4. Suggestions for improvement\\n\\n\"\n                    \"Keep your review concise and actionable.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure ok; consider tighter error handling and more edge-case tests.\"\n        except Exception as e:\n            review = f\"Error during review generation: {_safe_str(e)}\"\n        self._log(\"ACTION_END\", f\"Review completed ({len(_safe_str(review))} chars)\")\n        return _safe_str(review)\n\nclass Role(ABC):\n    \"\"\"Simple role abstraction that instantiates actions per invocation to avoid shared mutable state.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        # store action classes (not instances) for deterministic instantiation\n        self._action_classes: List[Type[Action]] = []\n        # watch_list contains names of actions to react to\n        self.watch_list: List[str] = []\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Any]):\n        \"\"\"\n        Accept either Action classes or pre-instantiated Action objects.\n        Normalize to classes for safe instantiation later.\n        \"\"\"\n        classes: List[Type[Action]] = []\n        for a in actions or []:\n            if isinstance(a, type) and issubclass(a, Action):\n                classes.append(a)\n            else:\n                # If instance provided, infer its class\n                try:\n                    classes.append(a.__class__)\n                except Exception:\n                    continue\n        self._action_classes = classes\n\n    def _watch(self, actions: List[Any]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n        self.watch_list = [n for n in names if n]\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Instantiate primary action with current context and execute it.\"\"\"\n        if not self._action_classes:\n            return None\n        action_cls = self._action_classes[0]\n        try:\n            # For reviewer, pass is_human flag into constructor if supported\n            if action_cls is SimpleWriteReview:\n                action = action_cls(is_human=self.is_human, context=self.context)\n            else:\n                action = action_cls(context=self.context)\n        except Exception:\n            # Fallback: try without args\n            try:\n                action = action_cls()\n                action.context = self.context\n            except Exception as e:\n                _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Failed to create action: {_safe_str(e)}\")\n                return None\n\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Executing action: {getattr(action, 'name', action_cls.__name__)}\")\n        try:\n            result = await action.execute(message=message, env=self.env)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {_safe_str(e)}\")\n            result = f\"Error in role {self.name}: {_safe_str(e)}\"\n\n        response = make_message(content=result, role=self.profile, cause_by=getattr(action, \"name\", \"\"), sent_from=self.name)\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, \"Action completed, message created\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode])\n        self._watch([])  # coder reacts to explicit user instruction\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        # Append to history and log a short preview\n        try:\n            self.history.append(message)\n            preview = (_safe_str(getattr(message, \"content\", \"\")))[:120]\n            sender = getattr(message, \"sent_from\", \"Unknown\")\n            cause = getattr(message, \"cause_by\", \"\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"From={sender} Cause={cause} Preview={preview}\")\n        except Exception:\n            _safe_log(self.tracer, \"ENV_ERROR\", \"Environment\", \"Failed to publish message\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches role.watch_list\"\"\"\n        if not getattr(role, \"watch_list\", None):\n            return []\n        watched = set(role.watch_list or [])\n        relevant: List[Message] = []\n        for m in self.history:\n            try:\n                if getattr(m, \"cause_by\", \"\") in watched:\n                    relevant.append(m)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for m in reversed(self.history):\n            try:\n                if getattr(m, \"cause_by\", \"\") == cause_name:\n                    return m\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Team orchestrator for the multi-agent workflow\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Add roles to the environment and align contexts.\"\"\"\n        for role in roles or []:\n            role.context = role.context or self.context\n            role.env = self.env\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = _safe_str(idea)\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial instruction message\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for rnd in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {rnd + 1}/{n_round}\")\n            # Deterministic role order\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    if rnd == 0 and getattr(role, \"profile\", \"\") == \"SimpleCoder\":\n                        # Coder should respond to initial instruction\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        # Use most recent relevant message\n                        trigger = relevant[-1]\n                        # For reviewer, prefer to assemble composite inside action.execute via environment lookups\n                        response = await role.act(trigger)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _safe_str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {rnd + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n### Inspiration 5 (Score: 3.2125, Type: Migrant)\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event: str, agent: str, details: str):\n    \"\"\"Best-effort logging helper that never raises.\"\"\"\n    if not tracer:\n        return\n    try:\n        tracer.log(event, agent, details)\n    except Exception:\n        pass\n\ndef _ensure_str(s: Optional[str]) -> str:\n    \"\"\"Convert possibly None or non-string to a safe string.\"\"\"\n    if s is None:\n        return \"\"\n    try:\n        return str(s)\n    except Exception:\n        return \"\"\n\nclass Action(ABC):\n    \"\"\"Simplified base Action with safe llm access and logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg is not None and getattr(cfg, \"llm\", None) is not None:\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate code for the provided idea/requirements.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea = _ensure_str(idea).strip()\n        self._log(\"ACTION_START\", f\"len_idea={len(idea)}\")\n        if not idea:\n            # Deterministic fallback to reduce variability/failure\n            fallback = (\n                \"# No idea provided. Placeholder implementation\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder solution.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python programmer. Write clean, testable Python code for the task below.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Clean, testable code\\n\"\n            \"- Basic error handling\\n\"\n            \"- Short comments for non-obvious parts\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = f\"# Implementation for: {idea}\\n# [LLM unavailable - fallback placeholder]\\n\"\n        except Exception as e:\n            code = f\"# Error generating code: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for given code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code = _ensure_str(code)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}\")\n        if not code.strip():\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the implementation below.\\n\\n\"\n            f\"Code (first 2000 chars):\\n{code[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover normal and edge cases\\n\"\n            \"- Include docstrings\\n\\n\"\n            \"Return only the test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide concise human-like or automated review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code = _ensure_str(code)\n        tests = _ensure_str(tests)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}, tests_len={len(tests)}, human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Looks good overall. Consider adding more edge-case tests and clearer docstrings.\"\n            self._log(\"ACTION_END\", \"human_review\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review of the code and tests.\\n\\n\"\n            f\"Code (first 1500 chars):\\n{code[:1500]}\\n\\n\"\n            f\"Tests (first 1500 chars):\\n{tests[:1500]}\\n\\n\"\n            \"Focus on readability, potential bugs, and test coverage. Be concise.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Automated review: Code structure acceptable. Add more boundary and negative-case tests.\"\n        except Exception as e:\n            review = f\"Review error: {e}\"\n        self._log(\"ACTION_END\", f\"generated_len={len(review)}\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Simple role abstraction with deterministic action selection.\"\"\"\n    def __init__(self, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = is_human\n        # single primary action instance per role\n        self.action: Optional[Action] = None\n        # watch_list: cause_by strings this role should respond to\n        self.watch_list: List[str] = []\n        # environment reference set when hired\n        self.env: Optional[\"Environment\"] = None\n\n    def set_action(self, action: Action):\n        # ensure action knows context\n        if getattr(action, \"context\", None) is None:\n            action.context = self.context\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, self.name, details)\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action using a small set of explicit, deterministic rules.\"\"\"\n        if not self.action:\n            self._log(\"ROLE_SKIP\", \"no_action\")\n            return None\n\n        self._log(\"ROLE_ACT\", f\"action={getattr(self.action, 'name', 'unknown')}, msg_id={getattr(message, 'id', None)}\")\n\n        try:\n            # Determine inputs in priority: explicit message -> env latest -> fallback\n            if getattr(self.action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await self.action.run(idea or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteTest.name:\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\")\n                elif self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await self.action.run(code_text or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteReview.name:\n                # prefer tests from triggering message and code from latest code message\n                tests_text = \"\"\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                    tests_text = getattr(message, \"content\", \"\")\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    if not tests_text:\n                        latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests_text = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                # Generic fallback: pass message content or empty string\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await self.action.run(payload)\n        except Exception as e:\n            err = f\"Action failed: {e}\"\n            self._log(\"ROLE_ERROR\", err)\n            result = err\n\n        # Construct a Message for response; keep compatible with both pydantic and fallback Message\n        try:\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=getattr(self.action, \"name\", \"\"),\n                sent_from=self.name\n            )\n        except Exception:\n            class _Mini:\n                pass\n            response = _Mini()\n            response.id = str(uuid.uuid4())\n            response.content = result\n            response.instruct_content = None\n            response.role = self.profile\n            response.cause_by = getattr(self.action, \"name\", \"\")\n            response.sent_from = self.name\n\n        self._log(\"ROLE_COMPLETE\", f\"produced_len={len(_ensure_str(result))}\")\n        return response\n\nclass SimpleCoder(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Alice\"), profile=kwargs.get(\"profile\", \"SimpleCoder\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # responds to initial user instruction\n\nclass SimpleTester(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Bob\"), profile=kwargs.get(\"profile\", \"SimpleTester\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Charlie\"), profile=kwargs.get(\"profile\", \"SimpleReviewer\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Lightweight environment for storing messages and providing simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role={role.name}\")\n\n    def publish_message(self, message: Message):\n        # Ensure message has id where possible and append; log safely\n        try:\n            if not hasattr(message, \"id\") or getattr(message, \"id\", None) is None:\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={getattr(message, 'sent_from', 'Unknown')} cause={getattr(message, 'cause_by', '')} preview={_ensure_str(getattr(message, 'content', ''))[:100]}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by is in role.watch_list (in chronological order).\"\"\"\n        if not role.watch_list:\n            return []\n        watched = set(role.watch_list)\n        result: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    result.append(msg)\n            except Exception:\n                continue\n        return result\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates roles to collaborate on an idea. Simple, deterministic and robust.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # Ensure context has tracer reference\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            # Bind team context and environment to roles and their actions\n            r.context = r.context or self.context\n            r.env = self.env\n            if getattr(r, \"action\", None):\n                try:\n                    r.action.context = r.action.context or self.context\n                except Exception:\n                    pass\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = float(investment)\n\n    def run_project(self, idea: str):\n        self.idea = _ensure_str(idea)\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running rounds={n_round}\")\n\n        # Initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        # Deterministic order: as added\n        for rnum in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"round={rnum+1}/{n_round}\")\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    # Give coder the initial message on first round\n                    if rnum == 0 and getattr(role.action, \"name\", \"\") == SimpleWriteCode.name:\n                        response = await role.act(initial_msg)\n                    else:\n                        candidates = self.env.get_messages_for_role(role)\n                        if not candidates:\n                            continue\n                        # Act on the most recent relevant message\n                        response = await role.act(candidates[-1])\n\n                    if response:\n                        # ensure cause_by present\n                        try:\n                            if not getattr(response, \"cause_by\", None):\n                                response.cause_by = getattr(role.action, \"name\", \"\") or \"\"\n                        except Exception:\n                            pass\n                        self.env.publish_message(response)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    # continue with next role despite errors\n                    continue\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"round={rnum+1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\nUnique approach: Modification: Full rewrite, Alternative overall_score approach\n\n\n\n# Current Program\n```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Stable string conversion without raising.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        if isinstance(x, str):\n            return x\n        return str(x)\n    except Exception:\n        return \"\"\n\ndef _make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None):\n    \"\"\"\n    Create a Message instance in a robust way that works with pydantic Message or fallback Message class.\n    Returns an object with expected attributes.\n    \"\"\"\n    content = _safe_str(content)\n    try:\n        # Preferred: named constructor (works with pydantic Message)\n        return Message(content=content, instruct_content=instruct_content, role=role, cause_by=cause_by or \"\", sent_from=sent_from)\n    except Exception:\n        try:\n            # Fallback positional\n            return Message(content, role, instruct_content=instruct_content, cause_by=cause_by or \"\", sent_from=sent_from)\n        except Exception:\n            # Last resort: minimal object\n            class _M:\n                def __init__(self, content, role, cause_by, sent_from, instruct_content):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = instruct_content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n            return _M(content, role, cause_by or \"\", sent_from, instruct_content)\n\nclass Action(ABC):\n    \"\"\"Small, predictable action base with lazy LLM init and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily instantiate LLMInterface; swallow errors to avoid failure modes.\"\"\"\n        if self._llm is None and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            try:\n                self._llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(event, getattr(self, \"name\", \"Action\"), details)\n            except Exception:\n                pass\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea = _safe_str(idea).strip()\n        self._log(\"ACTION_START\", f\"Writing code for: {idea[:120]}\")\n        prompt = (\n            \"You are an expert Python programmer. Produce concise, correct Python code for the request.\\n\\n\"\n            f\"Task:\\n{idea}\\n\\n\"\n            \"Requirements:\\n- Clean, testable code\\n- Basic error handling\\n- Short comments\\nReturn only the code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                resp = await self.llm.ask(messages)\n                code = _safe_str(resp)\n            else:\n                # Deterministic fallback reduces flakiness\n                code = (\n                    f\"# Implementation for: {idea}\\n\\n\"\n                    \"def placeholder_function():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'placeholder'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {_safe_str(e)}\"\n        self._log(\"ACTION_END\", f\"Generated {len(code)} chars\")\n        return code\n\nclass SimpleWriteTest(Action):\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code = _safe_str(code)\n        self._log(\"ACTION_START\", \"Writing tests for code\")\n        prompt = (\n            \"You are an expert QA engineer. Given the implementation, write pytest-style tests (positive and negative).\\n\\n\"\n            f\"Code:\\n{code[:2000]}\\n\\n\"\n            \"Return only the test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                resp = await self.llm.ask(messages)\n                tests = _safe_str(resp)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {_safe_str(e)}\"\n        self._log(\"ACTION_END\", f\"Generated {len(tests)} chars\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code = _safe_str(code)\n        tests = _safe_str(tests)\n        self._log(\"ACTION_START\", f\"Reviewing (human={self.is_human})\")\n        if self.is_human:\n            review = \"Human review: Looks reasonable. Consider adding more edge-case tests and clearer errors.\"\n        else:\n            prompt = (\n                \"You are a senior engineer. Provide a concise review focusing on code quality, test coverage, and issues.\\n\\n\"\n                f\"Code:\\n{code[:1500]}\\n\\nTests:\\n{tests[:1500]}\\n\\nKeep it concise.\"\n            )\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            try:\n                if self.llm:\n                    resp = await self.llm.ask(messages)\n                    review = _safe_str(resp)\n                else:\n                    review = \"Automated review: Acceptable structure; consider more edge cases and clearer error handling.\"\n            except Exception as e:\n                review = f\"Error during review: {_safe_str(e)}\"\n        self._log(\"ACTION_END\", f\"Review length {len(review)}\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Simplified role with deterministic selection and minimal mutable state.\"\"\"\n    def __init__(self, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains cause_by strings to respond to\n        self.watch_list: List[str] = []\n        # environment reference set when hired\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        # Ensure action contexts are consistent\n        prepared = []\n        for a in (actions or []):\n            try:\n                a.context = self.context\n            except Exception:\n                pass\n            prepared.append(a)\n        self.actions = prepared\n\n    def _watch(self, actions: List[Type[Action]]):\n        names: List[str] = []\n        for a in (actions or []):\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                try:\n                    names.append(getattr(a, \"name\"))\n                except Exception:\n                    pass\n            elif isinstance(a, type):\n                names.append(getattr(a, \"name\", a.__name__))\n        self.watch_list = names\n\n    def _log(self, event: str, details: str):\n        tracer = getattr(self.context, \"tracer\", None)\n        if tracer:\n            try:\n                tracer.log(event, self.name, details)\n            except Exception:\n                pass\n\n    async def act(self, message: Optional[Message] = None, env: Optional[\"Environment\"] = None) -> Optional[Message]:\n        \"\"\"\n        Determine appropriate action and produce a message.\n        Deterministic mapping:\n          - If there is an instruct_content -> SimpleWriteCode\n          - If message.cause_by == SimpleWriteCode -> SimpleWriteTest\n          - If message.cause_by == SimpleWriteTest -> SimpleWriteReview\n          - Otherwise default to first action.\n        \"\"\"\n        if not self.actions:\n            self._log(\"ROLE_SKIP\", \"No actions available\")\n            return None\n\n        env = env or self.env\n        selected = self.actions[0]\n\n        # Prefer explicit instruction for coder\n        if message and getattr(message, \"instruct_content\", None):\n            for a in self.actions:\n                if getattr(a, \"name\", \"\") == SimpleWriteCode.name:\n                    selected = a\n                    break\n        else:\n            cause = getattr(message, \"cause_by\", \"\") if message else \"\"\n            if cause:\n                if cause == SimpleWriteCode.name:\n                    for a in self.actions:\n                        if getattr(a, \"name\", \"\") == SimpleWriteTest.name:\n                            selected = a\n                            break\n                elif cause == SimpleWriteTest.name:\n                    for a in self.actions:\n                        if getattr(a, \"name\", \"\") == SimpleWriteReview.name:\n                            selected = a\n                            break\n\n        self._log(\"ROLE_ACT\", f\"Executing {getattr(selected, 'name', 'Action')}\")\n\n        try:\n            if getattr(selected, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await selected.run(idea)\n\n            elif getattr(selected, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code in the triggering message; else search env history\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                elif env:\n                    for m in reversed(env.history):\n                        if getattr(m, \"cause_by\", \"\") == SimpleWriteCode.name:\n                            code_text = getattr(m, \"content\", \"\") or \"\"\n                            break\n                result = await selected.run(code_text)\n\n            elif getattr(selected, \"name\", \"\") == SimpleWriteReview.name:\n                code_text = \"\"\n                tests_text = \"\"\n                # If message is tests or code prefer it\n                if message:\n                    if getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                        tests_text = getattr(message, \"content\", \"\") or \"\"\n                    elif getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                        code_text = getattr(message, \"content\", \"\") or \"\"\n                # Fill missing pieces from env\n                if env:\n                    if not code_text:\n                        for m in reversed(env.history):\n                            if getattr(m, \"cause_by\", \"\") == SimpleWriteCode.name:\n                                code_text = getattr(m, \"content\", \"\") or \"\"\n                                break\n                    if not tests_text:\n                        for m in reversed(env.history):\n                            if getattr(m, \"cause_by\", \"\") == SimpleWriteTest.name:\n                                tests_text = getattr(m, \"content\", \"\") or \"\"\n                                break\n                # Propagate human flag to action if possible\n                if isinstance(selected, SimpleWriteReview):\n                    selected.is_human = self.is_human\n                result = await selected.run(code_text, tests_text)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await selected.run(payload)\n        except Exception as e:\n            self._log(\"ROLE_ERROR\", f\"Action failed: {_safe_str(e)}\")\n            result = f\"Error executing action: {_safe_str(e)}\"\n\n        response = _make_message(content=result, role=self.profile, cause_by=getattr(selected, \"name\", \"\"), sent_from=self.name)\n        self._log(\"ROLE_COMPLETE\", f\"Produced message (cause_by={getattr(selected, 'name', '')})\")\n        return response\n\nclass SimpleCoder(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n        self._watch([])  # listens to explicit user instruction\n\nclass SimpleTester(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode])\n\nclass SimpleReviewer(Role):\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration with simple routing rules.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        # Attach environment reference to role for lookups\n        try:\n            role.env = self\n        except Exception:\n            pass\n        self.roles.append(role)\n        if self.tracer:\n            try:\n                self.tracer.log(\"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n            except Exception:\n                pass\n\n    def publish_message(self, message: Message):\n        \"\"\"Append message and log a short preview. Never raise.\"\"\"\n        try:\n            self.history.append(message)\n            if self.tracer:\n                sender = getattr(message, \"sent_from\", \"Unknown\")\n                preview = _safe_str(getattr(message, \"content\", \"\"))[:120]\n                cause = getattr(message, \"cause_by\", \"\")\n                self.tracer.log(\"ENV_MESSAGE\", \"Environment\", f\"From {sender} (cause={cause}): {preview}\")\n        except Exception:\n            # swallow any error to avoid interrupting runs\n            try:\n                if self.tracer:\n                    self.tracer.log(\"ENV_ERROR\", \"Environment\", \"Failed to publish message\")\n            except Exception:\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches role.watch_list.\"\"\"\n        if not role.watch_list:\n            return []\n        results: List[Message] = []\n        try:\n            watched = set(role.watch_list)\n            for m in self.history:\n                try:\n                    if getattr(m, \"cause_by\", \"\") in watched:\n                        results.append(m)\n                except Exception:\n                    continue\n        except Exception:\n            pass\n        return results\n\nclass Team:\n    \"\"\"Orchestrates roles deterministically with safe error handling.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        # expose env inside context for convenience\n        try:\n            self.context.env = self.env\n        except Exception:\n            pass\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        for r in (roles or []):\n            try:\n                r.context = self.context\n            except Exception:\n                pass\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = _safe_str(idea)\n        try:\n            if self.tracer:\n                self.tracer.log(\"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n        except Exception:\n            pass\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        try:\n            if self.tracer:\n                self.tracer.log(\"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        except Exception:\n            pass\n\n        # initial user message\n        initial = _make_message(content=f\"Let's work on this project: {self.idea}\", role=\"Human\", cause_by=\"UserInput\", sent_from=\"User\", instruct_content=self.idea)\n        self.env.publish_message(initial)\n\n        for round_num in range(n_round):\n            try:\n                if self.tracer:\n                    self.tracer.log(\"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            except Exception:\n                pass\n\n            # Iterate over a stable snapshot of roles\n            for role in list(self.env.roles):\n                response = None\n                try:\n                    # First round: coder responds to user input explicitly\n                    if round_num == 0 and role.profile == \"SimpleCoder\":\n                        response = await role.act(initial, env=self.env)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if relevant:\n                            response = await role.act(relevant[-1], env=self.env)\n                        else:\n                            continue\n                except Exception as e:\n                    try:\n                        if self.tracer:\n                            self.tracer.log(\"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{_safe_str(e)}\")\n                    except Exception:\n                        pass\n                    continue\n\n                if response:\n                    # Ensure cause_by present\n                    try:\n                        if not getattr(response, \"cause_by\", None):\n                            response.cause_by = getattr(response, \"cause_by\", \"\") or \"\"\n                    except Exception:\n                        pass\n                    self.env.publish_message(response)\n\n            try:\n                if self.tracer:\n                    self.tracer.log(\"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n            except Exception:\n                pass\n\n        try:\n            if self.tracer:\n                self.tracer.log(\"TEAM_END\", \"Team\", \"Project completed\")\n        except Exception:\n            pass\n\n        try:\n            summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n            if self.tracer:\n                self.tracer.log(\"SUMMARY\", \"Team\", summary)\n        except Exception:\n            pass\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["```python\n# python\n\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event: str, agent: str, details: str):\n    \"\"\"Best-effort logging helper that never raises.\"\"\"\n    if not tracer:\n        return\n    try:\n        tracer.log(event, agent, details)\n    except Exception:\n        pass\n\ndef _ensure_str(s: Optional[str]) -> str:\n    \"\"\"Convert possibly None or non-string to a safe string.\"\"\"\n    if s is None:\n        return \"\"\n    try:\n        return str(s)\n    except Exception:\n        return \"\"\n\nclass Action(ABC):\n    \"\"\"Simplified base Action with safe llm access and logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg is not None and getattr(cfg, \"llm\", None) is not None:\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate code for the provided idea/requirements.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea = _ensure_str(idea).strip()\n        self._log(\"ACTION_START\", f\"len_idea={len(idea)}\")\n        if not idea:\n            # Deterministic fallback to reduce variability/failure\n            fallback = (\n                \"# No idea provided. Placeholder implementation\\n\"\n                \"def solution(*args, **kwargs):\\n\"\n                \"    \\\"\\\"\\\"Placeholder solution.\\\"\\\"\\\"\\n\"\n                \"    return None\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are an expert Python programmer. Write clean, testable Python code for the task below.\\n\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Clean, testable code\\n\"\n            \"- Basic error handling\\n\"\n            \"- Short comments for non-obvious parts\\n\\n\"\n            \"Return only the code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                code = f\"# Implementation for: {idea}\\n# [LLM unavailable - fallback placeholder]\\n\"\n        except Exception as e:\n            code = f\"# Error generating code: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for given code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code = _ensure_str(code)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}\")\n        if not code.strip():\n            fallback = (\n                \"import pytest\\n\\n\"\n                \"def test_placeholder():\\n\"\n                \"    \\\"\\\"\\\"Placeholder test.\\\"\\\"\\\"\\n\"\n                \"    assert True\\n\"\n            )\n            self._log(\"ACTION_END\", \"used_fallback\")\n            return fallback\n\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the implementation below.\\n\\n\"\n            f\"Code (first 2000 chars):\\n{code[:2000]}\\n\\n\"\n            \"Requirements:\\n\"\n            \"- Use pytest\\n\"\n            \"- Cover normal and edge cases\\n\"\n            \"- Include docstrings\\n\\n\"\n            \"Return only the test code.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\\n\"\n        self._log(\"ACTION_END\", f\"generated_len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide concise human-like or automated review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code = _ensure_str(code)\n        tests = _ensure_str(tests)\n        self._log(\"ACTION_START\", f\"code_len={len(code)}, tests_len={len(tests)}, human={self.is_human}\")\n        if self.is_human:\n            review = \"Human review: Looks good overall. Consider adding more edge-case tests and clearer docstrings.\"\n            self._log(\"ACTION_END\", \"human_review\")\n            return review\n\n        prompt = (\n            \"You are a senior reviewer. Provide a concise actionable review of the code and tests.\\n\\n\"\n            f\"Code (first 1500 chars):\\n{code[:1500]}\\n\\n\"\n            f\"Tests (first 1500 chars):\\n{tests[:1500]}\\n\\n\"\n            \"Focus on readability, potential bugs, and test coverage. Be concise.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        try:\n            if self.llm:\n                review = await self.llm.ask(messages)\n            else:\n                review = \"Automated review: Code structure acceptable. Add more boundary and negative-case tests.\"\n        except Exception as e:\n            review = f\"Review error: {e}\"\n        self._log(\"ACTION_END\", f\"generated_len={len(review)}\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Simple role abstraction with deterministic action selection.\"\"\"\n    def __init__(self, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = is_human\n        # single primary action instance per role\n        self.action: Optional[Action] = None\n        # watch_list: cause_by strings this role should respond to\n        self.watch_list: List[str] = []\n        # environment reference set when hired\n        self.env: Optional[\"Environment\"] = None\n\n    def set_action(self, action: Action):\n        # ensure action knows context\n        if getattr(action, \"context\", None) is None:\n            action.context = self.context\n        self.action = action\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: List[str] = []\n        for a in actions or []:\n            if isinstance(a, str):\n                names.append(a)\n            elif hasattr(a, \"name\"):\n                names.append(getattr(a, \"name\"))\n            elif hasattr(a, \"__name__\"):\n                names.append(getattr(a, \"__name__\"))\n        self.watch_list = [n for n in names if n]\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, self.name, details)\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute the primary action using a small set of explicit, deterministic rules.\"\"\"\n        if not self.action:\n            self._log(\"ROLE_SKIP\", \"no_action\")\n            return None\n\n        self._log(\"ROLE_ACT\", f\"action={getattr(self.action, 'name', 'unknown')}, msg_id={getattr(message, 'id', None)}\")\n\n        try:\n            # Determine inputs in priority: explicit message -> env latest -> fallback\n            if getattr(self.action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await self.action.run(idea or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteTest.name:\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\")\n                elif self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await self.action.run(code_text or \"\")\n            elif getattr(self.action, \"name\", \"\") == SimpleWriteReview.name:\n                # prefer tests from triggering message and code from latest code message\n                tests_text = \"\"\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteTest.name:\n                    tests_text = getattr(message, \"content\", \"\")\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code_text = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    if not tests_text:\n                        latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                        tests_text = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                result = await self.action.run(code_text or \"\", tests_text or \"\")\n            else:\n                # Generic fallback: pass message content or empty string\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await self.action.run(payload)\n        except Exception as e:\n            err = f\"Action failed: {e}\"\n            self._log(\"ROLE_ERROR\", err)\n            result = err\n\n        # Construct a Message for response; keep compatible with both pydantic and fallback Message\n        try:\n            response = Message(\n                content=result,\n                role=self.profile,\n                cause_by=getattr(self.action, \"name\", \"\"),\n                sent_from=self.name\n            )\n        except Exception:\n            class _Mini:\n                pass\n            response = _Mini()\n            response.id = str(uuid.uuid4())\n            response.content = result\n            response.instruct_content = None\n            response.role = self.profile\n            response.cause_by = getattr(self.action, \"name\", \"\")\n            response.sent_from = self.name\n\n        self._log(\"ROLE_COMPLETE\", f\"produced_len={len(_ensure_str(result))}\")\n        return response\n\nclass SimpleCoder(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Alice\"), profile=kwargs.get(\"profile\", \"SimpleCoder\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteCode(context=self.context))\n        self._watch([])  # responds to initial user instruction\n\nclass SimpleTester(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Bob\"), profile=kwargs.get(\"profile\", \"SimpleTester\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteTest(context=self.context))\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    def __init__(self, **kwargs):\n        super().__init__(name=kwargs.get(\"name\", \"Charlie\"), profile=kwargs.get(\"profile\", \"SimpleReviewer\"), context=kwargs.get(\"context\"), is_human=kwargs.get(\"is_human\", False))\n        self.set_action(SimpleWriteReview(is_human=self.is_human, context=self.context))\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Lightweight environment for storing messages and providing simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role={role.name}\")\n\n    def publish_message(self, message: Message):\n        # Ensure message has id where possible and append; log safely\n        try:\n            if not hasattr(message, \"id\") or getattr(message, \"id\", None) is None:\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n        self.history.append(message)\n        _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={getattr(message, 'sent_from', 'Unknown')} cause={getattr(message, 'cause_by', '')} preview={_ensure_str(getattr(message, 'content', ''))[:100]}\")\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by is in role.watch_list (in chronological order).\"\"\"\n        if not role.watch_list:\n            return []\n        watched = set(role.watch_list)\n        result: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    result.append(msg)\n            except Exception:\n                continue\n        return result\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates roles to collaborate on an idea. Simple, deterministic and robust.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # Ensure context has tracer reference\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        for r in roles:\n            # Bind team context and environment to roles and their actions\n            r.context = r.context or self.context\n            r.env = self.env\n            if getattr(r, \"action\", None):\n                try:\n                    r.action.context = r.action.context or self.context\n                except Exception:\n                    pass\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = float(investment)\n\n    def run_project(self, idea: str):\n        self.idea = _ensure_str(idea)\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running rounds={n_round}\")\n\n        # Initial user message\n        initial_msg = Message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        # Deterministic order: as added\n        for rnum in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"round={rnum+1}/{n_round}\")\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    # Give coder the initial message on first round\n                    if rnum == 0 and getattr(role.action, \"name\", \"\") == SimpleWriteCode.name:\n                        response = await role.act(initial_msg)\n                    else:\n                        candidates = self.env.get_messages_for_role(role)\n                        if not candidates:\n                            continue\n                        # Act on the most recent relevant message\n                        response = await role.act(candidates[-1])\n\n                    if response:\n                        # ensure cause_by present\n                        try:\n                            if not getattr(response, \"cause_by\", None):\n                                response.cause_by = getattr(role.action, \"name\", \"\") or \"\"\n                        except Exception:\n                            pass\n                        self.env.publish_message(response)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), f\"{e}\")\n                    # continue with next role despite errors\n                    continue\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"round={rnum+1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"\n```"]}}}