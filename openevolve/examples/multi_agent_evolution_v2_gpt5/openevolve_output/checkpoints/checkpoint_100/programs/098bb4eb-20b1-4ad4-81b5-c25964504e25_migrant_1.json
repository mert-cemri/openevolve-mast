{"id": "098bb4eb-20b1-4ad4-81b5-c25964504e25_migrant_1", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_log(tracer: Optional[ExecutionTracer], event_type: str, agent: str, details: str):\n    \"\"\"Safe logging helper that never raises.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event_type, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str,\n                 role: str,\n                 cause_by: str = \"\",\n                 sent_from: Optional[str] = None,\n                 instruct_content: Optional[str] = None) -> Message:\n    \"\"\"\n    Robust factory to create Message objects compatible with both pydantic and fallback classes.\n    Accepts defaults for optional fields to reduce failure modes.\n    \"\"\"\n    kwargs = {\n        \"content\": content if content is not None else \"\",\n        \"role\": role if role is not None else \"\",\n        \"cause_by\": cause_by if cause_by is not None else \"\",\n        \"sent_from\": sent_from\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = instruct_content\n    try:\n        # Preferred construction for pydantic-based Message\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional/fallback Message constructor\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"],\n                           instruct_content=kwargs.get(\"instruct_content\"),\n                           cause_by=kwargs[\"cause_by\"],\n                           sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Final minimal fallback: simple object with expected attributes\n            class _M:\n                pass\n            m = _M()\n            m.id = str(uuid.uuid4())\n            m.content = kwargs[\"content\"]\n            m.instruct_content = kwargs.get(\"instruct_content\")\n            m.role = kwargs[\"role\"]\n            m.cause_by = kwargs[\"cause_by\"]\n            m.sent_from = kwargs[\"sent_from\"]\n            m.sent_to = None\n            m.send_to = set()\n            return m\n\nclass Action(ABC):\n    \"\"\"Minimal, robust action base with lazy LLM binding and safe logging.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, *, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        \"\"\"Lazily instantiate LLMInterface if configuration exists.\"\"\"\n        if self._llm is None and self.context is not None:\n            try:\n                cfg = getattr(self.context, \"config\", None)\n                if cfg and getattr(cfg, \"llm\", None):\n                    self._llm = LLMInterface(cfg.llm)\n            except Exception:\n                self._llm = None\n        return self._llm\n\n    def _log(self, event: str, details: str):\n        _safe_log(getattr(self.context, \"tracer\", None), event, getattr(self, \"name\", \"Action\"), details)\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code from a human idea.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea_text = (idea or \"\").strip()\n        self._log(\"ACTION_START\", f\"Generating code for idea (len={len(idea_text)})\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\\n\"\n            f\"Task: {idea_text}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Provide only the code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic safe fallback that is valid Python\n                code = (\n                    f\"# Implementation for: {idea_text}\\n\"\n                    \"def placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation until an LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        self._log(\"ACTION_END\", f\"Generated code length={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate pytest-style tests for provided code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code_snippet = (code or \"\")[:2000]\n        self._log(\"ACTION_START\", f\"Generating tests (code_len={len(code_snippet)})\")\n        prompt = (\n            \"You are a QA engineer. Write pytest-style tests for the following code:\\n\\n\"\n            f\"Code:\\n{code_snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain each test\\n\\n\"\n            \"Provide only the test code.\"\n        )\n        messages = [{\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n                    {\"role\": \"user\", \"content\": prompt}]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test until LLM is available.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        self._log(\"ACTION_END\", f\"Generated tests length={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Provide a concise review of code and tests.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, *, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code_text = (code or \"\")[:1500]\n        tests_text = (tests or \"\")[:1500]\n        self._log(\"ACTION_START\", f\"Reviewing (human={self.is_human}) code_len={len(code_text)} tests_len={len(tests_text)}\")\n        try:\n            if self.is_human:\n                review = \"Human review: Looks generally good. Consider additional error handling and edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code_text}\\n\\n\"\n                    f\"Tests:\\n{tests_text}\\n\\n\"\n                    \"Give a concise review focusing on code quality, test coverage, potential bugs and suggestions.\"\n                )\n                messages = [{\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                            {\"role\": \"user\", \"content\": prompt}]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable. Add more edge-case coverage and clearer exceptions.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        self._log(\"ACTION_END\", f\"Review length={len(review)}\")\n        return review\n\nclass Role:\n    \"\"\"Lightweight role holding a single primary action and a watch list of cause_by tokens.\"\"\"\n    def __init__(self, *, name: str = \"Role\", profile: str = \"Default\", context: Optional[Context] = None, is_human: bool = False):\n        self.name = name\n        self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains strings matching Message.cause_by\n        self.watch_list: Set[str] = set()\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Bind provided action instances and ensure context alignment.\"\"\"\n        bound: List[Action] = []\n        for a in (actions or []):\n            try:\n                a.context = a.context or self.context\n            except Exception:\n                a.context = self.context\n            bound.append(a)\n        self.actions = bound\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        names: Set[str] = set()\n        for a in (actions or []):\n            if isinstance(a, str):\n                names.add(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Run the primary action and return a Message result or None.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ACT\", self.name, f\"Action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        try:\n            # Routing: map messages/environment to action inputs deterministically and simply\n            if getattr(action, \"name\", \"\") == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n            elif getattr(action, \"name\", \"\") == SimpleWriteTest.name:\n                # Prefer code from the triggering message (if any); else fetch latest code from env\n                code = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code = getattr(message, \"content\", \"\") or \"\"\n                if not code and self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    code = getattr(latest, \"content\", \"\") if latest else \"\"\n                result = await action.run(code)\n            elif getattr(action, \"name\", \"\") == SimpleWriteReview.name:\n                # Gather best-effort code and tests from env or message\n                code = \"\"\n                tests = \"\"\n                if self.env:\n                    latest_code = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    latest_tests = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code = getattr(latest_code, \"content\", \"\") if latest_code else \"\"\n                    tests = getattr(latest_tests, \"content\", \"\") if latest_tests else \"\"\n                if message:\n                    tests = tests or getattr(message, \"content\", \"\") or \"\"\n                    code = code or getattr(message, \"instruct_content\", \"\") or \"\"\n                result = await action.run(code, tests)\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_ERROR\", self.name, f\"Exception during act: {e}\")\n            result = f\"Error in role {self.name}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _safe_log(getattr(self.context, \"tracer\", None), \"ROLE_COMPLETE\", self.name, f\"Created message id={getattr(response, 'id', None)}\")\n        return response\n\nclass SimpleCoder(Role):\n    \"\"\"Role that writes code\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Alice\")\n        profile = kwargs.get(\"profile\", \"SimpleCoder\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    \"\"\"Role that writes tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Bob\")\n        profile = kwargs.get(\"profile\", \"SimpleTester\")\n        context = kwargs.get(\"context\")\n        super().__init__(name=name, profile=profile, context=context, is_human=kwargs.get(\"is_human\", False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    \"\"\"Role that reviews code and tests\"\"\"\n    def __init__(self, **kwargs):\n        name = kwargs.get(\"name\", \"Charlie\")\n        profile = kwargs.get(\"profile\", \"SimpleReviewer\")\n        context = kwargs.get(\"context\")\n        is_human = kwargs.get(\"is_human\", False)\n        super().__init__(name=name, profile=profile, context=context, is_human=is_human)\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Environment for multi-agent collaboration: holds roles and messages and provides simple queries.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n\n    def add_role(self, role: Role):\n        try:\n            role.env = self\n        except Exception:\n            role.env = None\n        self.roles.append(role)\n        _safe_log(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def get_roles(self, profile: Optional[str] = None) -> List[Role]:\n        if profile:\n            return [r for r in self.roles if r.profile == profile]\n        return list(self.roles)\n\n    def publish_message(self, message: Message):\n        \"\"\"Append a message to history and log a short preview. Be resilient to message shape.\"\"\"\n        try:\n            # Ensure id exists where possible\n            if not getattr(message, \"id\", None):\n                try:\n                    message.id = str(uuid.uuid4())\n                except Exception:\n                    pass\n            self.history.append(message)\n            preview = (getattr(message, \"content\", \"\") or \"\")[:100]\n            sender = getattr(message, \"sent_from\", \"unknown\")\n            _safe_log(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"Message from {sender}: {preview}\")\n        except Exception:\n            # Try to normalize and store minimal message\n            try:\n                minimal = make_message(\n                    content=str(getattr(message, \"content\", \"\") or \"\"),\n                    role=getattr(message, \"role\", \"Unknown\"),\n                    cause_by=getattr(message, \"cause_by\", \"\"),\n                    sent_from=getattr(message, \"sent_from\", \"unknown\")\n                )\n                self.history.append(minimal)\n            except Exception:\n                # give up silently to avoid propagation\n                pass\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return messages whose cause_by matches anything in the role's watch_list, preserving order.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        relevant: List[Message] = []\n        for msg in self.history:\n            try:\n                if getattr(msg, \"cause_by\", \"\") in watched:\n                    relevant.append(msg)\n            except Exception:\n                continue\n        return relevant\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the most recent message with matching cause_by, or None.\"\"\"\n        for msg in reversed(self.history):\n            try:\n                if getattr(msg, \"cause_by\", \"\") == cause_name:\n                    return msg\n            except Exception:\n                continue\n        return None\n\nclass Team:\n    \"\"\"Orchestrates a group of roles to collaborate for n rounds with robust handling.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # ensure tracer accessible via context, but don't fail if not allowed\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Add roles to the team and align contexts and environments.\"\"\"\n        for role in roles:\n            try:\n                role.context = role.context or self.context\n                role.env = self.env\n                # Ensure action instances are context-aware\n                for a in getattr(role, \"actions\", []) or []:\n                    a.context = a.context or self.context\n            except Exception:\n                pass\n            self.env.add_role(role)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea or \"\"\n        _safe_log(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {self.idea}\")\n\n    async def run(self, n_round: int = 3):\n        n_round = max(1, int(n_round or 1))\n        _safe_log(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n\n        # Initial message (user instruction)\n        initial = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial)\n\n        for round_idx in range(n_round):\n            _safe_log(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_idx + 1}/{n_round}\")\n            # Deterministic iteration order of roles\n            for role in list(self.env.roles):\n                response: Optional[Message] = None\n                try:\n                    # First round: let coder(s) respond to initial input\n                    if round_idx == 0 and any(a.name == SimpleWriteCode.name for a in role.actions):\n                        response = await role.act(initial)\n                    else:\n                        relevant = self.env.get_messages_for_role(role)\n                        if not relevant:\n                            continue\n                        latest = relevant[-1]\n                        response = await role.act(latest)\n                except Exception as e:\n                    _safe_log(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), str(e))\n                    response = None\n\n                if response:\n                    self.env.publish_message(response)\n            _safe_log(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_idx + 1} completed\")\n\n        _safe_log(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _safe_log(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "098bb4eb-20b1-4ad4-81b5-c25964504e25", "generation": 3, "timestamp": 1754649464.1084902, "iteration_found": 0, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 1, "migrant": true}, "artifacts_json": null, "artifact_dir": null}