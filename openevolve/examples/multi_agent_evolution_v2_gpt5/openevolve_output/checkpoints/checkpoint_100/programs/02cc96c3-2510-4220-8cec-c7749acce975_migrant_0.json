{"id": "02cc96c3-2510-4220-8cec-c7749acce975_migrant_0", "code": "\"\"\"\nInitial multi-agent system for evolution.\nThis contains the core multi-agent logic that will be evolved to minimize failure modes.\n\"\"\"\n\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set, Type\n\ntry:\n    import aiohttp\nexcept ImportError:\n    aiohttp = None\n\ntry:\n    from pydantic import BaseModel, Field\nexcept ImportError:\n    BaseModel = None\n    Field = None\n\n# ============== Fixed Infrastructure (Not Evolved) ==============\n\nclass ExecutionTracer:\n    \"\"\"Comprehensive execution tracer for multi-agent interactions\"\"\"\n    \n    def __init__(self, log_file: Optional[str] = None):\n        self.log_file = log_file\n        self.trace_id = 0\n        \n        if self.log_file:\n            # Clear the log file at the start\n            with open(self.log_file, 'w') as f:\n                f.write(f\"Execution Trace Started: {datetime.now()}\\n\")\n                f.write(\"=\"*80 + \"\\n\")\n    \n    def log(self, event_type: str, agent: str, details: str):\n        \"\"\"Log an event to the trace file\"\"\"\n        self.trace_id += 1\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        log_entry = f\"[{self.trace_id:04d}] [{timestamp}] [{event_type}] [{agent}] {details}\\n\"\n        \n        if self.log_file:\n            with open(self.log_file, 'a') as f:\n                f.write(log_entry)\n        \n        return log_entry\n\nclass LLMType(Enum):\n    \"\"\"LLM types\"\"\"\n    OPENAI = \"openai\"\n    QWEN = \"qwen\"\n    CODELLAMA = \"codellama\"\n\nclass LLMConfig:\n    \"\"\"LLM configuration\"\"\"\n    def __init__(self):\n        self.api_type = LLMType.OPENAI\n        self.model = \"gpt-4o\"\n        self.api_key = None\n        self.base_url = \"https://api.openai.com/v1\"\n        self.proxy = \"\"\n        self.temperature = 0.7\n        self.max_token = 2048\n\nclass Config:\n    \"\"\"Configuration object\"\"\"\n    def __init__(self):\n        self.llm = LLMConfig()\n\nif BaseModel:\n    class Context(BaseModel):\n        \"\"\"Context object that holds configuration and shared state\"\"\"\n        config: Config = Field(default_factory=Config)\n        cost_manager: Optional[Any] = None\n        tracer: Optional[Any] = None\n        \n        class Config:\n            arbitrary_types_allowed = True\n    \n    class Message(BaseModel):\n        \"\"\"Message object for agent communication\"\"\"\n        id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n        content: str\n        instruct_content: Optional[str] = None\n        role: str\n        cause_by: str = \"\"\n        sent_from: Optional[str] = None\n        sent_to: Optional[str] = None\n        send_to: Set[str] = Field(default_factory=set)\n        \n        def __str__(self):\n            return f\"Message(role={self.role}, content={self.content[:50]}...)\"\nelse:\n    # Fallback classes if pydantic is not available\n    class Context:\n        def __init__(self):\n            self.config = Config()\n            self.cost_manager = None\n            self.tracer = None\n    \n    class Message:\n        def __init__(self, content, role, **kwargs):\n            self.id = str(uuid.uuid4())\n            self.content = content\n            self.instruct_content = kwargs.get('instruct_content')\n            self.role = role\n            self.cause_by = kwargs.get('cause_by', '')\n            self.sent_from = kwargs.get('sent_from')\n            self.sent_to = kwargs.get('sent_to')\n            self.send_to = kwargs.get('send_to', set())\n\nclass LLMInterface:\n    \"\"\"Interface for LLM communication\"\"\"\n    def __init__(self, config: LLMConfig):\n        self.config = config\n        self.api_key = config.api_key or os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n        self.base_url = config.base_url\n    \n    async def ask(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Send messages to LLM and get response\"\"\"\n        if not aiohttp:\n            # Fallback for testing without actual API calls\n            return \"I'll help you with that task. Let me write the code for you.\"\n        \n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # data = {\n        #     \"model\": self.config.model,\n        #     \"messages\": messages,\n        #     \"temperature\": self.config.temperature,\n        #     \"max_tokens\": self.config.max_token\n        # }\n        data = {\n            \"model\": self.config.model,\n            \"messages\": messages,\n            \"temperature\": self.config.temperature        \n            }\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.post(\n                    f\"{self.base_url}/chat/completions\",\n                    headers=headers,\n                    json=data,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    if response.status == 200:\n                        result = await response.json()\n                        return result[\"choices\"][0][\"message\"][\"content\"]\n                    else:\n                        error_text = await response.text()\n                        return f\"Error: {response.status} - {error_text[:200]}\"\n        except Exception as e:\n            return f\"Error communicating with LLM: {str(e)}\"\n\n# EVOLVE-BLOCK-START\n# This section contains the multi-agent system logic that will be evolved\n\ndef _safe_str(x: Any) -> str:\n    \"\"\"Return a safe string for any input.\"\"\"\n    try:\n        if x is None:\n            return \"\"\n        return x if isinstance(x, str) else str(x)\n    except Exception:\n        return \"\"\n\ndef _log_safe(tracer: Optional[ExecutionTracer], event: str, agent: str, details: str):\n    \"\"\"Best-effort logging helper to avoid raising inside logging.\"\"\"\n    if tracer:\n        try:\n            tracer.log(event, agent, details)\n        except Exception:\n            pass\n\ndef make_message(content: str, role: str, cause_by: str = \"\", sent_from: Optional[str] = None, instruct_content: Optional[str] = None) -> Message:\n    \"\"\"Construct a Message instance in a stable way for both pydantic and fallback Message.\"\"\"\n    kwargs = {\n        \"content\": _safe_str(content),\n        \"role\": _safe_str(role),\n        \"cause_by\": _safe_str(cause_by),\n        \"sent_from\": _safe_str(sent_from) if sent_from is not None else None\n    }\n    if instruct_content is not None:\n        kwargs[\"instruct_content\"] = _safe_str(instruct_content)\n    try:\n        return Message(**kwargs)\n    except Exception:\n        # Fallback to positional constructor if pydantic variant failed\n        try:\n            return Message(kwargs[\"content\"], kwargs[\"role\"], instruct_content=kwargs.get(\"instruct_content\"), cause_by=kwargs[\"cause_by\"], sent_from=kwargs[\"sent_from\"])\n        except Exception:\n            # Last-resort minimal object\n            class _M:\n                def __init__(self, content, role, cause_by, sent_from, instruct_content=None):\n                    self.id = str(uuid.uuid4())\n                    self.content = content\n                    self.instruct_content = instruct_content\n                    self.role = role\n                    self.cause_by = cause_by\n                    self.sent_from = sent_from\n                    self.sent_to = None\n                    self.send_to = set()\n            return _M(kwargs[\"content\"], kwargs[\"role\"], kwargs[\"cause_by\"], kwargs[\"sent_from\"], kwargs.get(\"instruct_content\"))\n\nclass Action(ABC):\n    \"\"\"Simple, single-responsibility Action base.\"\"\"\n    name: str = \"Action\"\n\n    def __init__(self, context: Optional[Context] = None):\n        self.context = context\n        self._llm: Optional[LLMInterface] = None\n        if self.context and getattr(self.context, \"config\", None) and getattr(self.context.config, \"llm\", None):\n            try:\n                self._llm = LLMInterface(self.context.config.llm)\n            except Exception:\n                self._llm = None\n\n    @property\n    def llm(self) -> Optional[LLMInterface]:\n        return self._llm\n\n    @abstractmethod\n    async def run(self, *args, **kwargs) -> str:\n        \"\"\"Perform the action and return textual result.\"\"\"\n        raise NotImplementedError\n\nclass SimpleWriteCode(Action):\n    \"\"\"Generate implementation code from requirements.\"\"\"\n    name = \"SimpleWriteCode\"\n\n    async def run(self, idea: str = \"\") -> str:\n        idea = _safe_str(idea).strip()\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"idea={idea[:120]}\")\n        prompt = (\n            \"You are a professional programmer. Write Python code for the following task:\\n\"\n            f\"Task: {idea}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write clean, functional Python code\\n\"\n            \"2. Include proper error handling\\n\"\n            \"3. Add comments explaining the logic\\n\"\n            \"4. Make it production-ready\\n\\n\"\n            \"Please provide only the code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert Python programmer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                code = await self.llm.ask(messages)\n            else:\n                # Deterministic, valid Python fallback\n                code = (\n                    f\"# Implementation for: {idea}\\n\"\n                    \"def placeholder_function(*args, **kwargs):\\n\"\n                    \"    \\\"\\\"\\\"Placeholder implementation when LLM is unavailable.\\\"\\\"\\\"\\n\"\n                    \"    try:\\n\"\n                    \"        return 'ok'\\n\"\n                    \"    except Exception:\\n\"\n                    \"        raise\\n\"\n                )\n        except Exception as e:\n            code = f\"# Error generating code: {e}\"\n        code = _safe_str(code)\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"len={len(code)}\")\n        return code\n\nclass SimpleWriteTest(Action):\n    \"\"\"Generate tests for a piece of code.\"\"\"\n    name = \"SimpleWriteTest\"\n\n    async def run(self, code: str = \"\") -> str:\n        code = _safe_str(code)\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"code_len={len(code)}\")\n        snippet = code[:2000] if code else \"# No code provided\"\n        prompt = (\n            \"You are a QA engineer. Write comprehensive tests for the following code:\\n\\n\"\n            f\"Code:\\n{snippet}\\n\\n\"\n            \"Requirements:\\n\"\n            \"1. Write pytest-style test cases\\n\"\n            \"2. Cover edge cases and error conditions\\n\"\n            \"3. Include both positive and negative tests\\n\"\n            \"4. Add docstrings to explain what each test does\\n\\n\"\n            \"Please provide only the test code without any explanation.\"\n        )\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert QA engineer.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        try:\n            if self.llm:\n                tests = await self.llm.ask(messages)\n            else:\n                tests = (\n                    \"import pytest\\n\\n\"\n                    \"def test_placeholder():\\n\"\n                    \"    \\\"\\\"\\\"Placeholder test when LLM is unavailable.\\\"\\\"\\\"\\n\"\n                    \"    assert True\\n\"\n                )\n        except Exception as e:\n            tests = f\"# Error generating tests: {e}\"\n        tests = _safe_str(tests)\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"len={len(tests)}\")\n        return tests\n\nclass SimpleWriteReview(Action):\n    \"\"\"Review code and tests and provide concise feedback.\"\"\"\n    name = \"SimpleWriteReview\"\n\n    def __init__(self, is_human: bool = False, context: Optional[Context] = None):\n        super().__init__(context=context)\n        self.is_human = bool(is_human)\n\n    async def run(self, code: str = \"\", tests: str = \"\") -> str:\n        code = _safe_str(code)\n        tests = _safe_str(tests)\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_START\", self.name, f\"is_human={self.is_human}\")\n        try:\n            if self.is_human:\n                review = \"Human review: Looks generally good. Consider more error handling and edge-case tests.\"\n            else:\n                prompt = (\n                    \"You are a senior code reviewer. Review the following code and tests:\\n\\n\"\n                    f\"Code:\\n{code[:1500]}\\n\\n\"\n                    f\"Tests:\\n{tests[:1500]}\\n\\n\"\n                    \"Provide a brief review focusing on:\\n\"\n                    \"1. Code quality and best practices\\n\"\n                    \"2. Test coverage\\n\"\n                    \"3. Potential bugs or issues\\n\"\n                    \"4. Suggestions for improvement\\n\\n\"\n                    \"Keep your review concise and actionable.\"\n                )\n                messages = [\n                    {\"role\": \"system\", \"content\": \"You are a senior software engineer doing code review.\"},\n                    {\"role\": \"user\", \"content\": prompt},\n                ]\n                if self.llm:\n                    review = await self.llm.ask(messages)\n                else:\n                    review = \"Automated review: Structure is reasonable; add more edge-case handling and clearer errors.\"\n        except Exception as e:\n            review = f\"Error during review: {e}\"\n        review = _safe_str(review)\n        _log_safe(getattr(self.context, \"tracer\", None), \"ACTION_END\", self.name, f\"len={len(review)}\")\n        return review\n\nclass Role(ABC):\n    \"\"\"Minimal, deterministic Role implementation.\"\"\"\n    name: str = \"Role\"\n    profile: str = \"Default\"\n\n    def __init__(self, name: Optional[str] = None, profile: Optional[str] = None, context: Optional[Context] = None, is_human: bool = False):\n        if name:\n            self.name = name\n        if profile:\n            self.profile = profile\n        self.context = context\n        self.is_human = bool(is_human)\n        self.actions: List[Action] = []\n        # watch_list contains cause_by string tokens indicating which messages to handle\n        self.watch_list: Set[str] = set()\n        self.env: Optional[\"Environment\"] = None\n\n    def set_actions(self, actions: List[Action]):\n        \"\"\"Assign action instances; ensure their context is aligned.\"\"\"\n        self.actions = actions or []\n        for a in self.actions:\n            a.context = self.context\n\n    def _watch(self, actions: List[Type[Action] or str]):\n        \"\"\"Normalize a watch list to names (strings).\"\"\"\n        names: Set[str] = set()\n        for a in actions or []:\n            if isinstance(a, str):\n                names.add(a)\n            elif isinstance(a, type) and hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n            elif hasattr(a, \"name\"):\n                names.add(getattr(a, \"name\"))\n        self.watch_list = names\n\n    async def act(self, message: Optional[Message] = None) -> Optional[Message]:\n        \"\"\"Execute primary action with clear routing rules.\"\"\"\n        if not self.actions:\n            return None\n        action = self.actions[0]\n        tracer = getattr(self.context, \"tracer\", None)\n        _log_safe(tracer, \"ROLE_ACT\", self.name, f\"action={getattr(action, 'name', 'Action')} msg_id={getattr(message, 'id', None)}\")\n        try:\n            # Routing by action name keeps behavior explicit and simple\n            if action.name == SimpleWriteCode.name:\n                idea = \"\"\n                if message:\n                    idea = getattr(message, \"instruct_content\", None) or getattr(message, \"content\", \"\") or \"\"\n                result = await action.run(idea)\n\n            elif action.name == SimpleWriteTest.name:\n                # Prefer code from triggering message (if caused by code action),\n                # else get latest code from environment if available.\n                code_text = \"\"\n                if message and getattr(message, \"cause_by\", \"\") == SimpleWriteCode.name:\n                    code_text = getattr(message, \"content\", \"\") or \"\"\n                if not code_text and self.env:\n                    latest = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    if latest:\n                        code_text = getattr(latest, \"content\", \"\") or \"\"\n                result = await action.run(code_text)\n\n            elif action.name == SimpleWriteReview.name:\n                # Compose code and tests from environment for review\n                code_text = \"\"\n                tests_text = \"\"\n                if self.env:\n                    code_msg = self.env.get_latest_message_by_cause(SimpleWriteCode.name)\n                    test_msg = self.env.get_latest_message_by_cause(SimpleWriteTest.name)\n                    code_text = getattr(code_msg, \"content\", \"\") if code_msg else \"\"\n                    tests_text = getattr(test_msg, \"content\", \"\") if test_msg else \"\"\n                # If message explicitly contains something, prefer its fields\n                if message:\n                    tests_text = tests_text or getattr(message, \"content\", \"\") or \"\"\n                    code_text = code_text or getattr(message, \"instruct_content\", \"\") or \"\"\n                result = await action.run(code_text, tests_text)\n\n            else:\n                payload = getattr(message, \"content\", \"\") if message else \"\"\n                result = await action.run(payload)\n        except Exception as e:\n            _log_safe(tracer, \"ROLE_ERROR\", self.name, _safe_str(e))\n            result = f\"Error executing {getattr(action, 'name', 'Action')}: {e}\"\n\n        response = make_message(\n            content=result,\n            role=self.profile,\n            cause_by=getattr(action, \"name\", \"\"),\n            sent_from=self.name\n        )\n        _log_safe(tracer, \"ROLE_COMPLETE\", self.name, f\"created_msg_id={getattr(response, 'id', None)}\")\n        return response\n\nclass SimpleCoder(Role):\n    name = \"Alice\"\n    profile = \"SimpleCoder\"\n    def __init__(self, **kwargs):\n        super().__init__(name=self.name, profile=self.profile, context=kwargs.get('context'), is_human=kwargs.get('is_human', False))\n        self.set_actions([SimpleWriteCode(context=self.context)])\n\nclass SimpleTester(Role):\n    name = \"Bob\"\n    profile = \"SimpleTester\"\n    def __init__(self, **kwargs):\n        super().__init__(name=self.name, profile=self.profile, context=kwargs.get('context'), is_human=kwargs.get('is_human', False))\n        self.set_actions([SimpleWriteTest(context=self.context)])\n        self._watch([SimpleWriteCode.name])\n\nclass SimpleReviewer(Role):\n    name = \"Charlie\"\n    profile = \"SimpleReviewer\"\n    def __init__(self, **kwargs):\n        super().__init__(name=self.name, profile=self.profile, context=kwargs.get('context'), is_human=kwargs.get('is_human', False))\n        self.set_actions([SimpleWriteReview(is_human=self.is_human, context=self.context)])\n        self._watch([SimpleWriteTest.name])\n\nclass Environment:\n    \"\"\"Lightweight environment to hold messages and provide simple queries with duplicate-prevention.\"\"\"\n    def __init__(self, tracer: Optional[ExecutionTracer] = None):\n        self.roles: List[Role] = []\n        self.history: List[Message] = []\n        self.tracer = tracer\n        # Track last processed message id per role to avoid repeated handling\n        self._last_processed: Dict[str, Optional[str]] = {}\n\n    def add_role(self, role: Role):\n        role.env = self\n        self.roles.append(role)\n        self._last_processed.setdefault(role.name, None)\n        _log_safe(self.tracer, \"ENV_ADD_ROLE\", \"Environment\", f\"Added role: {role.name} ({role.profile})\")\n\n    def _ensure_id(self, message: Message):\n        try:\n            if not getattr(message, \"id\", None):\n                message.id = str(uuid.uuid4())\n        except Exception:\n            pass\n\n    def publish_message(self, message: Message):\n        \"\"\"Append a message and log a concise preview.\"\"\"\n        self._ensure_id(message)\n        try:\n            self.history.append(message)\n        except Exception:\n            # Attempt to normalize and append\n            try:\n                m = make_message(\n                    content=_safe_str(getattr(message, \"content\", message)),\n                    role=_safe_str(getattr(message, \"role\", \"Unknown\")),\n                    cause_by=_safe_str(getattr(message, \"cause_by\", \"\")),\n                    sent_from=_safe_str(getattr(message, \"sent_from\", \"unknown\"))\n                )\n                self._ensure_id(m)\n                self.history.append(m)\n                message = m\n            except Exception:\n                return\n        preview = _safe_str(getattr(message, \"content\", \"\"))[:100]\n        _log_safe(self.tracer, \"ENV_MESSAGE\", \"Environment\", f\"from={getattr(message, 'sent_from', 'unknown')} cause={getattr(message, 'cause_by', '')} preview={preview}\")\n\n    def _index_of_message(self, msg_id: Optional[str]) -> int:\n        if not msg_id:\n            return -1\n        for i, m in enumerate(self.history):\n            try:\n                if getattr(m, \"id\", None) == msg_id:\n                    return i\n            except Exception:\n                continue\n        return -1\n\n    def get_messages_for_role(self, role: Role) -> List[Message]:\n        \"\"\"Return new messages whose cause_by is in the role's watch list and not yet processed by this role.\"\"\"\n        watched = set(role.watch_list or [])\n        if not watched:\n            return []\n        last_id = self._last_processed.get(role.name)\n        start_idx = self._index_of_message(last_id)\n        candidates = self.history[start_idx + 1:] if start_idx >= 0 else self.history\n        return [m for m in candidates if getattr(m, \"cause_by\", \"\") in watched]\n\n    def get_latest_message_by_cause(self, cause_name: str) -> Optional[Message]:\n        \"\"\"Return the latest message with matching cause_by, or None.\"\"\"\n        for m in reversed(self.history):\n            if getattr(m, \"cause_by\", \"\") == cause_name:\n                return m\n        return None\n\n    def mark_processed(self, role: Role, message: Message):\n        \"\"\"Mark a message as processed by a role to avoid duplicate handling.\"\"\"\n        try:\n            self._last_processed[role.name] = getattr(message, \"id\", None)\n            _log_safe(self.tracer, \"ENV_MARKED\", \"Environment\", f\"{role.name} processed {getattr(message, 'id', '')}\")\n        except Exception:\n            pass\n\nclass Team:\n    \"\"\"Orchestrates the roles and runs the collaboration rounds.\"\"\"\n    def __init__(self, context: Optional[Context] = None, log_file: Optional[str] = None):\n        self.context = context or Context()\n        self.tracer = ExecutionTracer(log_file)\n        # propagate tracer into context\n        try:\n            self.context.tracer = self.tracer\n        except Exception:\n            pass\n        self.env = Environment(self.tracer)\n        self.investment: float = 10.0\n        self.idea: str = \"\"\n        self.log_file = log_file\n\n    def hire(self, roles: List[Role]):\n        \"\"\"Attach roles to the team and align contexts.\"\"\"\n        for r in roles:\n            r.context = self.context\n            r.env = self.env\n            # Ensure actions point to the shared context\n            if hasattr(r, \"actions\"):\n                for a in r.actions:\n                    a.context = self.context\n                    # Keep review action aware of human flag\n                    if isinstance(a, SimpleWriteReview):\n                        a.is_human = r.is_human\n            self.env.add_role(r)\n\n    def invest(self, investment: float):\n        self.investment = investment\n\n    def run_project(self, idea: str):\n        self.idea = idea\n        _log_safe(self.tracer, \"TEAM_START\", \"Team\", f\"Starting project: {idea}\")\n\n    async def run(self, n_round: int = 3):\n        _log_safe(self.tracer, \"TEAM_RUN\", \"Team\", f\"Running {n_round} rounds\")\n        # initial message\n        initial_msg = make_message(\n            content=f\"Let's work on this project: {self.idea}\",\n            instruct_content=self.idea,\n            role=\"Human\",\n            sent_from=\"User\",\n            cause_by=\"UserInput\"\n        )\n        self.env.publish_message(initial_msg)\n\n        for round_num in range(n_round):\n            _log_safe(self.tracer, \"ROUND_START\", \"Team\", f\"Round {round_num + 1}/{n_round}\")\n            # iterate roles deterministically\n            for role in list(self.env.roles):\n                try:\n                    response = None\n                    trigger_msg: Optional[Message] = None\n                    if round_num == 0 and getattr(role, \"profile\", \"\") == \"SimpleCoder\":\n                        trigger_msg = initial_msg\n                        response = await role.act(initial_msg)\n                    else:\n                        msgs = self.env.get_messages_for_role(role)\n                        if not msgs:\n                            continue\n                        trigger_msg = msgs[-1]\n                        response = await role.act(trigger_msg)\n                except Exception as e:\n                    _log_safe(self.tracer, \"ROLE_EXCEPTION\", getattr(role, \"name\", \"Unknown\"), _safe_str(e))\n                    response = None\n                    trigger_msg = None\n\n                if trigger_msg is not None:\n                    self.env.mark_processed(role, trigger_msg)\n\n                if response:\n                    self.env.publish_message(response)\n            _log_safe(self.tracer, \"ROUND_END\", \"Team\", f\"Round {round_num + 1} completed\")\n\n        _log_safe(self.tracer, \"TEAM_END\", \"Team\", \"Project completed\")\n        summary = f\"Project '{self.idea}' completed after {n_round} rounds with {len(self.env.history)} messages exchanged.\"\n        _log_safe(self.tracer, \"SUMMARY\", \"Team\", summary)\n\n# EVOLVE-BLOCK-END\n\n# Fixed main execution function (not evolved)\nasync def run_multi_agent_task(idea: str, n_rounds: int = 3, log_file: str = None):\n    \"\"\"Run a multi-agent task and return the trace\"\"\"\n    # Create context\n    context = Context()\n    context.config.llm.api_key = os.getenv(\"OPENAI_API_KEY\", \"fake-key\")\n    \n    # Create team\n    team = Team(context=context, log_file=log_file)\n    team.hire([\n        SimpleCoder(context=context),\n        SimpleTester(context=context),\n        SimpleReviewer(context=context)\n    ])\n    \n    team.invest(investment=3.0)\n    team.run_project(idea)\n    await team.run(n_round=n_rounds)\n    \n    # Return the trace content\n    if log_file and os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            return f.read()\n    return \"\"", "language": "python", "parent_id": "02cc96c3-2510-4220-8cec-c7749acce975", "generation": 4, "timestamp": 1754649464.1087816, "iteration_found": 0, "metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 0.5, "overall_score": 0.25, "combined_score": 0.1, "avg_failures_per_task": 12.0}, "island": 0, "migrant": true}, "artifacts_json": null, "artifact_dir": null}