{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_log_trace(log_content):\n",
    "    \"\"\"Clean up raw terminal log traces by removing shell artifacts and keeping only relevant content.\n",
    "    \n",
    "    This function processes raw terminal logs to extract only the meaningful content like:\n",
    "    - Generated code blocks (between ```python and ``` tags)\n",
    "    - MetaGPT system messages about role actions and progress\n",
    "    \n",
    "    Args:\n",
    "        log_content (str): Raw terminal log content as string\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned log content with only relevant information\n",
    "        \n",
    "    Example:\n",
    "        raw_log = '''\n",
    "        [?2004h(base) ]0;mert@bliss1: ~$ python3 examples/build...\n",
    "        [32m2025-01-17 11:39:37.311[0m | [1mINFO[0m | Alice(SimpleCoder): writing code...\n",
    "        ```python\n",
    "        def my_function():\n",
    "            pass\n",
    "        ```\n",
    "        '''\n",
    "        cleaned = preprocess_log_trace(raw_log)\n",
    "        # Returns only the INFO message and code block\n",
    "    \"\"\"\n",
    "    lines = log_content.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    in_code_block = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Skip terminal control sequences and prompts\n",
    "        if any(x in line for x in ['[?2004', ']0;', '[01;', '[00m', '(base)', '(multiagent)']):\n",
    "            continue\n",
    "            \n",
    "        # Skip command echo lines\n",
    "        if line.strip().startswith('$') or 'mert@bliss1' in line:\n",
    "            continue\n",
    "            \n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "            \n",
    "        # Keep code blocks\n",
    "        if line.startswith('```'):\n",
    "            in_code_block = not in_code_block\n",
    "            cleaned_lines.append(line)\n",
    "            continue\n",
    "            \n",
    "        # Keep code content\n",
    "        if in_code_block:\n",
    "            cleaned_lines.append(line)\n",
    "            continue\n",
    "            \n",
    "        # Keep MetaGPT system messages\n",
    "        if 'INFO' in line and any(role in line for role in ['Alice', 'Bob', 'Charlie']):\n",
    "            # Remove ANSI color codes\n",
    "            clean_line = re.sub(r'\\x1b\\[[0-9;]*[a-zA-Z]', '', line)\n",
    "            cleaned_lines.append(clean_line)\n",
    "            \n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def parse_log_file(log_path):\n",
    "    \"\"\"Parse and clean a log file to extract only relevant content.\n",
    "    \n",
    "    This function reads a log file and processes it to remove shell artifacts\n",
    "    while preserving important content like code blocks and system messages.\n",
    "    \n",
    "    Args:\n",
    "        log_path (str): Path to the log file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains cleaned log content and timestamp\n",
    "            {\n",
    "                'timestamp': str,  # Extracted from first INFO message\n",
    "                'content': str     # Cleaned log content\n",
    "            }\n",
    "            \n",
    "    Example:\n",
    "        log_data = parse_log_file('logs/1.txt')\n",
    "        print(log_data['content'])  # Shows only relevant content\n",
    "    \"\"\"\n",
    "    with open(log_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Clean up the raw trace\n",
    "    cleaned_content = preprocess_log_trace(content)\n",
    "    \n",
    "    # Extract timestamp from first INFO line\n",
    "    timestamp_match = re.search(r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})', cleaned_content)\n",
    "    timestamp = timestamp_match.group(1) if timestamp_match else None\n",
    "    \n",
    "    # Extract costs using regex\n",
    "    cost_matches = re.findall(r'Total running cost: \\$(\\d+\\.\\d+)', content)\n",
    "    final_cost = float(cost_matches[-1]) if cost_matches else None\n",
    "\n",
    "    return {\n",
    "        'timestamp': timestamp,\n",
    "        'cost': final_cost,\n",
    "        'content': cleaned_content\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 31 individual run files in runs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_idea_from_command(command):\n",
    "    \"\"\"Extract the idea from a command string.\"\"\"\n",
    "    match = re.search(r'--idea \"([^\"]+)\"', command)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def build_log_database():\n",
    "    \"\"\"Build a database of all runs with their associated commands and logs.\"\"\"\n",
    "    # Read commands file\n",
    "    with open('commands.txt', 'r') as f:\n",
    "        commands = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    database = []\n",
    "    \n",
    "    # Create runs directory if it doesn't exist\n",
    "    runs_dir = Path('runs')\n",
    "    runs_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Process each command and its corresponding log\n",
    "    for i, command in enumerate(commands, 1):\n",
    "        log_path = f'logs/{i}.txt'\n",
    "        if not os.path.exists(log_path):\n",
    "            continue\n",
    "            \n",
    "        idea = extract_idea_from_command(command)\n",
    "        log_data = parse_log_file(log_path)\n",
    "        \n",
    "        # Generate keywords from the idea\n",
    "        keywords = [word.lower() for word in idea.split() if len(word) > 3]\n",
    "        \n",
    "        entry = {\n",
    "            'run_id': i,\n",
    "            'prompt': idea,\n",
    "            'content': log_data['content'],\n",
    "            'timestamp': log_data['timestamp'],\n",
    "            'cost': log_data['cost'],\n",
    "            'log_file': log_path\n",
    "        }\n",
    "        \n",
    "        # Save individual run data to separate JSON file\n",
    "        run_file = runs_dir / f'run_{i}_newer.json'\n",
    "        with open(run_file, 'w') as f:\n",
    "            json.dump(entry, f, indent=2)\n",
    "            \n",
    "        database.append(entry)\n",
    "    \n",
    "    print(f\"Created {len(database)} individual run files in {runs_dir}\")\n",
    "    return database\n",
    "\n",
    "database = build_log_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(database):\n",
    "    \"\"\"\n",
    "    Generate visualizations from the log database.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Convert database to DataFrame\n",
    "    df = pd.DataFrame(database)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Set style\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Cost over time\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    sns.scatterplot(data=df, x='timestamp', y='cost', ax=ax1)\n",
    "    ax1.set_title('Cost Over Time')\n",
    "    ax1.set_xlabel('Timestamp')\n",
    "    ax1.set_ylabel('Cost')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Cost distribution\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    sns.histplot(data=df, x='cost', bins=20, ax=ax2)\n",
    "    ax2.set_title('Cost Distribution')\n",
    "    ax2.set_xlabel('Cost')\n",
    "    ax2.set_ylabel('Count')\n",
    "    \n",
    "    # 3. Prompt length vs Cost\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    df['prompt_length'] = df['prompt'].str.len()\n",
    "    sns.scatterplot(data=df, x='prompt_length', y='cost', ax=ax3)\n",
    "    ax3.set_title('Prompt Length vs Cost')\n",
    "    ax3.set_xlabel('Prompt Length (characters)')\n",
    "    ax3.set_ylabel('Cost')\n",
    "    \n",
    "    # 4. Response length vs Cost\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    df['content_length'] = df['content'].str.len()\n",
    "    sns.scatterplot(data=df, x='content_length', y='cost', ax=ax4)\n",
    "    ax4.set_title('Response Length vs Cost')\n",
    "    ax4.set_xlabel('Response Length (characters)')\n",
    "    ax4.set_ylabel('Cost')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional time series analysis\n",
    "    daily_costs = df.set_index('timestamp').resample('D')['cost'].sum()\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    daily_costs.plot(kind='bar')\n",
    "    plt.title('Daily Total Costs')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Total Cost')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate visualizations from the database\n",
    "analysis_df = generate_visualizations(database)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
